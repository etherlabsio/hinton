"{\"body\": {\"segments\": [{\"id\": \"65f4fbfad46b4e7e93f779b1b61285f1\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:49:09Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:49:10.227186235Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:47:09Z\", \"updatedAt\": \"2019-10-31T03:50:12.021749429Z\", \"confidence\": 0.8303273440000002, \"recordingId\": \"bf19abe4dbba4f9ab1118f6bf31804ef\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"We do. This is by firstly We join group voice and video calls and have our own webrtc implementation, which is an SF you that is built as part of The Ether meet showcase app, but we can also connect to pretty much any third-party group video audio systems using standard protocols like the body csepp or just pstn dial. We integrate on messaging systems like slack teams time Etc. We are web Hooks and apis as a nap and is a bot. And what we do is use these views and for a couple of different things one one is, you know, our ether meet is for example built on top of slack and we use slack not only as a lot indication provider the ability to authenticate a user They're in the context of an Enterprise. But also we understand permission to access Who belongs to which team however, the team's collaborating and so on and so forth and by this, we also understand that when I am part of a climate change channel, for example, I may be talking about Amazon and that may have a very different connotation or context. To me being part of an infrastructure Channel where an Amazon they mean AWS infrastructure services and whereas when I'm part of a retail channel that could mean e-commerce Etc. So this type of a context is really derived from my association with a particular team and that's the information that we glean from say something like a slack Channel. Which anchors The Ether slur Learning models and we'll talk a little bit more. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"bb2a2864eb254062a32b27eeb9e9c97b\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:44:34Z\", \"duration\": 8, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:44:34.969466947Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:44:26Z\", \"updatedAt\": \"2019-10-31T03:44:56.021508689Z\", \"confidence\": 0.83832663, \"recordingId\": \"77f910990edf4d3b8b1458eda0de85cd\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"Ether is essentially the problem. We're trying to solve is let's see. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"6c6799abe47a43f38de83827a5a0c2a1\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:44:55Z\", \"duration\": 10, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:44:55.381467047Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:44:45Z\", \"updatedAt\": \"2019-10-31T03:45:16.3888711Z\", \"confidence\": 0.76966196, \"recordingId\": \"61759def1f9a41c88cd01cd2b7fd0561\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"Go Peter, the problem we're trying to solve is to facilitate. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"60ce5e04347c4acab04e631fe3c2e57d\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:47:08Z\", \"duration\": 13, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:47:08.870478355Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:46:55Z\", \"updatedAt\": \"2019-10-31T03:47:30.193021906Z\", \"confidence\": 0.8539128, \"recordingId\": \"ef2a5ee7f92c4af5b9e98f773b173ee0\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"- extract important call parts and also Auto summarize them and then later on expose some very interesting applications like the smart search and smart alerts. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"59ba61d3beb04328ad7ea0a1036da197\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:44:04Z\", \"duration\": 16, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:44:04.345439559Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:43:48Z\", \"updatedAt\": \"2019-10-31T03:44:25.363203209Z\", \"confidence\": 0.84650904, \"recordingId\": \"fbdb23920ab54505b4865139b75efd17\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"My name is Krishna Sai and the co-founder and CTO of ether want to take this opportunity to walk a little bit walk through a little bit about The Thirst platform today. We share the presentation. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"84bbfcb8bb0643bda41d7a063f127fc7\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:53:09Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:53:10.856498323Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:51:09Z\", \"updatedAt\": \"2019-10-31T03:54:12.655723857Z\", \"confidence\": 0.813087052, \"recordingId\": \"64aeb68abd40429f9d37cd4bac71918f\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"They production outage incident review and all of these can either be clicked and watched because they've been captured and made available asynchronously or may be integrated as part of a third party and a price to like Jada or Asana or just Google Calendar for example, so these types of meeting Primitives are conversational Primitives can be extracted automatically and made available. The second is once you have all of those available and indexed and made searchable. You can do smart semantic search. For example, I could go and say what it Colin say about the bank bail in South Africa three months ago and eater has the ability to provide a ranked list of results based on the conversations that you've had. So this allows you to quickly go back and get to exactly the portion of the call report. Love the part of the conversation that is relevant for a subject that you're interested in. The third aspect could be that there is an ongoing call. Let's say me and my colleague or discussing and I need to ping. You know, I need to there's a discussion that's happening and Colin whose lives in Austin for example, monotonous and normally plan on joining this call, but when he kind of understands that Hey listen sign, Discussing this particular issue with because platform architect and he may decide that something that is interested in so he can quickly jump in and join the call or adjust 3 meter watch it in offline mode and catch up on the discussion and then jump into the call. So this is kind of the blurring between real-time and non real-time kind of a TiVo concept if you will of \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"e22873ef2b3944fab6323a03e82ec768\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:55:12Z\", \"duration\": 3, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:55:12.878874969Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:55:09Z\", \"updatedAt\": \"2019-10-31T03:55:33.837905753Z\", \"confidence\": 0.8383257, \"recordingId\": \"cbe6f56267404c0592332a25673a3f7e\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"directly for example \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"a319ec12390445599a2290bc271e3138\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:59:28Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:59:29.041365382Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:57:28Z\", \"updatedAt\": \"2019-10-31T04:00:30.889675461Z\", \"confidence\": 0.8522536975, \"recordingId\": \"cdd93ba4b767417c8fb4ddea2459459c\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"We all of this happens is through the integration with our messaging system the messaging system essentially, for example, when we happen in our kind of shock is up, I'll eat the meat which is an app that is installed on top of slack the call get started out of a slack Channel or team Channel at a team space for example, and then the audio video and content are are continually captured and made available. Able to our persistence engine where our media analytics kicks and we do speech-to-text once a text is available. We of course do an LP and understanding we can also do apply computer vision to any slides that are shared during a meeting right and we can also do other intelligence smart applications like, you know being able to translate conversations, but the idea is that once this is captured This is analyzed. It is made available in a persistent, you know platform which is essentially in the back end and then a price Knowledge Graph and what the team persistent spaces whether it's slack channels or any other form of contextual persistence pays allow us to do is to in addition to giving us conditional access like I talked about before And idea of membership Who belongs to watch who has access to what what media and so on we met you they are low the conversations are low or learning engines to learn over time. So we know that what's being recent for example, get to get more weight age as opposed to something that was discussed a year ago, which may not be more anymore any longer relevant. So we kind of understand our engine understands what's relevant for a team and \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"04ff4813a8ad45f4a48b4aea72bcc8ce\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:46:55Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:46:56.233435828Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:44:55Z\", \"updatedAt\": \"2019-10-31T03:47:58.176944932Z\", \"confidence\": 0.8886340839999999, \"recordingId\": \"5a6b7564622b41c59934d7251b2a7c16\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"The communication and collaboration between teams that are distributed not only across distance, but also time. and part of this problem is that when teams are distributed across distance, they often collaborate using video and voice conferencing and through synchronous messaging system is like slack whereas less edges like messages that on Slack are persistent and available a lot of the conversations that happen over voice and video calls tend to get lost because they are ephemeral in even if you are recording Or even transcribing the entire call. Nobody really watches the entire recording or reads the entire transcript. And so when this happens what happens is teams often feel disconnected and this ends up happening, especially in large Enterprises where there are teams are distributed in and collaborating across multiple projects. This is a very common thing that we tend to see So when these set out to build ether we built our first showcase app called ether meet which is an AI enabled video calling service for teams. And essentially what we try to do here is to blur the line between synchronous and asynchronous collaboration between persistent and ephemeral modes of communication and so on. Three we do. This is we built a video collaboration service that connects to group video conferencing and audio conferencing systems and built on top of asynchronous messaging systems, like slack and while walk you through why this is a case and we do we apply media analytics and machine learning to continually analyze the video and audio media strange. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"4ce94233e2424073bf9aaffec61de42e\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:57:14Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:57:15.565806093Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:55:14Z\", \"updatedAt\": \"2019-10-31T03:58:17.292935104Z\", \"confidence\": 0.834829925, \"recordingId\": \"2140262e529a4700bb4f3710906aa8f4\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"So one key aspect of this is our real time persistence and analytics engine which we call as DeLorean. We're we're continually taking the media as and when it happens the audio/video its content and they're continually getting time slice and as a Time slice that not only allow us to Route these and make them available. But then we're also able to tag these call Parts intelligently because we have I'm still essentially every part of the call and also Associated that with the context whether it's a conversation that's happening or a key phrase that we've extracted and that makes us that makes it easy for us to search intelligent Lee by key phrase and get for example or by topic or by applying some semantic search and being able to get to very specific part of a conversation that may have happened in the Perpetuate e of conversations that have happened in the context of your team. The more interesting portion of this is that you can get alerted when something of interest to you as being discussed and this is again a very unique feature of ether where our platforms ability to capture call parts and time stamp them gives us the ability to create understand who is interested in why what and as our engine starts to learn and all of this gets mapped into the knowledge graph. We're able to quickly determine that hey, you know, John's working on a down the account manager for let's say a particular International Bank and whenever discussion topic related that by happens within the company, we know that John is probably \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"c84e305b75ca4e8d9322e44d23b2d70b\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T04:09:57Z\", \"duration\": 42, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T04:09:57.559474738Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T04:09:15Z\", \"updatedAt\": \"2019-10-31T04:10:18.746607035Z\", \"confidence\": 0.7592051799999999, \"recordingId\": \"d89d6b5d7df74d8394f9d3f111be98a3\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"Tensorflow and right Arch, a lot of our front end is built on react and react native. There are some portions that we use for the iOS native interfaces for especially when it comes to web RTC in a few integration of the media level integration. And of course all the other things that you'd expect from a modern Cloud native stack including observability logging infrastructure as code and see I see the pipeline's using GitHub at actions could push for react and react native. So all of these are kind of what you know is goes into building eaters. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"8e200031aa86415cb7c913297eb8f232\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T04:09:15Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T04:09:18.893687077Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T04:07:15Z\", \"updatedAt\": \"2019-10-31T04:10:20.693616767Z\", \"confidence\": 0.8251301225000001, \"recordingId\": \"69f41b7607304e71877d90db87b400cb\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"You're very high level idea of our Tech stack. All our hosting is currently on AWS mean we leverage pretty much any and every aw Services possible that gives us elasticity. He gives us scale. It gives us a lot of core platform capabilities that we need like being able to process a lot of our function in using serverless functions like lambdas, right? So essentially the idea there is that we've built either to be a cloud native platform from the ground up. All our code is written all our infrastructure is implemented as code using terraform. So for us it's a users the ability to easily spin up an entire deployment of ether literally the click of a button and make a new service available for example in a new VPC, right? So do we just built it to be extremely flexible and model? Tense, a lot of our core platforms and services are built using golang and we use postgres as our kind of primary database. We use even streaming mechanism. We use something called that rich is a just from the cloud native Foundation we and use you know, some clean architecture and domain-driven design in terms of how we've talked. You on built or Services Media Services, of course, we can integrate with webrtc services like Amazon jitsi. We can connect via serp use ffmpeg internally, but we can also use third-party media streaming services and integrate with them. We use a chalice for our as are streaming protocol Rai pipeline, of course built in built using standard machine learning tools. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"a1d05b813bd4435faf087b5b01fe9974\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T04:10:08Z\", \"duration\": 11, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T04:10:08.343550325Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T04:09:57Z\", \"updatedAt\": \"2019-10-31T04:10:29.34460263Z\", \"confidence\": 0.8522831, \"recordingId\": \"ae3a3fa3c8eb42e9b71b6bb3a0ef785c\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"So that's pretty much it from in terms of an overview for the platform will dive into the I portions in another call. Thank you. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"967e912c4f8a41ef90926b5a821afbe9\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:51:09Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:51:10.321876618Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:49:09Z\", \"updatedAt\": \"2019-10-31T03:52:12.0036656Z\", \"confidence\": 0.8266216433333332, \"recordingId\": \"498cc3b8161c4d328894a533b0fa1bfe\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"About this as we go on the third aspect, is that our media analytics engine which is which we call as DeLorean which continually captures and analyzes unstructured media and translates them to structure label data and make some usable and ether mines, which is our learning engines as we call them. We will talk a little bit more about them, but they continually learn from the Aish ins that happen within these Enterprises within these teams in the within within the Enterprises in the context of themes and we map all of these into graph relationships and they provide context recency and frequency to determine say what's important and what's not so on and so forth. And of course in the back are engine builds a contextual knowledge graph of users data content and attractions, basically, large Enterprise graph of who said what when and in what context so this is kind of a very high level view of how ether actually connects and works in an Enterprise collaboration context. So the idea is once you have eat the meat installed or ether as a platform enabled as part of your platform this kind of unleashes a few capabilities, for example, one of them could be that you may be missing a lot. You can't possibly be, you know, part of all the calls that are happening within the Enterprise of the ones that you need to know. So you could quickly catch up on what you need to know. So for example, that could be very simple things like hey, you know You need to follow up on a qbr that someone said and that called Park was extracted made available Boomerang to you. That could be a reminder for example in a calendar that shows up or \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"61c866b9784c4e36b86d4b97171441be\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T04:06:24Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T04:06:25.739827428Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T04:04:24Z\", \"updatedAt\": \"2019-10-31T04:07:27.557670635Z\", \"confidence\": 0.874618575, \"recordingId\": \"2ec4fed1612442a1b97ee591c35767c4\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"So at a high level if you look at eaters architecture rebuilt it to be very very modular and this is by Design and he so there are if you look at the core at the core of the either platform that our media Services which we talked about DeLorean real-time persistence media capture persistence and analytics engine, of course, all the media that has captured is stored in it. CDN in hls so that they can be streamed live. We have a whole lot of EI Services which includes foundational services like to speech to text and then the new vision but then we have this whole idea of Channel minds and how they serve as a basis from which features such as captioning meeting a call highlights search and alert and extracting key phases are using the knowledge graph. Extract meaningful insights all of those become possible. And of course, we have our core either Services where we have authentication engine the idea of meetings and ability to create markers and you know take the essentially a Time series data of conversations become, you know available as a service Etc now there are two key to order. Three key interfaces one as a group video adapter, which we talked about earlier that allows us to connect to a bunch of third-party voice and video conferencing Services. Second is a messaging adapter which allows us to connect to messaging in a synchronous systems, like slack beans Etc. But can also be any other type of you know, platformer tool that provides us understanding of teams gives us a think occasionally. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"f9dd49d1223f40698a384c68c6931646\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T04:07:14Z\", \"duration\": 50, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T04:07:14.707445529Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T04:06:24Z\", \"updatedAt\": \"2019-10-31T04:07:36.147969177Z\", \"confidence\": 0.820991075, \"recordingId\": \"d00c6505f4084730a9202093c2ca2bd0\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"Just the ability to to do permission access but also gives you the ability to understand it to give context for a team conversation trainer learning engines. And then we also have Enterprise adapters. So a lot of these meeting parameters that we extract for example action items can go feed directly into a third party to like trial or jira for example, and we Have all of these capabilities available not only on the web and the desktop app, but also the mobile app and all of these are of course also available as a pi so can be easily integrated into a third-party, you know, see past service of examples. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"fa2291b661f04156abaa7d962bacba70\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:55:09Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:55:10.590945292Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:53:09Z\", \"updatedAt\": \"2019-10-31T03:56:12.790228264Z\", \"confidence\": 0.852947295, \"recordingId\": \"fbca8966a6894165ab8276c850956769\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"Able to time shift conversations even when not only in the post call but also during the call as well so I can for example, there is a discussion that I'm having and you know, my teammate the color does not part of that call, but this is something that we want him to look at right way. I can say hey Colin, you know, look up this issue I can. Eight a marker with the mediator can create a marker marker that are an action for Colin and he'll get pinged immediately and you can get an alert notification on his mobile phone. He can click on Watch and watch and get caught up on the conversation and jump into the call if required. So those types of use cases get Unleashed because of this ability to capture call Parts make them routable and also make them watchable in real time. and of course, the last part is the ability to collaborate with teammates not only through specific markers or call parts that are created and this can be things like new topics that are being discussed action items that are being assigned or decisions that are being made but also just call summaries that are available for call happened because ethers ability to contextually understand what's important and what's not we're able to summarize a call very Effectively boomerang a boomerang that back into the slack Channel or make that available through email or some other persistent store and you know and make them available for the team all of that of course made available through permission access, which we understand from the team mapping that we get from. Let's say a platform like slack but could also get it from some other, you know enterprise system. It could simply be a \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"acf22cc02b714ebab37c14a4c90de24e\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T03:57:26Z\", \"duration\": 12, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T03:57:26.999925963Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:57:14Z\", \"updatedAt\": \"2019-10-31T03:57:47.928434751Z\", \"confidence\": 0.7651808, \"recordingId\": \"30e93af109864f2cade7733a0f74f5c7\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"To be interested in knowing about this and so he can either look good or you can just show up as a, you know, a recommended Watcher for a call summary. Hmm. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"b273b7162f5e401c9aec58d6c1984e33\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T04:02:37Z\", \"duration\": 69, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T04:02:37.746254544Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T04:01:28Z\", \"updatedAt\": \"2019-10-31T04:03:19.075285011Z\", \"confidence\": 0.7872180333333333, \"recordingId\": \"69edbe4cd9244ec296071e9dabee35e0\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"For example, we could you know, when it has invited which could prompt the did one of the team members to say what type of you know Channel this is about and if it's about software for example, softer mind will get attached to it. And that's a cells is as I think of it like a static template from which the learning can start but then as a conversations happen within the channel there goes our messages are audio video conversations, and we're able to capture sure and persist and learn from them the idea that these conversations continually train our models and then that gives us the dynamic portion of that and then as that happens the global template that got attached to the channel now starts to refine itself and becomes something very specific to that channel and the channel gets a very unique mind of its own. So this is a broad idea behind Channel. Lines and we'll talk more about it about how we build it. Now we train it and so on in REI discussions. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"16a904ffdd134cc3850843142aa21a29\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T04:04:22Z\", \"duration\": 104, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T04:04:23.654410693Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T04:02:38Z\", \"updatedAt\": \"2019-10-31T04:05:25.270019652Z\", \"confidence\": 0.8230081975, \"recordingId\": \"e8c23af4f4ee4a3593090e13a3908d55\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"In somebody from a functionality perspective ether provides two or three very broad type of capabilities that become valuable to our partners and our customers one is that we enable smart audio and video calls essentially breaking down this barrier of time that that comes in the way of effective team collaboration. The second is You know a lot of these persistent intelligent capabilities that we have an ether become very useful in a lot of vertical coil packs. For example, you could have a recruitment application where candidates can go in and talk and you know introduce themselves answer a bunch of questions and on specific topics and neither can the background analyze those topics and create like a screening application so you don't have to They're screening a candidate. A lot of that. I will let you know will is available out of the gate and you don't need to go back and look at and so on and so forth. It makes a whole screen process very efficient. For example, you can have applications and legal compliance purposes. You can have applications that are of course available in education surveillance and so on. So a lot of these types of capabilities become possible because of this the combination of being able to capture media and being able to analyze them not only in real time, but post real time and apply context to it to make that learning very very relevant. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}, {\"id\": \"01e55b87fc574a178b38d04f1489b7ce\", \"status\": \"completed\", \"deleted\": false, \"endTime\": \"2019-10-31T04:01:28Z\", \"duration\": 120, \"spokenBy\": \"8fff81b5b2f14aa5ad67405f3e8127f3\", \"createdAt\": \"2019-10-31T04:01:29.068637004Z\", \"deletedAt\": null, \"startTime\": \"2019-10-31T03:59:28Z\", \"updatedAt\": \"2019-10-31T04:02:30.999879302Z\", \"confidence\": 0.856388165, \"recordingId\": \"4760d0db30c94e24a63bc7e81c495efe\", \"transcriber\": \"google_speech_api\", \"languageCode\": \"en-IN\", \"originalText\": \"Arkansas so this is the idea of idea of what the value that the messaging systems provide. So the idea that you know this type of a deep, you know team or organizational learning can happen at a variety of levels. It can happen at the individual level because I may be interested in certain topics and I are I watch when a particular topic is just because her I'm in a meeting. Is that are talking about a certain topics? I can understand what's going on at the team level and of course we can understand what's going on at the organizational the Enterprise lab, right? So there's a hierarchy of learning that it gets Unleashed because of the way we've architected and built this engine. So the way this works is the way our learning engine works which we call as ether mines a channel Minds is that There we are continually training Global Minds on a variety of domains. For example, we have a lot of Minds that are going a little library of Minds that are trained on they do know broad topics such as software engineering HR Finance marketing Etc, but also on specific topics. So for example, it could be, you know climate change for example, or it could be a you know, electric electric vehicles will be e-commerce. It could be supply chain, you know, whatever. We have a variety of domains that are trained and not is that are available and then these static models are trained continuously in kept up-to-date and we have a set of global templates. And then when these channels are available when when ether is attached to a particular theme channel, for example a slack Channel we will attach a very specific domain to that particular. \", \"transcriptId\": \"8881ad12-7efd-427b-9301-f428b520bab0\"}], \"mindId\": \"01DAAQY88QZB19JQZ5PRJFR76Y\", \"contextId\": \"01DBB3SN874B4V18DCP4ATMRXA\", \"instanceId\": \"abc\"}}"