{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T10:00:32.508599Z",
     "start_time": "2019-10-14T10:00:32.471648Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T10:00:32.908196Z",
     "start_time": "2019-10-14T10:00:32.654982Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing topic level pims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read json Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T12:08:19.066028Z",
     "start_time": "2019-10-16T12:08:15.539283Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "import json\n",
    "\n",
    "with open('topic_testing/sync_eng_12_09.txt','rb') as f:\n",
    "    request = json.load(f)\n",
    "    if isinstance(request, str):\n",
    "        request = json.loads(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "Segment:  it's \n",
      "\n",
      "\n",
      "\n",
      "Segment:  And just to make sure that we are able to see that your problem is not there. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  testing testing \n",
      "\n",
      "\n",
      "\n",
      "Segment:  You can see Mariah. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Justin \n",
      "\n",
      "\n",
      "\n",
      "Segment:  schedule \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  having connective tissue for you All right. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, honey. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Call we were not able to share screen at used to say connective tissues. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  It started maybe possibly going to do an update on the new website. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So like from UI perspective on home page, I've made the changes which color might ask for and now I'm working on the dashboard by from where user would be pretty cool circuit like upgrade their plants and I'm using play in stripe. I'm using the test mode like a medical test mode for Prestige Elite crew and plan in like this product in it. And I'll be like as we discussed on Friday, maybe like the plan but the same it would be the our sports or 2500 as like that. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  The for the pop-up in desktop you had posted in friend Channel. I'll look into it because it just like it is an alert for desktop app you can do about it. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  I'll see I'll and to that. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  You do the drop-down, I guess the swinging took a vacation mode. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Let's talk about your search for a second. What platform dependencies away this? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So like for when user logs in after day, like I need an end point I think is already there. So I'll ask kitchen to shape file requests for it. So basically I need like how much they have used till now for the current month and then like once when you the like when they start a new call and if they using this over then I'll need back end to pain. Lake sent a notification event basically to website so that I can send out mail to that particular workspace customer that your user is over and that would like you can upgrade to like start new calls. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  um \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So Silent few questions, maybe we can sit together and write down specifically about this you said change one thing was because for the current plans we don't vote if I have and Because he is take them to free mode. Okay, do you want help on the usage of \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Pay that fee. For example, you will today you'll get an email that says something like this. You just give me a second. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  God bless you. He's chatting. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  You can even see the screen share. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  You don't see the my friendship. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah, it says having connectivity like you want I have a screenshot in this class. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  family \n",
      "\n",
      "\n",
      "\n",
      "Segment:  The only table feature me that account has expired. Whoa looks like a credit card as you climb or something like that. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So, what was your question? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  right now because of kotas the way we handle plans right now is If you want paid and you you get three. The end of the month, we don't tell them like sorry. Let me just think come back. So if you aren't free there's nothing to do if you go to pay which is basic plan. We tried to renew every month in won't has no problem saying that you're in free tier subscription is over. But let's see if you're interesting what happens is after 10 hours of live calls and Tenors are like all we start to reject saying that he looks like a user uses code has exceeded at this time. We don't send an email, right? When we send usage quotas experience. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  That doesn't change right now, right but we can always do that as an enhancement. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  But yeah. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  also that I \n",
      "\n",
      "\n",
      "\n",
      "Segment:  connectivity \n",
      "\n",
      "\n",
      "\n",
      "Segment:  continue no, I \n",
      "\n",
      "\n",
      "\n",
      "Segment:  You are saving also part that I lost. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  And if I think we're able to hear you. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  More news coming really ate like two seconds your side CoQ10 in the audience. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, I did anyone. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So far now because you don't send an email immediately even right now do we have to make the changes all the I'm not saying we need him? That's not the problem. The problem is I want to make sure that the usage related monitoring Etc. The Rollo fusions partial like we talked about is there's no need for a top of plan roll. If you exceed the $25 you get rejected after that and if you want to upgrade you upgrade to the hundred dollar plan. That's it. Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Excuse and we don't need to do a lot of yeah, let's addition the platform side. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  I was saying that there is no need for top of plan and all that right? It's very very simple. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah, that's it. That is for later on like one sweet. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Let's not even like consider all that keep it really simple. All we're doing is exactly the same. The only thing that I want to make sure is that Before we had a free plan, of course, there's always free and limited and then there is a basic or paid plan right again that was based on number of users. And then we had an Enterprise plan. So Enterprise line, we don't need to worry about because we don't have any users, but for the page planning now, there are two different variations of that based on one parameter called 25 and hundred. Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do. How does that work based on Usage Now the station need to go and change that thing to say every day. There is going to be an indication of how much has been used how much that has much of usage has been consumed. How much as me so my point being like all the work related to getting this to work? Yeah. Can we just list them together? You know, who's week's work on what? Yeah, okay. So part for any other things that need to be clarified on the servants clear. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Why do you want to go next Sunday did c-webb? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Like today, I'll be working on the speaker list on my neurologic change. Like I need to remove the feed from the participant list if he speaking like the active speaker else the early the vocalist of it's also should be the speaker is the small change I am talking. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Is Christopher for The Ether meet thing? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  That's all right. Maybe I didn't. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  When we discuss last week see right now, let's say I'm doing cast. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Diddly I see ether meet as a big screen in my big screen. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  That again. I'll pick pick it. I can pick it up that and also working on the like the Papas which we show like which we see moderators or disconnected ether meet and all to hide that pop ups as well. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, got it. Oh, that's all right. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Totally cool it on and push this these features to production and work one. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Get it current functionality get it all the way to production. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  We can guess that there is no other regressions, you know. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Doesn't Define it like there'll always be the small small things that we can improve the site. So don't wait on that like whatever is currently pushed if it's working functionally Fisher is working recording is working right pause resume is working, you know, speaker changes working all of that well, Then we should push it to production. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Like the major all those are working on the speaker's logic, which I had implemented was bit wrong. Like I'll modified and address the comments Josh Wise raised today and then push it up. I'll try to push it to production. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  I know what you do is once you've done all the children's push it this aging. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Franklin you run through a full regression test for all of these things. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yes, got it. Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  The basic functionality processive like all the things on web just run through and then if they're all works in will push it to production. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  The call is Moshi, Moshi. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Come to the a items later now. I guess you're not a dream started looking at cast right that Romanian all that yet obvious. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  No. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  You can do is maybe after you're done with the Gypsy. Maybe you can pick this up. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  the last \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Another cost being able to parse skip the pass portions and Playback, right? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Any any update on your side on their resume or else? I think your mom's you're trying to get that going right on last week? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yes, I so the first part where we omit the event is done. So we myself and um, she didn't get a chance on Friday to discuss on the table structure for Zoom even service. So today we'll discuss this on Friday. We did a project deploy and there were few minor issues. Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call. We used to ignore from back end so that I have fixed and it's already in production now, so once funds from she is--and will discuss on the zoom service site. Sorry. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. So between I guess we need to figure out Karthik like who can support partial on the usage related changes, right? I can do. Okay. All right or compressor particle help you with that with the usage deleterious the platform side. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Let's talk about like iOS so the bunch of things happening with iOS. I finish share deep. You guys want to go links? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So I have pushed the changes of me because most production and looking in the that thumbnail thing. So if we enter you are really not so along with the Tamil also showing the topic of the video now, but \n",
      "\n",
      "\n",
      "\n",
      "Segment:  The higher priority items in iOS for me are the highlights in the timeline. Don't show up now. All right. So when we generate the summary the highlights that we generate don't show up in the timeline. So we need to fix that. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Before they used to show up as FYI a marker. So we need to kind of align with what is going on on the right. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So that is 1 and the second which is probably the important thing. Is this annoying loading of the app that keeps happening. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  That happens only for beta product or it was happening for it was not happening for me. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  But even even otherwise like how do we speed that up? Right? That's the time is very important discussion to have because right now what happens is every time you start the app, you have to wait for you know, seven eight seconds and sometimes even longer than that depending on the network speed before you can start using the app. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Maybe they're only two things that are happening. Right one is slack authentication. Second is getting this channel list and showing both of you don't need because if you have a valid token you don't need and you already have a channel list that you pulled on the last side. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  The question is why did can we optimize act so that the app loading is very fast? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yes, so the next task on my list rifles handling the navigation flow into the IOS app. So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera. Mic all these are happening whenever we open the up. So so we'll remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens. So create the navigation like will correct the navigation flow. So that limbs over. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, I just spent the time length should be fairly simple. Right that was just like logic before we check for suggested FYI. Now we need to check for suggested topics. And then instead of showing FYI to show highlight, right? That's it. Yeah the and then you you know, I think it'll be good for you to focus on the the navigation flow to speak from here. Come back. Preview thing later like a background task, you know. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  All right D+ yet. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts. We'll call it used to come out even though like it was closed the 6 goes to there's one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow. Time doesn't mean joining like we'll just shows us why screen like it doesn't it starts connecting but it doesn't end of the connecting screen. It doesn't and so I look into that and then in the in this sweet, like we had planned to configure like es linked for JavaScript and ties typescript and like web and iOS projects. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. Okay. Got it. Okay. So your for your going to continue to focus on the refactoring this week is \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Particular regions, so I did take a creative blue team's recording today. Okay, but unfortunately once the recording is over the basic account the personal basis gone, there's no way to share it with others. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Immediately start with there's no sharing of your recording URL right in the personal account your go for Enterprise. I see so first of all before yourself, I think Alan has purchasing teams account in the team's one has to in order to be able to share go to the unlimited recording feature, which is an interface. So we have to go mystical how to I see if there's an all DHL blue team's thing we can do is we can start working like entire record in public for film. Just let it alone. Oh, yeah. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  This will talk about this is a few things right one was few things that we saw with respect to action items. Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah on the on the on the Akshay. I think it's illogical but that that I just fixed and tested it and the reply disk into production. So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself. So that needs a training so which currently such scenarios are not not that common. Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that's kind of not a mainstream case. Otherwise, I mean Shivam is not here, but he's trying to model. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Someone you know, you can do it now. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he's doing. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, ask him by the way. I don't know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation. We do, you know, yeah just talk naturally. See we're able to capture those types of things, you know, as you would normally see in a typical meeting, you know. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yep, Chef, I think mostly mostly we've been testing on the recordings. So also I have a initially when I deployed the first pass, I have a list of spoken out sentences that I use. I'm not sure if that's enough. Maybe we might want to update that and then test it this way. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  I thought it and the way I normally is interspersed action items with descriptions and then just like talking 50 and actually items just to see if there are any variations, right? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah, that's it. You know, so maybe we need that said like he can kind of keep that in mind. Yeah. chef \n",
      "\n",
      "\n",
      "\n",
      "Segment:  With respect to community aggression as the final concentration has and the mind condition. We are trying to handle both of them together for now and we have one or two approaches. So I actually wanted to put that on stage on Friday, but I had to changes so I will do it by today and I will do some color testing to see what and all it kind of throws out and what a knowledge. has \n",
      "\n",
      "\n",
      "\n",
      "Segment:  And the main thing is like whatever algorithm we have in the production the kind of assume one thing that we need more than one segments like continuously for it to identify it as a proper a topic like some relative understanding so that is actually kind of taking in the current stressful which we saw. So we assume we don't want to assume that it is kind of a rare condition. So we are also taking upon that which would actually reduce the accuracy bonus in the final communities. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Got it. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Anything else shank is outer summation. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  yeah, and this time okay action so with respect to recommended watches, so I've been testing over the weekend about how to put to suggest if it is completely unrelated. So so I'm still testing few more things. And so I plan to click deploy to production today so that I can test on our simples. So but otherwise so like right now for debugging debugging purposes. What I'm doing is like for every key phrase request like chapters or highlights or anything. I'm printing the suggested watches. So if you if you look at it a little more on The currency is quite good like I've tested on validation data as well. It's like around 70 75 person. But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now. So it is it has a lot of noise and it's sometimes very unrelated thing is I'm looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  But it's okay. I like we discussed rationale for the recommended launches. If you want to initially we can continue to go with just that the segment level right at the summary level, but keep it very conservative. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  And apart from that I like while testing all these things I saw few bugs with key phrase with it. Like there are like unnecessary entities coming up repetition of entities in key phrase or something like that. So June has like deployed a new model which also gives entity labels like, you know person location and all those things. So if I'm going to like me, Make a very small change in the Rocky Face always so that we can remove out filter out these kind of phrases. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Got it. So right now we're using our genes entity implementation in production already, right? Yes. He seems pretty much deprecated. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, cool. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Did we colored everyone? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Thank you. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seg_list = []\n",
    "for seg in request[\"body\"][\"segments\"]:\n",
    "    seg_list.append((seg[\"originalText\"], seg[\"startTime\"]))\n",
    "seg_list = sorted(seg_list, key=lambda kv:kv[1], reverse=False)\n",
    "\n",
    "print (len(seg_list))\n",
    "for seg in seg_list:\n",
    "    print (\"Segment: \", seg[0])\n",
    "    print (\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Groups for the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T12:09:56.535906Z",
     "start_time": "2019-10-16T12:08:19.069721Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /tmp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /tmp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  01DAAYHEKY5F4E02QVRJPTFTXV  for feature extraction\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 122, \"module\": \"scorer\", \"batches count\": 1, \"number of sentences\": 128, \"ts\": \"2019-12-09T17:30:51.774832Z\", \"msg\": \"computing in batches\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 125, \"module\": \"scorer\", \"iteration count:\": 0, \"ts\": \"2019-12-09T17:30:51.775556Z\", \"msg\": \"getting feature vector\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 133, \"module\": \"scorer\", \"iteration count\": 0, \"ts\": \"2019-12-09T17:30:57.365144Z\", \"msg\": \"Request Sent\"}\n",
      "('Totally cool it on and push this these features to production and work one.', '2019-12-09T06:18:24Z', '65bb83952fb54409a4bb59bb707f1375', '00726b2c-9727-4249-992f-42126fe08791') ('Get it current functionality get it all the way to production.', '2019-12-09T06:18:29Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '5e943419-cc9a-4592-8be6-fdb9b1490c31')\n",
      "('I know what you do is once you have done all the children is push it this aging.', '2019-12-09T06:19:25Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '019a5fa3-d7be-4cbf-bccc-d769e16562ab') ('Like I will modified and address the comments Josh Wise raised today and then push it up.', '2019-12-09T06:19:09Z', '65bb83952fb54409a4bb59bb707f1375', '36379e8d-ab29-40de-88ed-75f0d0d8a282')\n",
      "('Yes, so the next task on my list rifles handling the navigation flow into the IOS app.', '2019-12-09T06:24:23Z', 'c66797a92e6d46ad9573926e57f7dac3', '268c53da-8f4e-4d75-82bd-cadda50bce6a') ('Yeah the and then you you know, I think it will be good for you to focus on the the navigation flow to speak from here.', '2019-12-09T06:25:07Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'a4513419-bc40-40ae-8e26-aa3ba75ebd73')\n",
      "('So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera.', '2019-12-09T06:24:23Z', 'c66797a92e6d46ad9573926e57f7dac3', '268c53da-8f4e-4d75-82bd-cadda50bce6a') ('Right that was just like logic before we check for suggested FYI.', '2019-12-09T06:25:07Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'a4513419-bc40-40ae-8e26-aa3ba75ebd73')\n",
      "('So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera.', '2019-12-09T06:24:23Z', 'c66797a92e6d46ad9573926e57f7dac3', '268c53da-8f4e-4d75-82bd-cadda50bce6a') ('Yeah the and then you you know, I think it will be good for you to focus on the the navigation flow to speak from here.', '2019-12-09T06:25:07Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'a4513419-bc40-40ae-8e26-aa3ba75ebd73')\n",
      "('So so we will remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens.', '2019-12-09T06:24:23Z', 'c66797a92e6d46ad9573926e57f7dac3', '268c53da-8f4e-4d75-82bd-cadda50bce6a') ('Yeah the and then you you know, I think it will be good for you to focus on the the navigation flow to speak from here.', '2019-12-09T06:25:07Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'a4513419-bc40-40ae-8e26-aa3ba75ebd73')\n",
      "('So if we enter you are really not so along with the Tamil also showing the topic of the video now, but', '2019-12-09T06:22:30Z', 'c66797a92e6d46ad9573926e57f7dac3', '28442e10-5cd5-4478-9187-f6c38c30d851') ('Let is talk about like iOS so the bunch of things happening with iOS.', '2019-12-09T06:22:16Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '397d9254-8076-44b4-91d4-a6cba86be537')\n",
      "('I do not know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation.', '2019-12-09T06:29:37Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '2b1a2da6-3f4f-4f4f-b226-cf352349c17a') ('Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he is doing.', '2019-12-09T06:29:20Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'f4605d4f-a59d-44a0-b34c-06f9e2b5d118')\n",
      "('This will talk about this is a few things right one was few things that we saw with respect to action items.', '2019-12-09T06:28:00Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '3cfed39c-cffb-42c6-b23d-588e32893ec8') ('So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself.', '2019-12-09T06:28:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '67bc64ee-6e7d-4754-b318-b02aca628213')\n",
      "('Another cost being able to parse skip the pass portions and Playback, right?', '2019-12-09T06:20:30Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '8930fc4e-f570-4610-be6a-e5a5b7c3930d') ('Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast.', '2019-12-09T06:20:43Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'eb8745dd-0c0c-4b88-ad0a-6414671adc11')\n",
      "('With respect to community aggression as the final concentration has and the mind condition.', '2019-12-09T06:30:59Z', 'fb52cb663aec4795aee38ccfd904d315', '8b7a52cf-7a5c-4feb-8c11-7bc2faa8c856') ('So we are also taking upon that which would actually reduce the accuracy bonus in the final communities.', '2019-12-09T06:31:38Z', 'fb52cb663aec4795aee38ccfd904d315', 'dafc05cc-4e84-4bea-bc62-ba38b64a3c41')\n",
      "('We can guess that there is no other regressions, you know.', '2019-12-09T06:18:37Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'ae8cd93f-ea96-4a3f-a129-c5e42b8ea67d') ('Doesnt Define it like therell always be the small small things that we can improve the site.', '2019-12-09T06:18:42Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'd9a02a90-c43f-4b5e-92d4-229fe1080cf9')\n",
      "('Maybe we might want to update that and then test it this way.', '2019-12-09T06:30:01Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'c0c6d632-97ea-4513-8e89-97edbeb95cc2') ('I thought it and the way I normally is interspersed action items with descriptions and then just like talking XnumberX and actually items just to see if there are any variations, right?', '2019-12-09T06:30:21Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'caf8eb26-168f-42e3-8ba8-4bb8eab57e32')\n",
      "('I thought it and the way I normally is interspersed action items with descriptions and then just like talking XnumberX and actually items just to see if there are any variations, right?', '2019-12-09T06:30:21Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'caf8eb26-168f-42e3-8ba8-4bb8eab57e32') ('I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it.', '2019-12-09T06:30:36Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'fdf15628-cfc8-4003-86bf-50d9b75f7b13')\n",
      "('You know, so maybe we need that said like he can kind of keep that in mind.', '2019-12-09T06:30:46Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'd9779ea5-20a2-40d2-8ce9-4f05f8578863') ('I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it.', '2019-12-09T06:30:36Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'fdf15628-cfc8-4003-86bf-50d9b75f7b13')\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 391, \"module\": \"grouper_segments\", \"outlier threshold is : \": 0.34213531017303467, \"ts\": \"2019-12-09T17:30:57.635690Z\", \"msg\": \"Outlier Score\"}\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 1035, \"module\": \"grouper_segments\", \"edges before prunning\": 320, \"edges after prunning\": 320, \"modularity\": 0.8783638149373239, \"ts\": \"2019-12-09T17:30:57.858202Z\", \"msg\": \"Meeting Graph results\"}\n",
      "cluster before alteration=========>\n",
      "Totally cool it on and push this these features to production and work one.\n",
      "Get it current functionality get it all the way to production.\n",
      "cluster before alteration=========>\n",
      "I know what you do is once you have done all the children is push it this aging.\n",
      "Like I will modified and address the comments Josh Wise raised today and then push it up.\n",
      "Like the major all those are working on the speaker is logic, which I had implemented was bit wrong.\n",
      "cluster before alteration=========>\n",
      "And apart from that I like while testing all these things I saw few bugs with key phrase with it.\n",
      "Like there are like unnecessary entities coming up repetition of entities in key phrase or something like that.\n",
      "So June has like deployed a new model which also gives entity labels like, you know person location and all those things.\n",
      "So if I am going to like me, Make a very small change in the Rocky Face always so that we can remove out filter out these kind of phrases.\n",
      "cluster before alteration=========>\n",
      "So it is it has a lot of noise and it is sometimes very unrelated thing is I am looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something.\n",
      "yeah, and this time okay action so with respect to recommended watches, so I have been testing over the weekend about how to put to suggest if it is completely unrelated.\n",
      "And so I plan to click deploy to production today so that I can test on our simples.\n",
      "So but otherwise so like right now for debugging debugging purposes.\n",
      "What I am doing is like for every key phrase request like chapters or highlights or anything.\n",
      "So if you if you look at it a little more on The currency is quite good like I have tested on validation data as well.\n",
      "But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now.\n",
      "cluster before alteration=========>\n",
      "So we need to kind of align with what is going on on the right.\n",
      "cluster before alteration=========>\n",
      "I was saying that there is no need for top of plan and all that right?\n",
      "The Rollo fusions partial like we talked about is there is no need for a top of plan roll.\n",
      "Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast.\n",
      "If you exceed the XnumberX you get rejected after that and if you want to upgrade you upgrade to the hundred dollar plan.\n",
      "With respect to community aggression as the final concentration has and the mind condition.\n",
      "Another cost being able to parse skip the pass portions and Playback, right?\n",
      "We can guess that there is no other regressions, you know.\n",
      "Franklin you run through a full regression test for all of these things.\n",
      "Like today, I will be working on the speaker list on my neurologic change.\n",
      "Like I need to remove the feed from the participant list if he speaking like the active speaker else the early the vocalist of it is also should be the speaker is the small change I am talking.\n",
      "So I actually wanted to put that on stage on Friday, but I had to changes so I will do it by today and I will do some color testing to see what and all it kind of throws out and what a knowledge.\n",
      "cluster before alteration=========>\n",
      "And just to make sure that we are able to see that your problem is not there.\n",
      "cluster before alteration=========>\n",
      "That happens only for beta product or it was happening for it was not happening for me.\n",
      "cluster before alteration=========>\n",
      "Yes, so the next task on my list rifles handling the navigation flow into the IOS app.\n",
      "So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera.\n",
      "So so we will remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens.\n",
      "Yeah the and then you you know, I think it will be good for you to focus on the the navigation flow to speak from here.\n",
      "Right that was just like logic before we check for suggested FYI.\n",
      "Okay, I just spent the time length should be fairly simple.\n",
      "I thought it and the way I normally is interspersed action items with descriptions and then just like talking XnumberX and actually items just to see if there are any variations, right?\n",
      "I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it.\n",
      "You know, so maybe we need that said like he can kind of keep that in mind.\n",
      "cluster before alteration=========>\n",
      "So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts.\n",
      "Well call it used to come out even though like it was closed the XnumberX goes to there is one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow.\n",
      "Time does not mean joining like we will just shows us why screen like it does not it starts connecting but it does not end of the connecting screen.\n",
      "It does not and so I look into that and then in the in this sweet, like we had planned to configure like es linked for JavaScript and ties typescript and like web and iOS projects.\n",
      "cluster before alteration=========>\n",
      "Excuse and we do not need to do a lot of yeah, let us addition the platform side.\n",
      "I do not know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation.\n",
      "See we are able to capture those types of things, you know, as you would normally see in a typical meeting, you know.\n",
      "So far now because you do not send an email immediately even right now do we have to make the changes all the I am not saying we need him?\n",
      "So Silent few questions, maybe we can sit together and write down specifically about this you said change one thing was because for the current plans we do not vote if I have and Because he is take them to free mode.\n",
      "So do not wait on that like whatever is currently pushed if it is working functionally Fisher is working recording is working right pause resume is working, you know, speaker changes working all of that well, Then we should push it to production.\n",
      "Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he is doing.\n",
      "The problem is I want to make sure that the usage related monitoring Etc.\n",
      "cluster before alteration=========>\n",
      "Let is not even like consider all that keep it really simple.\n",
      "The only thing that I want to make sure is that Before we had a free plan, of course, there is always free and limited and then there is a basic or paid plan right again that was based on number of users.\n",
      "So Enterprise line, we do not need to worry about because we do not have any users, but for the page planning now, there are two different variations of that based on one parameter called XnumberX and hundred.\n",
      "Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do.\n",
      "How does that work based on Usage Now the station need to go and change that thing to say every day.\n",
      "There is going to be an indication of how much has been used how much that has much of usage has been consumed.\n",
      "How much as me so my point being like all the work related to getting this to work?\n",
      "So part for any other things that need to be clarified on the servants clear.\n",
      "So that is XnumberX and the second which is probably the important thing.\n",
      "cluster before alteration=========>\n",
      "So if you are not free there is nothing to do if you go to pay which is basic plan.\n",
      "right now because of kotas the way we handle plans right now is If you want paid and you you get three.\n",
      "The end of the month, we do not tell them like sorry.\n",
      "We tried to renew every month in will not has no problem saying that you are in free tier subscription is over.\n",
      "But let us see if you are interesting what happens is after XnumberX hours of live calls and Tenors are like all we start to reject saying that he looks like a user uses code has exceeded at this time.\n",
      "cluster before alteration=========>\n",
      "Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that is kind of not a mainstream case.\n",
      "This will talk about this is a few things right one was few things that we saw with respect to action items.\n",
      "Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift.\n",
      "So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself.\n",
      "The question is why did can we optimize act so that the app loading is very fast?\n",
      "Maybe we might want to update that and then test it this way.\n",
      "I think it is illogical but that that I just fixed and tested it and the reply disk into production.\n",
      "So that needs a training so which currently such scenarios are not not that common.\n",
      "Otherwise, I mean Shivam is not here, but he is trying to model.\n",
      "We are trying to handle both of them together for now and we have one or two approaches.\n",
      "Yep, Chef, I think mostly mostly we have been testing on the recordings.\n",
      "So also I have a initially when I deployed the first pass, I have a list of spoken out sentences that I use.\n",
      "cluster before alteration=========>\n",
      "Doesnt Define it like therell always be the small small things that we can improve the site.\n",
      "It started maybe possibly going to do an update on the new website.\n",
      "More news coming really ate like two seconds your side CoQXnumberX in the audience.\n",
      "Any any update on your side on their resume or else?\n",
      "I think your mom is you are trying to get that going right on last week?\n",
      "cluster before alteration=========>\n",
      "When we discuss last week see right now, let us say I am doing cast.\n",
      "cluster before alteration=========>\n",
      "So I have pushed the changes of me because most production and looking in the that thumbnail thing.\n",
      "So if we enter you are really not so along with the Tamil also showing the topic of the video now, but\n",
      "Let is talk about like iOS so the bunch of things happening with iOS.\n",
      "cluster before alteration=========>\n",
      "So we myself and um, she did not get a chance on Friday to discuss on the table structure for Zoom even service.\n",
      "Yes, I so the first part where we omit the event is done.\n",
      "We did a project deploy and there were few minor issues.\n",
      "Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call.\n",
      "We used to ignore from back end so that I have fixed and it is already in production now, so once funds from she isand will discuss on the zoom service site.\n",
      "cluster before alteration=========>\n",
      "And the main thing is like whatever algorithm we have in the production the kind of assume one thing that we need more than one segments like continuously for it to identify it as a proper a topic like some relative understanding so that is actually kind of taking in the current stressful which we saw.\n",
      "So we are also taking upon that which would actually reduce the accuracy bonus in the final communities.\n",
      "So we assume we do not want to assume that it is kind of a rare condition.\n",
      "The higher priority items in iOS for me are the highlights in the timeline.\n",
      "So when we generate the summary the highlights that we generate do not show up in the timeline.\n",
      "cluster before alteration=========>\n",
      "Yeah, it says having connectivity like you want I have a screenshot in this class.\n",
      "cluster before alteration=========>\n",
      "Particular regions, so I did take a creative blue team is recording today.\n",
      "Okay, but unfortunately once the recording is over the basic account the personal basis gone, there is no way to share it with others.\n",
      "Immediately start with there is no sharing of your recording URL right in the personal account your go for Enterprise.\n",
      "Second is getting this channel list and showing both of you do not need because if you have a valid token you do not need and you already have a channel list that you pulled on the last side.\n",
      "I see so first of all before yourself, I think Alan has purchasing teams account in the team is one has to in order to be able to share go to the unlimited recording feature, which is an interface.\n",
      "So we have to go mystical how to I see if there is an all DHL blue team is thing we can do is we can start working like entire record in public for film.\n",
      "cluster before alteration=========>\n",
      "I can pick it up that and also working on the like the Papas which we show like which we see moderators or disconnected ether meet and all to hide that pop ups as well.\n",
      "cluster before alteration=========>\n",
      "That does not change right now, right but we can always do that as an enhancement.\n",
      "cluster before alteration=========>\n",
      "You can do is maybe after you are done with the Gypsy.\n",
      "cluster before alteration=========>\n",
      "So right now we are using our genes entity implementation in production already, right?\n",
      "cluster before alteration=========>\n",
      "That is the time is very important discussion to have because right now what happens is every time you start the app, you have to wait for you know, seven eight seconds and sometimes even longer than that depending on the network speed before you can start using the app.\n",
      "cluster before alteration=========>\n",
      "So your for your going to continue to focus on the refactoring this week is\n",
      "cluster before alteration=========>\n",
      "For example, you will today you will get an email that says something like this.\n",
      "cluster before alteration=========>\n",
      "I guess you are not a dream started looking at cast right that Romanian all that yet obvious.\n",
      "cluster before alteration=========>\n",
      "The basic functionality processive like all the things on web just run through and then if they are all works in will push it to production.\n",
      "cluster before alteration=========>\n",
      "Call we were not able to share screen at used to say connective tissues.\n",
      "cluster before alteration=========>\n",
      "So like for when user logs in after day, like I need an end point I think is already there.\n",
      "So I will ask kitchen to shape file requests for it.\n",
      "So basically I need like how much they have used till now for the current month and then like once when you the like when they start a new call and if they using this over then I will need back end to pain.\n",
      "Lake sent a notification event basically to website so that I can send out mail to that particular workspace customer that your user is over and that would like you can upgrade to like start new calls.\n",
      "cluster before alteration=========>\n",
      "Whoa looks like a credit card as you climb or something like that.\n",
      "cluster before alteration=========>\n",
      "So like from UI perspective on home page, I have made the changes which color might ask for and now I am working on the dashboard by from where user would be pretty cool circuit like upgrade their plants and I am using play in stripe.\n",
      "I am using the test mode like a medical test mode for Prestige Elite crew and plan in like this product in it.\n",
      "And I will be like as we discussed on Friday, maybe like the plan but the same it would be the our sports or XnumberX as like that.\n",
      "cluster before alteration=========>\n",
      "Diddly I see ether meet as a big screen in my big screen.\n",
      "cluster before alteration=========>\n",
      "If you want to initially we can continue to go with just that the segment level right at the summary level, but keep it very conservative.\n",
      "cluster before alteration=========>\n",
      "You do the dropdown, I guess the swinging took a vacation mode.\n",
      "cluster before alteration=========>\n",
      "So between I guess we need to figure out Karthik like who can support partial on the usage related changes, right?\n",
      "All right or compressor particle help you with that with the usage deleterious the platform side.\n",
      "cluster before alteration=========>\n",
      "The for the popup in desktop you had posted in friend Channel.\n",
      "I will look into it because it just like it is an alert for desktop app you can do about it.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Totally cool it on and push this these features to production and work one.\n",
      "Get it current functionality get it all the way to production.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "I know what you do is once you have done all the children is push it this aging.\n",
      "Like I will modified and address the comments Josh Wise raised today and then push it up.\n",
      "Like the major all those are working on the speaker is logic, which I had implemented was bit wrong.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "And apart from that I like while testing all these things I saw few bugs with key phrase with it.\n",
      "Like there are like unnecessary entities coming up repetition of entities in key phrase or something like that.\n",
      "So June has like deployed a new model which also gives entity labels like, you know person location and all those things.\n",
      "So if I am going to like me, Make a very small change in the Rocky Face always so that we can remove out filter out these kind of phrases.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So it is it has a lot of noise and it is sometimes very unrelated thing is I am looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something.\n",
      "yeah, and this time okay action so with respect to recommended watches, so I have been testing over the weekend about how to put to suggest if it is completely unrelated.\n",
      "And so I plan to click deploy to production today so that I can test on our simples.\n",
      "So but otherwise so like right now for debugging debugging purposes.\n",
      "What I am doing is like for every key phrase request like chapters or highlights or anything.\n",
      "So if you if you look at it a little more on The currency is quite good like I have tested on validation data as well.\n",
      "But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So we need to kind of align with what is going on on the right.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "I was saying that there is no need for top of plan and all that right?\n",
      "Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast.\n",
      "With respect to community aggression as the final concentration has and the mind condition.\n",
      "Another cost being able to parse skip the pass portions and Playback, right?\n",
      "We can guess that there is no other regressions, you know.\n",
      "Franklin you run through a full regression test for all of these things.\n",
      "Like today, I will be working on the speaker list on my neurologic change.\n",
      "Like I need to remove the feed from the participant list if he speaking like the active speaker else the early the vocalist of it is also should be the speaker is the small change I am talking.\n",
      "So I actually wanted to put that on stage on Friday, but I had to changes so I will do it by today and I will do some color testing to see what and all it kind of throws out and what a knowledge.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "And just to make sure that we are able to see that your problem is not there.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "That happens only for beta product or it was happening for it was not happening for me.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yes, so the next task on my list rifles handling the navigation flow into the IOS app.\n",
      "So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera.\n",
      "So so we will remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens.\n",
      "Yeah the and then you you know, I think it will be good for you to focus on the the navigation flow to speak from here.\n",
      "Right that was just like logic before we check for suggested FYI.\n",
      "Okay, I just spent the time length should be fairly simple.\n",
      "I thought it and the way I normally is interspersed action items with descriptions and then just like talking XnumberX and actually items just to see if there are any variations, right?\n",
      "I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it.\n",
      "You know, so maybe we need that said like he can kind of keep that in mind.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts.\n",
      "Well call it used to come out even though like it was closed the XnumberX goes to there is one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow.\n",
      "Time does not mean joining like we will just shows us why screen like it does not it starts connecting but it does not end of the connecting screen.\n",
      "It does not and so I look into that and then in the in this sweet, like we had planned to configure like es linked for JavaScript and ties typescript and like web and iOS projects.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Excuse and we do not need to do a lot of yeah, let us addition the platform side.\n",
      "I do not know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation.\n",
      "See we are able to capture those types of things, you know, as you would normally see in a typical meeting, you know.\n",
      "So far now because you do not send an email immediately even right now do we have to make the changes all the I am not saying we need him?\n",
      "So Silent few questions, maybe we can sit together and write down specifically about this you said change one thing was because for the current plans we do not vote if I have and Because he is take them to free mode.\n",
      "Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he is doing.\n",
      "The problem is I want to make sure that the usage related monitoring Etc.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Let is not even like consider all that keep it really simple.\n",
      "The only thing that I want to make sure is that Before we had a free plan, of course, there is always free and limited and then there is a basic or paid plan right again that was based on number of users.\n",
      "So Enterprise line, we do not need to worry about because we do not have any users, but for the page planning now, there are two different variations of that based on one parameter called XnumberX and hundred.\n",
      "Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do.\n",
      "How does that work based on Usage Now the station need to go and change that thing to say every day.\n",
      "There is going to be an indication of how much has been used how much that has much of usage has been consumed.\n",
      "How much as me so my point being like all the work related to getting this to work?\n",
      "So part for any other things that need to be clarified on the servants clear.\n",
      "So that is XnumberX and the second which is probably the important thing.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So if you are not free there is nothing to do if you go to pay which is basic plan.\n",
      "right now because of kotas the way we handle plans right now is If you want paid and you you get three.\n",
      "The end of the month, we do not tell them like sorry.\n",
      "We tried to renew every month in will not has no problem saying that you are in free tier subscription is over.\n",
      "But let us see if you are interesting what happens is after XnumberX hours of live calls and Tenors are like all we start to reject saying that he looks like a user uses code has exceeded at this time.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that is kind of not a mainstream case.\n",
      "This will talk about this is a few things right one was few things that we saw with respect to action items.\n",
      "Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift.\n",
      "So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself.\n",
      "The question is why did can we optimize act so that the app loading is very fast?\n",
      "Maybe we might want to update that and then test it this way.\n",
      "I think it is illogical but that that I just fixed and tested it and the reply disk into production.\n",
      "So that needs a training so which currently such scenarios are not not that common.\n",
      "Otherwise, I mean Shivam is not here, but he is trying to model.\n",
      "Yep, Chef, I think mostly mostly we have been testing on the recordings.\n",
      "So also I have a initially when I deployed the first pass, I have a list of spoken out sentences that I use.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Doesnt Define it like therell always be the small small things that we can improve the site.\n",
      "It started maybe possibly going to do an update on the new website.\n",
      "More news coming really ate like two seconds your side CoQXnumberX in the audience.\n",
      "Any any update on your side on their resume or else?\n",
      "I think your mom is you are trying to get that going right on last week?\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "When we discuss last week see right now, let us say I am doing cast.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So I have pushed the changes of me because most production and looking in the that thumbnail thing.\n",
      "So if we enter you are really not so along with the Tamil also showing the topic of the video now, but\n",
      "Let is talk about like iOS so the bunch of things happening with iOS.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So we myself and um, she did not get a chance on Friday to discuss on the table structure for Zoom even service.\n",
      "Yes, I so the first part where we omit the event is done.\n",
      "We did a project deploy and there were few minor issues.\n",
      "Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call.\n",
      "We used to ignore from back end so that I have fixed and it is already in production now, so once funds from she isand will discuss on the zoom service site.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "And the main thing is like whatever algorithm we have in the production the kind of assume one thing that we need more than one segments like continuously for it to identify it as a proper a topic like some relative understanding so that is actually kind of taking in the current stressful which we saw.\n",
      "So we are also taking upon that which would actually reduce the accuracy bonus in the final communities.\n",
      "So we assume we do not want to assume that it is kind of a rare condition.\n",
      "The higher priority items in iOS for me are the highlights in the timeline.\n",
      "So when we generate the summary the highlights that we generate do not show up in the timeline.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yeah, it says having connectivity like you want I have a screenshot in this class.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Particular regions, so I did take a creative blue team is recording today.\n",
      "Okay, but unfortunately once the recording is over the basic account the personal basis gone, there is no way to share it with others.\n",
      "Immediately start with there is no sharing of your recording URL right in the personal account your go for Enterprise.\n",
      "Second is getting this channel list and showing both of you do not need because if you have a valid token you do not need and you already have a channel list that you pulled on the last side.\n",
      "I see so first of all before yourself, I think Alan has purchasing teams account in the team is one has to in order to be able to share go to the unlimited recording feature, which is an interface.\n",
      "So we have to go mystical how to I see if there is an all DHL blue team is thing we can do is we can start working like entire record in public for film.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "I can pick it up that and also working on the like the Papas which we show like which we see moderators or disconnected ether meet and all to hide that pop ups as well.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "That does not change right now, right but we can always do that as an enhancement.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "You can do is maybe after you are done with the Gypsy.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So right now we are using our genes entity implementation in production already, right?\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "That is the time is very important discussion to have because right now what happens is every time you start the app, you have to wait for you know, seven eight seconds and sometimes even longer than that depending on the network speed before you can start using the app.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So your for your going to continue to focus on the refactoring this week is\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "For example, you will today you will get an email that says something like this.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "I guess you are not a dream started looking at cast right that Romanian all that yet obvious.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "The basic functionality processive like all the things on web just run through and then if they are all works in will push it to production.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Call we were not able to share screen at used to say connective tissues.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So like for when user logs in after day, like I need an end point I think is already there.\n",
      "So I will ask kitchen to shape file requests for it.\n",
      "So basically I need like how much they have used till now for the current month and then like once when you the like when they start a new call and if they using this over then I will need back end to pain.\n",
      "Lake sent a notification event basically to website so that I can send out mail to that particular workspace customer that your user is over and that would like you can upgrade to like start new calls.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Whoa looks like a credit card as you climb or something like that.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So like from UI perspective on home page, I have made the changes which color might ask for and now I am working on the dashboard by from where user would be pretty cool circuit like upgrade their plants and I am using play in stripe.\n",
      "I am using the test mode like a medical test mode for Prestige Elite crew and plan in like this product in it.\n",
      "And I will be like as we discussed on Friday, maybe like the plan but the same it would be the our sports or XnumberX as like that.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Diddly I see ether meet as a big screen in my big screen.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "If you want to initially we can continue to go with just that the segment level right at the summary level, but keep it very conservative.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "You do the dropdown, I guess the swinging took a vacation mode.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So between I guess we need to figure out Karthik like who can support partial on the usage related changes, right?\n",
      "All right or compressor particle help you with that with the usage deleterious the platform side.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "The for the popup in desktop you had posted in friend Channel.\n",
      "I will look into it because it just like it is an alert for desktop app you can do about it.\n",
      "\n",
      "\n",
      "Checking Timerange --------------\n",
      "--------------\n",
      "Totally cool it on and push this these features to production and work one. 00726b2c-9727-4249-992f-42126fe08791 \n",
      "\n",
      "Get it current functionality get it all the way to production. 5e943419-cc9a-4592-8be6-fdb9b1490c31 \n",
      "\n",
      "--------------\n",
      "Like the major all those are working on the speaker is logic, which I had implemented was bit wrong. 36379e8d-ab29-40de-88ed-75f0d0d8a282 \n",
      "\n",
      "Like I will modified and address the comments Josh Wise raised today and then push it up. 36379e8d-ab29-40de-88ed-75f0d0d8a282 \n",
      "\n",
      "I know what you do is once you have done all the children is push it this aging. 019a5fa3-d7be-4cbf-bccc-d769e16562ab \n",
      "\n",
      "--------------\n",
      "Like there are like unnecessary entities coming up repetition of entities in key phrase or something like that. 080c8ab5-9300-439b-9acd-c9b1eb7ee122 \n",
      "\n",
      "So June has like deployed a new model which also gives entity labels like, you know person location and all those things. 080c8ab5-9300-439b-9acd-c9b1eb7ee122 \n",
      "\n",
      "So if I am going to like me, Make a very small change in the Rocky Face always so that we can remove out filter out these kind of phrases. 080c8ab5-9300-439b-9acd-c9b1eb7ee122 \n",
      "\n",
      "And apart from that I like while testing all these things I saw few bugs with key phrase with it. 080c8ab5-9300-439b-9acd-c9b1eb7ee122 \n",
      "\n",
      "--------------\n",
      "So if you if you look at it a little more on The currency is quite good like I have tested on validation data as well. 5837bb25-19bc-4506-86ec-d44ce876693c \n",
      "\n",
      "And so I plan to click deploy to production today so that I can test on our simples. 5837bb25-19bc-4506-86ec-d44ce876693c \n",
      "\n",
      "yeah, and this time okay action so with respect to recommended watches, so I have been testing over the weekend about how to put to suggest if it is completely unrelated. 5837bb25-19bc-4506-86ec-d44ce876693c \n",
      "\n",
      "But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now. 5837bb25-19bc-4506-86ec-d44ce876693c \n",
      "\n",
      "So but otherwise so like right now for debugging debugging purposes. 5837bb25-19bc-4506-86ec-d44ce876693c \n",
      "\n",
      "So it is it has a lot of noise and it is sometimes very unrelated thing is I am looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something. 5837bb25-19bc-4506-86ec-d44ce876693c \n",
      "\n",
      "What I am doing is like for every key phrase request like chapters or highlights or anything. 5837bb25-19bc-4506-86ec-d44ce876693c \n",
      "\n",
      "--------------\n",
      "So we need to kind of align with what is going on on the right. 0a75d7f3-5938-4af7-8e0e-a9492205d21f \n",
      "\n",
      "--------------\n",
      "I was saying that there is no need for top of plan and all that right? 17698ff0-f80a-4691-9ee0-3f81514b5548 \n",
      "\n",
      "Like I need to remove the feed from the participant list if he speaking like the active speaker else the early the vocalist of it is also should be the speaker is the small change I am talking. 4409e29d-6d39-47ba-aab6-42da4292f927 \n",
      "\n",
      "Like today, I will be working on the speaker list on my neurologic change. 4409e29d-6d39-47ba-aab6-42da4292f927 \n",
      "\n",
      "We can guess that there is no other regressions, you know. ae8cd93f-ea96-4a3f-a129-c5e42b8ea67d \n",
      "\n",
      "Franklin you run through a full regression test for all of these things. ef48de87-058d-48ec-9506-1d7c07f7f407 \n",
      "\n",
      "Another cost being able to parse skip the pass portions and Playback, right? 8930fc4e-f570-4610-be6a-e5a5b7c3930d \n",
      "\n",
      "Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast. eb8745dd-0c0c-4b88-ad0a-6414671adc11 \n",
      "\n",
      "With respect to community aggression as the final concentration has and the mind condition. 8b7a52cf-7a5c-4feb-8c11-7bc2faa8c856 \n",
      "\n",
      "So I actually wanted to put that on stage on Friday, but I had to changes so I will do it by today and I will do some color testing to see what and all it kind of throws out and what a knowledge. 8b7a52cf-7a5c-4feb-8c11-7bc2faa8c856 \n",
      "\n",
      "--------------\n",
      "And just to make sure that we are able to see that your problem is not there. 1abf265c-cb10-4479-a4dc-53d9e8688a3b \n",
      "\n",
      "--------------\n",
      "That happens only for beta product or it was happening for it was not happening for me. 1cefbc0e-eee6-4fd6-a62a-21ea4611c8e1 \n",
      "\n",
      "--------------\n",
      "So so we will remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens. 268c53da-8f4e-4d75-82bd-cadda50bce6a \n",
      "\n",
      "Yes, so the next task on my list rifles handling the navigation flow into the IOS app. 268c53da-8f4e-4d75-82bd-cadda50bce6a \n",
      "\n",
      "So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera. 268c53da-8f4e-4d75-82bd-cadda50bce6a \n",
      "\n",
      "Right that was just like logic before we check for suggested FYI. a4513419-bc40-40ae-8e26-aa3ba75ebd73 \n",
      "\n",
      "Okay, I just spent the time length should be fairly simple. a4513419-bc40-40ae-8e26-aa3ba75ebd73 \n",
      "\n",
      "Yeah the and then you you know, I think it will be good for you to focus on the the navigation flow to speak from here. a4513419-bc40-40ae-8e26-aa3ba75ebd73 \n",
      "\n",
      "I thought it and the way I normally is interspersed action items with descriptions and then just like talking XnumberX and actually items just to see if there are any variations, right? caf8eb26-168f-42e3-8ba8-4bb8eab57e32 \n",
      "\n",
      "I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it. fdf15628-cfc8-4003-86bf-50d9b75f7b13 \n",
      "\n",
      "You know, so maybe we need that said like he can kind of keep that in mind. d9779ea5-20a2-40d2-8ce9-4f05f8578863 \n",
      "\n",
      "--------------\n",
      "Time does not mean joining like we will just shows us why screen like it does not it starts connecting but it does not end of the connecting screen. 26aa8c37-1a99-4987-aa3a-9d28ca4657e3 \n",
      "\n",
      "Well call it used to come out even though like it was closed the XnumberX goes to there is one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow. 26aa8c37-1a99-4987-aa3a-9d28ca4657e3 \n",
      "\n",
      "So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts. 26aa8c37-1a99-4987-aa3a-9d28ca4657e3 \n",
      "\n",
      "It does not and so I look into that and then in the in this sweet, like we had planned to configure like es linked for JavaScript and ties typescript and like web and iOS projects. 26aa8c37-1a99-4987-aa3a-9d28ca4657e3 \n",
      "\n",
      "--------------\n",
      "So Silent few questions, maybe we can sit together and write down specifically about this you said change one thing was because for the current plans we do not vote if I have and Because he is take them to free mode. c6cb8b52-5c28-4109-afd7-8f2e05d689ab \n",
      "\n",
      "So far now because you do not send an email immediately even right now do we have to make the changes all the I am not saying we need him? 3d4d3b31-5184-466a-9542-415ac3c242a7 \n",
      "\n",
      "The problem is I want to make sure that the usage related monitoring Etc. 3d4d3b31-5184-466a-9542-415ac3c242a7 \n",
      "\n",
      "Excuse and we do not need to do a lot of yeah, let us addition the platform side. 50890f4d-a41f-4e18-8194-60176008ab08 \n",
      "\n",
      "Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he is doing. f4605d4f-a59d-44a0-b34c-06f9e2b5d118 \n",
      "\n",
      "I do not know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation. 2b1a2da6-3f4f-4f4f-b226-cf352349c17a \n",
      "\n",
      "See we are able to capture those types of things, you know, as you would normally see in a typical meeting, you know. 2b1a2da6-3f4f-4f4f-b226-cf352349c17a \n",
      "\n",
      "--------------\n",
      "How does that work based on Usage Now the station need to go and change that thing to say every day. 276720eb-6c04-4aa4-a3b3-eddcb7512fd1 \n",
      "\n",
      "Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do. 276720eb-6c04-4aa4-a3b3-eddcb7512fd1 \n",
      "\n",
      "Let is not even like consider all that keep it really simple. 276720eb-6c04-4aa4-a3b3-eddcb7512fd1 \n",
      "\n",
      "There is going to be an indication of how much has been used how much that has much of usage has been consumed. 276720eb-6c04-4aa4-a3b3-eddcb7512fd1 \n",
      "\n",
      "How much as me so my point being like all the work related to getting this to work? 276720eb-6c04-4aa4-a3b3-eddcb7512fd1 \n",
      "\n",
      "The only thing that I want to make sure is that Before we had a free plan, of course, there is always free and limited and then there is a basic or paid plan right again that was based on number of users. 276720eb-6c04-4aa4-a3b3-eddcb7512fd1 \n",
      "\n",
      "So Enterprise line, we do not need to worry about because we do not have any users, but for the page planning now, there are two different variations of that based on one parameter called XnumberX and hundred. 276720eb-6c04-4aa4-a3b3-eddcb7512fd1 \n",
      "\n",
      "So part for any other things that need to be clarified on the servants clear. 276720eb-6c04-4aa4-a3b3-eddcb7512fd1 \n",
      "\n",
      "So that is XnumberX and the second which is probably the important thing. 8f6244c8-ec06-4ff7-82ef-1a9b55300d29 \n",
      "\n",
      "--------------\n",
      "But let us see if you are interesting what happens is after XnumberX hours of live calls and Tenors are like all we start to reject saying that he looks like a user uses code has exceeded at this time. ab3a4cca-425a-48ca-8767-0feb2ac567be \n",
      "\n",
      "We tried to renew every month in will not has no problem saying that you are in free tier subscription is over. ab3a4cca-425a-48ca-8767-0feb2ac567be \n",
      "\n",
      "The end of the month, we do not tell them like sorry. ab3a4cca-425a-48ca-8767-0feb2ac567be \n",
      "\n",
      "right now because of kotas the way we handle plans right now is If you want paid and you you get three. ab3a4cca-425a-48ca-8767-0feb2ac567be \n",
      "\n",
      "So if you are not free there is nothing to do if you go to pay which is basic plan. ab3a4cca-425a-48ca-8767-0feb2ac567be \n",
      "\n",
      "--------------\n",
      "The question is why did can we optimize act so that the app loading is very fast? 62d494e3-62b7-40e3-878a-647baa801e56 \n",
      "\n",
      "Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift. 3cfed39c-cffb-42c6-b23d-588e32893ec8 \n",
      "\n",
      "This will talk about this is a few things right one was few things that we saw with respect to action items. 3cfed39c-cffb-42c6-b23d-588e32893ec8 \n",
      "\n",
      "So that needs a training so which currently such scenarios are not not that common. 67bc64ee-6e7d-4754-b318-b02aca628213 \n",
      "\n",
      "Otherwise, I mean Shivam is not here, but he is trying to model. 67bc64ee-6e7d-4754-b318-b02aca628213 \n",
      "\n",
      "So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself. 67bc64ee-6e7d-4754-b318-b02aca628213 \n",
      "\n",
      "Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that is kind of not a mainstream case. 67bc64ee-6e7d-4754-b318-b02aca628213 \n",
      "\n",
      "I think it is illogical but that that I just fixed and tested it and the reply disk into production. 67bc64ee-6e7d-4754-b318-b02aca628213 \n",
      "\n",
      "Maybe we might want to update that and then test it this way. c0c6d632-97ea-4513-8e89-97edbeb95cc2 \n",
      "\n",
      "So also I have a initially when I deployed the first pass, I have a list of spoken out sentences that I use. c0c6d632-97ea-4513-8e89-97edbeb95cc2 \n",
      "\n",
      "Yep, Chef, I think mostly mostly we have been testing on the recordings. c0c6d632-97ea-4513-8e89-97edbeb95cc2 \n",
      "\n",
      "--------------\n",
      "It started maybe possibly going to do an update on the new website. 7dc88ae8-9b0b-4f6a-a807-c90c2547603a \n",
      "\n",
      "More news coming really ate like two seconds your side CoQXnumberX in the audience. 93209f2e-220d-44e5-8f90-55d695ea3bb5 \n",
      "\n",
      "Doesnt Define it like therell always be the small small things that we can improve the site. d9a02a90-c43f-4b5e-92d4-229fe1080cf9 \n",
      "\n",
      "Any any update on your side on their resume or else? a59b4853-a808-4ba8-a44a-d67f83434395 \n",
      "\n",
      "I think your mom is you are trying to get that going right on last week? a59b4853-a808-4ba8-a44a-d67f83434395 \n",
      "\n",
      "--------------\n",
      "When we discuss last week see right now, let us say I am doing cast. 27c2e9cd-826f-4988-a23c-9bf6069b0584 \n",
      "\n",
      "--------------\n",
      "Let is talk about like iOS so the bunch of things happening with iOS. 397d9254-8076-44b4-91d4-a6cba86be537 \n",
      "\n",
      "So if we enter you are really not so along with the Tamil also showing the topic of the video now, but 28442e10-5cd5-4478-9187-f6c38c30d851 \n",
      "\n",
      "So I have pushed the changes of me because most production and looking in the that thumbnail thing. 28442e10-5cd5-4478-9187-f6c38c30d851 \n",
      "\n",
      "--------------\n",
      "We did a project deploy and there were few minor issues. 760276fc-b7b6-45dc-b9da-e12bb6c8dc11 \n",
      "\n",
      "Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call. 760276fc-b7b6-45dc-b9da-e12bb6c8dc11 \n",
      "\n",
      "So we myself and um, she did not get a chance on Friday to discuss on the table structure for Zoom even service. 760276fc-b7b6-45dc-b9da-e12bb6c8dc11 \n",
      "\n",
      "We used to ignore from back end so that I have fixed and it is already in production now, so once funds from she isand will discuss on the zoom service site. 760276fc-b7b6-45dc-b9da-e12bb6c8dc11 \n",
      "\n",
      "Yes, I so the first part where we omit the event is done. 760276fc-b7b6-45dc-b9da-e12bb6c8dc11 \n",
      "\n",
      "--------------\n",
      "So when we generate the summary the highlights that we generate do not show up in the timeline. d6d09b02-5b6e-4264-9279-5fcb1ad9e38a \n",
      "\n",
      "The higher priority items in iOS for me are the highlights in the timeline. d6d09b02-5b6e-4264-9279-5fcb1ad9e38a \n",
      "\n",
      "So we assume we do not want to assume that it is kind of a rare condition. dafc05cc-4e84-4bea-bc62-ba38b64a3c41 \n",
      "\n",
      "So we are also taking upon that which would actually reduce the accuracy bonus in the final communities. dafc05cc-4e84-4bea-bc62-ba38b64a3c41 \n",
      "\n",
      "And the main thing is like whatever algorithm we have in the production the kind of assume one thing that we need more than one segments like continuously for it to identify it as a proper a topic like some relative understanding so that is actually kind of taking in the current stressful which we saw. dafc05cc-4e84-4bea-bc62-ba38b64a3c41 \n",
      "\n",
      "--------------\n",
      "Yeah, it says having connectivity like you want I have a screenshot in this class. 467c9bf4-2102-4f4e-b1d2-10c4ba512e17 \n",
      "\n",
      "--------------\n",
      "Second is getting this channel list and showing both of you do not need because if you have a valid token you do not need and you already have a channel list that you pulled on the last side. 8ceb5659-53e2-4b14-9589-face4cfe36da \n",
      "\n",
      "Okay, but unfortunately once the recording is over the basic account the personal basis gone, there is no way to share it with others. 4a199c77-1edf-4303-a945-30abb0dcbfa1 \n",
      "\n",
      "Particular regions, so I did take a creative blue team is recording today. 4a199c77-1edf-4303-a945-30abb0dcbfa1 \n",
      "\n",
      "So we have to go mystical how to I see if there is an all DHL blue team is thing we can do is we can start working like entire record in public for film. d1778f69-a823-4a45-8439-6d2af4e9cfbe \n",
      "\n",
      "Immediately start with there is no sharing of your recording URL right in the personal account your go for Enterprise. d1778f69-a823-4a45-8439-6d2af4e9cfbe \n",
      "\n",
      "I see so first of all before yourself, I think Alan has purchasing teams account in the team is one has to in order to be able to share go to the unlimited recording feature, which is an interface. d1778f69-a823-4a45-8439-6d2af4e9cfbe \n",
      "\n",
      "--------------\n",
      "I can pick it up that and also working on the like the Papas which we show like which we see moderators or disconnected ether meet and all to hide that pop ups as well. 578c6112-9672-4f55-ab05-0448f46c454f \n",
      "\n",
      "--------------\n",
      "That does not change right now, right but we can always do that as an enhancement. 5e7b76f9-551c-44b5-ad36-f16324b05267 \n",
      "\n",
      "--------------\n",
      "You can do is maybe after you are done with the Gypsy. 5eaa829d-be03-4300-8ec7-80a4cc46e649 \n",
      "\n",
      "--------------\n",
      "So right now we are using our genes entity implementation in production already, right? 6189f50c-d77c-4fdb-a9f6-37d0795699c8 \n",
      "\n",
      "--------------\n",
      "That is the time is very important discussion to have because right now what happens is every time you start the app, you have to wait for you know, seven eight seconds and sometimes even longer than that depending on the network speed before you can start using the app. 697853d3-5086-40a6-9b74-1a70d634b316 \n",
      "\n",
      "--------------\n",
      "So your for your going to continue to focus on the refactoring this week is 6aa867d5-4f2d-4388-b56d-c90ebc804f3c \n",
      "\n",
      "--------------\n",
      "For example, you will today you will get an email that says something like this. 74e5d50b-f702-424f-a59b-58660b53dfcf \n",
      "\n",
      "--------------\n",
      "I guess you are not a dream started looking at cast right that Romanian all that yet obvious. 76e395cf-d05e-4837-b4c6-54276b7576bd \n",
      "\n",
      "--------------\n",
      "The basic functionality processive like all the things on web just run through and then if they are all works in will push it to production. 840d3fbb-b97b-419c-8567-b57afc4c242b \n",
      "\n",
      "--------------\n",
      "Call we were not able to share screen at used to say connective tissues. 8c17e765-9255-4bf0-a7b0-933b2660e4ee \n",
      "\n",
      "--------------\n",
      "Lake sent a notification event basically to website so that I can send out mail to that particular workspace customer that your user is over and that would like you can upgrade to like start new calls. 9096fb4e-5dbd-4163-acf4-655406cab6f4 \n",
      "\n",
      "So basically I need like how much they have used till now for the current month and then like once when you the like when they start a new call and if they using this over then I will need back end to pain. 9096fb4e-5dbd-4163-acf4-655406cab6f4 \n",
      "\n",
      "So I will ask kitchen to shape file requests for it. 9096fb4e-5dbd-4163-acf4-655406cab6f4 \n",
      "\n",
      "So like for when user logs in after day, like I need an end point I think is already there. 9096fb4e-5dbd-4163-acf4-655406cab6f4 \n",
      "\n",
      "--------------\n",
      "Whoa looks like a credit card as you climb or something like that. 9365e6e9-e727-4d93-8297-26b73b76729e \n",
      "\n",
      "--------------\n",
      "So like from UI perspective on home page, I have made the changes which color might ask for and now I am working on the dashboard by from where user would be pretty cool circuit like upgrade their plants and I am using play in stripe. 94d8f843-b0db-4a17-8540-8f4049194cc2 \n",
      "\n",
      "I am using the test mode like a medical test mode for Prestige Elite crew and plan in like this product in it. 94d8f843-b0db-4a17-8540-8f4049194cc2 \n",
      "\n",
      "And I will be like as we discussed on Friday, maybe like the plan but the same it would be the our sports or XnumberX as like that. 94d8f843-b0db-4a17-8540-8f4049194cc2 \n",
      "\n",
      "--------------\n",
      "Diddly I see ether meet as a big screen in my big screen. 9c31b02f-e3f7-47a0-be8a-5dccd544a99c \n",
      "\n",
      "--------------\n",
      "If you want to initially we can continue to go with just that the segment level right at the summary level, but keep it very conservative. ad163b9d-7df8-4e71-b426-aa1b451e60dc \n",
      "\n",
      "--------------\n",
      "You do the dropdown, I guess the swinging took a vacation mode. e787f885-765f-4358-a1d4-dbd2c488aa5f \n",
      "\n",
      "--------------\n",
      "All right or compressor particle help you with that with the usage deleterious the platform side. ebf97eb8-970a-4839-8fa2-e8c656f0d40a \n",
      "\n",
      "So between I guess we need to figure out Karthik like who can support partial on the usage related changes, right? ebf97eb8-970a-4839-8fa2-e8c656f0d40a \n",
      "\n",
      "--------------\n",
      "The for the popup in desktop you had posted in friend Channel. f993f2f1-e284-41e0-910d-b338a8ceb6df \n",
      "\n",
      "I will look into it because it just like it is an alert for desktop app you can do about it. f993f2f1-e284-41e0-910d-b338a8ceb6df \n",
      "\n",
      "<---------------->\n",
      "order difference: 1\n",
      "Relevant sentence:  Totally cool it on and push this these features to production and work one.    =====    Get it current functionality get it all the way to production.\n",
      "order difference: 0\n",
      "Relevant sentence:  Like the major all those are working on the speaker is logic, which I had implemented was bit wrong.    =====    Like I will modified and address the comments Josh Wise raised today and then push it up.\n",
      "order difference: 1\n",
      "Relevant sentence:  Like I will modified and address the comments Josh Wise raised today and then push it up.    =====    I know what you do is once you have done all the children is push it this aging.\n",
      "order difference: 0\n",
      "Relevant sentence:  Like there are like unnecessary entities coming up repetition of entities in key phrase or something like that.    =====    So June has like deployed a new model which also gives entity labels like, you know person location and all those things.\n",
      "order difference: 0\n",
      "Relevant sentence:  So June has like deployed a new model which also gives entity labels like, you know person location and all those things.    =====    So if I am going to like me, Make a very small change in the Rocky Face always so that we can remove out filter out these kind of phrases.\n",
      "order difference: 0\n",
      "Relevant sentence:  So if I am going to like me, Make a very small change in the Rocky Face always so that we can remove out filter out these kind of phrases.    =====    And apart from that I like while testing all these things I saw few bugs with key phrase with it.\n",
      "order difference: 0\n",
      "Relevant sentence:  So if you if you look at it a little more on The currency is quite good like I have tested on validation data as well.    =====    And so I plan to click deploy to production today so that I can test on our simples.\n",
      "order difference: 0\n",
      "Relevant sentence:  And so I plan to click deploy to production today so that I can test on our simples.    =====    yeah, and this time okay action so with respect to recommended watches, so I have been testing over the weekend about how to put to suggest if it is completely unrelated.\n",
      "order difference: 0\n",
      "Relevant sentence:  yeah, and this time okay action so with respect to recommended watches, so I have been testing over the weekend about how to put to suggest if it is completely unrelated.    =====    But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now.\n",
      "order difference: 0\n",
      "Relevant sentence:  But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now.    =====    So but otherwise so like right now for debugging debugging purposes.\n",
      "order difference: 0\n",
      "Relevant sentence:  So but otherwise so like right now for debugging debugging purposes.    =====    So it is it has a lot of noise and it is sometimes very unrelated thing is I am looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something.\n",
      "order difference: 0\n",
      "Relevant sentence:  So it is it has a lot of noise and it is sometimes very unrelated thing is I am looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something.    =====    What I am doing is like for every key phrase request like chapters or highlights or anything.\n",
      "Not Relevant sentence:  I was saying that there is no need for top of plan and all that right?    !=    Like I need to remove the feed from the participant list if he speaking like the active speaker else the early the vocalist of it is also should be the speaker is the small change I am talking.\n",
      "order difference: 5\n",
      "order difference: 0\n",
      "Relevant sentence:  Like I need to remove the feed from the participant list if he speaking like the active speaker else the early the vocalist of it is also should be the speaker is the small change I am talking.    =====    Like today, I will be working on the speaker list on my neurologic change.\n",
      "Not Relevant sentence:  Like today, I will be working on the speaker list on my neurologic change.    !=    We can guess that there is no other regressions, you know.\n",
      "order difference: 9\n",
      "Not Relevant sentence:  We can guess that there is no other regressions, you know.    !=    Franklin you run through a full regression test for all of these things.\n",
      "order difference: 4\n",
      "Not Relevant sentence:  Franklin you run through a full regression test for all of these things.    !=    Another cost being able to parse skip the pass portions and Playback, right?\n",
      "order difference: 9\n",
      "order difference: 1\n",
      "Relevant sentence:  Another cost being able to parse skip the pass portions and Playback, right?    =====    Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast.\n",
      "Not Relevant sentence:  Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast.    !=    With respect to community aggression as the final concentration has and the mind condition.\n",
      "order difference: 31\n",
      "order difference: 0\n",
      "Relevant sentence:  With respect to community aggression as the final concentration has and the mind condition.    =====    So I actually wanted to put that on stage on Friday, but I had to changes so I will do it by today and I will do some color testing to see what and all it kind of throws out and what a knowledge.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so we will remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens.    =====    Yes, so the next task on my list rifles handling the navigation flow into the IOS app.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yes, so the next task on my list rifles handling the navigation flow into the IOS app.    =====    So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera.\n",
      "order difference: 1\n",
      "Relevant sentence:  So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera.    =====    Right that was just like logic before we check for suggested FYI.\n",
      "order difference: 0\n",
      "Relevant sentence:  Right that was just like logic before we check for suggested FYI.    =====    Okay, I just spent the time length should be fairly simple.\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay, I just spent the time length should be fairly simple.    =====    Yeah the and then you you know, I think it will be good for you to focus on the the navigation flow to speak from here.\n",
      "Not Relevant sentence:  Yeah the and then you you know, I think it will be good for you to focus on the the navigation flow to speak from here.    !=    I thought it and the way I normally is interspersed action items with descriptions and then just like talking XnumberX and actually items just to see if there are any variations, right?\n",
      "order difference: 13\n",
      "order difference: 1\n",
      "Relevant sentence:  I thought it and the way I normally is interspersed action items with descriptions and then just like talking XnumberX and actually items just to see if there are any variations, right?    =====    I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it.\n",
      "order difference: 1\n",
      "Relevant sentence:  I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it.    =====    You know, so maybe we need that said like he can kind of keep that in mind.\n",
      "order difference: 0\n",
      "Relevant sentence:  Time does not mean joining like we will just shows us why screen like it does not it starts connecting but it does not end of the connecting screen.    =====    Well call it used to come out even though like it was closed the XnumberX goes to there is one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow.\n",
      "order difference: 0\n",
      "Relevant sentence:  Well call it used to come out even though like it was closed the XnumberX goes to there is one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow.    =====    So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts.    =====    It does not and so I look into that and then in the in this sweet, like we had planned to configure like es linked for JavaScript and ties typescript and like web and iOS projects.\n",
      "Not Relevant sentence:  So Silent few questions, maybe we can sit together and write down specifically about this you said change one thing was because for the current plans we do not vote if I have and Because he is take them to free mode.    !=    So far now because you do not send an email immediately even right now do we have to make the changes all the I am not saying we need him?\n",
      "order difference: 19\n",
      "order difference: 0\n",
      "Relevant sentence:  So far now because you do not send an email immediately even right now do we have to make the changes all the I am not saying we need him?    =====    The problem is I want to make sure that the usage related monitoring Etc.\n",
      "order difference: 1\n",
      "Relevant sentence:  The problem is I want to make sure that the usage related monitoring Etc.    =====    Excuse and we do not need to do a lot of yeah, let us addition the platform side.\n",
      "Not Relevant sentence:  Excuse and we do not need to do a lot of yeah, let us addition the platform side.    !=    Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he is doing.\n",
      "order difference: 54\n",
      "order difference: 1\n",
      "Relevant sentence:  Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he is doing.    =====    I do not know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation.\n",
      "order difference: 0\n",
      "Relevant sentence:  I do not know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation.    =====    See we are able to capture those types of things, you know, as you would normally see in a typical meeting, you know.\n",
      "order difference: 0\n",
      "Relevant sentence:  How does that work based on Usage Now the station need to go and change that thing to say every day.    =====    Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do.\n",
      "order difference: 0\n",
      "Relevant sentence:  Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do.    =====    Let is not even like consider all that keep it really simple.\n",
      "order difference: 0\n",
      "Relevant sentence:  Let is not even like consider all that keep it really simple.    =====    There is going to be an indication of how much has been used how much that has much of usage has been consumed.\n",
      "order difference: 0\n",
      "Relevant sentence:  There is going to be an indication of how much has been used how much that has much of usage has been consumed.    =====    How much as me so my point being like all the work related to getting this to work?\n",
      "order difference: 0\n",
      "Relevant sentence:  How much as me so my point being like all the work related to getting this to work?    =====    The only thing that I want to make sure is that Before we had a free plan, of course, there is always free and limited and then there is a basic or paid plan right again that was based on number of users.\n",
      "order difference: 0\n",
      "Relevant sentence:  The only thing that I want to make sure is that Before we had a free plan, of course, there is always free and limited and then there is a basic or paid plan right again that was based on number of users.    =====    So Enterprise line, we do not need to worry about because we do not have any users, but for the page planning now, there are two different variations of that based on one parameter called XnumberX and hundred.\n",
      "order difference: 0\n",
      "Relevant sentence:  So Enterprise line, we do not need to worry about because we do not have any users, but for the page planning now, there are two different variations of that based on one parameter called XnumberX and hundred.    =====    So part for any other things that need to be clarified on the servants clear.\n",
      "Not Relevant sentence:  So part for any other things that need to be clarified on the servants clear.    !=    So that is XnumberX and the second which is probably the important thing.\n",
      "order difference: 35\n",
      "order difference: 0\n",
      "Relevant sentence:  But let us see if you are interesting what happens is after XnumberX hours of live calls and Tenors are like all we start to reject saying that he looks like a user uses code has exceeded at this time.    =====    We tried to renew every month in will not has no problem saying that you are in free tier subscription is over.\n",
      "order difference: 0\n",
      "Relevant sentence:  We tried to renew every month in will not has no problem saying that you are in free tier subscription is over.    =====    The end of the month, we do not tell them like sorry.\n",
      "order difference: 0\n",
      "Relevant sentence:  The end of the month, we do not tell them like sorry.    =====    right now because of kotas the way we handle plans right now is If you want paid and you you get three.\n",
      "order difference: 0\n",
      "Relevant sentence:  right now because of kotas the way we handle plans right now is If you want paid and you you get three.    =====    So if you are not free there is nothing to do if you go to pay which is basic plan.\n",
      "Not Relevant sentence:  The question is why did can we optimize act so that the app loading is very fast?    !=    Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift.\n",
      "order difference: 9\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift.    =====    This will talk about this is a few things right one was few things that we saw with respect to action items.\n",
      "order difference: 1\n",
      "Relevant sentence:  This will talk about this is a few things right one was few things that we saw with respect to action items.    =====    So that needs a training so which currently such scenarios are not not that common.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that needs a training so which currently such scenarios are not not that common.    =====    Otherwise, I mean Shivam is not here, but he is trying to model.\n",
      "order difference: 0\n",
      "Relevant sentence:  Otherwise, I mean Shivam is not here, but he is trying to model.    =====    So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself.\n",
      "order difference: 0\n",
      "Relevant sentence:  So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself.    =====    Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that is kind of not a mainstream case.\n",
      "order difference: 0\n",
      "Relevant sentence:  Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that is kind of not a mainstream case.    =====    I think it is illogical but that that I just fixed and tested it and the reply disk into production.\n",
      "Not Relevant sentence:  I think it is illogical but that that I just fixed and tested it and the reply disk into production.    !=    Maybe we might want to update that and then test it this way.\n",
      "order difference: 4\n",
      "order difference: 0\n",
      "Relevant sentence:  Maybe we might want to update that and then test it this way.    =====    So also I have a initially when I deployed the first pass, I have a list of spoken out sentences that I use.\n",
      "order difference: 0\n",
      "Relevant sentence:  So also I have a initially when I deployed the first pass, I have a list of spoken out sentences that I use.    =====    Yep, Chef, I think mostly mostly we have been testing on the recordings.\n",
      "Not Relevant sentence:  It started maybe possibly going to do an update on the new website.    !=    More news coming really ate like two seconds your side CoQXnumberX in the audience.\n",
      "order difference: 25\n",
      "Not Relevant sentence:  More news coming really ate like two seconds your side CoQXnumberX in the audience.    !=    Doesnt Define it like therell always be the small small things that we can improve the site.\n",
      "order difference: 19\n",
      "Not Relevant sentence:  Doesnt Define it like therell always be the small small things that we can improve the site.    !=    Any any update on your side on their resume or else?\n",
      "order difference: 14\n",
      "order difference: 0\n",
      "Relevant sentence:  Any any update on your side on their resume or else?    =====    I think your mom is you are trying to get that going right on last week?\n",
      "order difference: 1\n",
      "Relevant sentence:  Let is talk about like iOS so the bunch of things happening with iOS.    =====    So if we enter you are really not so along with the Tamil also showing the topic of the video now, but\n",
      "order difference: 0\n",
      "Relevant sentence:  So if we enter you are really not so along with the Tamil also showing the topic of the video now, but    =====    So I have pushed the changes of me because most production and looking in the that thumbnail thing.\n",
      "order difference: 0\n",
      "Relevant sentence:  We did a project deploy and there were few minor issues.    =====    Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call.\n",
      "order difference: 0\n",
      "Relevant sentence:  Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call.    =====    So we myself and um, she did not get a chance on Friday to discuss on the table structure for Zoom even service.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we myself and um, she did not get a chance on Friday to discuss on the table structure for Zoom even service.    =====    We used to ignore from back end so that I have fixed and it is already in production now, so once funds from she isand will discuss on the zoom service site.\n",
      "order difference: 0\n",
      "Relevant sentence:  We used to ignore from back end so that I have fixed and it is already in production now, so once funds from she isand will discuss on the zoom service site.    =====    Yes, I so the first part where we omit the event is done.\n",
      "order difference: 0\n",
      "Relevant sentence:  So when we generate the summary the highlights that we generate do not show up in the timeline.    =====    The higher priority items in iOS for me are the highlights in the timeline.\n",
      "Not Relevant sentence:  The higher priority items in iOS for me are the highlights in the timeline.    !=    So we assume we do not want to assume that it is kind of a rare condition.\n",
      "order difference: 25\n",
      "order difference: 0\n",
      "Relevant sentence:  So we assume we do not want to assume that it is kind of a rare condition.    =====    So we are also taking upon that which would actually reduce the accuracy bonus in the final communities.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we are also taking upon that which would actually reduce the accuracy bonus in the final communities.    =====    And the main thing is like whatever algorithm we have in the production the kind of assume one thing that we need more than one segments like continuously for it to identify it as a proper a topic like some relative understanding so that is actually kind of taking in the current stressful which we saw.\n",
      "Not Relevant sentence:  Second is getting this channel list and showing both of you do not need because if you have a valid token you do not need and you already have a channel list that you pulled on the last side.    !=    Okay, but unfortunately once the recording is over the basic account the personal basis gone, there is no way to share it with others.\n",
      "order difference: 8\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay, but unfortunately once the recording is over the basic account the personal basis gone, there is no way to share it with others.    =====    Particular regions, so I did take a creative blue team is recording today.\n",
      "order difference: 1\n",
      "Relevant sentence:  Particular regions, so I did take a creative blue team is recording today.    =====    So we have to go mystical how to I see if there is an all DHL blue team is thing we can do is we can start working like entire record in public for film.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we have to go mystical how to I see if there is an all DHL blue team is thing we can do is we can start working like entire record in public for film.    =====    Immediately start with there is no sharing of your recording URL right in the personal account your go for Enterprise.\n",
      "order difference: 0\n",
      "Relevant sentence:  Immediately start with there is no sharing of your recording URL right in the personal account your go for Enterprise.    =====    I see so first of all before yourself, I think Alan has purchasing teams account in the team is one has to in order to be able to share go to the unlimited recording feature, which is an interface.\n",
      "order difference: 0\n",
      "Relevant sentence:  Lake sent a notification event basically to website so that I can send out mail to that particular workspace customer that your user is over and that would like you can upgrade to like start new calls.    =====    So basically I need like how much they have used till now for the current month and then like once when you the like when they start a new call and if they using this over then I will need back end to pain.\n",
      "order difference: 0\n",
      "Relevant sentence:  So basically I need like how much they have used till now for the current month and then like once when you the like when they start a new call and if they using this over then I will need back end to pain.    =====    So I will ask kitchen to shape file requests for it.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I will ask kitchen to shape file requests for it.    =====    So like for when user logs in after day, like I need an end point I think is already there.\n",
      "order difference: 0\n",
      "Relevant sentence:  So like from UI perspective on home page, I have made the changes which color might ask for and now I am working on the dashboard by from where user would be pretty cool circuit like upgrade their plants and I am using play in stripe.    =====    I am using the test mode like a medical test mode for Prestige Elite crew and plan in like this product in it.\n",
      "order difference: 0\n",
      "Relevant sentence:  I am using the test mode like a medical test mode for Prestige Elite crew and plan in like this product in it.    =====    And I will be like as we discussed on Friday, maybe like the plan but the same it would be the our sports or XnumberX as like that.\n",
      "order difference: 0\n",
      "Relevant sentence:  All right or compressor particle help you with that with the usage deleterious the platform side.    =====    So between I guess we need to figure out Karthik like who can support partial on the usage related changes, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  The for the popup in desktop you had posted in friend Channel.    =====    I will look into it because it just like it is an alert for desktop app you can do about it.\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13), (14, 14)]\n",
      "[[['Another cost being able to parse skip the pass portions and Playback, right? '], '2019-12-09T06:20:30Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '8930fc4e-f570-4610-be6a-e5a5b7c3930d'], [['Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast. '], '2019-12-09T06:20:43Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'eb8745dd-0c0c-4b88-ad0a-6414671adc11']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"So far now because you don't send an email immediately even right now do we have to make the changes all the I'm not saying we need him? That's not the problem. The problem is I want to make sure that the usage related monitoring Etc. The Rollo fusions partial like we talked about is there's no need for a top of plan roll. If you exceed the $25 you get rejected after that and if you want to upgrade you upgrade to the hundred dollar plan. That's it. Okay. \"], '2019-12-09T06:14:16Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '3d4d3b31-5184-466a-9542-415ac3c242a7'], [[\"Excuse and we don't need to do a lot of yeah, let's addition the platform side. \"], '2019-12-09T06:15:01Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '50890f4d-a41f-4e18-8194-60176008ab08']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Let's not even like consider all that keep it really simple. All we're doing is exactly the same. The only thing that I want to make sure is that Before we had a free plan, of course, there's always free and limited and then there is a basic or paid plan right again that was based on number of users. And then we had an Enterprise plan. So Enterprise line, we don't need to worry about because we don't have any users, but for the page planning now, there are two different variations of that based on one parameter called 25 and hundred. Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do. How does that work based on Usage Now the station need to go and change that thing to say every day. There is going to be an indication of how much has been used how much that has much of usage has been consumed. How much as me so my point being like all the work related to getting this to work? Yeah. Can we just list them together? You know, who's week's work on what? Yeah, okay. So part for any other things that need to be clarified on the servants clear. \"], '2019-12-09T06:15:24Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '276720eb-6c04-4aa4-a3b3-eddcb7512fd1']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yes, so the next task on my list rifles handling the navigation flow into the IOS app. So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera. Mic all these are happening whenever we open the up. So so we'll remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens. So create the navigation like will correct the navigation flow. So that limbs over. \"], '2019-12-09T06:24:23Z', 'c66797a92e6d46ad9573926e57f7dac3', '268c53da-8f4e-4d75-82bd-cadda50bce6a'], [[\"Okay, I just spent the time length should be fairly simple. Right that was just like logic before we check for suggested FYI. Now we need to check for suggested topics. And then instead of showing FYI to show highlight, right? That's it. Yeah the and then you you know, I think it'll be good for you to focus on the the navigation flow to speak from here. Come back. Preview thing later like a background task, you know. \"], '2019-12-09T06:25:07Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'a4513419-bc40-40ae-8e26-aa3ba75ebd73']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['This will talk about this is a few things right one was few things that we saw with respect to action items. Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift. '], '2019-12-09T06:28:00Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '3cfed39c-cffb-42c6-b23d-588e32893ec8'], [[\"Yeah on the on the on the Akshay. I think it's illogical but that that I just fixed and tested it and the reply disk into production. So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself. So that needs a training so which currently such scenarios are not not that common. Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that's kind of not a mainstream case. Otherwise, I mean Shivam is not here, but he's trying to model. \"], '2019-12-09T06:28:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '67bc64ee-6e7d-4754-b318-b02aca628213']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"yeah, and this time okay action so with respect to recommended watches, so I've been testing over the weekend about how to put to suggest if it is completely unrelated. So so I'm still testing few more things. And so I plan to click deploy to production today so that I can test on our simples. So but otherwise so like right now for debugging debugging purposes. What I'm doing is like for every key phrase request like chapters or highlights or anything. I'm printing the suggested watches. So if you if you look at it a little more on The currency is quite good like I've tested on validation data as well. It's like around 70 75 person. But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now. So it is it has a lot of noise and it's sometimes very unrelated thing is I'm looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something. \"], '2019-12-09T06:32:38Z', '7e7ccbba232d411aa95ad3f244a35f40', '5837bb25-19bc-4506-86ec-d44ce876693c']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['Totally cool it on and push this these features to production and work one. '], '2019-12-09T06:18:24Z', '65bb83952fb54409a4bb59bb707f1375', '00726b2c-9727-4249-992f-42126fe08791'], [['Get it current functionality get it all the way to production. '], '2019-12-09T06:18:29Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '5e943419-cc9a-4592-8be6-fdb9b1490c31']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yes, I so the first part where we omit the event is done. So we myself and um, she didn't get a chance on Friday to discuss on the table structure for Zoom even service. So today we'll discuss this on Friday. We did a project deploy and there were few minor issues. Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call. We used to ignore from back end so that I have fixed and it's already in production now, so once funds from she is--and will discuss on the zoom service site. Sorry. \"], '2019-12-09T06:21:05Z', '75bdf310110b4b8fab88b16fafce920e', '760276fc-b7b6-45dc-b9da-e12bb6c8dc11']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['I thought it and the way I normally is interspersed action items with descriptions and then just like talking 50 and actually items just to see if there are any variations, right? '], '2019-12-09T06:30:21Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'caf8eb26-168f-42e3-8ba8-4bb8eab57e32'], [['I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it. '], '2019-12-09T06:30:36Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'fdf15628-cfc8-4003-86bf-50d9b75f7b13'], [[\"Yeah, that's it. You know, so maybe we need that said like he can kind of keep that in mind. Yeah. chef \"], '2019-12-09T06:30:46Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'd9779ea5-20a2-40d2-8ce9-4f05f8578863']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Particular regions, so I did take a creative blue team's recording today. Okay, but unfortunately once the recording is over the basic account the personal basis gone, there's no way to share it with others. \"], '2019-12-09T06:26:58Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '4a199c77-1edf-4303-a945-30abb0dcbfa1'], [[\"Immediately start with there's no sharing of your recording URL right in the personal account your go for Enterprise. I see so first of all before yourself, I think Alan has purchasing teams account in the team's one has to in order to be able to share go to the unlimited recording feature, which is an interface. So we have to go mystical how to I see if there's an all DHL blue team's thing we can do is we can start working like entire record in public for film. Just let it alone. Oh, yeah. \"], '2019-12-09T06:27:18Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'd1778f69-a823-4a45-8439-6d2af4e9cfbe']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he's doing. \"], '2019-12-09T06:29:20Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'f4605d4f-a59d-44a0-b34c-06f9e2b5d118'], [[\"Okay, ask him by the way. I don't know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation. We do, you know, yeah just talk naturally. See we're able to capture those types of things, you know, as you would normally see in a typical meeting, you know. \"], '2019-12-09T06:29:37Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '2b1a2da6-3f4f-4f4f-b226-cf352349c17a']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts. We'll call it used to come out even though like it was closed the 6 goes to there's one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow. Time doesn't mean joining like we'll just shows us why screen like it doesn't it starts connecting but it doesn't end of the connecting screen. It doesn't and so I look into that and then in the in this sweet, like we had planned to configure like es linked for JavaScript and ties typescript and like web and iOS projects. \"], '2019-12-09T06:25:48Z', 'b4a57b25de68446cac990f856d3fe4d5', '26aa8c37-1a99-4987-aa3a-9d28ca4657e3']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Let's talk about like iOS so the bunch of things happening with iOS. I finish share deep. You guys want to go links? \"], '2019-12-09T06:22:16Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '397d9254-8076-44b4-91d4-a6cba86be537'], [['So I have pushed the changes of me because most production and looking in the that thumbnail thing. So if we enter you are really not so along with the Tamil also showing the topic of the video now, but '], '2019-12-09T06:22:30Z', 'c66797a92e6d46ad9573926e57f7dac3', '28442e10-5cd5-4478-9187-f6c38c30d851']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Like the major all those are working on the speaker's logic, which I had implemented was bit wrong. Like I'll modified and address the comments Josh Wise raised today and then push it up. I'll try to push it to production. \"], '2019-12-09T06:19:09Z', '65bb83952fb54409a4bb59bb707f1375', '36379e8d-ab29-40de-88ed-75f0d0d8a282'], [[\"I know what you do is once you've done all the children's push it this aging. \"], '2019-12-09T06:19:25Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '019a5fa3-d7be-4cbf-bccc-d769e16562ab']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"right now because of kotas the way we handle plans right now is If you want paid and you you get three. The end of the month, we don't tell them like sorry. Let me just think come back. So if you aren't free there's nothing to do if you go to pay which is basic plan. We tried to renew every month in won't has no problem saying that you're in free tier subscription is over. But let's see if you're interesting what happens is after 10 hours of live calls and Tenors are like all we start to reject saying that he looks like a user uses code has exceeded at this time. We don't send an email, right? When we send usage quotas experience. \"], '2019-12-09T06:12:06Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'ab3a4cca-425a-48ca-8767-0feb2ac567be']] \n",
      "\n",
      "\n",
      "14\n",
      "Before Merging 15\n",
      "[]\n",
      "After Merging 15\n"
     ]
    }
   ],
   "source": [
    "from main import handler\n",
    "\n",
    "res = handler(request, None)\n",
    "group = json.loads(res['body'])\n",
    "\n",
    "group_sorted = {}\n",
    "group_sorted [\"group\"] = {}\n",
    "temp_group = sorted(group['group'].items(), key= lambda kv:kv[1][0]['startTime'], reverse=False)\n",
    "for g in temp_group:\n",
    "    group_sorted[\"group\"][g[0]] = g[1]\n",
    "\n",
    "group = group_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6\n",
      "13\n",
      "0\n",
      "12\n",
      "3\n",
      "9\n",
      "4\n",
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for g in group['group'].keys():\n",
    "    if len(group['group'][g])>1:\n",
    "        print (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:39:16  to  13 days, 20:40:01 \n",
      "\n",
      "\n",
      "So far now because you don't send an email immediately even right now do we have to make the changes all the I'm not saying we need him? That's not the problem. The problem is I want to make sure that the usage related monitoring Etc. The Rollo fusions partial like we talked about is there's no need for a top of plan roll. If you exceed the $25 you get rejected after that and if you want to upgrade you upgrade to the hundred dollar plan. That's it. Okay.  \n",
      "\n",
      "Excuse and we don't need to do a lot of yeah, let's addition the platform side.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:43:24  to  13 days, 20:43:29 \n",
      "\n",
      "\n",
      "Totally cool it on and push this these features to production and work one.  \n",
      "\n",
      "Get it current functionality get it all the way to production.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:44:09  to  13 days, 20:44:25 \n",
      "\n",
      "\n",
      "Like the major all those are working on the speaker's logic, which I had implemented was bit wrong. Like I'll modified and address the comments Josh Wise raised today and then push it up. I'll try to push it to production.  \n",
      "\n",
      "I know what you do is once you've done all the children's push it this aging.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:45:30  to  13 days, 20:45:43 \n",
      "\n",
      "\n",
      "Another cost being able to parse skip the pass portions and Playback, right?  \n",
      "\n",
      "Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:47:16  to  13 days, 20:47:30 \n",
      "\n",
      "\n",
      "Let's talk about like iOS so the bunch of things happening with iOS. I finish share deep. You guys want to go links?  \n",
      "\n",
      "So I have pushed the changes of me because most production and looking in the that thumbnail thing. So if we enter you are really not so along with the Tamil also showing the topic of the video now, but  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:49:23  to  13 days, 20:50:07 \n",
      "\n",
      "\n",
      "Yes, so the next task on my list rifles handling the navigation flow into the IOS app. So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera. Mic all these are happening whenever we open the up. So so we'll remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens. So create the navigation like will correct the navigation flow. So that limbs over.  \n",
      "\n",
      "Okay, I just spent the time length should be fairly simple. Right that was just like logic before we check for suggested FYI. Now we need to check for suggested topics. And then instead of showing FYI to show highlight, right? That's it. Yeah the and then you you know, I think it'll be good for you to focus on the the navigation flow to speak from here. Come back. Preview thing later like a background task, you know.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:51:58  to  13 days, 20:52:18 \n",
      "\n",
      "\n",
      "Particular regions, so I did take a creative blue team's recording today. Okay, but unfortunately once the recording is over the basic account the personal basis gone, there's no way to share it with others.  \n",
      "\n",
      "Immediately start with there's no sharing of your recording URL right in the personal account your go for Enterprise. I see so first of all before yourself, I think Alan has purchasing teams account in the team's one has to in order to be able to share go to the unlimited recording feature, which is an interface. So we have to go mystical how to I see if there's an all DHL blue team's thing we can do is we can start working like entire record in public for film. Just let it alone. Oh, yeah.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:53:00  to  13 days, 20:53:27 \n",
      "\n",
      "\n",
      "This will talk about this is a few things right one was few things that we saw with respect to action items. Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift.  \n",
      "\n",
      "Yeah on the on the on the Akshay. I think it's illogical but that that I just fixed and tested it and the reply disk into production. So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself. So that needs a training so which currently such scenarios are not not that common. Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that's kind of not a mainstream case. Otherwise, I mean Shivam is not here, but he's trying to model.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:54:20  to  13 days, 20:54:37 \n",
      "\n",
      "\n",
      "Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he's doing.  \n",
      "\n",
      "Okay, ask him by the way. I don't know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation. We do, you know, yeah just talk naturally. See we're able to capture those types of things, you know, as you would normally see in a typical meeting, you know.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   13 days, 20:55:21  to  13 days, 20:55:46 \n",
      "\n",
      "\n",
      "I thought it and the way I normally is interspersed action items with descriptions and then just like talking 50 and actually items just to see if there are any variations, right?  \n",
      "\n",
      "I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it.  \n",
      "\n",
      "Yeah, that's it. You know, so maybe we need that said like he can kind of keep that in mind. Yeah. chef  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "from backports.datetime_fromisoformat import MonkeyPatch\n",
    "MonkeyPatch.patch_fromisoformat()\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True) #eng_19\n",
    "#m_time = formatTime(\"2019-09-20T07:12:00Z\", True) #eng_front_end_20\n",
    "#m_time = formatTime(\"2019-09-24T06:11:00Z\", True) #eng_24\n",
    "#m_time = formatTime(\"2019-10-04T05:44:00Z\", True)  #podcast_04\n",
    "#m_time = formatTime(\"2019-10-08T11:55:00Z\", True)  #podcast_08\n",
    "#m_time = formatTime(\"2019-10-14T06:04:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "#m_time = formatTime(\"2019-11-26T09:03:00Z\", True)  # set_1\n",
    "#m_time = formatTime(\"2019-11-21T06:30:00Z\", True) # sync_11_21\n",
    "m_time = formatTime(\"2019-11-25T09:35:00Z\", True) # sync_11_25_ml\n",
    "#m_time = formatTime(\"2019-11-26T06:15:00Z\", True) # sync_11_26\n",
    "for i in group['group'].keys():\n",
    "    if len(group['group'][i])!=1:\n",
    "        print (\"\\n\\n Chapter Discussion:  \", formatTime(group['group'][i][0]['startTime'], True) - m_time, \" to \", formatTime(group['group'][i][-1]['startTime'], True) - m_time, \"\\n\\n\")\n",
    "        for seg in group['group'][i]:\n",
    "            #print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "            print (seg['originalText'],\"\\n\")\n",
    "    \n",
    "#     elif len(group['group'][i])==1:\n",
    "#         print (\"\\n\\n Chapter Discussion:  \", formatTime(group['group'][i][0]['startTime'], True) - m_time , \"\\n\\n\")\n",
    "#         for seg in group['group'][i]:\n",
    "#             #print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "#             print (seg['originalText'],\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Group Id:  14\n",
      "Karthik Muralidharan Discussed \n",
      "\n",
      " Text: \n",
      "right now because of kotas the way we handle plans right now is If you want paid and you you get three. The end of the month, we don't tell them like sorry. Let me just think come back. So if you aren't free there's nothing to do if you go to pay which is basic plan. We tried to renew every month in won't has no problem saying that you're in free tier subscription is over. But let's see if you're interesting what happens is after 10 hours of live calls and Tenors are like all we start to reject saying that he looks like a user uses code has exceeded at this time. We don't send an email, right? When we send usage quotas experience. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  1\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "So far now because you don't send an email immediately even right now do we have to make the changes all the I'm not saying we need him? That's not the problem. The problem is I want to make sure that the usage related monitoring Etc. The Rollo fusions partial like we talked about is there's no need for a top of plan roll. If you exceed the $25 you get rejected after that and if you want to upgrade you upgrade to the hundred dollar plan. That's it. Okay. \n",
      "\n",
      "Excuse and we don't need to do a lot of yeah, let's addition the platform side. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  2\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Let's not even like consider all that keep it really simple. All we're doing is exactly the same. The only thing that I want to make sure is that Before we had a free plan, of course, there's always free and limited and then there is a basic or paid plan right again that was based on number of users. And then we had an Enterprise plan. So Enterprise line, we don't need to worry about because we don't have any users, but for the page planning now, there are two different variations of that based on one parameter called 25 and hundred. Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do. How does that work based on Usage Now the station need to go and change that thing to say every day. There is going to be an indication of how much has been used how much that has much of usage has been consumed. How much as me so my point being like all the work related to getting this to work? Yeah. Can we just list them together? You know, who's week's work on what? Yeah, okay. So part for any other things that need to be clarified on the servants clear. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  6\n",
      "Vani, Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Totally cool it on and push this these features to production and work one. \n",
      "\n",
      "Get it current functionality get it all the way to production. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  13\n",
      "Vani, Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Like the major all those are working on the speaker's logic, which I had implemented was bit wrong. Like I'll modified and address the comments Josh Wise raised today and then push it up. I'll try to push it to production. \n",
      "\n",
      "I know what you do is once you've done all the children's push it this aging. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  0\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Another cost being able to parse skip the pass portions and Playback, right? \n",
      "\n",
      "Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  7\n",
      "Trishanth Diwate Discussed \n",
      "\n",
      " Text: \n",
      "Yes, I so the first part where we omit the event is done. So we myself and um, she didn't get a chance on Friday to discuss on the table structure for Zoom even service. So today we'll discuss this on Friday. We did a project deploy and there were few minor issues. Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call. We used to ignore from back end so that I have fixed and it's already in production now, so once funds from she is--and will discuss on the zoom service site. Sorry. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  12\n",
      "Krishna Sai, Nisha Yadav Discussed \n",
      "\n",
      " Text: \n",
      "Let's talk about like iOS so the bunch of things happening with iOS. I finish share deep. You guys want to go links? \n",
      "\n",
      "So I have pushed the changes of me because most production and looking in the that thumbnail thing. So if we enter you are really not so along with the Tamil also showing the topic of the video now, but \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  3\n",
      "Nisha Yadav, Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Yes, so the next task on my list rifles handling the navigation flow into the IOS app. So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera. Mic all these are happening whenever we open the up. So so we'll remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens. So create the navigation like will correct the navigation flow. So that limbs over. \n",
      "\n",
      "Okay, I just spent the time length should be fairly simple. Right that was just like logic before we check for suggested FYI. Now we need to check for suggested topics. And then instead of showing FYI to show highlight, right? That's it. Yeah the and then you you know, I think it'll be good for you to focus on the the navigation flow to speak from here. Come back. Preview thing later like a background task, you know. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  11\n",
      "Deep Discussed \n",
      "\n",
      " Text: \n",
      "So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts. We'll call it used to come out even though like it was closed the 6 goes to there's one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow. Time doesn't mean joining like we'll just shows us why screen like it doesn't it starts connecting but it doesn't end of the connecting screen. It doesn't and so I look into that and then in the in this sweet, like we had planned to configure like es linked for JavaScript and ties typescript and like web and iOS projects. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  9\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Particular regions, so I did take a creative blue team's recording today. Okay, but unfortunately once the recording is over the basic account the personal basis gone, there's no way to share it with others. \n",
      "\n",
      "Immediately start with there's no sharing of your recording URL right in the personal account your go for Enterprise. I see so first of all before yourself, I think Alan has purchasing teams account in the team's one has to in order to be able to share go to the unlimited recording feature, which is an interface. So we have to go mystical how to I see if there's an all DHL blue team's thing we can do is we can start working like entire record in public for film. Just let it alone. Oh, yeah. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  4\n",
      "Krishna Sai, Venkata Dikshit Discussed \n",
      "\n",
      " Text: \n",
      "This will talk about this is a few things right one was few things that we saw with respect to action items. Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift. \n",
      "\n",
      "Yeah on the on the on the Akshay. I think it's illogical but that that I just fixed and tested it and the reply disk into production. So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself. So that needs a training so which currently such scenarios are not not that common. Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that's kind of not a mainstream case. Otherwise, I mean Shivam is not here, but he's trying to model. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  10\n",
      "Venkata Dikshit, Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he's doing. \n",
      "\n",
      "Okay, ask him by the way. I don't know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation. We do, you know, yeah just talk naturally. See we're able to capture those types of things, you know, as you would normally see in a typical meeting, you know. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  8\n",
      "Krishna Sai, Venkata Dikshit Discussed \n",
      "\n",
      " Text: \n",
      "I thought it and the way I normally is interspersed action items with descriptions and then just like talking 50 and actually items just to see if there are any variations, right? \n",
      "\n",
      "I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it. \n",
      "\n",
      "Yeah, that's it. You know, so maybe we need that said like he can kind of keep that in mind. Yeah. chef \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  5\n",
      "Shashank Discussed \n",
      "\n",
      " Text: \n",
      "yeah, and this time okay action so with respect to recommended watches, so I've been testing over the weekend about how to put to suggest if it is completely unrelated. So so I'm still testing few more things. And so I plan to click deploy to production today so that I can test on our simples. So but otherwise so like right now for debugging debugging purposes. What I'm doing is like for every key phrase request like chapters or highlights or anything. I'm printing the suggested watches. So if you if you look at it a little more on The currency is quite good like I've tested on validation data as well. It's like around 70 75 person. But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now. So it is it has a lot of noise and it's sometimes very unrelated thing is I'm looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id_map = {}\n",
    "user_id_map = {\"3f01f2032f584b178fafde6b437058ae\":\"Venkat\",\"8fff81b5b2f14aa5ad67405f3e8127f3\":\"Sai\",\"60d2ea6bed8c48269c8c024202a4148d\":\"Shubham\",\"70caa6269d8e4869a45f7ea91ade3472\":\"Ether\",\"3e1a008f734448b0ad9190778449af81\":\"Cullen\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep\",\"716067a60a1a4034abc49a12ecafb39b\":\"Cullen\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Cullen\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "text_list = []\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    print (\"User\", end=\" \")\n",
    "#     if len(seg_list) == 1 :\n",
    "#         continue\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \")\n",
    "    print ( *seg_list, sep=\"\\n\\n\", end=\"\\n\\n\")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\")\n",
    "    text_list.append(\" \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Group Id:  15\n",
      "Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  right now because of kotas the way we handle plans right now is If you want paid and you you get three. The end of the month, we don't tell them like sorry. Let me just think come back. So if you aren't free there's nothing to do if you go to pay which is basic plan. We tried to renew every month in won't has no problem saying that you're in free tier subscription is over. But let's see if you're interesting what happens is after 10 hours of live calls and Tenors are like all we start to reject saying that he looks like a user uses code has exceeded at this time. We don't send an email, right? When we send usage quotas experience.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  2\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text:  So far now because you don't send an email immediately even right now do we have to make the changes all the I'm not saying we need him? That's not the problem. The problem is I want to make sure that the usage related monitoring Etc. The Rollo fusions partial like we talked about is there's no need for a top of plan roll. If you exceed the $25 you get rejected after that and if you want to upgrade you upgrade to the hundred dollar plan. That's it. Okay.  Excuse and we don't need to do a lot of yeah, let's addition the platform side.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  3\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text:  Let's not even like consider all that keep it really simple. All we're doing is exactly the same. The only thing that I want to make sure is that Before we had a free plan, of course, there's always free and limited and then there is a basic or paid plan right again that was based on number of users. And then we had an Enterprise plan. So Enterprise line, we don't need to worry about because we don't have any users, but for the page planning now, there are two different variations of that based on one parameter called 25 and hundred. Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do. How does that work based on Usage Now the station need to go and change that thing to say every day. There is going to be an indication of how much has been used how much that has much of usage has been consumed. How much as me so my point being like all the work related to getting this to work? Yeah. Can we just list them together? You know, who's week's work on what? Yeah, okay. So part for any other things that need to be clarified on the servants clear.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  7\n",
      "Vani, Krishna Sai Discussed \n",
      "\n",
      " Text:  Totally cool it on and push this these features to production and work one.  Get it current functionality get it all the way to production.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  14\n",
      "Vani, Krishna Sai Discussed \n",
      "\n",
      " Text:  Like the major all those are working on the speaker's logic, which I had implemented was bit wrong. Like I'll modified and address the comments Josh Wise raised today and then push it up. I'll try to push it to production.  I know what you do is once you've done all the children's push it this aging.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  0\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text:  Another cost being able to parse skip the pass portions and Playback, right?  Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  8\n",
      "Trishanth Diwate Discussed \n",
      "\n",
      " Text:  Yes, I so the first part where we omit the event is done. So we myself and um, she didn't get a chance on Friday to discuss on the table structure for Zoom even service. So today we'll discuss this on Friday. We did a project deploy and there were few minor issues. Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call. We used to ignore from back end so that I have fixed and it's already in production now, so once funds from she is--and will discuss on the zoom service site. Sorry.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  13\n",
      "Krishna Sai, Nisha Yadav Discussed \n",
      "\n",
      " Text:  Let's talk about like iOS so the bunch of things happening with iOS. I finish share deep. You guys want to go links?  So I have pushed the changes of me because most production and looking in the that thumbnail thing. So if we enter you are really not so along with the Tamil also showing the topic of the video now, but  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  4\n",
      "Nisha Yadav, Krishna Sai Discussed \n",
      "\n",
      " Text:  Yes, so the next task on my list rifles handling the navigation flow into the IOS app. So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera. Mic all these are happening whenever we open the up. So so we'll remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens. So create the navigation like will correct the navigation flow. So that limbs over.  Okay, I just spent the time length should be fairly simple. Right that was just like logic before we check for suggested FYI. Now we need to check for suggested topics. And then instead of showing FYI to show highlight, right? That's it. Yeah the and then you you know, I think it'll be good for you to focus on the the navigation flow to speak from here. Come back. Preview thing later like a background task, you know.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  12\n",
      "Deep Discussed \n",
      "\n",
      " Text:  So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts. We'll call it used to come out even though like it was closed the 6 goes to there's one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow. Time doesn't mean joining like we'll just shows us why screen like it doesn't it starts connecting but it doesn't end of the connecting screen. It doesn't and so I look into that and then in the in this sweet, like we had planned to configure like es linked for JavaScript and ties typescript and like web and iOS projects.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  10\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text:  Particular regions, so I did take a creative blue team's recording today. Okay, but unfortunately once the recording is over the basic account the personal basis gone, there's no way to share it with others.  Immediately start with there's no sharing of your recording URL right in the personal account your go for Enterprise. I see so first of all before yourself, I think Alan has purchasing teams account in the team's one has to in order to be able to share go to the unlimited recording feature, which is an interface. So we have to go mystical how to I see if there's an all DHL blue team's thing we can do is we can start working like entire record in public for film. Just let it alone. Oh, yeah.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  5\n",
      "Krishna Sai, Venkata Dikshit Discussed \n",
      "\n",
      " Text:  This will talk about this is a few things right one was few things that we saw with respect to action items. Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift.  Yeah on the on the on the Akshay. I think it's illogical but that that I just fixed and tested it and the reply disk into production. So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself. So that needs a training so which currently such scenarios are not not that common. Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that's kind of not a mainstream case. Otherwise, I mean Shivam is not here, but he's trying to model.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  11\n",
      "Venkata Dikshit, Krishna Sai Discussed \n",
      "\n",
      " Text:  Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he's doing.  Okay, ask him by the way. I don't know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation. We do, you know, yeah just talk naturally. See we're able to capture those types of things, you know, as you would normally see in a typical meeting, you know.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  9\n",
      "Venkata Dikshit, Krishna Sai Discussed \n",
      "\n",
      " Text:  Yep, Chef, I think mostly mostly we've been testing on the recordings. So also I have a initially when I deployed the first pass, I have a list of spoken out sentences that I use. I'm not sure if that's enough. Maybe we might want to update that and then test it this way.  I thought it and the way I normally is interspersed action items with descriptions and then just like talking 50 and actually items just to see if there are any variations, right?  I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it.  Yeah, that's it. You know, so maybe we need that said like he can kind of keep that in mind. Yeah. chef  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  1\n",
      "Reagan Rewop Discussed \n",
      "\n",
      " Text:  With respect to community aggression as the final concentration has and the mind condition. We are trying to handle both of them together for now and we have one or two approaches. So I actually wanted to put that on stage on Friday, but I had to changes so I will do it by today and I will do some color testing to see what and all it kind of throws out and what a knowledge. has  And the main thing is like whatever algorithm we have in the production the kind of assume one thing that we need more than one segments like continuously for it to identify it as a proper a topic like some relative understanding so that is actually kind of taking in the current stressful which we saw. So we assume we don't want to assume that it is kind of a rare condition. So we are also taking upon that which would actually reduce the accuracy bonus in the final communities.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  6\n",
      "Shashank Discussed \n",
      "\n",
      " Text:  yeah, and this time okay action so with respect to recommended watches, so I've been testing over the weekend about how to put to suggest if it is completely unrelated. So so I'm still testing few more things. And so I plan to click deploy to production today so that I can test on our simples. So but otherwise so like right now for debugging debugging purposes. What I'm doing is like for every key phrase request like chapters or highlights or anything. I'm printing the suggested watches. So if you if you look at it a little more on The currency is quite good like I've tested on validation data as well. It's like around 70 75 person. But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now. So it is it has a lot of noise and it's sometimes very unrelated thing is I'm looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something.  \n",
      "\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id_map = {}\n",
    "user_id_map = {\"3f01f2032f584b178fafde6b437058ae\":\"Venkat\",\"8fff81b5b2f14aa5ad67405f3e8127f3\":\"Sai\",\"60d2ea6bed8c48269c8c024202a4148d\":\"Shubham\",\"70caa6269d8e4869a45f7ea91ade3472\":\"Ether\",\"3e1a008f734448b0ad9190778449af81\":\"Cullen\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep\",\"716067a60a1a4034abc49a12ecafb39b\":\"Cullen\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Cullen\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "text_list = []\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    print (\"User\", end=\" \")\n",
    "#     if len(seg_list) == 1 :\n",
    "#         continue\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\")\n",
    "    text_list.append(\" \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /tmp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /tmp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  01DAAYHEKY5F4E02QVRJPTFTXV  for feature extraction\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 122, \"module\": \"scorer\", \"batches count\": 1, \"number of sentences\": 81, \"ts\": \"2019-12-06T11:23:57.078283Z\", \"msg\": \"computing in batches\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 125, \"module\": \"scorer\", \"iteration count:\": 0, \"ts\": \"2019-12-06T11:23:57.078710Z\", \"msg\": \"getting feature vector\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 133, \"module\": \"scorer\", \"iteration count\": 0, \"ts\": \"2019-12-06T11:23:58.185178Z\", \"msg\": \"Request Sent\"}\n",
      "('If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.', '2019-11-05T06:35:50Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'f621ac9d6aba42159cb4a49132967749') ('So then we started to gather this, you know, this body called communitycentric tests that we have.', '2019-11-05T06:36:22Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e4331d0b261b4239a82fba773bf0301c')\n",
      "('So then we started to gather this, you know, this body called communitycentric tests that we have.', '2019-11-05T06:36:22Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e4331d0b261b4239a82fba773bf0301c') ('So I am a little aggressive there just to be sure that we are getting good sleep.', '2019-11-05T06:37:00Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a7d82816e0d24b9dbe4f43645f5f0384')\n",
      "('And yeah on the action items, I just spoke to pressure on top Christian.', '2019-11-05T06:37:00Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a7d82816e0d24b9dbe4f43645f5f0384') ('So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.', '2019-11-05T06:38:13Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'd578d8a89fb24790970910c74f5a98a4')\n",
      "('So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality.', '2019-11-05T06:37:00Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a7d82816e0d24b9dbe4f43645f5f0384') ('So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.', '2019-11-05T06:38:13Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'd578d8a89fb24790970910c74f5a98a4')\n",
      "('But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad.', '2019-11-05T06:38:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3f528d8706c342adadc1177e4fa8f2c4') ('Well find out but that is also we have seen we have seen few noises segments.', '2019-11-05T06:38:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '8dad9074cc044d00817d35e39186ef72')\n",
      "('Yeah, if the community is good and I like like they have enough content.', '2019-11-05T06:40:39Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '0c87b0d6af3f4cb79f39a025c3fdfd9b') ('Yeah, so yeah, pretty much those were the things those are the things that I am working on.', '2019-11-05T06:42:13Z', '7e7ccbba232d411aa95ad3f244a35f40', '2bf145322e4d421484c5be3d34c45a58')\n",
      "('So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.', '2019-11-05T06:44:42Z', '7e7ccbba232d411aa95ad3f244a35f40', '03bdb0a4e7ae4e3985582c5bd2dd4dca') ('So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.', '2019-11-05T06:45:34Z', '75bdf310110b4b8fab88b16fafce920e', '212eb9ca06d04dec9f8928e34bd595d3')\n",
      "('So Google those got filtered but these who still came up.', '2019-11-05T06:44:42Z', '7e7ccbba232d411aa95ad3f244a35f40', '03bdb0a4e7ae4e3985582c5bd2dd4dca') ('So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.', '2019-11-05T06:45:34Z', '75bdf310110b4b8fab88b16fafce920e', '212eb9ca06d04dec9f8928e34bd595d3')\n",
      "('So so something like some fun videos that I am checking on me like an ideal way to remove.', '2019-11-05T06:44:42Z', '7e7ccbba232d411aa95ad3f244a35f40', '03bdb0a4e7ae4e3985582c5bd2dd4dca') ('So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.', '2019-11-05T06:45:34Z', '75bdf310110b4b8fab88b16fafce920e', '212eb9ca06d04dec9f8928e34bd595d3')\n",
      "('It is a new service analysis service and even the schema thing.', '2019-11-05T06:46:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c41fd0e424e349f2b52789f4d4c73117') ('So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.', '2019-11-05T06:46:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '7b400835c1eb473391b033c4b0ec9755')\n",
      "('It is a new service analysis service and even the schema thing.', '2019-11-05T06:46:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c41fd0e424e349f2b52789f4d4c73117') ('Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever.', '2019-11-05T06:46:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '7b400835c1eb473391b033c4b0ec9755')\n",
      "('Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.', '2019-11-05T06:47:51Z', '84fbaa66a2474ea29ae053f3a2e519d6', '979467829a7a4b19a856890922031440') ('So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.', '2019-11-05T06:48:25Z', '0bbbfe84c66145af8d0ffcd5258bba38', '9bf5fd91a17a4f0f89b202d8e9a03baf')\n",
      "('Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.', '2019-11-05T06:49:26Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '1f21ff88317e4cdd8492ef55f0dd4de1') ('I just staggered a bit or for adding that bug snack logs the issues.', '2019-11-05T06:51:53Z', 'c66797a92e6d46ad9573926e57f7dac3', 'e04864365d1949b0a9f3ebedcefd59e9')\n",
      "('Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.', '2019-11-05T06:49:26Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '1f21ff88317e4cdd8492ef55f0dd4de1') ('So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.', '2019-11-05T06:51:53Z', 'c66797a92e6d46ad9573926e57f7dac3', 'e04864365d1949b0a9f3ebedcefd59e9')\n",
      "('So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.', '2019-11-05T06:55:16Z', '1a21542584494fcaba957d768b595b80', '353c7be408ed49cfa9bb90a35c8d6ca1') ('So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.', '2019-11-05T06:56:01Z', '1a21542584494fcaba957d768b595b80', '6a565c02d9304106ab038ad6c21e686c')\n",
      "('So we need to spend a little bit more time on that.', '2019-11-05T06:56:44Z', '1a21542584494fcaba957d768b595b80', '2e2647dded0c4765b33cbe192410e4a5') ('Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.', '2019-11-05T06:57:38Z', '1a21542584494fcaba957d768b595b80', 'e708f000baeb40c0be30454cd6edb3c5')\n",
      "('Yeah, so sorry said like let us find out on this room thing.', '2019-11-05T06:57:38Z', '1a21542584494fcaba957d768b595b80', 'e708f000baeb40c0be30454cd6edb3c5') ('So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.', '2019-11-05T06:58:11Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9b60758a5c6945ef821942903414bf11')\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 390, \"module\": \"grouper_segments\", \"outlier threshold is : \": 0.2529652714729309, \"ts\": \"2019-12-06T11:23:58.375291Z\", \"msg\": \"Outlier Score\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 951, \"module\": \"grouper_segments\", \"edges before prunning\": 216, \"edges after prunning\": 216, \"modularity\": 0.8609170703934522, \"ts\": \"2019-12-06T11:23:58.562516Z\", \"msg\": \"Meeting Graph results\"}\n",
      "cluster before alteration=========>\n",
      "Is there a like a test case of something that we can build to validate the performance or say consistently.\n",
      "If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.\n",
      "Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we are developing currently what all the tested all the tests meetings that we have our segment Centre, right?\n",
      "So then we started to gather this, you know, this body called communitycentric tests that we have.\n",
      "cluster before alteration=========>\n",
      "Yeah, a couple of things right on the on the community based teams.\n",
      "We had seen some somewhat off of the track pins yesterday.\n",
      "So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films.\n",
      "We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive.\n",
      "Actually So currently it is very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation.\n",
      "And they and also the body called the Dead the relationship formation the graph Community formation.\n",
      "But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control.\n",
      "We should not be doing like a blanket formation so which which is the problem that we have.\n",
      "I mean currently solving a tap from a more technical standpoint.\n",
      "cluster before alteration=========>\n",
      "So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality.\n",
      "So I am a little aggressive there just to be sure that we are getting good sleep.\n",
      "And yeah on the action items, I just spoke to pressure on top Christian.\n",
      "The trans at least whatever it detects would be highly confident and can be reliable.\n",
      "And so I think we can enable that for The Ether engineering Channel.\n",
      "So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.\n",
      "cluster before alteration=========>\n",
      "So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.\n",
      "It is actually pretty decent terms if this is a detective, yeah.\n",
      "So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.\n",
      "I will just add all the information to document whatever I find a husband.\n",
      "My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not.\n",
      "Just need to see even even with the believability cave might need to associate one workspace to XnumberX inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association.\n",
      "cluster before alteration=========>\n",
      "So we need to spend a little bit more time on that.\n",
      "A lot of losing out on the data because now through God we cannot even capture history as its history.\n",
      "I think whatever we see for the pins would reflect their so let us go God.\n",
      "Yeah, so sorry said like let us find out on this room thing.\n",
      "The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working.\n",
      "So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free.\n",
      "Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.\n",
      "So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.\n",
      "cluster before alteration=========>\n",
      "But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad.\n",
      "Well find out but that is also we have seen we have seen few noises segments.\n",
      "That is why God or whether you are in an open.\n",
      "Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the\n",
      "Like I am constantly seeing the red network error going back and forth to the canteen.\n",
      "I think the biggest issue we are facing is with operate like being able to use the app at all.\n",
      "cluster before alteration=========>\n",
      "Now what I have done is the key phrase since it does not have the popular graph flag red line has just commented it out because I am not sure whether it works or not if I sent a text.\n",
      "Little feature flag thing with popular graph is equal to false.\n",
      "But now I think in the request before you also get different modified text.\n",
      "So these were like hardcoded in the current key phrase except he faces function so I need okay.\n",
      "cluster before alteration=========>\n",
      "Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.\n",
      "I just staggered a bit or for adding that bug snack logs the issues.\n",
      "So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.\n",
      "What recent call was Capcom was kept on loading right spinning.\n",
      "Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,\n",
      "cluster before alteration=========>\n",
      "So because of that there is actually an overlap on the segments.\n",
      "Yeah, there is no there is a there is no breakage between two kind of two segments.\n",
      "Yeah, I saw that for some reason this duplication postprocessing thing did not catch a right way of loading lower case in all the people is.\n",
      "cluster before alteration=========>\n",
      "Actually we were just it is to is already well informed discussion like in our mind and we just discussing to and fro and it would be similar to alakazoom recording where it is just play back and there is no miss a stronger silence points between signals.\n",
      "cluster before alteration=========>\n",
      "So whether there is a way to improve the quality of key phrases, I think we should not see any difference between the pins and communities from the key phrase quality perspective if I think because the input to them is different and then the inherently the communities were back.\n",
      "So otherwise if the community algorithm is good at the key phrases would be at least as good as the pin pin ches.\n",
      "cluster before alteration=========>\n",
      "Yeah, if the community is good and I like like they have enough content.\n",
      "Yeah, so yeah, pretty much those were the things those are the things that I am working on.\n",
      "So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings.\n",
      "And the other thing is I will make the changes for the communitybased summary.\n",
      "So we had this question that you are going to get you that list of groups and with analyzed take all right.\n",
      "cluster before alteration=========>\n",
      "It is a new service analysis service and even the schema thing.\n",
      "So I have mode all the analysis code from transcription service.\n",
      "So the changes are there like it still yet to be tested or that it was.\n",
      "So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.\n",
      "Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever.\n",
      "So slick if it is a segment strategy will go with volt annulment analyzer.\n",
      "cluster before alteration=========>\n",
      "So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.\n",
      "So where there was like sea and Earth has capitals and small and everything.\n",
      "So Google those got filtered but these who still came up.\n",
      "So so something like some fun videos that I am checking on me like an ideal way to remove.\n",
      "So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.\n",
      "So basically, I mean since there was no Stables, you are not maintaining any tables for actions.\n",
      "So by end of day today, I will end up dating curtain on my status.\n",
      "cluster before alteration=========>\n",
      "Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.\n",
      "So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.\n",
      "So currently I am working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it is done, I will deploy it on stage in two.\n",
      "cluster before alteration=========>\n",
      "Okay, but should you need any assistance from the front thinking of testing or evaluating certain part pieces of the yeah.\n",
      "cluster before alteration=========>\n",
      "So mostly like maybe like we will do it together and this chain XnumberX E both will help with the testing.\n",
      "cluster before alteration=========>\n",
      "Anytime your places where we need to call the apis and we need to figure out a way what they do what Zoom Force when they when somebody installs an apple with zoom account.\n",
      "So you need to get the account ID and last term if I remember there are few things missing.\n",
      "So even if I will check if they have change in there because they are not giving the parent account ID.\n",
      "Eid are U second to have multiple sub accounts, so we need to understand a little bit about\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Is there a like a test case of something that we can build to validate the performance or say consistently.\n",
      "If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.\n",
      "Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we are developing currently what all the tested all the tests meetings that we have our segment Centre, right?\n",
      "So then we started to gather this, you know, this body called communitycentric tests that we have.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yeah, a couple of things right on the on the community based teams.\n",
      "We had seen some somewhat off of the track pins yesterday.\n",
      "So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films.\n",
      "We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive.\n",
      "Actually So currently it is very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation.\n",
      "And they and also the body called the Dead the relationship formation the graph Community formation.\n",
      "But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control.\n",
      "We should not be doing like a blanket formation so which which is the problem that we have.\n",
      "I mean currently solving a tap from a more technical standpoint.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality.\n",
      "So I am a little aggressive there just to be sure that we are getting good sleep.\n",
      "And yeah on the action items, I just spoke to pressure on top Christian.\n",
      "The trans at least whatever it detects would be highly confident and can be reliable.\n",
      "And so I think we can enable that for The Ether engineering Channel.\n",
      "So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.\n",
      "So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.\n",
      "I will just add all the information to document whatever I find a husband.\n",
      "My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not.\n",
      "Just need to see even even with the believability cave might need to associate one workspace to XnumberX inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So we need to spend a little bit more time on that.\n",
      "A lot of losing out on the data because now through God we cannot even capture history as its history.\n",
      "Yeah, so sorry said like let us find out on this room thing.\n",
      "The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working.\n",
      "So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free.\n",
      "Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.\n",
      "So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad.\n",
      "Well find out but that is also we have seen we have seen few noises segments.\n",
      "That is why God or whether you are in an open.\n",
      "Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the\n",
      "Like I am constantly seeing the red network error going back and forth to the canteen.\n",
      "I think the biggest issue we are facing is with operate like being able to use the app at all.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Now what I have done is the key phrase since it does not have the popular graph flag red line has just commented it out because I am not sure whether it works or not if I sent a text.\n",
      "Little feature flag thing with popular graph is equal to false.\n",
      "But now I think in the request before you also get different modified text.\n",
      "So these were like hardcoded in the current key phrase except he faces function so I need okay.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.\n",
      "I just staggered a bit or for adding that bug snack logs the issues.\n",
      "So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.\n",
      "What recent call was Capcom was kept on loading right spinning.\n",
      "Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So because of that there is actually an overlap on the segments.\n",
      "Yeah, there is no there is a there is no breakage between two kind of two segments.\n",
      "Yeah, I saw that for some reason this duplication postprocessing thing did not catch a right way of loading lower case in all the people is.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Actually we were just it is to is already well informed discussion like in our mind and we just discussing to and fro and it would be similar to alakazoom recording where it is just play back and there is no miss a stronger silence points between signals.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So whether there is a way to improve the quality of key phrases, I think we should not see any difference between the pins and communities from the key phrase quality perspective if I think because the input to them is different and then the inherently the communities were back.\n",
      "So otherwise if the community algorithm is good at the key phrases would be at least as good as the pin pin ches.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yeah, if the community is good and I like like they have enough content.\n",
      "Yeah, so yeah, pretty much those were the things those are the things that I am working on.\n",
      "So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings.\n",
      "And the other thing is I will make the changes for the communitybased summary.\n",
      "So we had this question that you are going to get you that list of groups and with analyzed take all right.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "It is a new service analysis service and even the schema thing.\n",
      "So I have mode all the analysis code from transcription service.\n",
      "So the changes are there like it still yet to be tested or that it was.\n",
      "So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.\n",
      "Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever.\n",
      "So slick if it is a segment strategy will go with volt annulment analyzer.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.\n",
      "So where there was like sea and Earth has capitals and small and everything.\n",
      "So Google those got filtered but these who still came up.\n",
      "So so something like some fun videos that I am checking on me like an ideal way to remove.\n",
      "So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.\n",
      "So basically, I mean since there was no Stables, you are not maintaining any tables for actions.\n",
      "So by end of day today, I will end up dating curtain on my status.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.\n",
      "So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.\n",
      "So currently I am working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it is done, I will deploy it on stage in two.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Okay, but should you need any assistance from the front thinking of testing or evaluating certain part pieces of the yeah.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So mostly like maybe like we will do it together and this chain XnumberX E both will help with the testing.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Anytime your places where we need to call the apis and we need to figure out a way what they do what Zoom Force when they when somebody installs an apple with zoom account.\n",
      "So you need to get the account ID and last term if I remember there are few things missing.\n",
      "So even if I will check if they have change in there because they are not giving the parent account ID.\n",
      "Eid are U second to have multiple sub accounts, so we need to understand a little bit about\n",
      "\n",
      "\n",
      "Checking Timerange --------------\n",
      "--------------\n",
      "If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help. f621ac9d6aba42159cb4a49132967749 \n",
      "\n",
      "Is there a like a test case of something that we can build to validate the performance or say consistently. f621ac9d6aba42159cb4a49132967749 \n",
      "\n",
      "So then we started to gather this, you know, this body called communitycentric tests that we have. e4331d0b261b4239a82fba773bf0301c \n",
      "\n",
      "Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we are developing currently what all the tested all the tests meetings that we have our segment Centre, right? e4331d0b261b4239a82fba773bf0301c \n",
      "\n",
      "--------------\n",
      "But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "And they and also the body called the Dead the relationship formation the graph Community formation. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "I mean currently solving a tap from a more technical standpoint. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "We should not be doing like a blanket formation so which which is the problem that we have. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "Yeah, a couple of things right on the on the community based teams. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "We had seen some somewhat off of the track pins yesterday. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "Actually So currently it is very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "--------------\n",
      "So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "The trans at least whatever it detects would be highly confident and can be reliable. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "And so I think we can enable that for The Ether engineering Channel. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "So I am a little aggressive there just to be sure that we are getting good sleep. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "And yeah on the action items, I just spoke to pressure on top Christian. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. d578d8a89fb24790970910c74f5a98a4 \n",
      "\n",
      "--------------\n",
      "I will just add all the information to document whatever I find a husband. 353c7be408ed49cfa9bb90a35c8d6ca1 \n",
      "\n",
      "So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. 353c7be408ed49cfa9bb90a35c8d6ca1 \n",
      "\n",
      "So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. 6a565c02d9304106ab038ad6c21e686c \n",
      "\n",
      "My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. 6a565c02d9304106ab038ad6c21e686c \n",
      "\n",
      "Just need to see even even with the believability cave might need to associate one workspace to XnumberX inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. 6a565c02d9304106ab038ad6c21e686c \n",
      "\n",
      "--------------\n",
      "So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. 2e2647dded0c4765b33cbe192410e4a5 \n",
      "\n",
      "So we need to spend a little bit more time on that. 2e2647dded0c4765b33cbe192410e4a5 \n",
      "\n",
      "The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. 2e2647dded0c4765b33cbe192410e4a5 \n",
      "\n",
      "Yeah, so sorry said like let us find out on this room thing. e708f000baeb40c0be30454cd6edb3c5 \n",
      "\n",
      "Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way. e708f000baeb40c0be30454cd6edb3c5 \n",
      "\n",
      "A lot of losing out on the data because now through God we cannot even capture history as its history. 9b60758a5c6945ef821942903414bf11 \n",
      "\n",
      "So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore. 9b60758a5c6945ef821942903414bf11 \n",
      "\n",
      "--------------\n",
      "But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad. 3f528d8706c342adadc1177e4fa8f2c4 \n",
      "\n",
      "That is why God or whether you are in an open. 8dad9074cc044d00817d35e39186ef72 \n",
      "\n",
      "Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the 8dad9074cc044d00817d35e39186ef72 \n",
      "\n",
      "Well find out but that is also we have seen we have seen few noises segments. 8dad9074cc044d00817d35e39186ef72 \n",
      "\n",
      "Like I am constantly seeing the red network error going back and forth to the canteen. 92b083bc074d4c25b746d9e63d265fec \n",
      "\n",
      "I think the biggest issue we are facing is with operate like being able to use the app at all. 92b083bc074d4c25b746d9e63d265fec \n",
      "\n",
      "--------------\n",
      "So these were like hardcoded in the current key phrase except he faces function so I need okay. 10c80968772c4b4c839a3caa4a847342 \n",
      "\n",
      "But now I think in the request before you also get different modified text. 10c80968772c4b4c839a3caa4a847342 \n",
      "\n",
      "Little feature flag thing with popular graph is equal to false. 10c80968772c4b4c839a3caa4a847342 \n",
      "\n",
      "Now what I have done is the key phrase since it does not have the popular graph flag red line has just commented it out because I am not sure whether it works or not if I sent a text. a978434d3ba34453884c6ef07c763b85 \n",
      "\n",
      "--------------\n",
      "Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail. 1f21ff88317e4cdd8492ef55f0dd4de1 \n",
      "\n",
      "Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know, e04864365d1949b0a9f3ebedcefd59e9 \n",
      "\n",
      "So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task. e04864365d1949b0a9f3ebedcefd59e9 \n",
      "\n",
      "What recent call was Capcom was kept on loading right spinning. e04864365d1949b0a9f3ebedcefd59e9 \n",
      "\n",
      "I just staggered a bit or for adding that bug snack logs the issues. e04864365d1949b0a9f3ebedcefd59e9 \n",
      "\n",
      "--------------\n",
      "Yeah, there is no there is a there is no breakage between two kind of two segments. d7529d570c774cb6b87adef4784f9e26 \n",
      "\n",
      "So because of that there is actually an overlap on the segments. d7529d570c774cb6b87adef4784f9e26 \n",
      "\n",
      "Yeah, I saw that for some reason this duplication postprocessing thing did not catch a right way of loading lower case in all the people is. e82eda1dec5d46caa0d9bd0bb34b6453 \n",
      "\n",
      "--------------\n",
      "Actually we were just it is to is already well informed discussion like in our mind and we just discussing to and fro and it would be similar to alakazoom recording where it is just play back and there is no miss a stronger silence points between signals. f8d20183a3e34389865f1df3f2003b98 \n",
      "\n",
      "--------------\n",
      "So otherwise if the community algorithm is good at the key phrases would be at least as good as the pin pin ches. 348f137b708a456f8a134dd7268afee6 \n",
      "\n",
      "So whether there is a way to improve the quality of key phrases, I think we should not see any difference between the pins and communities from the key phrase quality perspective if I think because the input to them is different and then the inherently the communities were back. 348f137b708a456f8a134dd7268afee6 \n",
      "\n",
      "--------------\n",
      "Yeah, if the community is good and I like like they have enough content. 0c87b0d6af3f4cb79f39a025c3fdfd9b \n",
      "\n",
      "So we had this question that you are going to get you that list of groups and with analyzed take all right. 2bf145322e4d421484c5be3d34c45a58 \n",
      "\n",
      "So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. 2bf145322e4d421484c5be3d34c45a58 \n",
      "\n",
      "And the other thing is I will make the changes for the communitybased summary. 2bf145322e4d421484c5be3d34c45a58 \n",
      "\n",
      "Yeah, so yeah, pretty much those were the things those are the things that I am working on. 2bf145322e4d421484c5be3d34c45a58 \n",
      "\n",
      "--------------\n",
      "So the changes are there like it still yet to be tested or that it was. c41fd0e424e349f2b52789f4d4c73117 \n",
      "\n",
      "So I have mode all the analysis code from transcription service. c41fd0e424e349f2b52789f4d4c73117 \n",
      "\n",
      "It is a new service analysis service and even the schema thing. c41fd0e424e349f2b52789f4d4c73117 \n",
      "\n",
      "So slick if it is a segment strategy will go with volt annulment analyzer. 7b400835c1eb473391b033c4b0ec9755 \n",
      "\n",
      "So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. 7b400835c1eb473391b033c4b0ec9755 \n",
      "\n",
      "Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever. 7b400835c1eb473391b033c4b0ec9755 \n",
      "\n",
      "--------------\n",
      "So Google those got filtered but these who still came up. 03bdb0a4e7ae4e3985582c5bd2dd4dca \n",
      "\n",
      "So where there was like sea and Earth has capitals and small and everything. 03bdb0a4e7ae4e3985582c5bd2dd4dca \n",
      "\n",
      "So so something like some fun videos that I am checking on me like an ideal way to remove. 03bdb0a4e7ae4e3985582c5bd2dd4dca \n",
      "\n",
      "So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. 03bdb0a4e7ae4e3985582c5bd2dd4dca \n",
      "\n",
      "So by end of day today, I will end up dating curtain on my status. 212eb9ca06d04dec9f8928e34bd595d3 \n",
      "\n",
      "So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. 212eb9ca06d04dec9f8928e34bd595d3 \n",
      "\n",
      "So basically, I mean since there was no Stables, you are not maintaining any tables for actions. 212eb9ca06d04dec9f8928e34bd595d3 \n",
      "\n",
      "--------------\n",
      "Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue. 979467829a7a4b19a856890922031440 \n",
      "\n",
      "So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. 9bf5fd91a17a4f0f89b202d8e9a03baf \n",
      "\n",
      "So currently I am working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it is done, I will deploy it on stage in two. 9bf5fd91a17a4f0f89b202d8e9a03baf \n",
      "\n",
      "--------------\n",
      "Okay, but should you need any assistance from the front thinking of testing or evaluating certain part pieces of the yeah. 33291fe1c24442308d90c7ef54f23696 \n",
      "\n",
      "--------------\n",
      "So mostly like maybe like we will do it together and this chain XnumberX E both will help with the testing. 41d1a59fd6b249c3a4820673184b0598 \n",
      "\n",
      "--------------\n",
      "Anytime your places where we need to call the apis and we need to figure out a way what they do what Zoom Force when they when somebody installs an apple with zoom account. 495198df58aa4f4f99110e8b84e27e9f \n",
      "\n",
      "So even if I will check if they have change in there because they are not giving the parent account ID. 495198df58aa4f4f99110e8b84e27e9f \n",
      "\n",
      "Eid are U second to have multiple sub accounts, so we need to understand a little bit about 495198df58aa4f4f99110e8b84e27e9f \n",
      "\n",
      "So you need to get the account ID and last term if I remember there are few things missing. 495198df58aa4f4f99110e8b84e27e9f \n",
      "\n",
      "<---------------->\n",
      "order difference: 0\n",
      "Relevant sentence:  If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.    =====    Is there a like a test case of something that we can build to validate the performance or say consistently.\n",
      "order difference: 1\n",
      "Relevant sentence:  Is there a like a test case of something that we can build to validate the performance or say consistently.    =====    So then we started to gather this, you know, this body called communitycentric tests that we have.\n",
      "order difference: 0\n",
      "Relevant sentence:  So then we started to gather this, you know, this body called communitycentric tests that we have.    =====    Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we are developing currently what all the tested all the tests meetings that we have our segment Centre, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control.    =====    We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive.\n",
      "order difference: 0\n",
      "Relevant sentence:  We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive.    =====    And they and also the body called the Dead the relationship formation the graph Community formation.\n",
      "order difference: 0\n",
      "Relevant sentence:  And they and also the body called the Dead the relationship formation the graph Community formation.    =====    I mean currently solving a tap from a more technical standpoint.\n",
      "order difference: 0\n",
      "Relevant sentence:  I mean currently solving a tap from a more technical standpoint.    =====    We should not be doing like a blanket formation so which which is the problem that we have.\n",
      "order difference: 0\n",
      "Relevant sentence:  We should not be doing like a blanket formation so which which is the problem that we have.    =====    Yeah, a couple of things right on the on the community based teams.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, a couple of things right on the on the community based teams.    =====    So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films.\n",
      "order difference: 0\n",
      "Relevant sentence:  So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films.    =====    We had seen some somewhat off of the track pins yesterday.\n",
      "order difference: 0\n",
      "Relevant sentence:  We had seen some somewhat off of the track pins yesterday.    =====    Actually So currently it is very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation.\n",
      "order difference: 0\n",
      "Relevant sentence:  So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality.    =====    The trans at least whatever it detects would be highly confident and can be reliable.\n",
      "order difference: 0\n",
      "Relevant sentence:  The trans at least whatever it detects would be highly confident and can be reliable.    =====    And so I think we can enable that for The Ether engineering Channel.\n",
      "order difference: 0\n",
      "Relevant sentence:  And so I think we can enable that for The Ether engineering Channel.    =====    So I am a little aggressive there just to be sure that we are getting good sleep.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I am a little aggressive there just to be sure that we are getting good sleep.    =====    And yeah on the action items, I just spoke to pressure on top Christian.\n",
      "order difference: 1\n",
      "Relevant sentence:  And yeah on the action items, I just spoke to pressure on top Christian.    =====    So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.\n",
      "order difference: 0\n",
      "Relevant sentence:  I will just add all the information to document whatever I find a husband.    =====    So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.\n",
      "order difference: 1\n",
      "Relevant sentence:  So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.    =====    So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.    =====    My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not.\n",
      "order difference: 0\n",
      "Relevant sentence:  My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not.    =====    Just need to see even even with the believability cave might need to associate one workspace to XnumberX inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free.    =====    So we need to spend a little bit more time on that.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we need to spend a little bit more time on that.    =====    The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working.\n",
      "order difference: 1\n",
      "Relevant sentence:  The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working.    =====    Yeah, so sorry said like let us find out on this room thing.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, so sorry said like let us find out on this room thing.    =====    Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.\n",
      "order difference: 1\n",
      "Relevant sentence:  Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.    =====    A lot of losing out on the data because now through God we cannot even capture history as its history.\n",
      "order difference: 0\n",
      "Relevant sentence:  A lot of losing out on the data because now through God we cannot even capture history as its history.    =====    So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.\n",
      "order difference: 1\n",
      "Relevant sentence:  But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad.    =====    That is why God or whether you are in an open.\n",
      "order difference: 0\n",
      "Relevant sentence:  That is why God or whether you are in an open.    =====    Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the\n",
      "order difference: 0\n",
      "Relevant sentence:  Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the    =====    Well find out but that is also we have seen we have seen few noises segments.\n",
      "Not Relevant sentence:  Well find out but that is also we have seen we have seen few noises segments.    !=    Like I am constantly seeing the red network error going back and forth to the canteen.\n",
      "order difference: 19\n",
      "order difference: 0\n",
      "Relevant sentence:  Like I am constantly seeing the red network error going back and forth to the canteen.    =====    I think the biggest issue we are facing is with operate like being able to use the app at all.\n",
      "order difference: 0\n",
      "Relevant sentence:  So these were like hardcoded in the current key phrase except he faces function so I need okay.    =====    But now I think in the request before you also get different modified text.\n",
      "order difference: 0\n",
      "Relevant sentence:  But now I think in the request before you also get different modified text.    =====    Little feature flag thing with popular graph is equal to false.\n",
      "Not Relevant sentence:  Little feature flag thing with popular graph is equal to false.    !=    Now what I have done is the key phrase since it does not have the popular graph flag red line has just commented it out because I am not sure whether it works or not if I sent a text.\n",
      "order difference: 6\n",
      "order difference: 1\n",
      "Relevant sentence:  Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.    =====    Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,\n",
      "order difference: 0\n",
      "Relevant sentence:  Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,    =====    So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.\n",
      "order difference: 0\n",
      "Relevant sentence:  So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.    =====    What recent call was Capcom was kept on loading right spinning.\n",
      "order difference: 0\n",
      "Relevant sentence:  What recent call was Capcom was kept on loading right spinning.    =====    I just staggered a bit or for adding that bug snack logs the issues.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, there is no there is a there is no breakage between two kind of two segments.    =====    So because of that there is actually an overlap on the segments.\n",
      "Not Relevant sentence:  So because of that there is actually an overlap on the segments.    !=    Yeah, I saw that for some reason this duplication postprocessing thing did not catch a right way of loading lower case in all the people is.\n",
      "order difference: 6\n",
      "order difference: 0\n",
      "Relevant sentence:  So otherwise if the community algorithm is good at the key phrases would be at least as good as the pin pin ches.    =====    So whether there is a way to improve the quality of key phrases, I think we should not see any difference between the pins and communities from the key phrase quality perspective if I think because the input to them is different and then the inherently the communities were back.\n",
      "order difference: 1\n",
      "Relevant sentence:  Yeah, if the community is good and I like like they have enough content.    =====    So we had this question that you are going to get you that list of groups and with analyzed take all right.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we had this question that you are going to get you that list of groups and with analyzed take all right.    =====    So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings.\n",
      "order difference: 0\n",
      "Relevant sentence:  So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings.    =====    And the other thing is I will make the changes for the communitybased summary.\n",
      "order difference: 0\n",
      "Relevant sentence:  And the other thing is I will make the changes for the communitybased summary.    =====    Yeah, so yeah, pretty much those were the things those are the things that I am working on.\n",
      "order difference: 0\n",
      "Relevant sentence:  So the changes are there like it still yet to be tested or that it was.    =====    So I have mode all the analysis code from transcription service.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I have mode all the analysis code from transcription service.    =====    It is a new service analysis service and even the schema thing.\n",
      "order difference: 1\n",
      "Relevant sentence:  It is a new service analysis service and even the schema thing.    =====    So slick if it is a segment strategy will go with volt annulment analyzer.\n",
      "order difference: 0\n",
      "Relevant sentence:  So slick if it is a segment strategy will go with volt annulment analyzer.    =====    So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.\n",
      "order difference: 0\n",
      "Relevant sentence:  So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.    =====    Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever.\n",
      "order difference: 0\n",
      "Relevant sentence:  So Google those got filtered but these who still came up.    =====    So where there was like sea and Earth has capitals and small and everything.\n",
      "order difference: 0\n",
      "Relevant sentence:  So where there was like sea and Earth has capitals and small and everything.    =====    So so something like some fun videos that I am checking on me like an ideal way to remove.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so something like some fun videos that I am checking on me like an ideal way to remove.    =====    So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.\n",
      "order difference: 1\n",
      "Relevant sentence:  So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.    =====    So by end of day today, I will end up dating curtain on my status.\n",
      "order difference: 0\n",
      "Relevant sentence:  So by end of day today, I will end up dating curtain on my status.    =====    So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.\n",
      "order difference: 0\n",
      "Relevant sentence:  So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.    =====    So basically, I mean since there was no Stables, you are not maintaining any tables for actions.\n",
      "order difference: 1\n",
      "Relevant sentence:  Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.    =====    So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.\n",
      "order difference: 0\n",
      "Relevant sentence:  So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.    =====    So currently I am working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it is done, I will deploy it on stage in two.\n",
      "order difference: 0\n",
      "Relevant sentence:  Anytime your places where we need to call the apis and we need to figure out a way what they do what Zoom Force when they when somebody installs an apple with zoom account.    =====    So even if I will check if they have change in there because they are not giving the parent account ID.\n",
      "order difference: 0\n",
      "Relevant sentence:  So even if I will check if they have change in there because they are not giving the parent account ID.    =====    Eid are U second to have multiple sub accounts, so we need to understand a little bit about\n",
      "order difference: 0\n",
      "Relevant sentence:  Eid are U second to have multiple sub accounts, so we need to understand a little bit about    =====    So you need to get the account ID and last term if I remember there are few things missing.\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 959, \"module\": \"grouper_segments\", \"PIMs\": {\"0\": {\"segment0\": [[\"Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail. \"], \"2019-11-05T06:49:26Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"1f21ff88317e4cdd8492ef55f0dd4de1\"], \"segment1\": [[\"I just staggered a bit or for adding that bug snack logs the issues. I was with me yesterday. What recent call was Capcom was kept on loading right spinning. So once the build is done, we'll just test it again and then a sinking I haven't yet started on the localization task. Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know, \"], \"2019-11-05T06:51:53Z\", \"c66797a92e6d46ad9573926e57f7dac3\", \"e04864365d1949b0a9f3ebedcefd59e9\"]}, \"1\": {\"segment0\": [[\"Yeah, a couple of things right on the on the community based teams. We had seen some somewhat off of the track pins yesterday. So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it's illogical book, so he's going to fix that today and And that s*** - or at least improve improve the way we are seeing the community based films. I mean it wouldn't be so off but still parallely. We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive. Actually So currently it's very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation. And they and also the body called the Dead the relationship formation the graph Community formation. So it needs some experimentation. We are we are discussing on that and also parallel. We are what you call experimenting so we should have when we will keep you posted on this. But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control. So it's like a blanket hierarchy for Direction. So we have to take control of that. That means we should be fuzzy about it. We shouldn't be doing like a blanket formation so which which is the problem that we have. I mean currently solving a tap from a more technical standpoint. \"], \"2019-11-05T06:33:54Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"516dce6af97741929a1da5e52d0d4a16\"]}, \"2\": {\"segment0\": [[\"The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. So we need to spend a little bit more time on that. So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. I can also look into upgrading that JavaScript. \"], \"2019-11-05T06:56:44Z\", \"1a21542584494fcaba957d768b595b80\", \"2e2647dded0c4765b33cbe192410e4a5\"], \"segment1\": [[\"Yeah, so sorry said like let's find out on this room thing. Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so We're just gonna put this way. \"], \"2019-11-05T06:57:38Z\", \"1a21542584494fcaba957d768b595b80\", \"e708f000baeb40c0be30454cd6edb3c5\"], \"segment2\": [[\"A lot of losing out on the data because now through God we cannot even capture history as its history. So at least we should start getting data as my concern you can in a soil to check but that's why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore. \"], \"2019-11-05T06:58:11Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"9b60758a5c6945ef821942903414bf11\"]}, \"3\": {\"segment0\": [[\"Yogurt for somebody new the new community-based summary, right? So I have mode all the analysis code from transcription service. It's a new service analysis service and even the schema thing. So the changes are there like it still yet to be tested or that it was. \"], \"2019-11-05T06:46:19Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"c41fd0e424e349f2b52789f4d4c73117\"], \"segment1\": [[\"So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. So slick if it is a segment strategy will go with volt annulment analyzer. Otherwise, we'll go with their Community segment analyzer the the that's all like and also the summary we also moved to a different schema all those push the code now Cody's first time ever. \"], \"2019-11-05T06:46:42Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"7b400835c1eb473391b033c4b0ec9755\"]}, \"4\": {\"segment0\": [[\"Let's say we even do this. Is there a like a test case of something that we can build to validate the performance or say consistently. This is based on this these test cases. This is better than the what we have right now. Yes. If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help. \"], \"2019-11-05T06:35:50Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"f621ac9d6aba42159cb4a49132967749\"], \"segment1\": [[\"Yeah, we have the test set. Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we're developing currently what all the tested all the tests meetings that we have our segment Centre, right? So then we started to gather this, you know, this body called community-centric tests that we have. Going to build so there is also parallel going on. So any validation would happen on that. W? \"], \"2019-11-05T06:36:22Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"e4331d0b261b4239a82fba773bf0301c\"]}, \"5\": {\"segment0\": [[\"So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. So let me see what I can find. I'll just add all the information to document whatever I find a husband. \"], \"2019-11-05T06:55:16Z\", \"1a21542584494fcaba957d768b595b80\", \"353c7be408ed49cfa9bb90a35c8d6ca1\"], \"segment1\": [[\"My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. So I'm just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. Just need to see even even with the believability cave might need to associate one workspace to 1 inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. Okay. \"], \"2019-11-05T06:56:01Z\", \"1a21542584494fcaba957d768b595b80\", \"6a565c02d9304106ab038ad6c21e686c\"]}, \"6\": {\"segment0\": [[\"Yeah, because eventually that's what we see, right? Yeah, if the community is good and I like like they have enough content. I think whatever we see for the pins would reflect their so let's go God. Yeah. \"], \"2019-11-05T06:40:39Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"0c87b0d6af3f4cb79f39a025c3fdfd9b\"], \"segment1\": [[\"Yeah, so yeah, pretty much those were the things those are the things that I'm working on. So like converting. So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I'm going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. How's it going? What is the approach and what it requires as input? And the other thing is I'll make the changes for the community-based summary. So we had this question that you're going to get you that list of groups and with analyzed take all right. \"], \"2019-11-05T06:42:13Z\", \"7e7ccbba232d411aa95ad3f244a35f40\", \"2bf145322e4d421484c5be3d34c45a58\"]}, \"7\": {\"segment0\": [[\"So in before post-processing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. So where there was like sea and Earth has capitals and small and everything. So Google those got filtered but these who still came up. So so something like some fun videos that I'm checking on me like an ideal way to remove. \"], \"2019-11-05T06:44:42Z\", \"7e7ccbba232d411aa95ad3f244a35f40\", \"03bdb0a4e7ae4e3985582c5bd2dd4dca\"], \"segment1\": [[\"So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. So basically, I mean since there was no Stables, you're not maintaining any tables for actions. No, it's taking some time. So by end of day today, I'll end up dating curtain on my status. \"], \"2019-11-05T06:45:34Z\", \"75bdf310110b4b8fab88b16fafce920e\", \"212eb9ca06d04dec9f8928e34bd595d3\"]}, \"8\": {\"segment0\": [[\"But the bim's did look, okay, like if you look at the films as opposed to the chapters, yeah, there's not necessarily bad. It's actually pretty decent terms if this is a detective, yeah. \"], \"2019-11-05T06:38:40Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"3f528d8706c342adadc1177e4fa8f2c4\"], \"segment1\": [[\"We'll find out but that's also we have seen we have seen few noises segments. That's why God or whether you are in an open. Mike. Well, you're on the actual headphones are on the open window the own societies that a call and iOS and you just get the \"], \"2019-11-05T06:38:54Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"8dad9074cc044d00817d35e39186ef72\"]}, \"9\": {\"segment0\": [[\"And yeah on the action items, I just spoke to pressure on top Christian. So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. Whereas I think we fairly have good. The trans at least whatever it detects would be highly confident and can be reliable. So I'm a little aggressive there just to be sure that we are getting good sleep. And so I think we can enable that for The Ether engineering Channel. \"], \"2019-11-05T06:37:00Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"a7d82816e0d24b9dbe4f43645f5f0384\"], \"segment1\": [[\"So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. Yeah. \"], \"2019-11-05T06:38:13Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"d578d8a89fb24790970910c74f5a98a4\"]}, \"10\": {\"segment0\": [[\"Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue. \"], \"2019-11-05T06:47:51Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"979467829a7a4b19a856890922031440\"], \"segment1\": [[\"So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. So currently I'm working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it's done, I'll deploy it on stage in two. \"], \"2019-11-05T06:48:25Z\", \"0bbbfe84c66145af8d0ffcd5258bba38\", \"9bf5fd91a17a4f0f89b202d8e9a03baf\"]}}, \"ts\": \"2019-12-06T11:23:58.622472Z\", \"msg\": \"Final PIMs\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail. '], '2019-11-05T06:49:26Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '1f21ff88317e4cdd8492ef55f0dd4de1'], [[\"I just staggered a bit or for adding that bug snack logs the issues. I was with me yesterday. What recent call was Capcom was kept on loading right spinning. So once the build is done, we'll just test it again and then a sinking I haven't yet started on the localization task. Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know, \"], '2019-11-05T06:51:53Z', 'c66797a92e6d46ad9573926e57f7dac3', 'e04864365d1949b0a9f3ebedcefd59e9']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yeah, a couple of things right on the on the community based teams. We had seen some somewhat off of the track pins yesterday. So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it's illogical book, so he's going to fix that today and And that s*** - or at least improve improve the way we are seeing the community based films. I mean it wouldn't be so off but still parallely. We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive. Actually So currently it's very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation. And they and also the body called the Dead the relationship formation the graph Community formation. So it needs some experimentation. We are we are discussing on that and also parallel. We are what you call experimenting so we should have when we will keep you posted on this. But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control. So it's like a blanket hierarchy for Direction. So we have to take control of that. That means we should be fuzzy about it. We shouldn't be doing like a blanket formation so which which is the problem that we have. I mean currently solving a tap from a more technical standpoint. \"], '2019-11-05T06:33:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '516dce6af97741929a1da5e52d0d4a16']]\n",
      "====================Group Cluster=========================\n",
      "[[['The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. So we need to spend a little bit more time on that. So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. I can also look into upgrading that JavaScript. '], '2019-11-05T06:56:44Z', '1a21542584494fcaba957d768b595b80', '2e2647dded0c4765b33cbe192410e4a5'], [[\"Yeah, so sorry said like let's find out on this room thing. Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so We're just gonna put this way. \"], '2019-11-05T06:57:38Z', '1a21542584494fcaba957d768b595b80', 'e708f000baeb40c0be30454cd6edb3c5'], [[\"A lot of losing out on the data because now through God we cannot even capture history as its history. So at least we should start getting data as my concern you can in a soil to check but that's why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore. \"], '2019-11-05T06:58:11Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9b60758a5c6945ef821942903414bf11']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yogurt for somebody new the new community-based summary, right? So I have mode all the analysis code from transcription service. It's a new service analysis service and even the schema thing. So the changes are there like it still yet to be tested or that it was. \"], '2019-11-05T06:46:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c41fd0e424e349f2b52789f4d4c73117'], [[\"So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. So slick if it is a segment strategy will go with volt annulment analyzer. Otherwise, we'll go with their Community segment analyzer the the that's all like and also the summary we also moved to a different schema all those push the code now Cody's first time ever. \"], '2019-11-05T06:46:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '7b400835c1eb473391b033c4b0ec9755']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"Let's say we even do this. Is there a like a test case of something that we can build to validate the performance or say consistently. This is based on this these test cases. This is better than the what we have right now. Yes. If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help. \"], '2019-11-05T06:35:50Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'f621ac9d6aba42159cb4a49132967749'], [[\"Yeah, we have the test set. Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we're developing currently what all the tested all the tests meetings that we have our segment Centre, right? So then we started to gather this, you know, this body called community-centric tests that we have. Going to build so there is also parallel going on. So any validation would happen on that. W? \"], '2019-11-05T06:36:22Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e4331d0b261b4239a82fba773bf0301c']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. So let me see what I can find. I'll just add all the information to document whatever I find a husband. \"], '2019-11-05T06:55:16Z', '1a21542584494fcaba957d768b595b80', '353c7be408ed49cfa9bb90a35c8d6ca1'], [[\"My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. So I'm just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. Just need to see even even with the believability cave might need to associate one workspace to 1 inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. Okay. \"], '2019-11-05T06:56:01Z', '1a21542584494fcaba957d768b595b80', '6a565c02d9304106ab038ad6c21e686c']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yeah, because eventually that's what we see, right? Yeah, if the community is good and I like like they have enough content. I think whatever we see for the pins would reflect their so let's go God. Yeah. \"], '2019-11-05T06:40:39Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '0c87b0d6af3f4cb79f39a025c3fdfd9b'], [[\"Yeah, so yeah, pretty much those were the things those are the things that I'm working on. So like converting. So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I'm going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. How's it going? What is the approach and what it requires as input? And the other thing is I'll make the changes for the community-based summary. So we had this question that you're going to get you that list of groups and with analyzed take all right. \"], '2019-11-05T06:42:13Z', '7e7ccbba232d411aa95ad3f244a35f40', '2bf145322e4d421484c5be3d34c45a58']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"So in before post-processing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. So where there was like sea and Earth has capitals and small and everything. So Google those got filtered but these who still came up. So so something like some fun videos that I'm checking on me like an ideal way to remove. \"], '2019-11-05T06:44:42Z', '7e7ccbba232d411aa95ad3f244a35f40', '03bdb0a4e7ae4e3985582c5bd2dd4dca'], [[\"So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. So basically, I mean since there was no Stables, you're not maintaining any tables for actions. No, it's taking some time. So by end of day today, I'll end up dating curtain on my status. \"], '2019-11-05T06:45:34Z', '75bdf310110b4b8fab88b16fafce920e', '212eb9ca06d04dec9f8928e34bd595d3']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"But the bim's did look, okay, like if you look at the films as opposed to the chapters, yeah, there's not necessarily bad. It's actually pretty decent terms if this is a detective, yeah. \"], '2019-11-05T06:38:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3f528d8706c342adadc1177e4fa8f2c4'], [[\"We'll find out but that's also we have seen we have seen few noises segments. That's why God or whether you are in an open. Mike. Well, you're on the actual headphones are on the open window the own societies that a call and iOS and you just get the \"], '2019-11-05T06:38:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '8dad9074cc044d00817d35e39186ef72']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"And yeah on the action items, I just spoke to pressure on top Christian. So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. Whereas I think we fairly have good. The trans at least whatever it detects would be highly confident and can be reliable. So I'm a little aggressive there just to be sure that we are getting good sleep. And so I think we can enable that for The Ether engineering Channel. \"], '2019-11-05T06:37:00Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a7d82816e0d24b9dbe4f43645f5f0384'], [['So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. Yeah. '], '2019-11-05T06:38:13Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'd578d8a89fb24790970910c74f5a98a4']]\n",
      "====================Group Cluster=========================\n",
      "[[['Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue. '], '2019-11-05T06:47:51Z', '84fbaa66a2474ea29ae053f3a2e519d6', '979467829a7a4b19a856890922031440'], [[\"So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. So currently I'm working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it's done, I'll deploy it on stage in two. \"], '2019-11-05T06:48:25Z', '0bbbfe84c66145af8d0ffcd5258bba38', '9bf5fd91a17a4f0f89b202d8e9a03baf']]\n"
     ]
    }
   ],
   "source": [
    "from main import handler\n",
    "\n",
    "res = handler(request, None)\n",
    "group2 = json.loads(res['body'])\n",
    "\n",
    "group_sorted = {}\n",
    "group_sorted [\"group\"] = {}\n",
    "temp_group = sorted(group2['group'].items(), key= lambda kv:kv[1][0]['startTime'], reverse=False)\n",
    "for g in temp_group:\n",
    "    group_sorted[\"group\"][g[0]] = g[1]\n",
    "\n",
    "group2 = group_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "9\n",
      "8\n",
      "6\n",
      "7\n",
      "3\n",
      "10\n",
      "0\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for g in group2['group'].keys():\n",
    "    if len(group2['group'][g])>1:\n",
    "        print (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:20:50  to  -21 days, 0:21:22 \n",
      "\n",
      "\n",
      "Let's say we even do this. Is there a like a test case of something that we can build to validate the performance or say consistently. This is based on this these test cases. This is better than the what we have right now. Yes. If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.  \n",
      "\n",
      "Yeah, we have the test set. Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we're developing currently what all the tested all the tests meetings that we have our segment Centre, right? So then we started to gather this, you know, this body called community-centric tests that we have. Going to build so there is also parallel going on. So any validation would happen on that. W?  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:22:00  to  -21 days, 0:23:13 \n",
      "\n",
      "\n",
      "And yeah on the action items, I just spoke to pressure on top Christian. So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. Whereas I think we fairly have good. The trans at least whatever it detects would be highly confident and can be reliable. So I'm a little aggressive there just to be sure that we are getting good sleep. And so I think we can enable that for The Ether engineering Channel.  \n",
      "\n",
      "So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. Yeah.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:23:40  to  -21 days, 0:23:54 \n",
      "\n",
      "\n",
      "But the bim's did look, okay, like if you look at the films as opposed to the chapters, yeah, there's not necessarily bad. It's actually pretty decent terms if this is a detective, yeah.  \n",
      "\n",
      "We'll find out but that's also we have seen we have seen few noises segments. That's why God or whether you are in an open. Mike. Well, you're on the actual headphones are on the open window the own societies that a call and iOS and you just get the  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:25:39  to  -21 days, 0:27:13 \n",
      "\n",
      "\n",
      "Yeah, because eventually that's what we see, right? Yeah, if the community is good and I like like they have enough content. I think whatever we see for the pins would reflect their so let's go God. Yeah.  \n",
      "\n",
      "Yeah, so yeah, pretty much those were the things those are the things that I'm working on. So like converting. So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I'm going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. How's it going? What is the approach and what it requires as input? And the other thing is I'll make the changes for the community-based summary. So we had this question that you're going to get you that list of groups and with analyzed take all right.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:29:42  to  -21 days, 0:30:34 \n",
      "\n",
      "\n",
      "So in before post-processing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. So where there was like sea and Earth has capitals and small and everything. So Google those got filtered but these who still came up. So so something like some fun videos that I'm checking on me like an ideal way to remove.  \n",
      "\n",
      "So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. So basically, I mean since there was no Stables, you're not maintaining any tables for actions. No, it's taking some time. So by end of day today, I'll end up dating curtain on my status.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:31:19  to  -21 days, 0:31:42 \n",
      "\n",
      "\n",
      "Yogurt for somebody new the new community-based summary, right? So I have mode all the analysis code from transcription service. It's a new service analysis service and even the schema thing. So the changes are there like it still yet to be tested or that it was.  \n",
      "\n",
      "So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. So slick if it is a segment strategy will go with volt annulment analyzer. Otherwise, we'll go with their Community segment analyzer the the that's all like and also the summary we also moved to a different schema all those push the code now Cody's first time ever.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:32:51  to  -21 days, 0:33:25 \n",
      "\n",
      "\n",
      "Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.  \n",
      "\n",
      "So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. So currently I'm working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it's done, I'll deploy it on stage in two.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:34:26  to  -21 days, 0:36:53 \n",
      "\n",
      "\n",
      "Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.  \n",
      "\n",
      "I just staggered a bit or for adding that bug snack logs the issues. I was with me yesterday. What recent call was Capcom was kept on loading right spinning. So once the build is done, we'll just test it again and then a sinking I haven't yet started on the localization task. Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:40:16  to  -21 days, 0:41:01 \n",
      "\n",
      "\n",
      "So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. So let me see what I can find. I'll just add all the information to document whatever I find a husband.  \n",
      "\n",
      "My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. So I'm just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. Just need to see even even with the believability cave might need to associate one workspace to 1 inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. Okay.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:41:44  to  -21 days, 0:43:11 \n",
      "\n",
      "\n",
      "The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. So we need to spend a little bit more time on that. So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. I can also look into upgrading that JavaScript.  \n",
      "\n",
      "Yeah, so sorry said like let's find out on this room thing. Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so We're just gonna put this way.  \n",
      "\n",
      "A lot of losing out on the data because now through God we cannot even capture history as its history. So at least we should start getting data as my concern you can in a soil to check but that's why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "from backports.datetime_fromisoformat import MonkeyPatch\n",
    "MonkeyPatch.patch_fromisoformat()\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True) #eng_19\n",
    "#m_time = formatTime(\"2019-09-20T07:12:00Z\", True) #eng_front_end_20\n",
    "#m_time = formatTime(\"2019-09-24T06:11:00Z\", True) #eng_24\n",
    "#m_time = formatTime(\"2019-10-04T05:44:00Z\", True)  #podcast_04\n",
    "#m_time = formatTime(\"2019-10-08T11:55:00Z\", True)  #podcast_08\n",
    "#m_time = formatTime(\"2019-10-14T06:04:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "#m_time = formatTime(\"2019-11-26T09:03:00Z\", True)  # set_1\n",
    "#m_time = formatTime(\"2019-11-21T06:30:00Z\", True) # sync_11_21\n",
    "#m_time = formatTime(\"2019-11-25T09:35:00Z\", True) # sync_11_25_ml\n",
    "m_time = formatTime(\"2019-11-26T06:15:00Z\", True) # sync_11_26\n",
    "for i in group2['group'].keys():\n",
    "    if len(group2['group'][i])!=1:\n",
    "        print (\"\\n\\n Chapter Discussion:  \", formatTime(group2['group'][i][0]['startTime'], True) - m_time, \" to \", formatTime(group2['group'][i][-1]['startTime'], True) - m_time, \"\\n\\n\")\n",
    "        for seg in group2['group'][i]:\n",
    "            #print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "            print (seg['originalText'],\"\\n\")\n",
    "    \n",
    "#     elif len(group['group'][i])==1:\n",
    "#         print (\"\\n\\n Chapter Discussion:  \", formatTime(group['group'][i][0]['startTime'], True) - m_time , \"\\n\\n\")\n",
    "#         for seg in group['group'][i]:\n",
    "#             #print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "#             print (seg['originalText'],\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Id:  4\n",
      "Karthik Muralidharan, Venkata Dikshit Discussed \n",
      "\n",
      " Text:  Let's say we even do this. Is there a like a test case of something that we can build to validate the performance or say consistently. This is based on this these test cases. This is better than the what we have right now. Yes. If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.  Yeah, we have the test set. Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we're developing currently what all the tested all the tests meetings that we have our segment Centre, right? So then we started to gather this, you know, this body called community-centric tests that we have. Going to build so there is also parallel going on. So any validation would happen on that. W?  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  9\n",
      "Venkata Dikshit, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  And yeah on the action items, I just spoke to pressure on top Christian. So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. Whereas I think we fairly have good. The trans at least whatever it detects would be highly confident and can be reliable. So I'm a little aggressive there just to be sure that we are getting good sleep. And so I think we can enable that for The Ether engineering Channel.  So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. Yeah.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  8\n",
      "Karthik Muralidharan, Venkata Dikshit Discussed \n",
      "\n",
      " Text:  But the bim's did look, okay, like if you look at the films as opposed to the chapters, yeah, there's not necessarily bad. It's actually pretty decent terms if this is a detective, yeah.  We'll find out but that's also we have seen we have seen few noises segments. That's why God or whether you are in an open. Mike. Well, you're on the actual headphones are on the open window the own societies that a call and iOS and you just get the  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  6\n",
      "Venkata Dikshit, Shashank Discussed \n",
      "\n",
      " Text:  Yeah, because eventually that's what we see, right? Yeah, if the community is good and I like like they have enough content. I think whatever we see for the pins would reflect their so let's go God. Yeah.  Yeah, so yeah, pretty much those were the things those are the things that I'm working on. So like converting. So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I'm going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. How's it going? What is the approach and what it requires as input? And the other thing is I'll make the changes for the community-based summary. So we had this question that you're going to get you that list of groups and with analyzed take all right.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  7\n",
      "Shashank, Trishanth Diwate Discussed \n",
      "\n",
      " Text:  So in before post-processing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. So where there was like sea and Earth has capitals and small and everything. So Google those got filtered but these who still came up. So so something like some fun videos that I'm checking on me like an ideal way to remove.  So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. So basically, I mean since there was no Stables, you're not maintaining any tables for actions. No, it's taking some time. So by end of day today, I'll end up dating curtain on my status.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  3\n",
      "Mithun Discussed \n",
      "\n",
      " Text:  Yogurt for somebody new the new community-based summary, right? So I have mode all the analysis code from transcription service. It's a new service analysis service and even the schema thing. So the changes are there like it still yet to be tested or that it was.  So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. So slick if it is a segment strategy will go with volt annulment analyzer. Otherwise, we'll go with their Community segment analyzer the the that's all like and also the summary we also moved to a different schema all those push the code now Cody's first time ever.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  10\n",
      "Mithun, Parshwa Nemi Jain Discussed \n",
      "\n",
      " Text:  Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.  So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. So currently I'm working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it's done, I'll deploy it on stage in two.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  0\n",
      "Karthik Muralidharan, Nisha Yadav Discussed \n",
      "\n",
      " Text:  Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.  I just staggered a bit or for adding that bug snack logs the issues. I was with me yesterday. What recent call was Capcom was kept on loading right spinning. So once the build is done, we'll just test it again and then a sinking I haven't yet started on the localization task. Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  5\n",
      "Vamshi Krishna Discussed \n",
      "\n",
      " Text:  So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. So let me see what I can find. I'll just add all the information to document whatever I find a husband.  My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. So I'm just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. Just need to see even even with the believability cave might need to associate one workspace to 1 inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. Okay.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  2\n",
      "Vamshi Krishna, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. So we need to spend a little bit more time on that. So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. I can also look into upgrading that JavaScript.  Yeah, so sorry said like let's find out on this room thing. Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so We're just gonna put this way.  A lot of losing out on the data because now through God we cannot even capture history as its history. So at least we should start getting data as my concern you can in a soil to check but that's why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.  \n",
      "\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id_map = {}\n",
    "user_id_map = {\"8fff81b5b2f14aa5ad67405f3e8127f3\":\"Sai\",\"70caa6269d8e4869a45f7ea91ade3472\":\"Ether\",\"3e1a008f734448b0ad9190778449af81\":\"Deep\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep\",\"716067a60a1a4034abc49a12ecafb39b\":\"Cullen\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Cullen\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group2['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group2['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    if len(seg_list) == 1 :\n",
    "        continue\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for g in group['group'].keys():\n",
    "    if len(group['group'][g])>1:\n",
    "        print (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  Nautical elements and behavior then we are taking of installation at ID is equal to 10. That means same as insulation status not in sir.  I'm starting bar token as same value.  If it was not in not installed State then we go inside and check if it is deleted. We still set the port access token. if it is not deleted that means there's only one set remaining which is  Hey use, the same installation access code.  And if we was all not already installed, it was never installed before then. We said customer ID to installation of customer idea, but the problem is because in else case if it is not installed customized still be empty.  Let's not find putting it in an SQL. So I took it out. I said customer identical do insulation or customer rating because it's the same thing either ways.  One of the cases it will still be empty.  Okay, in one case it will be empty because if there is no installation at all, not even one day so that time it will be empty.  Else it will not reduce insulation. So it is same as either being empty or an example. So for this put it out.  So this function I broke it down to check. Okay, if that you're using what access token and do cases that means the state is not okay, what access token with setting only one is installation is when it's not installed or it  so the more some state is not installed on the extent that  I'm still thinking that what if he has not provided board token.  Instant cash rate. I don't know how we ended it.  So this L scale bar token insulation access token, which is not needed because it's insulation is already present. That means insulation is valid object then it is already present in the right place, but I don't have the set is condition. Right the bot CTX set access token uses the installation objects exist open field only.  Ruby where are we going getting access token every time? No, right. No for even if the installation exist.  That part that's why I check so we're not actually building users are upsetting users actually are not present.  Reading user roles for customer ID getting the usual for customers and we generating an outspoken and responding. These are the common things creating user cetera. The only thing is if the admins folks are not present.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  This is the same as a customer or customer of the customer ID integration it is okay. So we create an installation object. here with the  This is pertaining so Bart is not being used certainly.  What are you see is that that use case ready for installation is deleted and user is doing a normal login, right? I think it still crashes. I see I think once she added that extra length blind for betokened, right? You're you're trying to get user input. Can you go to that place like authorized or to go authenticate method?  Yeah.  Yeah, she can taste it out.  No, not this one after you're setting that bot access token, right?  board context  You're doing that. Yeah, after that you call user that user info this. This line that get user info was updated like recently after some time like after my changes from she added that change.  Somebody at this you scream and then I don't know. Check for cops is a right. That's not install is there but where are we doing this check for sports?  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Mithun, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  They were once again on the one thing. I'm really see Nick for example user remote installation. And then this trying to do a normal login make a joint link.  Yeah, that's it will go into exception here.  it's only when  Was installation is removed here. We are setting a empty access to condemn.  only setting this when the state is not installed or  We are removed as in the sense like installation was deleted. Right like if app is removed. We say installation don't deleted is true. Correct.  At which point the token is also invited.  But bought access token is something which he has authorized right? Like if he has not authorized for the required things will not get the bot token then.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  It's not technical schools. Check for Scopes validate Scopes mayor because of our Expose and we say users groups guarded over at Muskoka granted.  If install state is not installed. And he has not granted admin Scopes. We are saying ether Meet app not installed.  And then we this is relatively still.  Environment scope is granted.  And uses for planted false reading if you use a scope insufficients hopes authorized by users.  also farted scopes  Not granted and not install them is not installed either with uninstall your dough into case. We are into doing it. Yeah, and as well as this court has struck the right. Yeah. Okay then thing.  this is  Is there I wonder if we should have just checked?  validates Cooks  before violets quotes Oh, yeah, we want to check if they have currently provided insulation level Scopes. That's why we did not return only thing if it is not installed.  We know that well risk of before that before installation process.  The moment I call get instruction set. I used to call that are valued cook same same way. This should be fine.  If it is, so you're saying that we should we check if installation CD is equal to not. Install or remove and admin scope is not granted directly nature.  We are doing inside that validates group it all those things. We are returning an error rate. That is what check for scopes.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  So I just use that but direct message may I won't get it. So I'm using that. I know that's about direct messages, but I'm just adding that they're just so that it doesn't break in the future, but  Act was the  Remember some conversation.  This one when their friends effect and is remember this is the slacks negatives informational Channel contains everything about everything that is present in good conditions whether this is a channel is General remember? So I'm using this determines with the access token that was used to make the call because I'm passing the Bots access token here. It is.  always remember there  You guys since I was I think I can just print it out.  Have you known for this Direct?  markers  I mean, I'm public-private direct privacy thing.  Gifted if you can get rid of additional emails.  So that is what slack is using. Is it 0 1 2 Legacy time?  Now we are mapping actually.  So entertaining get Roman for your mercy.  Yeah.  Community Channel not  Okay.  this is  Yeah is the public channel for directors? That is?  Well, they have holes there is private.  See ya. That's like there have a flag in bullsháá.  They also have a thing that detectives on like the start position if it is G or if it's CEO, isn't that so we should probably just have a more clear.  Yeah, okay. Let me let our add more locks Inferno.  Also, there's one thing I just want to take the authorized we were.  And get installation from her room or something. I remove that matter because the part on the base contacts already do the same thing.  I'll take that beer its newly updated is it?  Yeah, I'm gonna need last night. So I build the bar context here, which was integration team ID same same parameters a depositor and I create a board level context. Okay, and they're very appalling get installation for room 14.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  My horse barn validator, right? So added / the man. Okay. I create a bar context. Okay. It's sort of with the base context that means case workspace in.  Yeah, it's other perpendicular.  Then after validating it doesn't give an error.  points working for book meeting. Okay, but doesn't seem to have for summarize. I'll check actually, maybe some book for me like validate for room right - okay, I take it customer not active then. I'm gonna defend myself.  What is the error this year for the user? It's not a summarizing or qualifications?  It's there is not. So it should be a validation error flag. You should say if I'm inviting if I don't invite about and I do / come on any command besides hell. I should see the void. Like I need to run all the basic validation that the bottle of you know, you're not doing something the DL.  The only for summarized it is skipping Z.  No, I think it's happening for meeting. Also, I think it's the pit Isabel. I need so the bar context is the bot is present in the serum. This is sort of either returning his suffering.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  Correct. So basically we were coupling in book validate meeting check for presence all the checks that we do right now at command level and whether the provider is supported or not. But so I had to separate that valet create it meeting to remove all the prior checks ready check if the comet is present Etc. Like what happened in the room Etc. And move it to higher level like to bot contacts. So yeah slacks.  The meeting we just called by the API.  Again, will the base context and I check valid for whom?  Yes, I think this is the thing.  It is very far from Texas.  He'll test it out and fight. Yes.  For The Ether castrate I have almost similar same files getting changed.  Somebody asked for my birthday. Let's see.  audience  I think yeah, it's just you know.  They once you tested you just let me know then we can then I can rebase or whatever it is. Yeah mind. There are.  Here's our love Geneva III. This is getting hard so our time because I have lot of small small commits that I have built up.  What happens is when I rebates it goes supplies on top of every commit and have the kids.  I just take the current development mode it to my Visa bans because all the comments in one shot and then merge it back to dollar.  You do get it much. Okay, okay.  So I had the problem I think last time also because I generally keep small small combats with more descriptive anymore what's changing but I have a lot of comment generally in a feature Branch. So when I went everywhere be in a very committed I'm getting rebates or acts like conflicts. Correct? Pretty much resolve all the commit history in my teacher, but who did much develop that means from a feature branch? I was at the other Branch into my feature Branch resolve the conflicts in one shot and then  one more coming  As a magic away, that's the most common and then feature branch is resolved. So then the dimension we March back.  A lot of people say it's better because you don't know destructive editing. That means you're not changing the commit history because of rebase and just try to avoid the next recommend impossible. That's one of the better side.  But at some point you can still do it gets crash, right?  We can squash the question is do squash after the reviewer before the so for me I prefer to people to see like small small keep committing incrementally. So people see the changes so I don't squash before.  Better you must because a lot of code changes exact similar file similar lines.  reading in the museum  Yeah, yeah - inter-korea have to commit symbol.  And also like it'll help you because I'm screwing some of the checks and validation if you need it. Anyways, neither.  I understand that. Barbara Nation I do with all entry points and disaster man and the book meeting. We're headed for a wherever board level validation is required because you can go lower already clicked a civilization bottle variation. We need to do meeting you can do beating neural. We can follow the same we can end up following the same patterns, okay.  \n",
      "\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id_map = {}\n",
    "user_id_map = {\"3e1a008f734448b0ad9190778449af81\":\"Deep\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep\",\"716067a60a1a4034abc49a12ecafb39b\":\"Cullen\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Cullen\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "#     if len(seg_list) == 1 :\n",
    "#         continue\n",
    "    #print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T12:10:08.092248Z",
     "start_time": "2019-10-16T12:09:56.539286Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "user_id_map = {\"716067a60a1a4034abc49a12ecafb39b\":\"Ether\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"ether\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_result = {}\n",
    "pim_response = {}\n",
    "pim_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\"}\n",
    "pim_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\", \"segments\": []}\n",
    "temp = \"\"\n",
    "temp_users = []\n",
    "for groupid in group['group'].keys():\n",
    "    temp = \"\"\n",
    "    temp_users = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        temp+=segi[\"originalText\"]\n",
    "        temp_users.append(segi[\"spokenBy\"])\n",
    "    pim_response[\"segments\"].append({\"id\":\"abc\",\"originalText\":temp,\"spokenBy\":temp_users})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_pims_score({\"body\":pim_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pim = json.loads(result)['d2vResult']\n",
    "pim = sorted(pim, key=lambda kv:kv[\"distance\"], reverse=False)\n",
    "for seg in pim:\n",
    "    print ( \" , \".join(list(set(user_id_map[i] for i in seg[\"speaker\"]))), \" discussed: \\n\", seg[\"text\"], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "with open(\"para_graph\", \"rb\") as f:\n",
    "    nodes, edges, graph_list = pickle.load(f)  \n",
    "G = nx.Graph()  \n",
    "G.add_nodes_from(nodes)  \n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      " [[[\"It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences? \"], '2019-11-25T10:00:03Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4b071181e837421397b43105aab313bd'], [[\"From my test. I thought we could use the refresh similarity as a start where the key phrase is given as it is as it takes feature, not the sentence. It's a part of \"], '2019-11-25T10:00:31Z', '81a3e15469374fceba1cf972faa209b2', 'e87dde57d82c4d4b95fe801494025a55']] \n",
      "\n",
      "\n",
      "1 \n",
      "\n",
      " [[[\"So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at. \"], '2019-11-25T09:41:09Z', '81a3e15469374fceba1cf972faa209b2', '788c2d15650749c68f8108aca0a5500e']] \n",
      "\n",
      "\n",
      "2 \n",
      "\n",
      " [[[\"We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine. \"], '2019-11-25T10:21:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '37365403bd9b40f5bd9d212b9959c205'], [[\"Okay, got it. At least we'll start populating then we'll think of where to use the event unless the mind or something. Yeah. Got it. \"], '2019-11-25T10:21:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4b5d8559bb82405dba16aeaec45f4a5a']] \n",
      "\n",
      "\n",
      "3 \n",
      "\n",
      " [[[\"From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise. \"], '2019-11-25T09:48:29Z', '81a3e15469374fceba1cf972faa209b2', '12b5618f1c764d1f8150cad42776aaab'], [['If there is an entity with only two sentences, there is there is there is there is a very good chance that this most similar entities would have got 200 sentences. It has no relation. '], '2019-11-25T09:49:05Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '17d06e1f3aeb4884a05949fed71cc21e'], [[\"Yep. Okay, that is good. So that is interesting. Yeah. So the basic thing is if suppose you encounter an entity in a sentence if the sentence has more than one new entity in a then you are essentially comparing the same sentence for both entities like yeah, hence it is bad. So I thought in that case continued use the query has like a combination of both as in cosine similarity of the entity as it is. Plus like the center said it's a part of in case of similar entity. That's what I'm saying. \"], '2019-11-25T09:49:39Z', '81a3e15469374fceba1cf972faa209b2', 'dac2f5245bfd42ac8bc013b9b6baf80a'], [['Okay now coming back to what what SRI was pointing about comparing two sentences. He says that they are there douche must be related. Like like if entities it has improved it should also improve on the gel in a totally unrelated sentences. '], '2019-11-25T09:50:39Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '53bc47e0a23746b483ea34e13056486c']] \n",
      "\n",
      "\n",
      "4 \n",
      "\n",
      " [[[\"That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say. \"], '2019-11-25T09:50:56Z', '81a3e15469374fceba1cf972faa209b2', '9dd38ee0a73048d68ffe58f362afdfe8'], [['But with so when we are doing all these aggregation of sentences, right? So that means that all these entities features get either added up or get zoomed in while other public testing these kind of phrases or words get Lift Away. '], '2019-11-25T09:51:42Z', 'fb52cb663aec4795aee38ccfd904d315', 'e0fa078a2e384cbfaec422f71fb7c15f'], [[\"So instead of aggregating is it possible to select particular set of features for us, which is dominating. For that sentence like instead of like if you create a new sentence, which has a new NPP somehow we should be able to reproduce it as if it is already present in the hole if it already doesn't like in 10 to 20 sentences. \"], '2019-11-25T09:52:15Z', 'fb52cb663aec4795aee38ccfd904d315', '8642dfd5703c4bb2a3807eaa5be3538b']] \n",
      "\n",
      "\n",
      "5 \n",
      "\n",
      " [[['We need to do similarity measure. Now. The problem is when I checked on the staging to data the drawer there were 29 users with key phrases and are they around five or six of them had at least 1200 key phrases as '], '2019-11-25T10:32:22Z', '7e7ccbba232d411aa95ad3f244a35f40', 'e7306ec37a2e4b91988e3de98feddc66'], [[\"So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but \"], '2019-11-25T10:32:41Z', '7e7ccbba232d411aa95ad3f244a35f40', 'd3791a390d6640e5afbc53a238d2e462'], [['So the search engine so Jen comparison parties working finals faster than just cosine work dries cosine similarity. Okay, the result is not conclusive because of skewed is to data. Yeah. '], '2019-11-25T10:33:36Z', '7e7ccbba232d411aa95ad3f244a35f40', 'f6c40b6541f5406f8ee8c2f6ec6a990a']] \n",
      "\n",
      "\n",
      "6 \n",
      "\n",
      " [[['but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because '], '2019-11-25T09:56:39Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '8241d1ad10a34bee9a55de2f95f6e722'], [[\"That is different. But let's assume that for two entities effect. If you can rank the features, but you cannot subset the pages as soon as the subset the features out of 768 you lose the ability to compare because you will always compare you have to compare against those feature in this. He's not others. \"], '2019-11-25T09:56:51Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'dd0bd835048c42a68568e3a19bef9445']] \n",
      "\n",
      "\n",
      "7 \n",
      "\n",
      " [[['Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah. '], '2019-11-25T10:19:15Z', 'fb52cb663aec4795aee38ccfd904d315', '143c3ac9f3d44becbef3abb4ce4c3682'], [[\"Under the separation keep to keep it simple. It could be separate. If you want to you want to be optimal about the computation. Then we have to think of the right spot in the key phrases section service on where it should be happening because rest of the pre or post processing things are very negligible here because their sentence level in you're just aggregating dictionary of something and then they are not ankle. They are not bottleneck tasks. \"], '2019-11-25T10:19:57Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'b158a51386e244b383bb389e3035cf2f'], [['You want to optimize competition one one thing we can do is keep her service when it calls entity and it gets entities in the key phrase service can position our stop it. And so this this entity graph service will be listening to that topic and so it will basically get segment and entities it is no call for that. '], '2019-11-25T10:20:29Z', '7e7ccbba232d411aa95ad3f244a35f40', 'dcc373952c7e42c8b97cbba3c6cdea31']] \n",
      "\n",
      "\n",
      "8 \n",
      "\n",
      " [[[\"But I'm which one are you trying to address the the models ability to learn A/C and heater or your you to test that you're using the entity similarity as a repository task? \"], '2019-11-25T09:42:26Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ee57b27ce92749cca5e47445ea436ade'], [[\"I'm choosing the latter. Actually. I'm testing testing both models using this entity to similarity because that's something that came up recently as a requirement for the moderate. So trying to use that as a test to see whether okay, you know, the engineering model is able to capture so \"], '2019-11-25T09:42:43Z', '81a3e15469374fceba1cf972faa209b2', '4fa3c94fd14d43d9a96aac1ccbbd9e9f']] \n",
      "\n",
      "\n",
      "9 \n",
      "\n",
      " [[[\"So what I was trying to say is like you have a hundred sentences of 1800 sentences, you know that there are some particular entities for example, like Docker which is kept on beating in all the hundred sentences. So now we take the aggregated feature Vector for this entity. Yes, not all these sentences right now. If you get a new entity something called as an eternal then we don't have some repeated understand sentences where the heat is being presented. So, but if we are able to find the dominating feature vector Our official of features which would be equal to using that same word ether in hundreds and Cancers. Okay. \"], '2019-11-25T09:53:39Z', 'fb52cb663aec4795aee38ccfd904d315', '915cc438c5c34776b68061f30d5042e3'], [[\"You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context. \"], '2019-11-25T09:54:21Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '33c7f1545803448db80588e9f6cacb16'], [['For something like entity called his dog when you take all its sentences by Rocker is being present in then if you take an aggregator feature Vector of all the sentences, then there will be set of features which would be dominating all these sentences in digits, right? '], '2019-11-25T09:55:31Z', 'fb52cb663aec4795aee38ccfd904d315', 'a095de9c1ebe414095d68df183abcb00'], [[\"That's what I'm going to do it. So if we can find a subset assume that it is been pointing to some kind of a common pattern in all those in multiple cases then instead of trying to find a hundred sentences sentences for particular intervening. We can take the pattern of subsets for one single sentence itself. \"], '2019-11-25T09:56:05Z', 'fb52cb663aec4795aee38ccfd904d315', '371361b3cb1c492bb4875115a75cbdae']] \n",
      "\n",
      "\n",
      "10 \n",
      "\n",
      " [[[\"Identity similarity if you're talking about literal entity similarity, which means the string of the entity. I'm not sure if that's the right right way to answer your question. But if you don't know what the sentence well, maybe yes, I mean that the in DC Community feature is nothing but the aggregation of all the sentences that we that it is part of \"], '2019-11-25T09:45:07Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '83363541221b47f88122467066eddc5a'], [['Yeah, sorry. Anyway, I think both of these tests. So one was a literal string comparison of entities as well as the aggregated sentences. So while comparing these two methods are found that the aggregated sentences work better because JP has a tendency to select more similar words that start with the same letter. So ether it will sort of pick all tokens that are there in its reputation that start Withey similarly for Docker and stuff, yeah '], '2019-11-25T09:45:44Z', '81a3e15469374fceba1cf972faa209b2', '04daee2ad57442779efef38f292f1a3d'], [[\"Because when it's up when it updates a language model, it updates on a token level not on a word level. So see ya. So if you get Docker you'll get the and cker. Yeah, so it will also pick words that have Bo in it like the okay. I will be very similar to talker. \"], '2019-11-25T09:46:28Z', '81a3e15469374fceba1cf972faa209b2', '1bad0e3ca1b44441a4f1e2f832f2ce17']] \n",
      "\n",
      "\n",
      "11 \n",
      "\n",
      " [[['And like butter salt collecting false negative and I thought that was able to find out and I end I end users. '], '2019-11-25T10:40:40Z', '7e7ccbba232d411aa95ad3f244a35f40', '61e9df1dd0854370a7b4a877f505cfbd'], [[\"No, actually we thought you you're going to find out some test calls tested data set up for the web to validate this right? \"], '2019-11-25T10:40:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ab91bd38db874a32ace7338698f796f8']] \n",
      "\n",
      "\n",
      "12 \n",
      "\n",
      " [[[\"Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not. \"], '2019-11-25T10:27:26Z', 'fb52cb663aec4795aee38ccfd904d315', 'cdb0de417eff4855a54961d71a54c8eb'], [[\"Nothing specific. So that the main reason was we were initially having some either because all the plumbing right now is only is three days away. We just copy some mindset or model side and push it there. Yeah, so it's easy to lose track of where we are copying or pasting it. So and it's not like a staging to environment directly push to production it still copy-pasting substrates, including multiple testing to production. So even there some problem might occur. So I just wanted to make sure that every time you push in just six with some basic validation scheme whether people to the right path. \"], '2019-11-25T10:28:03Z', 'fb52cb663aec4795aee38ccfd904d315', 'fd763bdc144e4b999add674996ac6a90'], [['So for example, like if you push some ice in mind or SE model to production and then what it does is like because there is a new push to the GitHub. Then it would automatically have a gift of fashion which could trigger a script which would internally call Lambda. So with this land ourselves would get requests. Like what was what was the kind of the model or particular term starting from servers? We get some wine service been what model online that it needs to chill. And then it would pull the model of mine from bs3 then have some validations from behind planet and then push back to school. '], '2019-11-25T10:28:54Z', 'fb52cb663aec4795aee38ccfd904d315', 'd62e80a00c1945e7aad8fa6ee4135f6b']] \n",
      "\n",
      "\n",
      "13 \n",
      "\n",
      " [[[\"So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of \"], '2019-11-25T10:11:41Z', '7e7ccbba232d411aa95ad3f244a35f40', '51e910ab50b142e2b6928f67fdc6feb9'], [['Yeah, if it is, like for mind representation of any kind of thing, then we should be capturing all this information so later it is up to us. We can control which which one we want to keep it or remove but it is better if we think from now self what all things we might use it for and capture all of them. '], '2019-11-25T10:12:17Z', '7e7ccbba232d411aa95ad3f244a35f40', '3b13daf16b7c4fe4be27f1192cc93d22'], [[\"I thought of it but I was which means all you're trying to say is you capture all the key phrases and everything. \"], '2019-11-25T10:12:36Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '3b30d499e6ec45a4a82e109b03673cba']] \n",
      "\n",
      "\n",
      "14 \n",
      "\n",
      " [[[\"Try hittin it is just to be sure. I mean, I just he's done it again plus saying happened with that Curative on all sides. I didn't get the entities earlier, but now I got I don't know it just to look at it. \"], '2019-11-25T10:25:42Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'c7635ea2677644a9aba36de8f2013d7d'], [[\"And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it. \"], '2019-11-25T10:26:11Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '565a4f54dab447538e082aba37f1f4a6']] \n",
      "\n",
      "\n",
      "15 \n",
      "\n",
      " [[[\"You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris. \"], '2019-11-25T10:04:57Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '21a7f9b470984a59b7c15cd0bcee15c5'], [[\"Now if you are actually building the stick to God because that's like let's assume that they have done enough experiments on that and then came up with the specialty right so that way you can be alive. \"], '2019-11-25T10:05:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '57b5b9323a234d4295527c1458712462'], [[\"Yeah, that's what so if that is if that model is performing way better than what we have right now. It's respect to sentencing levity. So it means that the entity should be given very much high priority over others in a particular sentence. Yeah. \"], '2019-11-25T10:06:02Z', 'fb52cb663aec4795aee38ccfd904d315', '874ae1201d3545278f3e72ae3241e594']] \n",
      "\n",
      "\n",
      "16 \n",
      "\n",
      " [[[\"So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works. \"], '2019-11-25T10:31:08Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '1923ad595df44b51a2531505dd6f8875'], [[\"Yeah, so now right now I'm not advocating any feature vectors or anything. So the way I'm testing it right now is so say in summary we get a highlight right so that the set of keywords in those in that highlight will be the query will be against which we want to check what other similar works. And the complete list of similar words comes from the D graph query for all the users. \"], '2019-11-25T10:31:35Z', '7e7ccbba232d411aa95ad3f244a35f40', '0d97e07156084295b6eecd4e48df048f'], [['so now what happens is and then so if we have each other because for this highlight key words and then we get features actors for all the keywords of the users. '], '2019-11-25T10:32:09Z', '7e7ccbba232d411aa95ad3f244a35f40', '75242d46cda744ac98f6af191c7cccec']] \n",
      "\n",
      "\n",
      "17 \n",
      "\n",
      " [[[\"I've got that gets populated during which service should be accurately or should the platform. Victor should the platforms then the segment to this Louis has feel like every other service. \"], '2019-11-25T10:16:49Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '6683397b55324b53bc6e3b0c55f96440'], [['We can have it as Lambda but like right now the easiest one would be to have it but to have it communicate with Nets but and but if we can because the performers so called that it is not a big thing to write a proxy for night service so you can write it so they can Implement that so we can have it as a Lambda and it can listen to this Nats topics and do everything normally the egg. '], '2019-11-25T10:17:33Z', '7e7ccbba232d411aa95ad3f244a35f40', '419786a5c6b54ef08e58a1de798e4973'], [[\"Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated. \"], '2019-11-25T10:18:02Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '6668dd8ef4b144488f3f31795677fda8'], [['So how different is it for the O of the Lambda to be waiting for that? And then as soon as it gets the segment it just it just extracts the key phrase the entities and then populate the graph and then and then we there am I missing something. '], '2019-11-25T10:18:23Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'c0199c99d7f94654b332c536b5203049']] \n",
      "\n",
      "\n",
      "18 \n",
      "\n",
      " [[['No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service. '], '2019-11-25T10:14:40Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '08fae38348474eab9fd4ab66703f544f'], [[\"Okay. Cool. Okay. Yeah, so maybe if we if we if you do that the immediate thing would be like what we were discussing this morning right for the the known domains or under man's lips will just only will attach all the current Minds at least in the current state to to this entity graphs. \"], '2019-11-25T10:15:12Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '2bc3e2aa5f204e33984d887046529592']] \n",
      "\n",
      "\n",
      "19 \n",
      "\n",
      " [[['Even if we capture just send text and entities even that should be fine if you just like a backfill. '], '2019-11-25T10:12:46Z', '7e7ccbba232d411aa95ad3f244a35f40', '7b171151aabc41f58a266a16716b6dbb'], [['Yeah, yeah. Yeah we can do back we can do the back self apart as fit as we start thinking because currently what is established is only the entity features. '], '2019-11-25T10:12:53Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a493037c4fbd4492b77db851e2be6df8']] \n",
      "\n",
      "\n",
      "20 \n",
      "\n",
      " [[[\"yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone. \"], '2019-11-25T09:37:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '499e809ad0354b02a00b399b1225f0e8'], [[\"Fine actually, so we are discussing this morning about how to go about filtration. That means we're trying to find out if they're to two places to optimize that action items. Right one is the model L2 at the post processing level. So the model we are just using the 50% conference threshold. I think that's fine for now the biggest One potential Improvement is that even your back? Right? So one potential Improvement is to find out the leakage is where in you you have you have confidence for a an action item? But it just got just got out because there is now there is the subject isn't really qualitative. So for that currently again again under that we have we are addressing only the sentences that are having self-contained subjects, right? So so if they're not if they are referring to prop up pronouns and we are just filtering out so that's one one candidate for improvement. So which which I think show em should be working on and then and then the other other one is there is there is a there is a The sentence is self-contained. But still we are we are not we are just filtering it out. So we just need to find out the Mist Outpost. I mean the post-processing steps that are causing this and then see how you can fix that. like so and on the model part, we haven't I don't think we need anything right now to I think the current model is suffice. It is giving enough false positives and true positive. So, so it's all about reducing the false positives and bye. \"], '2019-11-25T09:38:31Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '41708d237fe642be8cea7ef3a3501cf9']] \n",
      "\n",
      "\n",
      "21 \n",
      "\n",
      " [[['For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls. '], '2019-11-25T10:29:34Z', 'fb52cb663aec4795aee38ccfd904d315', '506d98d1fded4ca084f52079196cf08c'], [['Then it may be like a mix playlist or then it would take better after publication. It has been happening on but if it happens and it would say that resources healthy orders. It will just put that it is unhealthy and we have chicken. '], '2019-11-25T10:29:46Z', 'fb52cb663aec4795aee38ccfd904d315', 'bc8f4af90421429780653dbd35b5b57a']] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in G:\n",
    "    print (node, \"\\n\\n\", graph_list[node], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (list(map(lambda kv: (kv[1][\"weight\"]).tolist(), G[4].items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0979940970388943\n",
      "0.09745418054971748\n",
      "0.009602843054468234\n",
      "0.009497317306616933\n",
      "0.4889771941598955\n",
      "0.5864313747096129\n",
      "0.5338221192359924\n",
      "0.6467412859201431\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "print (statistics.stdev(weights))\n",
    "print (statistics.pstdev(weights))\n",
    "print (statistics.variance(weights))\n",
    "print (statistics.pvariance(weights))\n",
    "print (statistics.mean(weights))\n",
    "print (statistics.mean(weights)+statistics.pstdev(weights))\n",
    "\n",
    "q3 = np.percentile(weights, 75)\n",
    "print (q3)\n",
    "iqr = np.subtract(*np.percentile(weights, [75, 25]))\n",
    "outlier = q3 + 1.5 * iqr\n",
    "print(q3+iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4., 14., 16., 31., 19.,  3.,  2.,  1.,  0.,  1.]),\n",
       " array([0.3205182 , 0.38846639, 0.45641458, 0.52436277, 0.59231097,\n",
       "        0.66025916, 0.72820735, 0.79615554, 0.86410373, 0.93205193,\n",
       "        1.00000012]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "#sns.set(color_codes=True)\n",
    "\n",
    "matplotlib.pyplot.hist(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/arjun/BERT_Similarity_experiments/code/\")\n",
    "from gpt_feat_utils import GPT_Inference\n",
    "#\n",
    "# #gpt_model = gpt_feat_utils.GPT_SimInference(\"/home/arjun/gpt_experiments/models/model_lm+sim_ep3/\", device=\"cuda\")\n",
    "# #gpt_model = gpt_feat_utils.GPT_SimInference(\"/home/arjun/gpt_experiments/models/model_lm+nsp_sim_ep3/\", device=\"cuda\")\n",
    "#gpt_model = GPT_Inference(\"/home/arjun/gpt_experiments/engg_models/se+ether_2+1s_ep5_#2/\", device=\"cuda\")\n",
    "gpt_model = GPT_Inference(\"/home/shubham/projects/domain_minds_v2_gpt/se/model/epoch3/\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5472243428230286"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "text1 = \"Is it is an open source tool that allows you to take advantage of onpremises hybrid or public Cloud infrastructure giving you the freedom to move workloads where ever you want it offers security networking and storage services and can manage more than one cluster at a time kubernetes makes more efficient use of hard work allowing you to maximize your resources and save money, but here is where things get tricky use a container orchestration tool like kubernetes.\"\n",
    "text2 =  \"so, There are guardrails and brand building blocks confining the process but it is mostly just me being myself is the brand this has in turn created.\"\n",
    "1- cosine(gpt_model.get_text_feats(text1), gpt_model.get_text_feats(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "with open(\"para_graph\", \"rb\") as f:\n",
    "    nodes, edges, graph_list = pickle.load(f)  \n",
    "G = nx.Graph()  \n",
    "G.add_nodes_from(nodes)  \n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 0,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 0,\n",
       " 8: 6,\n",
       " 9: 0,\n",
       " 10: 7,\n",
       " 11: 8,\n",
       " 12: 9,\n",
       " 13: 10,\n",
       " 14: 9,\n",
       " 15: 11,\n",
       " 16: 12,\n",
       " 17: 13,\n",
       " 18: 12,\n",
       " 19: 14,\n",
       " 20: 15}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import community\n",
    "community.best_partition(G, resolution=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "{'weight': 0.92328954} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "{'weight': 0.8328446} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "{'weight': 0.88329726} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 0.77467877} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.91811305} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.89699703} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.777256} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.8738942} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.8928244} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.7341685} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.82322294} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.78939074} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.7762697} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.8665182} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.8141417} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.7597266} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.7245356} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.823713} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.7947237} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.76237845} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "{'weight': 0.8993241} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "{'weight': 0.92887914} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 0.8496546} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.92803895} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.9341834} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.7196365} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.91499746} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.85081244} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.8164714} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.8925918} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.8779402} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.8626029} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.8946911} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.8878992} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.855345} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8086537} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.8968499} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.872483} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.823006} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "{'weight': 0.9159603} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 0.90287524} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.8629291} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.91617274} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.6786895} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.9005708} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.79057086} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.90341854} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.8981212} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.93115956} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.91279477} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9150223} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.9283157} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.87245333} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8588382} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9399267} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8228537} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8874168} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 0.846638} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.92478186} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.92416906} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.7418453} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.9013027} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.8647404} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.8284235} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.9032241} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.8852914} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.85443413} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9147646} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.9093653} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.8581683} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8264689} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.90325797} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.81833154} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.85632324} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.8264507} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.87423164} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.6110558} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.9002441} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.7464302} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.86269397} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.8939672} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.92030627} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.91263956} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.8722543} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.9012274} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9010484} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8796459} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9153882} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8295256} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8839631} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.9318245} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.72150284} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.91954875} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.91769403} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.7710582} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.90761256} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.8369133} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.8217574} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9053838} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.8849815} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.8580924} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.825349} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.87670135} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8495423} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8317523} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.9999999} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.7456162} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.93661755} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.88635} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.8403528} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.9251913} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.90646595} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.8963443} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.92750955} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.91138977} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.8801544} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.85176015} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9231866} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8660093} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.87084967} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.7251331} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.7375643} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.56380635} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.67211443} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.6630176} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.6149763} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.7118748} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.6313942} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.61478823} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.6045831} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.6397539} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.5896895} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.61334467} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.84857786} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.8393849} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.94927} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.9134601} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.90691715} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9212214} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.91255206} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9312906} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.887371} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9188649} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.88705975} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8816016} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.6955854} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.81745654} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.74966216} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.72867966} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.85997224} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.7901722} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.7452622} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.7118756} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.79074764} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.76456875} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.7445951} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.8423488} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.91389763} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.90745723} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.8783389} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.8942388} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.834108} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8302275} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.91389555} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8055003} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.873123} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.91938496} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.9128424} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.91348535} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.93157107} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.94382703} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.9073216} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.93044055} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.86840326} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8991719} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.94006604} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.923592} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.92838436} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9202186} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.9006554} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9495855} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.85074526} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.9292982} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 1.0000001} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.91213304} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.94006187} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9185777} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.9219902} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.95762223} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8863065} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.93315864} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9999999} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.927358} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.88287854} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.87636125} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.94851345} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8774245} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.9220265} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 1.0000001} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9353381} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.92013484} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.97347444} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.890964} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.9345485} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.94143337} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9249534} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8690697} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.91480136} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 1.0000001} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9152199} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.84585977} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.90727204} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.9040195} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.9438234} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.99999994} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8507762} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for nodea, nodeb, weight in G.edges.data():\n",
    "    if nodea not in scores.keys():\n",
    "        scores[nodea] = [(nodeb, weight)]\n",
    "    else:\n",
    "        scores[nodea].append((nodeb, weight))\n",
    "        scores[nodea] = sorted(scores[nodea], key=lambda kv:kv[1]['weight'], reverse=True)\n",
    "    #if nodea==4:\n",
    "        #if weight[\"weight\"]> 0.5864313747096129:\n",
    "    print (\"------- sentence ---------\")\n",
    "    print (\" \".join([seg[0] for seg in graph_list[nodea][0]]), \"\\n\")\n",
    "    print (\" \".join([seg[0] for seg in graph_list[nodeb][0]]), \"\\n\")\n",
    "    print (weight, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------sentence------- \n",
      "\n",
      "What do you say like run an ETL pipeline detail code for the for around a hundred graph dumps from staircase to data. \n",
      "\n",
      "comparison sentence:  What do you say like run an ETL pipeline detail code for the for around a hundred graph dumps from staircase to data. ====>  1.0 \n",
      "\n",
      "comparison sentence:  If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. ====>  0.7805325 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.7801076 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.7797588 \n",
      "\n",
      "comparison sentence:  You summaries for which we need a entity model, which Arjun is improving one and then mystery and I are working on experimenting with some approaches where we can aggregate this just segments or the sentences instead of going only by the segment. ====>  0.7793624 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So there is like that there is locally now and I am like populating them with degree of bulk method and everything. \n",
      "\n",
      "comparison sentence:  So there is like that there is locally now and I am like populating them with degree of bulk method and everything. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. ====>  0.90093464 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8862273 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8794582 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8794336 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "The one that we still have in staging is do we know that is it better than what we have is Tim is in \n",
      "\n",
      "comparison sentence:  The one that we still have in staging is do we know that is it better than what we have is Tim is in ====>  1.0 \n",
      "\n",
      "comparison sentence:  And I protect sales in the sales wind is and staging I tested out then if it is fine, then we will move it to production. ====>  0.8841187 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8530063 \n",
      "\n",
      "comparison sentence:  So is the release version running find on the yeah the release version? ====>  0.8527691 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.84945464 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Their communities started the summary and the under Community with summaries. \n",
      "\n",
      "comparison sentence:  Their communities started the summary and the under Community with summaries. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Itll be interesting to see what chapters gives the communities approaches by perceiving with production. ====>  0.6350874 \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  0.618715 \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  0.5624383 \n",
      "\n",
      "comparison sentence:  I know you are busy with the past implementation, but they want to jump in on setting up with the data Macedonia. ====>  0.56091696 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So we are we are working on the what you call the then symbol for that like like them the back and model needed and then and then the processor so Shri Arjun and I are trying to work together on that to see where you know, how we can make the entity. \n",
      "\n",
      "comparison sentence:  So we are we are working on the what you call the then symbol for that like like them the back and model needed and then and then the processor so Shri Arjun and I are trying to work together on that to see where you know, how we can make the entity. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.88333106 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8777002 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8762465 \n",
      "\n",
      "comparison sentence:  So and also the entity model it is in it is a it is in staging to so so Arjun is working with Russian to have it in our tin production. ====>  0.87427205 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "You summaries for which we need a entity model, which Arjun is improving one and then mystery and I are working on experimenting with some approaches where we can aggregate this just segments or the sentences instead of going only by the segment. \n",
      "\n",
      "comparison sentence:  You summaries for which we need a entity model, which Arjun is improving one and then mystery and I are working on experimenting with some approaches where we can aggregate this just segments or the sentences instead of going only by the segment. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.83886904 \n",
      "\n",
      "comparison sentence:  So there are fewer of them changes required on that path for both for both for this entity model and for sales mind. ====>  0.8357606 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8158475 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.81569505 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We might we will we might conclude on at least couple of approaches by by next week. \n",
      "\n",
      "comparison sentence:  We might we will we might conclude on at least couple of approaches by by next week. ====>  1.0 \n",
      "\n",
      "comparison sentence:  You know even with I will share some things that I got from today is call with action, I think. ====>  0.8394194 \n",
      "\n",
      "comparison sentence:  It would be the it would be that approach which we can actually can achieve what you want with that approach. ====>  0.83692014 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.8348489 \n",
      "\n",
      "comparison sentence:  We might have some some insights and then we can work on it. ====>  0.8284428 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Well, it works really well on few cases and then and then it just Falls flat. \n",
      "\n",
      "comparison sentence:  Well, it works really well on few cases and then and then it just Falls flat. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  This is not possible like using this as using it as as they can because it works almost everything in the back and it only provides the apis. ====>  0.794613 \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.7453964 \n",
      "\n",
      "comparison sentence:  We might have some some insights and then we can work on it. ====>  0.73192495 \n",
      "\n",
      "comparison sentence:  On a local machine we are able to debug the app like run both the debug and release versions, but on the device debug version we are not able to do. ====>  0.7298552 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So we just do not just do not have any reason to deploy it into to take it all the way to Productions. \n",
      "\n",
      "comparison sentence:  So we just do not just do not have any reason to deploy it into to take it all the way to Productions. ====>  1.0 \n",
      "\n",
      "comparison sentence:  We just do not want to we have to handle it says study to go all the way to see all the it is subjects around it so that we can that is one fix that we will have it in so that you become would be testing and then we should that should improve the at least the existing action items. ====>  0.8976565 \n",
      "\n",
      "comparison sentence:  So we are trying to extend that a little so that you do not miss out the sentence endings, which I eventually it also depends on the transcript, but whatever can be done from our side for these are abrupt ending we can we can handle that. ====>  0.8854183 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.8662958 \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.846234 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "You know even with I will share some things that I got from today is call with action, I think. \n",
      "\n",
      "comparison sentence:  You know even with I will share some things that I got from today is call with action, I think. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.9125148 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.90298927 \n",
      "\n",
      "comparison sentence:  Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. ====>  0.9006855 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.8998433 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Itll be interesting to see what chapters gives the communities approaches by perceiving with production. \n",
      "\n",
      "comparison sentence:  Itll be interesting to see what chapters gives the communities approaches by perceiving with production. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I do not think it is worth the effort right now, honestly, unless we find something working really well. ====>  0.7399583 \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  0.7166699 \n",
      "\n",
      "comparison sentence:  I know you are busy with the past implementation, but they want to jump in on setting up with the data Macedonia. ====>  0.7005648 \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  0.689796 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But even if you even if you try to compare current segments with the with the communities that we have right it is better not to proceed without without any conclusion on the current communities. \n",
      "\n",
      "comparison sentence:  But even if you even if you try to compare current segments with the with the communities that we have right it is better not to proceed without without any conclusion on the current communities. ====>  1.0 \n",
      "\n",
      "comparison sentence:  It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? ====>  0.8052279 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.80049515 \n",
      "\n",
      "comparison sentence:  So there are fewer of them changes required on that path for both for both for this entity model and for sales mind. ====>  0.7994112 \n",
      "\n",
      "comparison sentence:  If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. ====>  0.7961692 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I do not think it is worth the effort right now, honestly, unless we find something working really well. \n",
      "\n",
      "comparison sentence:  I do not think it is worth the effort right now, honestly, unless we find something working really well. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.7897733 \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  0.7845767 \n",
      "\n",
      "comparison sentence:  But so, let us see if it is enough data on. ====>  0.78273445 \n",
      "\n",
      "comparison sentence:  But attacking there were some points that maybe it is because of Internet issue or something but did not work out like for us. ====>  0.7573882 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So so sugar makes working on improvements for those things like like instead of abruptly ending the sentence like we have seen some cases. \n",
      "\n",
      "comparison sentence:  So so sugar makes working on improvements for those things like like instead of abruptly ending the sentence like we have seen some cases. ====>  1.0 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.89114696 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.88200027 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.8649752 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8599686 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So we are trying to extend that a little so that you do not miss out the sentence endings, which I eventually it also depends on the transcript, but whatever can be done from our side for these are abrupt ending we can we can handle that. \n",
      "\n",
      "comparison sentence:  So we are trying to extend that a little so that you do not miss out the sentence endings, which I eventually it also depends on the transcript, but whatever can be done from our side for these are abrupt ending we can we can handle that. ====>  1.0 \n",
      "\n",
      "comparison sentence:  We just do not want to we have to handle it says study to go all the way to see all the it is subjects around it so that we can that is one fix that we will have it in so that you become would be testing and then we should that should improve the at least the existing action items. ====>  0.9081117 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.9006758 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8484097 \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.8464556 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Let the subject ending at the end without like a noun phrase if there is a noun phrase with two words if we currently tend to end it with the first for itself. \n",
      "\n",
      "comparison sentence:  Let the subject ending at the end without like a noun phrase if there is a noun phrase with two words if we currently tend to end it with the first for itself. ====>  1.0 \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  0.6742957 \n",
      "\n",
      "comparison sentence:  So right now we just take the final table type in segments. ====>  0.6128769 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.6085311 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.59846836 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We just do not want to we have to handle it says study to go all the way to see all the it is subjects around it so that we can that is one fix that we will have it in so that you become would be testing and then we should that should improve the at least the existing action items. \n",
      "\n",
      "comparison sentence:  We just do not want to we have to handle it says study to go all the way to see all the it is subjects around it so that we can that is one fix that we will have it in so that you become would be testing and then we should that should improve the at least the existing action items. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.89856434 \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.8562451 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8336064 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.8143942 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, that is one obvious observation from some of the test calls and the production calls that have seen. \n",
      "\n",
      "comparison sentence:  Yeah, that is one obvious observation from some of the test calls and the production calls that have seen. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.8775055 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8723551 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.85949236 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.8503166 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I mean, at least this way we can have more visibility even after this call. \n",
      "\n",
      "comparison sentence:  I mean, at least this way we can have more visibility even after this call. ====>  1.0 \n",
      "\n",
      "comparison sentence:  We might have some some insights and then we can work on it. ====>  0.86321884 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.8424406 \n",
      "\n",
      "comparison sentence:  If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. ====>  0.8265507 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.82498705 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We might have some some insights and then we can work on it. \n",
      "\n",
      "comparison sentence:  We might have some some insights and then we can work on it. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.82589865 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.82042336 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8138594 \n",
      "\n",
      "comparison sentence:  Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. ====>  0.8097114 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So and also the entity model it is in it is a it is in staging to so so Arjun is working with Russian to have it in our tin production. \n",
      "\n",
      "comparison sentence:  So and also the entity model it is in it is a it is in staging to so so Arjun is working with Russian to have it in our tin production. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8808867 \n",
      "\n",
      "comparison sentence:  And I protect sales in the sales wind is and staging I tested out then if it is fine, then we will move it to production. ====>  0.87765247 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.8621177 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.8588982 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So there are fewer of them changes required on that path for both for both for this entity model and for sales mind. \n",
      "\n",
      "comparison sentence:  So there are fewer of them changes required on that path for both for both for this entity model and for sales mind. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.827658 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8206023 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8195918 \n",
      "\n",
      "comparison sentence:  It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? ====>  0.81938034 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah for now it is only for key phrase but it will also be used for it is definitely going to be used for the communities. \n",
      "\n",
      "comparison sentence:  Yeah for now it is only for key phrase but it will also be used for it is definitely going to be used for the communities. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8720393 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.8630226 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.86284024 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8527612 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So once that is done, then I will be working on the getting setting up a complete pipeline starting from creating the these hundred grafts gums and using that data for Downstream costly recommended vultures and rated \n",
      "\n",
      "comparison sentence:  So once that is done, then I will be working on the getting setting up a complete pipeline starting from creating the these hundred grafts gums and using that data for Downstream costly recommended vultures and rated ====>  1.0 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.799971 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.7977954 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.7870965 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.7802407 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So I did not like once the pipeline is set then I will basically run need to has as part of key phrase or some other service and log d results. \n",
      "\n",
      "comparison sentence:  So I did not like once the pipeline is set then I will basically run need to has as part of key phrase or some other service and log d results. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.9040317 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.82619995 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.8200663 \n",
      "\n",
      "comparison sentence:  But much more than the feel like I have recipe are and like it is take a lot of time. ====>  0.81802946 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So right now we just take the final table type in segments. \n",
      "\n",
      "comparison sentence:  So right now we just take the final table type in segments. ====>  1.0 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.7569195 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.75078404 \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  0.73169255 \n",
      "\n",
      "comparison sentence:  So whenever they come along with the key phases or they will be like all separate service which will check for recommended watches and then I will just log it so that I can see it. ====>  0.71964407 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So whenever they come along with the key phases or they will be like all separate service which will check for recommended watches and then I will just log it so that I can see it. \n",
      "\n",
      "comparison sentence:  So whenever they come along with the key phases or they will be like all separate service which will check for recommended watches and then I will just log it so that I can see it. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.8940114 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8688184 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8673093 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.85762364 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I know you are busy with the past implementation, but they want to jump in on setting up with the data Macedonia. \n",
      "\n",
      "comparison sentence:  I know you are busy with the past implementation, but they want to jump in on setting up with the data Macedonia. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  But so, let us see if it is enough data on. ====>  0.7901658 \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  0.7697591 \n",
      "\n",
      "comparison sentence:  And also it is not that does not show up in the join list like the front end in the clients. ====>  0.71857196 \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.707919 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, so I think probably today I will be done with a Turkish changes and then I will work on the infrastructure part for decaf I try there to ECS approach for setting of the graph instance. \n",
      "\n",
      "comparison sentence:  Yeah, so I think probably today I will be done with a Turkish changes and then I will work on the infrastructure part for decaf I try there to ECS approach for setting of the graph instance. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.8681121 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.86342275 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8631541 \n",
      "\n",
      "comparison sentence:  Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. ====>  0.8606209 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. \n",
      "\n",
      "comparison sentence:  If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8647046 \n",
      "\n",
      "comparison sentence:  It would be the it would be that approach which we can actually can achieve what you want with that approach. ====>  0.85892135 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.8581814 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.85050786 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. \n",
      "\n",
      "comparison sentence:  Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.91029185 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.90423775 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.89365757 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.8879648 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But so, let us see if it is enough data on. \n",
      "\n",
      "comparison sentence:  But so, let us see if it is enough data on. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.77640724 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.776276 \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  0.7712242 \n",
      "\n",
      "comparison sentence:  And also it is not that does not show up in the join list like the front end in the clients. ====>  0.7707466 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "And I protect sales in the sales wind is and staging I tested out then if it is fine, then we will move it to production. \n",
      "\n",
      "comparison sentence:  And I protect sales in the sales wind is and staging I tested out then if it is fine, then we will move it to production. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.88873523 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8754037 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.86805767 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.8578063 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Okay, he is going to hyphenate it from his side, but it is for us to do it then take this task. \n",
      "\n",
      "comparison sentence:  Okay, he is going to hyphenate it from his side, but it is for us to do it then take this task. ====>  1.0 \n",
      "\n",
      "comparison sentence:  It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? ====>  0.8327133 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.82826686 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8219878 \n",
      "\n",
      "comparison sentence:  But much more than the feel like I have recipe are and like it is take a lot of time. ====>  0.8213264 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Like yesterday, I was working on connecting the same is not as is breaking. \n",
      "\n",
      "comparison sentence:  Like yesterday, I was working on connecting the same is not as is breaking. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.8974169 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.89559627 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.89034307 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8687934 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "This is not possible like using this as using it as as they can because it works almost everything in the back and it only provides the apis. \n",
      "\n",
      "comparison sentence:  This is not possible like using this as using it as as they can because it works almost everything in the back and it only provides the apis. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.8180413 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.8159762 \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  0.78930295 \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.78846246 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We should at least be able to toggle at least are being on the show The Speaker stacks and then \n",
      "\n",
      "comparison sentence:  We should at least be able to toggle at least are being on the show The Speaker stacks and then ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8334735 \n",
      "\n",
      "comparison sentence:  Basically that if we want we can do it in the front and also ====>  0.82589126 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.82520306 \n",
      "\n",
      "comparison sentence:  So is the release version running find on the yeah the release version? ====>  0.8185135 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Click there is no way using like customizing the UI of the Seagate we can have the knitted C library and put the all the components as lik done by the did see me people and compile our own and you further up. \n",
      "\n",
      "comparison sentence:  Click there is no way using like customizing the UI of the Seagate we can have the knitted C library and put the all the components as lik done by the did see me people and compile our own and you further up. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.8803953 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.84427404 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.8425867 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.84153306 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It would be the it would be that approach which we can actually can achieve what you want with that approach. \n",
      "\n",
      "comparison sentence:  It would be the it would be that approach which we can actually can achieve what you want with that approach. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.88951993 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.885751 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8731067 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.87211734 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Like if you see also did if we clone the Gypsy meet we make some modify in the did simic file when we run in the local. \n",
      "\n",
      "comparison sentence:  Like if you see also did if we clone the Gypsy meet we make some modify in the did simic file when we run in the local. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Basically that if we want we can do it in the front and also ====>  0.89710355 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.87200826 \n",
      "\n",
      "comparison sentence:  So is the release version running find on the yeah the release version? ====>  0.85552144 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.852442 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It shows all those strangers, but when you build it and give the same source to our app. \n",
      "\n",
      "comparison sentence:  It shows all those strangers, but when you build it and give the same source to our app. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.6848122 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.6767761 \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  0.6660399 \n",
      "\n",
      "comparison sentence:  But when I saw that I am not able to run that in the device. ====>  0.66271836 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Zoom that did not show the same UI or functionality which we used to run in the local because everything again it becomes ice remnants will be there Rebel. \n",
      "\n",
      "comparison sentence:  Zoom that did not show the same UI or functionality which we used to run in the local because everything again it becomes ice remnants will be there Rebel. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.81290823 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.80842894 \n",
      "\n",
      "comparison sentence:  And also it is not that does not show up in the join list like the front end in the clients. ====>  0.8074536 \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.80159724 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.9073943 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.89898676 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.897452 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.89403766 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.88387406 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.87913644 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8790082 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It is also depends on how much knowledge you guys have on signaling on its take and how much information you know, how to Multiplex the you know, it is not the sweetest in my platoon is also and Link Network. \n",
      "\n",
      "comparison sentence:  It is also depends on how much knowledge you guys have on signaling on its take and how much information you know, how to Multiplex the you know, it is not the sweetest in my platoon is also and Link Network. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.7618458 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.760654 \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  0.7493282 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.7260725 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? \n",
      "\n",
      "comparison sentence:  It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.88347435 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.8592164 \n",
      "\n",
      "comparison sentence:  But much more than the feel like I have recipe are and like it is take a lot of time. ====>  0.8551204 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.83696586 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "This one is we can host their own with simic server. \n",
      "\n",
      "comparison sentence:  This one is we can host their own with simic server. ====>  1.0 \n",
      "\n",
      "comparison sentence:  You can launch a WPA will support it but joining never showed. ====>  0.8159941 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.81196314 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.8026819 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.7945014 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.8650516 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8634286 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.85954493 \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  0.84442043 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But much more than the feel like I have recipe are and like it is take a lot of time. \n",
      "\n",
      "comparison sentence:  But much more than the feel like I have recipe are and like it is take a lot of time. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.892966 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.872345 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.8677631 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8555602 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8822585 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.87687564 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.8752989 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  1.0 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8706241 \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  0.86147636 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8551856 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.85463876 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It would be easier for us to fall in like the photo. \n",
      "\n",
      "comparison sentence:  It would be easier for us to fall in like the photo. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.7238345 \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.7122862 \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.6981353 \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  0.6943024 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8938504 \n",
      "\n",
      "comparison sentence:  So with the other negation that I am testing the slack connectors and the other thing is being able to unify all the basic validations at the bottom level for things like whether the bot is present in the meeting. ====>  0.88342863 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.87119406 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We were facing a lot of issues and a lot of comments on this. \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But attacking there were some points that maybe it is because of Internet issue or something but did not work out like for us. ====>  0.7944021 \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.7342586 \n",
      "\n",
      "comparison sentence:  Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. ====>  0.73103476 \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  0.7224962 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8371394 \n",
      "\n",
      "comparison sentence:  So with the other negation that I am testing the slack connectors and the other thing is being able to unify all the basic validations at the bottom level for things like whether the bot is present in the meeting. ====>  0.8271075 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.82343316 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "to hide the config in a CPR Just make it high double like in the sense that option to hide the top portion. \n",
      "\n",
      "comparison sentence:  to hide the config in a CPR Just make it high double like in the sense that option to hide the top portion. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.7347824 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.70591915 \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  0.69368523 \n",
      "\n",
      "comparison sentence:  Let is treat this as a higher priority than the product support because if you are not able to test upgradability of anything the app on the physical device and cremation deploy anyways. ====>  0.69032556 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "That is good that we the faster we do it for now always ask for thing and it seemed to me that part. \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.90101564 \n",
      "\n",
      "comparison sentence:  So maybe you can check because I know we had but two bucks integration implemented so far we should send it if that is an exception. ====>  0.88943624 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.88326776 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "For the month like I just went through like it is not a stable version It is Alpha version of something and when I navigate about information, it says company Google and also the Dozer name as Firefox. \n",
      "\n",
      "comparison sentence:  For the month like I just went through like it is not a stable version It is Alpha version of something and when I navigate about information, it says company Google and also the Dozer name as Firefox. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8633429 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.8515751 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.84793633 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.8422221 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So I think once the stable version comes with it will be buggy and it because it fails to load our application. \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.8451611 \n",
      "\n",
      "comparison sentence:  The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. ====>  0.83302623 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But attacking there were some points that maybe it is because of Internet issue or something but did not work out like for us. \n",
      "\n",
      "comparison sentence:  But attacking there were some points that maybe it is because of Internet issue or something but did not work out like for us. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.7983915 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.79764533 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  1.0 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.83118814 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.8183796 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.8172293 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8156877 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So when you get undefined errors, do we capture these errors and bugs and Atkins about science and them with socks not? \n",
      "\n",
      "comparison sentence:  So when you get undefined errors, do we capture these errors and bugs and Atkins about science and them with socks not? ====>  1.0 \n",
      "\n",
      "comparison sentence:  Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. ====>  0.74834996 \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.6873695 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. \n",
      "\n",
      "comparison sentence:  Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.8050018 \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  0.78637606 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So maybe you can check because I know we had but two bucks integration implemented so far we should send it if that is an exception. \n",
      "\n",
      "comparison sentence:  So maybe you can check because I know we had but two bucks integration implemented so far we should send it if that is an exception. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8624521 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.8605583 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.85438824 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8243169 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.8175967 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8596265 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.8541281 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.85332525 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But when I saw that I am not able to run that in the device. \n",
      "\n",
      "comparison sentence:  But when I saw that I am not able to run that in the device. ====>  1.0 \n",
      "\n",
      "comparison sentence:  On a local machine we are able to debug the app like run both the debug and release versions, but on the device debug version we are not able to do. ====>  0.76197255 \n",
      "\n",
      "comparison sentence:  I was able to install receive events and the able to generate the token you too. ====>  0.7498472 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.72956306 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.72018623 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So like I am working on it and we will get to know you get on a call. \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.91713494 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.9018492 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.88098305 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Let is treat this as a higher priority than the product support because if you are not able to test upgradability of anything the app on the physical device and cremation deploy anyways. \n",
      "\n",
      "comparison sentence:  Let is treat this as a higher priority than the product support because if you are not able to test upgradability of anything the app on the physical device and cremation deploy anyways. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.76627 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "On a local machine we are able to debug the app like run both the debug and release versions, but on the device debug version we are not able to do. \n",
      "\n",
      "comparison sentence:  On a local machine we are able to debug the app like run both the debug and release versions, but on the device debug version we are not able to do. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.69745207 \n",
      "\n",
      "comparison sentence:  We need to create a separate email address for each and every board quickly verify that if you get set up. ====>  0.68609357 \n",
      "\n",
      "comparison sentence:  They have added it in the user list is a response. ====>  0.6851982 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So is the release version running find on the yeah the release version? \n",
      "\n",
      "comparison sentence:  So is the release version running find on the yeah the release version? ====>  1.0 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.8445156 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8443142 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.83755434 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.83638525 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.8617314 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  0.859672 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.85055417 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.85487723 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "And also it is not that does not show up in the join list like the front end in the clients. \n",
      "\n",
      "comparison sentence:  And also it is not that does not show up in the join list like the front end in the clients. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.7825554 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.7745512 \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.7700623 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "You can launch a WPA will support it but joining never showed. \n",
      "\n",
      "comparison sentence:  You can launch a WPA will support it but joining never showed. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8363667 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.82283753 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, you cannot in front and the other the API will support it. \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Basically that if we want we can do it in the front and also ====>  0.89141256 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.8673457 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  0.8058135 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Basically that if we want we can do it in the front and also \n",
      "\n",
      "comparison sentence:  Basically that if we want we can do it in the front and also ====>  1.0 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.87001747 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.85122854 \n",
      "\n",
      "comparison sentence:  Oops, mr. Scopes that you needed because and then get user by user ID. ====>  0.8193083 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, but we should not show the trait which we are not even replying back in the active meetings list. \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  1.0 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.8541121 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.8453989 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Source like a wrapper around that first to want to use a Google aps looks like in at the pole that is one thing and there are few things that I need to check on the event list you can see there are two calendars the to APS we can use so you are you want to use only the calendar things Google Calendar eraser there you want to go through the emails a Google Gmail appear so there I think we can start with The calendar EPs and then you can see if you can all the people of all the things that were neither getting from this AP this APA then calendar equation will be enough for us get started. \n",
      "\n",
      "comparison sentence:  Source like a wrapper around that first to want to use a Google aps looks like in at the pole that is one thing and there are few things that I need to check on the event list you can see there are two calendars the to APS we can use so you are you want to use only the calendar things Google Calendar eraser there you want to go through the emails a Google Gmail appear so there I think we can start with The calendar EPs and then you can see if you can all the people of all the things that were neither getting from this AP this APA then calendar equation will be enough for us get started. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Oops, mr. Scopes that you needed because and then get user by user ID. ====>  0.75370747 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.7465507 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.7168822 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.68876415 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.86137855 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8217551 \n",
      "\n",
      "comparison sentence:  The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. ====>  0.8133593 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I was able to install receive events and the able to generate the token you too. \n",
      "\n",
      "comparison sentence:  I was able to install receive events and the able to generate the token you too. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.82748747 \n",
      "\n",
      "comparison sentence:  The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. ====>  0.80069995 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.7657545 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.76114976 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. \n",
      "\n",
      "comparison sentence:  The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8723883 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.84328675 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "They have added it in the user list is a response. \n",
      "\n",
      "comparison sentence:  They have added it in the user list is a response. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.73341936 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.7313473 \n",
      "\n",
      "comparison sentence:  We need to create a separate email address for each and every board quickly verify that if you get set up. ====>  0.72984797 \n",
      "\n",
      "comparison sentence:  Oops, mr. Scopes that you needed because and then get user by user ID. ====>  0.72523767 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.8530575 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  1.0 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8767249 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So you can put your second events also was working for unexpected ones out then that I have like there is a dissipation Industries now, then there are few Sports. \n",
      "\n",
      "comparison sentence:  So you can put your second events also was working for unexpected ones out then that I have like there is a dissipation Industries now, then there are few Sports. ====>  1.0 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.8407777 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Oops, mr. Scopes that you needed because and then get user by user ID. \n",
      "\n",
      "comparison sentence:  Oops, mr. Scopes that you needed because and then get user by user ID. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.80031 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.8650484 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But Google base is a is it looks like there is no way through kind of thing. \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.8476606 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.8777228 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.86982197 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "There are ways can do push notifications also, let me let me go through the months. \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.76341444 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.7284176 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I just wanted to see if you are getting the Alias email lady. \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  1.0 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Also, if you do not get it, then like it will be huge overhead for us first. \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.99999994 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We need to create a separate email address for each and every board quickly verify that if you get set up. \n",
      "\n",
      "comparison sentence:  We need to create a separate email address for each and every board quickly verify that if you get set up. ====>  1.0000001 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "One more thing is I was added to change to print out every one the channel when someone issues a summarize. \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.87516874 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I am just working on a bi that address the bunch of issues right now. \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.87215364 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.99999994 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So with the other negation that I am testing the slack connectors and the other thing is being able to unify all the basic validations at the bottom level for things like whether the bot is present in the meeting. \n",
      "\n",
      "comparison sentence:  So with the other negation that I am testing the slack connectors and the other thing is being able to unify all the basic validations at the bottom level for things like whether the bot is present in the meeting. ====>  0.99999994 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Present in the room is if it is a DM and the other stuff that we commonly do for any kind of operations at from slack to compare when they are issued from commands or when we issue slack API call to create a meeting Etc. \n",
      "\n",
      "comparison sentence:  Present in the room is if it is a DM and the other stuff that we commonly do for any kind of operations at from slack to compare when they are issued from commands or when we issue slack API call to create a meeting Etc. ====>  1.0 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nodea in scores.keys():\n",
    "    print (\"------sentence-------\", \"\\n\")\n",
    "    print (graph_list[nodea][0], \"\\n\")\n",
    "    for values in scores[nodea][:5]:\n",
    "        print (\"comparison sentence: \", graph_list[values[0]][0], \"====> \", values[1]['weight'], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PIMs for the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:32:07.101125Z",
     "start_time": "2019-10-16T09:32:07.014546Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import client\n",
    "from botocore.client import Config\n",
    "import numpy as np\n",
    "import json\n",
    "aws_config = Config(\n",
    "        connect_timeout=60,\n",
    "        read_timeout=300,\n",
    "        retries={\"max_attempts\": 0},\n",
    "        region_name=\"us-east-1\",\n",
    "    )\n",
    "lambda_client = client(\"lambda\", config=aws_config)\n",
    "\n",
    "def get_pims_score(req):\n",
    "\n",
    "    #if req_data is None:\n",
    "    #    lambda_payload = {\"body\": input_list}\n",
    "    #    print (json.dumps(lambda_payload))\n",
    "    #else:\n",
    "    #    lambda_payload = {\"body\": {\"request\": req_data, \"text_input\": input_list}}\n",
    "        \n",
    "    try:\n",
    "        #logger.info(\"Invoking lambda function\")\n",
    "        invoke_response = lambda_client.invoke(\n",
    "            FunctionName=\"pim\",\n",
    "            InvocationType=\"RequestResponse\",\n",
    "            Payload=json.dumps(req),\n",
    "        )\n",
    "        lambda_output = (\n",
    "            invoke_response[\"Payload\"].read().decode(\"utf8\")\n",
    "        )\n",
    "        response = json.loads(lambda_output)\n",
    "        status_code = response[\"statusCode\"]\n",
    "        response_body = response[\"body\"]\n",
    "\n",
    "        #if status_code == 200:\n",
    "        #    result = json.loads(response_body)['d2vResult'][0]['distance']\n",
    "        return response_body\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:32:55.418939Z",
     "start_time": "2019-10-16T09:32:07.762456Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pim_result = {}\n",
    "pim_response = {}\n",
    "pim_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\"}\n",
    "pim_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\", \"segments\": []}\n",
    "temp = {}\n",
    "for seg in request['body']['segments']:\n",
    "    pim_request[\"segments\"] = [seg]\n",
    "    # get_pims_score({\"body\":pim_request})\n",
    "    pim_result[seg[\"recordingId\"]] =  get_pims_score({\"body\":pim_request})\n",
    "    temp = seg\n",
    "    temp[\"distance\"] = pim_result[seg[\"recordingId\"]]\n",
    "    pim_response[\"segments\"].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:47.292227Z",
     "start_time": "2019-10-16T09:33:47.205140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for seg in pim_response[\"segments\"]:\n",
    "    result.append( (seg[\"originalText\"], seg[\"distance\"], seg[\"recordingId\"]))\n",
    "result = sorted(result, key=lambda kv:kv[1])\n",
    "for (text, score, segid) in result:\n",
    "    print (text , \" =====> \", score, segid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T07:16:12.948463Z",
     "start_time": "2019-10-16T07:16:12.892361Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract topic level pims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:49.539609Z",
     "start_time": "2019-10-16T09:33:49.494149Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import extract_topic_pims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:52.577313Z",
     "start_time": "2019-10-16T09:33:52.520939Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from extract_topic_pims.main import handler\n",
    "\n",
    "res = handler({\"body\":{\"groups\": group[\"group\"], \"pims\": pim_response}}, None)\n",
    "final_pims = json.loads(res)[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:56.517504Z",
     "start_time": "2019-10-16T09:33:56.462922Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "user_id_map = {\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Shubham\",\"2cd90f0674f348cc922acd6b8782ba0f\":\"Shubham\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep Moradia\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ai-engine/pkg/\")\n",
    "\n",
    "from graphrank.core import GraphRank\n",
    "from graphrank.utils import GraphUtils, TextPreprocess\n",
    "\n",
    "gr = GraphRank()\n",
    "tp = TextPreprocess()\n",
    "gu = GraphUtils()\n",
    "\n",
    "def get_desc(sentence):\n",
    "    original_tokens, pos_tuple, filtered_pos_tuple = tp.preprocess_text(sentence, filter_by_pos=True, stop_words=False)\n",
    "    word_graph = gr.build_word_graph(graph_obj=None, input_pos_text=pos_tuple, window=4, preserve_common_words=False)\n",
    "    normal_keyphrase = gr.get_keyphrases(word_graph, pos_tuple, post_process=True)\n",
    "    desc_keyphrase = gr.get_keyphrases(word_graph, pos_tuple, descriptive=True, post_process_descriptive=True)\n",
    "    desc_keyphrase = sorted(desc_keyphrase, key=lambda kv:kv[1], reverse=True)\n",
    "    normal_kp = [phrase for phrase, score in normal_keyphrase]\n",
    "    desc_kp = [phrase for phrase, score in desc_keyphrase]\n",
    "    \n",
    "    return normal_kp, desc_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:34:06.058534Z",
     "start_time": "2019-10-16T09:34:05.255435Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for groupid in final_pims:\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in groupid:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    print (\"Keyphrases: \", end=\"\")\n",
    "    print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:34:01.892976Z",
     "start_time": "2019-10-16T09:34:01.837042Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "user_id_map = {\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing hierarchy community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:02:27.110487Z",
     "start_time": "2019-09-30T15:02:27.050494Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('topic_testing/podcast_28.txt', 'rb') as f:\n",
    "    request = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:04:15.380539Z",
     "start_time": "2019-09-30T15:02:27.410077Z"
    }
   },
   "outputs": [],
   "source": [
    "from main import handler\n",
    "\n",
    "res = handler(request, None)\n",
    "group = json.loads(res['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:05:44.525847Z",
     "start_time": "2019-09-30T15:05:44.435681Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "m_time = formatTime(\"2019-09-28T05:34:21Z\", True)\n",
    "#m_time = formatTime(\"2019-09-30T10:28:00Z\", True)\n",
    "for i in group['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:16:21.322195Z",
     "start_time": "2019-09-30T15:16:21.261435Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = []\n",
    "for i in group['group'].keys():\n",
    "    if len(group['group'][i])==1:\n",
    "        continue\n",
    "    else:\n",
    "        temp = []\n",
    "        for seg in group['group'][i]:\n",
    "            temp.append(seg['originalText'])\n",
    "        groups.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:17:35.047968Z",
     "start_time": "2019-09-30T15:16:21.757535Z"
    }
   },
   "outputs": [],
   "source": [
    "group_result = {}\n",
    "#group_response = {}\n",
    "group_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01daaqyn9gbebc92aywnxedp0c\", \"instanceId\": \"xyz\"}\n",
    "#group_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DADP74WFV607KNPCB6VVXGTG\", \"segments\": []}\n",
    "temp = {}\n",
    "group_itr = None\n",
    "for segments_id in group['group'].keys():\n",
    "    if len(group['group'][segments_id]) > 2:\n",
    "        group_request['segments'] = group['group'][segments_id]\n",
    "        res = handler({\"body\":group_request}, None)\n",
    "        group_itr = json.loads(res['body'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:21:36.916596Z",
     "start_time": "2019-09-30T15:21:36.514422Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:28:00Z\", True)\n",
    "m_time = formatTime(\"2019-09-28T05:34:21Z\", True)\n",
    "for i in group_itr['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group_itr['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:29:39.535024Z",
     "start_time": "2019-09-30T14:29:07.063968Z"
    }
   },
   "outputs": [],
   "source": [
    "group_result = {}\n",
    "#group_response = {}\n",
    "group_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DADP74WFV607KNPCB6VVXGTG\", \"instanceId\": \"xyz\"}\n",
    "#group_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DADP74WFV607KNPCB6VVXGTG\", \"segments\": []}\n",
    "temp = {}\n",
    "group_itr_2 = None\n",
    "for segments_id in group_itr['group'].keys():\n",
    "    if len(group_itr['group'][segments_id]) > 2:\n",
    "        group_request['segments'] = group_itr['group'][segments_id]\n",
    "        res = handler({\"body\":group_request}, None)\n",
    "        group_itr_2 = json.loads(res['body'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:30:41.736210Z",
     "start_time": "2019-09-30T14:30:41.595388Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:28:00Z\", True)\n",
    "for i in group_itr_2['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group_itr_2['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:12:14.592267Z",
     "start_time": "2019-09-30T14:12:14.446839Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:08:00Z\", True)\n",
    "for i in group['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ai-engine/pkg/\")\n",
    "import math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from boto3 import client as boto3_client\n",
    "import json\n",
    "import logging\n",
    "from botocore.client import Config\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "config = Config(connect_timeout=240, read_timeout=240, retries={'max_attempts': 0} )\n",
    "lambda_client = boto3_client('lambda', config=config,     aws_access_key_id=\"AKIA5SUS6MWO4MP7KDEJ\",\n",
    "    aws_secret_access_key=\"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\"\n",
    ")\n",
    "\n",
    "def get_output(input_sent, req_data=None):\n",
    "    #aws_config = Config(\n",
    "    #    connect_timeout=60,\n",
    "    ##    read_timeout=300,\n",
    "    #    retries={\"max_attempts\": 0},\n",
    "    #    region_name=\"us-east-1\",\n",
    "    #)\n",
    "    #lambda_client = boto3_client(\"lambda\", config=aws_config)\n",
    "    if req_data is None:\n",
    "        lambda_payload = input_sent\n",
    "    #logger.info(\"Invoking lambda function\")\n",
    "    invoke_response = lambda_client.invoke(\n",
    "        FunctionName=\"arn:aws:lambda:us-east-1:933389821341:function:group-segments\",\n",
    "        InvocationType=\"RequestResponse\",\n",
    "        Payload=lambda_payload\n",
    "    )\n",
    "    print (\"response recieved\", invoke_response)\n",
    "    lambda_output = (\n",
    "        invoke_response[\"Payload\"].read().decode(\"utf8\").replace(\"'\", '\"')\n",
    "    )\n",
    "    response = json.loads(lambda_output)\n",
    "    status_code = response[\"statusCode\"]\n",
    "    response_body = response[\"body\"]\n",
    "\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"topic_testing/sync_eng_21_10.txt\",\"rb\") as f:\n",
    "    request = json.load(f)\n",
    "response = get_output(json.dumps(request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = response\n",
    "user_id_map = {}\n",
    "user_id_map = {\"716067a60a1a4034abc49a12ecafb39b\":\"Ether\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"ether\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sri_gpt",
   "language": "python3",
   "name": "sri_gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
