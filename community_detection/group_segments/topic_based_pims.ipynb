{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T10:00:32.508599Z",
     "start_time": "2019-10-14T10:00:32.471648Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T10:00:32.908196Z",
     "start_time": "2019-10-14T10:00:32.654982Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing topic level pims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read json Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T12:08:19.066028Z",
     "start_time": "2019-10-16T12:08:15.539283Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "import json\n",
    "\n",
    "with open('topic_testing/sync_eng_12_19.txt','rb') as f:\n",
    "    request = json.load(f)\n",
    "    if isinstance(request, str):\n",
    "        request = json.loads(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "Segment:  It started. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Let me share my Flex clean. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  A few things one has four slash notes read a couple of tweaks to the slack messages that we sent it posted it in platforms yesterday. Do you think we can kind of get those dumb like there's a couple of things here, I think as \n",
      "\n",
      "\n",
      "\n",
      "Segment:  I think this these things are already done or whatever these things about time you had to cut this thing to production areas. Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let's have a quick calls day and see is As expected and then you can push the product, okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  This one's right. So \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So that's one and that's what things I like all the new notification that we get in forms like an Android and iOS. We have the pretext as still as the potential important moment the study of history rather than highlight so we can make more than that. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  The send like how do how do these Scopes sorry? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Like when when when we put the met somebody to slab earlier we used to call the somebody has potentially important moment. Correct? And there are two arguments to this message one is like 350 is actually displayed in notifications have notifications. Okay, but first, so if you see the current if you see the current notifications, they still say potentially important moment, but if You go to the slack at there is nothing called. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  From the back end. Okay. Alright, okay, how we can change that also? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  All right. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So that is one Windows desktop app is already released. Do we have the windows up copper to work Franklin? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Is to not let the other guy do we have? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  All right. Yeah, I have it be contested. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  My body is logged in user programs Williams. Is there pressure on them? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. Yeah, if you can we please the ram of that laptop, it would be great because otherwise it takes a lot of time to load. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So there we have the other one, right the one that time which is my Microsoft Surface. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, we'll check by the CSA events. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. Otherwise, if not, I'll tested back in the office. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  By the way, the other one also, I told him to increase the ram. That another one. Yeah. I told him to just give it an even crazier than I am. That'll help we can just give you do that on this side. Anyway, yeah. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, baby, then SRI. I don't know like that. If you're here any kind of update on the capping the summary segments. Yeah. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah, two things I run one is clapping that is in the K that is directly based on the the Mind association with the summaries. So this way we need not Brute Force fabric. So if he and it's unlikely to have life more than cleverness summaries if we filter out with the mines, so even if you have we are just wrapping it to the five to seven depending upon the confidence of each of the community. What we are currently doing this we just tested it an Essie before deployment. We're trying to test out on Multi all the if not all at least most of them most of the domain mind so that we have consistent is across once that is done. We will deploy it into staging too. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. Okay. Got it. All right. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So the big ones then we'll just kind of run through the others Joshua morning on the front and side. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yesterday I was working on the box. Let me log out and the sign in page which we are saying is already signing trying to sign into some particular workspace from which we had blocked. It should be generic. I worked on it today stankin can test tissue. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Running what about the issue speaker change? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  That is fixed. That is also hand that also I will text. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, so we can push that the production we need to discuss. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  That is in a production lie. So those picanha. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Plenty of work. What a partial. What do you guys plan to take on next? See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback. That will be good. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I'll have a discussion with one key after this thing called. So then if it's a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing. In a meeting to a particular channel, that will be inside me try. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  right \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Associated with the channel if it is not precious. Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  The flow is like this. The flow is like this. So Zone called will happen. You will invite Zoom. We are either calendar you will get an email and the email will have a summary and then they'll be a share into slack button. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Click on the share and dislike button. Yeah, it will open the me tap there will be a drop down of there will be you know at a minimum. There will be like select slack Channel and share like the screen design there are that's a fly. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. Okay, so we do not need to handle it in Netflix video playback. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Actually, it's you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  But one thing like with it, even if it's not a test, it comes up in networks view. He had them from Netflix me. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  so actually we each room meeting is actually attached to the DM channel for the \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Got it. Got it. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Actually view the meeting as a tile in the Netflix you maybe it's a good idea from from there. Also, we can provide a shaper done is not a different Channel. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, but okay. Alright. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  First iteration we can we can have a shareable from the email then we can together. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  You can have all three states first. We'll make the email like the link to which works from email and second. We can add the same functionality on like internet review end playback. So even if that they are viewing the playback and it's not associated. They can just click on the button and associated. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. Yeah, let's let's just do this the email one first part. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  We'll do that first and we'll pick up the women will be. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Come on credit later, because in the citational logic we have to add about whether it's shared already or not. You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack. So there's a bunch of things. We have to be careful about. Let's do that. Let's just do the email and share from email. Got it. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, the the other there's a couple of other things that will require, you know, maybe some like joint work between Trenton and platform team that is for the cast and Truman's right one is handling the consul of cast right? So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that. So we should figure out kind of and then that That requires some back-end work as well. I think maternal Gothic were discussing this yesterday. Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do. Okay in the other one that Colin brought up yesterday was in terms of slide into a way, you know forecast, you know, you started the cost. And then today we kind of show some messages. Right? Like for example, we don't show who started the cast and then sorry we don't show it when you start the cast and then it shows something like cast has been started or something like that. And then the markers start to show up. Right? Yeah, but the problem will be if I am doing it and then I'm canceling the cast, right? Then there are cases like that. So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right? So you start a car. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  And then once the cast is done the summary will get pushed now. I don't know how hard that is to handle the handle the scenario of you know, not pushing manual markers Etc or interim messages back into slack, but only forecast. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  You can do that. It's just that we have to write a bunch of conditions. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  It should be easier. It should be easy. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. Alright. So in that case, let's take both of these on right forecast. So that that cost related things are completed. Okay. All right sigh I can take up that path but \n",
      "\n",
      "\n",
      "\n",
      "Segment:  DeGraff work is completely done for single node. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  But before taking this class, I was thinking of having the summary year there was one issue in summary a period so we don't push back the topic or actions time at the type what time they spoke like the offset is not being sent in the AP response. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Whenever using the summary APA right now, we're not using right now. We are not using but right. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  But once this Zoom thing also Contracting the worm she is using the same API right? Forget it. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  I'm actually started using the APA but it's in the connectors. But the main aim was to use it in the front end where we can irritate people. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. So what I would do is within if we if we let's let's do this. Let's prioritize a cast ones above. If possible unless it's a requirement for Zumba. She what do you want? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  No, not that we can we can work within can go down the car. Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Clicks on the actions, but you won't get at what time it was spoken by the race with the whole screen. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So I'm looking at not actually using I'm using not using the entire response from the summary right now. Okay, all we go. We can go to the cash. There are few things that we can add or remove the somebody. But okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Di gusting right now, whatever we have discussed earlier ate the whole thing is implemented like any easy to you can bring it up and the volume remains always the same EBS volume so will not end up recreating EBS volume or anything like that. So you have EBS volume and snapshots are also creating created. So whatever was discussed for single node is all done for 3 node. Also it is okay meaning and in modules we can still send it to create it in the Creator 3 node cluster also hope that once we needed we can again start looking good. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah, that's fine. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Shouldn't take much time since it's all in modules will be easy. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. So in that case my turn what you do is once like you can if the DeGraff things ready like a basic DeGraff single note thing is ready just wrap that up and then you can help with the cast. Okay, then we can pick up the other ones. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  I'm Shay anything to add on the zoom things? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah, we so we actually run a interest today. This is one of the priorities changed a staging to mind. It's looking as expected for one of those delinquents meeting and there are few debts. We need to put in place the chances of them looking into that you can add more other than that. Yeah, it's pretty much finished from commercial vehicle for the single instance thing. You can we can really push it to production. Maybe next time we can have a sink on you. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Got it. Yeah. Okay cool. That's pretty good. We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event. Yes. Those are small. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Going to implement really upon the like, you know early yesterday we discussed that we will more except that place. Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there aren't there to bunch of small small things. So those things we can truly, you know added as an input. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Rod it okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  On my side which has to be connected by two languages most and try to submit the resume. Not sure if they are going to accept it because it's under the year. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah, let's do one thing. Let's let's wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yeah, at least we can be alone. Yeah by then. We'll be done with all that. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Exactly. Yeah because anyways is no point doing marketing during holidays. Also, nobody will be seeing it. So anyway, we'll pick back up any Zoom or notes related marketing only after the beginning of the year. So by then exhume is also approved then it will actually be nice, you know. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yes, one more thing is I we need to create a new email for staging because if you use the bottle because that is the staging also will be reading like production mean besides product. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  So I can just create like a new you need a new email address or new areas new email at the scoreboard. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Paging me wrong. Let's try again. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, let's see if we tested tested. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Pleasing to all and bleeding from production board at people as if I go all the image will come through her. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  More instances into I have reduced the so yesterday. We remember that we added like 10 second delay between \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work. But let's see what is actually doing. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Got it. Okay deep was the video that \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Yes, I am working on the adding the react router navigation and creating. Let me think the app flow faster on whenever somebody opens the app for the first time. So I will so there's only I think I guess there will be just one delay when we're looking the app that is like were to check for code push with any new bundle or not. That is new. Only thing that I think would take a bit of time. Otherwise, you'll be able to see the sturgeon screen quickly. We assign them so this okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay, so I think those are the big ones the one big user story that we need to pick up. Maybe I don't know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we can't get rid of the header. So that's the reason we need we need that second is sometimes transcripts. show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Missing transcription of the last segment in a call and then audio clips in playback. So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Listen since say when Karen and I had a discussion yesterday when we find them we were coming. I'll actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you're running recording time. We can use that now Vixens communities move to a different, you know sentence based approach, but we want You just test it with the the transcription from uni passed a full meeting wave to the segment. ER whether it is because if you get more fine-grained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  We'll have to run a few experiments to see if that transcriptions are acceptable for performing are related workloads that we currently support. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Okay. \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Alright anything else to talk about? \n",
      "\n",
      "\n",
      "\n",
      "Segment:  Thanks guys. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seg_list = []\n",
    "for seg in request[\"body\"][\"segments\"]:\n",
    "    seg_list.append((seg[\"originalText\"], seg[\"startTime\"]))\n",
    "seg_list = sorted(seg_list, key=lambda kv:kv[1], reverse=False)\n",
    "\n",
    "print (len(seg_list))\n",
    "for seg in seg_list:\n",
    "    print (\"Segment: \", seg[0])\n",
    "    print (\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Groups for the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T12:09:56.535906Z",
     "start_time": "2019-10-16T12:08:19.069721Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /tmp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /tmp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  01DAAYHEKY5F4E02QVRJPTFTXV  for feature extraction\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 122, \"module\": \"scorer\", \"batches count\": 1, \"number of sentences\": 103, \"ts\": \"2019-12-19T07:37:01.792621Z\", \"msg\": \"computing in batches\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 125, \"module\": \"scorer\", \"iteration count:\": 0, \"ts\": \"2019-12-19T07:37:01.793197Z\", \"msg\": \"getting feature vector\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 133, \"module\": \"scorer\", \"iteration count\": 0, \"ts\": \"2019-12-19T07:37:06.482148Z\", \"msg\": \"Request Sent\"}\n",
      "('Yeah, if you can we please the ram of that laptop, it would be great because otherwise it takes a lot of time to load.', '2019-12-19T06:06:51Z', '0bbbfe84c66145af8d0ffcd5258bba38', '003673f8-1106-4bcb-88de-0eb0b74edd8d') ('Thatll help we can just give you do that on this side.', '2019-12-19T06:07:16Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'fd3309b7-4121-440a-a8c1-e82694547075')\n",
      "('It is just that we have to write a bunch of conditions.', '2019-12-19T06:15:36Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '08f15ac1-1ac0-462b-a1a1-f8be0e0f0f86') ('Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do.', '2019-12-19T06:13:32Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '8e139327-69d6-440f-8600-21763e906b4c')\n",
      "('Not sure if they are going to accept it because it is under the year.', '2019-12-19T06:20:21Z', '1a21542584494fcaba957d768b595b80', '0967de49-c222-4ea0-8735-f537f67b6d39') ('Going to implement really upon the like, you know early yesterday we discussed that we will more except that place.', '2019-12-19T06:19:50Z', '1a21542584494fcaba957d768b595b80', '72ddba77-7fa4-469a-a784-4dbc4b543d74')\n",
      "('Not sure if they are going to accept it because it is under the year.', '2019-12-19T06:20:21Z', '1a21542584494fcaba957d768b595b80', '0967de49-c222-4ea0-8735-f537f67b6d39') ('Let is let us wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year.', '2019-12-19T06:20:42Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'a01c0450-6894-464a-a305-ceabb23d2457')\n",
      "('I think this these things are already done or whatever these things about time you had to cut this thing to production areas.', '2019-12-19T06:04:08Z', '1a21542584494fcaba957d768b595b80', '12420e65-ef60-4f60-8e96-76dedfbb2e23') ('Do you think we can kind of get those dumb like there is a couple of things here, I think as', '2019-12-19T06:03:47Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '1b81d6f2-d369-402c-b62a-a990c213ea7b')\n",
      "('Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let us have a quick calls day and see is As expected and then you can push the product, okay.', '2019-12-19T06:04:08Z', '1a21542584494fcaba957d768b595b80', '12420e65-ef60-4f60-8e96-76dedfbb2e23') ('So that is one and that is what things I like all the new notification that we get in forms like an Android and iOS.', '2019-12-19T06:04:52Z', '1a21542584494fcaba957d768b595b80', '4310d857-1b78-49ba-a9af-0b9a4acdab07')\n",
      "('Otherwise, you will be able to see the sturgeon screen quickly.', '2019-12-19T06:22:47Z', 'b4a57b25de68446cac990f856d3fe4d5', '19bc16e0-243b-4a3d-9358-db204346e352') ('Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work.', '2019-12-19T06:22:13Z', '1a21542584494fcaba957d768b595b80', '742bcce9-b938-4184-af8f-d24bba61b6b9')\n",
      "('We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event.', '2019-12-19T06:19:35Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '27eb7db0-3eec-443d-95de-414296c002c3') ('So in that case my turn what you do is once like you can if the DeGraff things ready like a basic DeGraff single note thing is ready just wrap that up and then you can help with the cast.', '2019-12-19T06:18:27Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '38ba0c61-9167-4198-bea1-f027587600f9')\n",
      "('We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event.', '2019-12-19T06:19:35Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '27eb7db0-3eec-443d-95de-414296c002c3') ('Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there are not there to bunch of small small things.', '2019-12-19T06:19:50Z', '1a21542584494fcaba957d768b595b80', '72ddba77-7fa4-469a-a784-4dbc4b543d74')\n",
      "('Well make the email like the link to which works from email and second.', '2019-12-19T06:12:41Z', '0bbbfe84c66145af8d0ffcd5258bba38', '2b60be6b-b710-46a8-ac08-b9ea6224aad2') ('First iteration we can we can have a shareable from the email then we can together.', '2019-12-19T06:12:32Z', '1a21542584494fcaba957d768b595b80', 'd2d5571c-901a-4e76-ac4f-034ed100e442')\n",
      "('We can add the same functionality on like internet review end playback.', '2019-12-19T06:12:41Z', '0bbbfe84c66145af8d0ffcd5258bba38', '2b60be6b-b710-46a8-ac08-b9ea6224aad2') ('First iteration we can we can have a shareable from the email then we can together.', '2019-12-19T06:12:32Z', '1a21542584494fcaba957d768b595b80', 'd2d5571c-901a-4e76-ac4f-034ed100e442')\n",
      "('Let me log out and the sign in page which we are saying is already signing trying to sign into some particular workspace from which we had blocked.', '2019-12-19T06:08:49Z', '65bb83952fb54409a4bb59bb707f1375', '32136eaa-66ae-4400-bc04-ac7cf2117785') ('What we are currently doing this we just tested it an Essie before deployment.', '2019-12-19T06:07:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a854a0cd-64e5-4a43-8dce-edec3341a4e8')\n",
      "('So there we have the other one, right the one that time which is my Microsoft Surface.', '2019-12-19T06:06:58Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '334821e3-99f9-4a56-80b4-95ed9b722acd') ('Thatll help we can just give you do that on this side.', '2019-12-19T06:07:16Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'fd3309b7-4121-440a-a8c1-e82694547075')\n",
      "('Also, we can provide a shaper done is not a different Channel.', '2019-12-19T06:12:11Z', '1a21542584494fcaba957d768b595b80', '3842acb8-9ded-4ef9-a6c8-f65f7386b0b2') ('First iteration we can we can have a shareable from the email then we can together.', '2019-12-19T06:12:32Z', '1a21542584494fcaba957d768b595b80', 'd2d5571c-901a-4e76-ac4f-034ed100e442')\n",
      "('So you have EBS volume and snapshots are also creating created.', '2019-12-19T06:17:39Z', '84fbaa66a2474ea29ae053f3a2e519d6', '59155015-2164-4f00-9c5f-1c52cec88b6c') ('So I am looking at not actually using I am using not using the entire response from the summary right now.', '2019-12-19T06:17:17Z', '1a21542584494fcaba957d768b595b80', '8f566d3d-b209-4e8f-bac7-00835cc1c63d')\n",
      "('So whatever was discussed for single node is all done for XnumberX node.', '2019-12-19T06:17:39Z', '84fbaa66a2474ea29ae053f3a2e519d6', '59155015-2164-4f00-9c5f-1c52cec88b6c') ('So I am looking at not actually using I am using not using the entire response from the summary right now.', '2019-12-19T06:17:17Z', '1a21542584494fcaba957d768b595b80', '8f566d3d-b209-4e8f-bac7-00835cc1c63d')\n",
      "('Come on credit later, because in the citational logic we have to add about whether it is shared already or not.', '2019-12-19T06:13:08Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '62be212b-dc64-434c-9f02-3f8f759807e1') ('So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that.', '2019-12-19T06:13:32Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '8e139327-69d6-440f-8600-21763e906b4c')\n",
      "('Come on credit later, because in the citational logic we have to add about whether it is shared already or not.', '2019-12-19T06:13:08Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '62be212b-dc64-434c-9f02-3f8f759807e1') ('So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right?', '2019-12-19T06:13:32Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '8e139327-69d6-440f-8600-21763e906b4c')\n",
      "('You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack.', '2019-12-19T06:13:08Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '62be212b-dc64-434c-9f02-3f8f759807e1') ('So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that.', '2019-12-19T06:13:32Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '8e139327-69d6-440f-8600-21763e906b4c')\n",
      "('Okay, so we do not need to handle it in Netflix video playback.', '2019-12-19T06:11:35Z', '0bbbfe84c66145af8d0ffcd5258bba38', '83738537-2323-496c-9886-92e41438d2e8') ('Actually, it is you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel.', '2019-12-19T06:11:42Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'd8e03669-d04a-4ce6-a780-29295eb694a4')\n",
      "('Maybe I do not know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we cannot get rid of the header.', '2019-12-19T06:23:37Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '871c87b7-095c-4f4b-b688-a01f907607cd') ('So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders.', '2019-12-19T06:24:25Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '99666ff3-e998-423a-a761-ab8c9cc60b14')\n",
      "('Maybe I do not know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we cannot get rid of the header.', '2019-12-19T06:23:37Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '871c87b7-095c-4f4b-b688-a01f907607cd') ('I will actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you are running recording time.', '2019-12-19T06:24:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bb97dad3-65f5-40fc-abda-456dc1b8a261')\n",
      "('So that is the reason we need we need that second is sometimes transcripts.', '2019-12-19T06:23:37Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '871c87b7-095c-4f4b-b688-a01f907607cd') ('So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders.', '2019-12-19T06:24:25Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '99666ff3-e998-423a-a761-ab8c9cc60b14')\n",
      "('So that is the reason we need we need that second is sometimes transcripts.', '2019-12-19T06:23:37Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '871c87b7-095c-4f4b-b688-a01f907607cd') ('I will actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you are running recording time.', '2019-12-19T06:24:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bb97dad3-65f5-40fc-abda-456dc1b8a261')\n",
      "('show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every', '2019-12-19T06:23:37Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '871c87b7-095c-4f4b-b688-a01f907607cd') ('ER whether it is because if you get more finegrained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together.', '2019-12-19T06:24:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bb97dad3-65f5-40fc-abda-456dc1b8a261')\n",
      "('So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders.', '2019-12-19T06:24:25Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '99666ff3-e998-423a-a761-ab8c9cc60b14') ('I will actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you are running recording time.', '2019-12-19T06:24:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bb97dad3-65f5-40fc-abda-456dc1b8a261')\n",
      "('We are either calendar you will get an email and the email will have a summary and then they will be a share into slack button.', '2019-12-19T06:11:01Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '9fc378b0-a4a9-4927-a1b7-370675beb5e5') ('So then if it is a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing.', '2019-12-19T06:09:55Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'd5f6b164-8cd2-4c5b-9af8-fa7fc726b982')\n",
      "('We are either calendar you will get an email and the email will have a summary and then they will be a share into slack button.', '2019-12-19T06:11:01Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '9fc378b0-a4a9-4927-a1b7-370675beb5e5') ('There will be like select slack Channel and share like the screen design there are that is a fly.', '2019-12-19T06:11:19Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'd67ce22a-89d8-40ba-8c3b-48d4d64b1ae7')\n",
      "('Let is let us wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year.', '2019-12-19T06:20:42Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'a01c0450-6894-464a-a305-ceabb23d2457') ('So anyway, we will pick back up any Zoom or notes related marketing only after the beginning of the year.', '2019-12-19T06:20:58Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'bc420bc9-7cef-4474-99a0-f1f633ef9523')\n",
      "('So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode?', '2019-12-19T06:10:32Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'a48a753b-e77f-4fd2-9ad9-dc03c68e5e26') ('Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I will have a discussion with one key after this thing called.', '2019-12-19T06:09:55Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'd5f6b164-8cd2-4c5b-9af8-fa7fc726b982')\n",
      "('So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode?', '2019-12-19T06:10:32Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'a48a753b-e77f-4fd2-9ad9-dc03c68e5e26') ('So then if it is a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing.', '2019-12-19T06:09:55Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'd5f6b164-8cd2-4c5b-9af8-fa7fc726b982')\n",
      "('So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode?', '2019-12-19T06:10:32Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'a48a753b-e77f-4fd2-9ad9-dc03c68e5e26') ('There will be like select slack Channel and share like the screen design there are that is a fly.', '2019-12-19T06:11:19Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'd67ce22a-89d8-40ba-8c3b-48d4d64b1ae7')\n",
      "('What we are currently doing this we just tested it an Essie before deployment.', '2019-12-19T06:07:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a854a0cd-64e5-4a43-8dce-edec3341a4e8') ('Thatll help we can just give you do that on this side.', '2019-12-19T06:07:16Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'fd3309b7-4121-440a-a8c1-e82694547075')\n",
      "('So by then exhume is also approved then it will actually be nice, you know.', '2019-12-19T06:20:58Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'bc420bc9-7cef-4474-99a0-f1f633ef9523') ('So I can just create like a new you need a new email address or new areas new email at the scoreboard.', '2019-12-19T06:21:36Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'f616a264-fa75-44b9-b917-5315b0b9083c')\n",
      "('Whenever using the summary APA right now, we are not using right now.', '2019-12-19T06:16:27Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'cd9470bb-d1e7-4a50-9a2d-19078faac782') ('I am actually started using the APA but it is in the connectors.', '2019-12-19T06:16:40Z', '1a21542584494fcaba957d768b595b80', 'd397bc8c-9796-4de8-aa4b-a9e405cad05e')\n",
      "('See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback.', '2019-12-19T06:09:38Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'cff93d89-53d9-4d37-865e-b03fc7c2a175') ('Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I will have a discussion with one key after this thing called.', '2019-12-19T06:09:55Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'd5f6b164-8cd2-4c5b-9af8-fa7fc726b982')\n",
      "('See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback.', '2019-12-19T06:09:38Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'cff93d89-53d9-4d37-865e-b03fc7c2a175') ('So then if it is a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing.', '2019-12-19T06:09:55Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'd5f6b164-8cd2-4c5b-9af8-fa7fc726b982')\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 391, \"module\": \"grouper_segments\", \"outlier threshold is : \": 0.41864025592803955, \"ts\": \"2019-12-19T07:37:06.673830Z\", \"msg\": \"Outlier Score\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 1035, \"module\": \"grouper_segments\", \"edges before prunning\": 266, \"edges after prunning\": 266, \"modularity\": 0.8491558933469706, \"ts\": \"2019-12-19T07:37:06.834362Z\", \"msg\": \"Meeting Graph results\"}\n",
      "cluster before alteration=========>\n",
      "Yeah, if you can we please the ram of that laptop, it would be great because otherwise it takes a lot of time to load.\n",
      "Thatll help we can just give you do that on this side.\n",
      "Let me log out and the sign in page which we are saying is already signing trying to sign into some particular workspace from which we had blocked.\n",
      "What we are currently doing this we just tested it an Essie before deployment.\n",
      "So there we have the other one, right the one that time which is my Microsoft Surface.\n",
      "Yeah, two things I run one is clapping that is in the K that is directly based on the the Mind association with the summaries.\n",
      "So if he and it is unlikely to have life more than cleverness summaries if we filter out with the mines, so even if you have we are just wrapping it to the five to seven depending upon the confidence of each of the community.\n",
      "Were trying to test out on Multi all the if not all at least most of them most of the domain mind so that we have consistent is across once that is done.\n",
      "By the way, the other one also, I told him to increase the ram.\n",
      "cluster before alteration=========>\n",
      "It is just that we have to write a bunch of conditions.\n",
      "Well have to run a few experiments to see if that transcriptions are acceptable for performing are related workloads that we currently support.\n",
      "Come on credit later, because in the citational logic we have to add about whether it is shared already or not.\n",
      "There are few things that we can add or remove the somebody.\n",
      "So you have EBS volume and snapshots are also creating created.\n",
      "Di gusting right now, whatever we have discussed earlier ate the whole thing is implemented like any easy to you can bring it up and the volume remains always the same EBS volume so will not end up recreating EBS volume or anything like that.\n",
      "Also it is okay meaning and in modules we can still send it to create it in the Creator XnumberX node cluster also hope that once we needed we can again start looking good.\n",
      "So whatever was discussed for single node is all done for XnumberX node.\n",
      "So I am looking at not actually using I am using not using the entire response from the summary right now.\n",
      "cluster before alteration=========>\n",
      "Only thing that I think would take a bit of time.\n",
      "Yes, I am working on the adding the react router navigation and creating.\n",
      "Let me think the app flow faster on whenever somebody opens the app for the first time.\n",
      "So I will so there is only I think I guess there will be just one delay when we are looking the app that is like were to check for code push with any new bundle or not.\n",
      "Otherwise, you will be able to see the sturgeon screen quickly.\n",
      "Clicks on the actions, but you will not get at what time it was spoken by the race with the whole screen.\n",
      "Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work.\n",
      "Pleasing to all and bleeding from production board at people as if I go all the image will come through her.\n",
      "cluster before alteration=========>\n",
      "Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do.\n",
      "So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that.\n",
      "So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right?\n",
      "Okay, the the other there is a couple of other things that will require, you know, maybe some like joint work between Trenton and platform team that is for the cast and Truman is right one is handling the consul of cast right?\n",
      "So we should figure out kind of and then that That requires some backend work as well.\n",
      "Okay in the other one that Colin brought up yesterday was in terms of slide into a way, you know forecast, you know, you started the cost.\n",
      "Like for example, we do not show who started the cast and then sorry we do not show it when you start the cast and then it shows something like cast has been started or something like that.\n",
      "Yeah, but the problem will be if I am doing it and then I am canceling the cast, right?\n",
      "cluster before alteration=========>\n",
      "We need to put in place the chances of them looking into that you can add more other than that.\n",
      "This is one of the priorities changed a staging to mind.\n",
      "It is looking as expected for one of those delinquents meeting and there are few debts.\n",
      "Yeah, it is pretty much finished from commercial vehicle for the single instance thing.\n",
      "cluster before alteration=========>\n",
      "On my side which has to be connected by two languages most and try to submit the resume.\n",
      "Not sure if they are going to accept it because it is under the year.\n",
      "Going to implement really upon the like, you know early yesterday we discussed that we will more except that place.\n",
      "Let is let us wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year.\n",
      "We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event.\n",
      "So in that case my turn what you do is once like you can if the DeGraff things ready like a basic DeGraff single note thing is ready just wrap that up and then you can help with the cast.\n",
      "Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there are not there to bunch of small small things.\n",
      "So those things we can truly, you know added as an input.\n",
      "cluster before alteration=========>\n",
      "Like when when when we put the met somebody to slab earlier we used to call the somebody has potentially important moment.\n",
      "And there are two arguments to this message one is like XnumberX is actually displayed in notifications have notifications.\n",
      "Okay, but first, so if you see the current if you see the current notifications, they still say potentially important moment, but if You go to the slack at there is nothing called.\n",
      "cluster before alteration=========>\n",
      "I think this these things are already done or whatever these things about time you had to cut this thing to production areas.\n",
      "Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let us have a quick calls day and see is As expected and then you can push the product, okay.\n",
      "Do you think we can kind of get those dumb like there is a couple of things here, I think as\n",
      "So that is one and that is what things I like all the new notification that we get in forms like an Android and iOS.\n",
      "A few things one has four slash notes read a couple of tweaks to the slack messages that we sent it posted it in platforms yesterday.\n",
      "cluster before alteration=========>\n",
      "I am actually started using the APA but it is in the connectors.\n",
      "If you are here any kind of update on the capping the summary segments.\n",
      "Missing transcription of the last segment in a call and then audio clips in playback.\n",
      "Whenever using the summary APA right now, we are not using right now.\n",
      "cluster before alteration=========>\n",
      "But the main aim was to use it in the front end where we can irritate people.\n",
      "You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack.\n",
      "Actually, it is you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel.\n",
      "Okay, so we do not need to handle it in Netflix video playback.\n",
      "But one thing like with it, even if it is not a test, it comes up in networks view.\n",
      "cluster before alteration=========>\n",
      "Well make the email like the link to which works from email and second.\n",
      "We can add the same functionality on like internet review end playback.\n",
      "So even if that they are viewing the playback and it is not associated.\n",
      "First iteration we can we can have a shareable from the email then we can together.\n",
      "Actually view the meeting as a tile in the Netflix you maybe it is a good idea from from there.\n",
      "Also, we can provide a shaper done is not a different Channel.\n",
      "cluster before alteration=========>\n",
      "But once this Zoom thing also Contracting the worm she is using the same API right?\n",
      "cluster before alteration=========>\n",
      "And then once the cast is done the summary will get pushed now.\n",
      "We have the pretext as still as the potential important moment the study of history rather than highlight so we can make more than that.\n",
      "So in that case, let us take both of these on right forecast.\n",
      "So anyway, we will pick back up any Zoom or notes related marketing only after the beginning of the year.\n",
      "I do not know how hard that is to handle the handle the scenario of you know, not pushing manual markers Etc or interim messages back into slack, but only forecast.\n",
      "But before taking this class, I was thinking of having the summary year there was one issue in summary a period so we do not push back the topic or actions time at the type what time they spoke like the offset is not being sent in the AP response.\n",
      "So by then exhume is also approved then it will actually be nice, you know.\n",
      "So I can just create like a new you need a new email address or new areas new email at the scoreboard.\n",
      "cluster before alteration=========>\n",
      "Okay, so we can push that the production we need to discuss.\n",
      "cluster before alteration=========>\n",
      "So that is the reason we need we need that second is sometimes transcripts.\n",
      "Okay, so I think those are the big ones the one big user story that we need to pick up.\n",
      "Maybe I do not know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we cannot get rid of the header.\n",
      "show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every\n",
      "So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders.\n",
      "I will actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you are running recording time.\n",
      "ER whether it is because if you get more finegrained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together.\n",
      "Listen since say when Karen and I had a discussion yesterday when we find them we were coming.\n",
      "We can use that now Vixens communities move to a different, you know sentence based approach, but we want You just test it with the the transcription from uni passed a full meeting wave to the segment.\n",
      "cluster before alteration=========>\n",
      "So the big ones then we will just kind of run through the others Joshua morning on the front and side.\n",
      "cluster before alteration=========>\n",
      "We are either calendar you will get an email and the email will have a summary and then they will be a share into slack button.\n",
      "So then if it is a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing.\n",
      "There will be like select slack Channel and share like the screen design there are that is a fly.\n",
      "So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode?\n",
      "Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I will have a discussion with one key after this thing called.\n",
      "See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback.\n",
      "In a meeting to a particular channel, that will be inside me try.\n",
      "Yeah, it will open the me tap there will be a drop down of there will be you know at a minimum.\n",
      "cluster before alteration=========>\n",
      "Shouldnt take much time since it is all in modules will be easy.\n",
      "cluster before alteration=========>\n",
      "so actually we each room meeting is actually attached to the DM channel for the\n",
      "cluster before alteration=========>\n",
      "Yeah, let us let us just do this the email one first part.\n",
      "cluster before alteration=========>\n",
      "Well do that first and we will pick up the women will be.\n",
      "cluster before alteration=========>\n",
      "No, not that we can we can work within can go down the car.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yeah, if you can we please the ram of that laptop, it would be great because otherwise it takes a lot of time to load.\n",
      "Thatll help we can just give you do that on this side.\n",
      "Let me log out and the sign in page which we are saying is already signing trying to sign into some particular workspace from which we had blocked.\n",
      "What we are currently doing this we just tested it an Essie before deployment.\n",
      "So there we have the other one, right the one that time which is my Microsoft Surface.\n",
      "Yeah, two things I run one is clapping that is in the K that is directly based on the the Mind association with the summaries.\n",
      "So if he and it is unlikely to have life more than cleverness summaries if we filter out with the mines, so even if you have we are just wrapping it to the five to seven depending upon the confidence of each of the community.\n",
      "Were trying to test out on Multi all the if not all at least most of them most of the domain mind so that we have consistent is across once that is done.\n",
      "By the way, the other one also, I told him to increase the ram.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "It is just that we have to write a bunch of conditions.\n",
      "Well have to run a few experiments to see if that transcriptions are acceptable for performing are related workloads that we currently support.\n",
      "There are few things that we can add or remove the somebody.\n",
      "So you have EBS volume and snapshots are also creating created.\n",
      "Di gusting right now, whatever we have discussed earlier ate the whole thing is implemented like any easy to you can bring it up and the volume remains always the same EBS volume so will not end up recreating EBS volume or anything like that.\n",
      "Also it is okay meaning and in modules we can still send it to create it in the Creator XnumberX node cluster also hope that once we needed we can again start looking good.\n",
      "So whatever was discussed for single node is all done for XnumberX node.\n",
      "So I am looking at not actually using I am using not using the entire response from the summary right now.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Only thing that I think would take a bit of time.\n",
      "Yes, I am working on the adding the react router navigation and creating.\n",
      "Let me think the app flow faster on whenever somebody opens the app for the first time.\n",
      "So I will so there is only I think I guess there will be just one delay when we are looking the app that is like were to check for code push with any new bundle or not.\n",
      "Otherwise, you will be able to see the sturgeon screen quickly.\n",
      "Clicks on the actions, but you will not get at what time it was spoken by the race with the whole screen.\n",
      "Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work.\n",
      "Pleasing to all and bleeding from production board at people as if I go all the image will come through her.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do.\n",
      "So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that.\n",
      "So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right?\n",
      "Okay, the the other there is a couple of other things that will require, you know, maybe some like joint work between Trenton and platform team that is for the cast and Truman is right one is handling the consul of cast right?\n",
      "So we should figure out kind of and then that That requires some backend work as well.\n",
      "Okay in the other one that Colin brought up yesterday was in terms of slide into a way, you know forecast, you know, you started the cost.\n",
      "Like for example, we do not show who started the cast and then sorry we do not show it when you start the cast and then it shows something like cast has been started or something like that.\n",
      "Yeah, but the problem will be if I am doing it and then I am canceling the cast, right?\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "We need to put in place the chances of them looking into that you can add more other than that.\n",
      "This is one of the priorities changed a staging to mind.\n",
      "It is looking as expected for one of those delinquents meeting and there are few debts.\n",
      "Yeah, it is pretty much finished from commercial vehicle for the single instance thing.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "On my side which has to be connected by two languages most and try to submit the resume.\n",
      "Not sure if they are going to accept it because it is under the year.\n",
      "Going to implement really upon the like, you know early yesterday we discussed that we will more except that place.\n",
      "Let is let us wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year.\n",
      "We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event.\n",
      "So in that case my turn what you do is once like you can if the DeGraff things ready like a basic DeGraff single note thing is ready just wrap that up and then you can help with the cast.\n",
      "Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there are not there to bunch of small small things.\n",
      "So those things we can truly, you know added as an input.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Like when when when we put the met somebody to slab earlier we used to call the somebody has potentially important moment.\n",
      "And there are two arguments to this message one is like XnumberX is actually displayed in notifications have notifications.\n",
      "Okay, but first, so if you see the current if you see the current notifications, they still say potentially important moment, but if You go to the slack at there is nothing called.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "I think this these things are already done or whatever these things about time you had to cut this thing to production areas.\n",
      "Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let us have a quick calls day and see is As expected and then you can push the product, okay.\n",
      "Do you think we can kind of get those dumb like there is a couple of things here, I think as\n",
      "A few things one has four slash notes read a couple of tweaks to the slack messages that we sent it posted it in platforms yesterday.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "If you are here any kind of update on the capping the summary segments.\n",
      "Whenever using the summary APA right now, we are not using right now.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "But the main aim was to use it in the front end where we can irritate people.\n",
      "You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack.\n",
      "Actually, it is you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel.\n",
      "Okay, so we do not need to handle it in Netflix video playback.\n",
      "But one thing like with it, even if it is not a test, it comes up in networks view.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Well make the email like the link to which works from email and second.\n",
      "We can add the same functionality on like internet review end playback.\n",
      "So even if that they are viewing the playback and it is not associated.\n",
      "First iteration we can we can have a shareable from the email then we can together.\n",
      "Actually view the meeting as a tile in the Netflix you maybe it is a good idea from from there.\n",
      "Also, we can provide a shaper done is not a different Channel.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "But once this Zoom thing also Contracting the worm she is using the same API right?\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "And then once the cast is done the summary will get pushed now.\n",
      "We have the pretext as still as the potential important moment the study of history rather than highlight so we can make more than that.\n",
      "So in that case, let us take both of these on right forecast.\n",
      "So anyway, we will pick back up any Zoom or notes related marketing only after the beginning of the year.\n",
      "I do not know how hard that is to handle the handle the scenario of you know, not pushing manual markers Etc or interim messages back into slack, but only forecast.\n",
      "But before taking this class, I was thinking of having the summary year there was one issue in summary a period so we do not push back the topic or actions time at the type what time they spoke like the offset is not being sent in the AP response.\n",
      "So by then exhume is also approved then it will actually be nice, you know.\n",
      "So I can just create like a new you need a new email address or new areas new email at the scoreboard.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Okay, so we can push that the production we need to discuss.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So that is the reason we need we need that second is sometimes transcripts.\n",
      "Okay, so I think those are the big ones the one big user story that we need to pick up.\n",
      "Maybe I do not know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we cannot get rid of the header.\n",
      "show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every\n",
      "So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders.\n",
      "I will actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you are running recording time.\n",
      "ER whether it is because if you get more finegrained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together.\n",
      "Listen since say when Karen and I had a discussion yesterday when we find them we were coming.\n",
      "We can use that now Vixens communities move to a different, you know sentence based approach, but we want You just test it with the the transcription from uni passed a full meeting wave to the segment.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So the big ones then we will just kind of run through the others Joshua morning on the front and side.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "We are either calendar you will get an email and the email will have a summary and then they will be a share into slack button.\n",
      "So then if it is a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing.\n",
      "There will be like select slack Channel and share like the screen design there are that is a fly.\n",
      "So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode?\n",
      "Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I will have a discussion with one key after this thing called.\n",
      "See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback.\n",
      "In a meeting to a particular channel, that will be inside me try.\n",
      "Yeah, it will open the me tap there will be a drop down of there will be you know at a minimum.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Shouldnt take much time since it is all in modules will be easy.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "so actually we each room meeting is actually attached to the DM channel for the\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yeah, let us let us just do this the email one first part.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Well do that first and we will pick up the women will be.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "No, not that we can we can work within can go down the car.\n",
      "\n",
      "\n",
      "Checking Timerange --------------\n",
      "--------------\n",
      "Yeah, if you can we please the ram of that laptop, it would be great because otherwise it takes a lot of time to load. 003673f8-1106-4bcb-88de-0eb0b74edd8d \n",
      "\n",
      "So there we have the other one, right the one that time which is my Microsoft Surface. 334821e3-99f9-4a56-80b4-95ed9b722acd \n",
      "\n",
      "Thatll help we can just give you do that on this side. fd3309b7-4121-440a-a8c1-e82694547075 \n",
      "\n",
      "By the way, the other one also, I told him to increase the ram. fd3309b7-4121-440a-a8c1-e82694547075 \n",
      "\n",
      "What we are currently doing this we just tested it an Essie before deployment. a854a0cd-64e5-4a43-8dce-edec3341a4e8 \n",
      "\n",
      "Yeah, two things I run one is clapping that is in the K that is directly based on the the Mind association with the summaries. a854a0cd-64e5-4a43-8dce-edec3341a4e8 \n",
      "\n",
      "Were trying to test out on Multi all the if not all at least most of them most of the domain mind so that we have consistent is across once that is done. a854a0cd-64e5-4a43-8dce-edec3341a4e8 \n",
      "\n",
      "So if he and it is unlikely to have life more than cleverness summaries if we filter out with the mines, so even if you have we are just wrapping it to the five to seven depending upon the confidence of each of the community. a854a0cd-64e5-4a43-8dce-edec3341a4e8 \n",
      "\n",
      "Let me log out and the sign in page which we are saying is already signing trying to sign into some particular workspace from which we had blocked. 32136eaa-66ae-4400-bc04-ac7cf2117785 \n",
      "\n",
      "--------------\n",
      "It is just that we have to write a bunch of conditions. 08f15ac1-1ac0-462b-a1a1-f8be0e0f0f86 \n",
      "\n",
      "So I am looking at not actually using I am using not using the entire response from the summary right now. 8f566d3d-b209-4e8f-bac7-00835cc1c63d \n",
      "\n",
      "There are few things that we can add or remove the somebody. 8f566d3d-b209-4e8f-bac7-00835cc1c63d \n",
      "\n",
      "So whatever was discussed for single node is all done for XnumberX node. 59155015-2164-4f00-9c5f-1c52cec88b6c \n",
      "\n",
      "Also it is okay meaning and in modules we can still send it to create it in the Creator XnumberX node cluster also hope that once we needed we can again start looking good. 59155015-2164-4f00-9c5f-1c52cec88b6c \n",
      "\n",
      "So you have EBS volume and snapshots are also creating created. 59155015-2164-4f00-9c5f-1c52cec88b6c \n",
      "\n",
      "Di gusting right now, whatever we have discussed earlier ate the whole thing is implemented like any easy to you can bring it up and the volume remains always the same EBS volume so will not end up recreating EBS volume or anything like that. 59155015-2164-4f00-9c5f-1c52cec88b6c \n",
      "\n",
      "Well have to run a few experiments to see if that transcriptions are acceptable for performing are related workloads that we currently support. 3cab1639-06f6-446d-bdaf-95c880ebe51f \n",
      "\n",
      "--------------\n",
      "Clicks on the actions, but you will not get at what time it was spoken by the race with the whole screen. 5c3686e8-a762-4d1a-9743-957d965a9035 \n",
      "\n",
      "Pleasing to all and bleeding from production board at people as if I go all the image will come through her. c33633c5-1972-4fee-8244-0d02d8487ce8 \n",
      "\n",
      "Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work. 742bcce9-b938-4184-af8f-d24bba61b6b9 \n",
      "\n",
      "Only thing that I think would take a bit of time. 19bc16e0-243b-4a3d-9358-db204346e352 \n",
      "\n",
      "Let me think the app flow faster on whenever somebody opens the app for the first time. 19bc16e0-243b-4a3d-9358-db204346e352 \n",
      "\n",
      "Yes, I am working on the adding the react router navigation and creating. 19bc16e0-243b-4a3d-9358-db204346e352 \n",
      "\n",
      "Otherwise, you will be able to see the sturgeon screen quickly. 19bc16e0-243b-4a3d-9358-db204346e352 \n",
      "\n",
      "So I will so there is only I think I guess there will be just one delay when we are looking the app that is like were to check for code push with any new bundle or not. 19bc16e0-243b-4a3d-9358-db204346e352 \n",
      "\n",
      "--------------\n",
      "Yeah, but the problem will be if I am doing it and then I am canceling the cast, right? 8e139327-69d6-440f-8600-21763e906b4c \n",
      "\n",
      "Okay, the the other there is a couple of other things that will require, you know, maybe some like joint work between Trenton and platform team that is for the cast and Truman is right one is handling the consul of cast right? 8e139327-69d6-440f-8600-21763e906b4c \n",
      "\n",
      "So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right? 8e139327-69d6-440f-8600-21763e906b4c \n",
      "\n",
      "Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do. 8e139327-69d6-440f-8600-21763e906b4c \n",
      "\n",
      "Okay in the other one that Colin brought up yesterday was in terms of slide into a way, you know forecast, you know, you started the cost. 8e139327-69d6-440f-8600-21763e906b4c \n",
      "\n",
      "So we should figure out kind of and then that That requires some backend work as well. 8e139327-69d6-440f-8600-21763e906b4c \n",
      "\n",
      "Like for example, we do not show who started the cast and then sorry we do not show it when you start the cast and then it shows something like cast has been started or something like that. 8e139327-69d6-440f-8600-21763e906b4c \n",
      "\n",
      "So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that. 8e139327-69d6-440f-8600-21763e906b4c \n",
      "\n",
      "--------------\n",
      "We need to put in place the chances of them looking into that you can add more other than that. acb8bdc5-af26-4666-b96e-7efde8c37d83 \n",
      "\n",
      "Yeah, it is pretty much finished from commercial vehicle for the single instance thing. acb8bdc5-af26-4666-b96e-7efde8c37d83 \n",
      "\n",
      "This is one of the priorities changed a staging to mind. acb8bdc5-af26-4666-b96e-7efde8c37d83 \n",
      "\n",
      "It is looking as expected for one of those delinquents meeting and there are few debts. acb8bdc5-af26-4666-b96e-7efde8c37d83 \n",
      "\n",
      "--------------\n",
      "So in that case my turn what you do is once like you can if the DeGraff things ready like a basic DeGraff single note thing is ready just wrap that up and then you can help with the cast. 38ba0c61-9167-4198-bea1-f027587600f9 \n",
      "\n",
      "We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event. 27eb7db0-3eec-443d-95de-414296c002c3 \n",
      "\n",
      "So those things we can truly, you know added as an input. 72ddba77-7fa4-469a-a784-4dbc4b543d74 \n",
      "\n",
      "Going to implement really upon the like, you know early yesterday we discussed that we will more except that place. 72ddba77-7fa4-469a-a784-4dbc4b543d74 \n",
      "\n",
      "Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there are not there to bunch of small small things. 72ddba77-7fa4-469a-a784-4dbc4b543d74 \n",
      "\n",
      "On my side which has to be connected by two languages most and try to submit the resume. 0967de49-c222-4ea0-8735-f537f67b6d39 \n",
      "\n",
      "Not sure if they are going to accept it because it is under the year. 0967de49-c222-4ea0-8735-f537f67b6d39 \n",
      "\n",
      "Let is let us wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year. a01c0450-6894-464a-a305-ceabb23d2457 \n",
      "\n",
      "--------------\n",
      "Like when when when we put the met somebody to slab earlier we used to call the somebody has potentially important moment. 0bde7f12-fd9a-4f55-b459-6e19910db096 \n",
      "\n",
      "And there are two arguments to this message one is like XnumberX is actually displayed in notifications have notifications. 0bde7f12-fd9a-4f55-b459-6e19910db096 \n",
      "\n",
      "Okay, but first, so if you see the current if you see the current notifications, they still say potentially important moment, but if You go to the slack at there is nothing called. 0bde7f12-fd9a-4f55-b459-6e19910db096 \n",
      "\n",
      "--------------\n",
      "A few things one has four slash notes read a couple of tweaks to the slack messages that we sent it posted it in platforms yesterday. 1b81d6f2-d369-402c-b62a-a990c213ea7b \n",
      "\n",
      "Do you think we can kind of get those dumb like there is a couple of things here, I think as 1b81d6f2-d369-402c-b62a-a990c213ea7b \n",
      "\n",
      "Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let us have a quick calls day and see is As expected and then you can push the product, okay. 12420e65-ef60-4f60-8e96-76dedfbb2e23 \n",
      "\n",
      "I think this these things are already done or whatever these things about time you had to cut this thing to production areas. 12420e65-ef60-4f60-8e96-76dedfbb2e23 \n",
      "\n",
      "--------------\n",
      "If you are here any kind of update on the capping the summary segments. 34abdd36-ef73-46bd-8c3e-25907b13beee \n",
      "\n",
      "Whenever using the summary APA right now, we are not using right now. cd9470bb-d1e7-4a50-9a2d-19078faac782 \n",
      "\n",
      "--------------\n",
      "Okay, so we do not need to handle it in Netflix video playback. 83738537-2323-496c-9886-92e41438d2e8 \n",
      "\n",
      "Actually, it is you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel. d8e03669-d04a-4ce6-a780-29295eb694a4 \n",
      "\n",
      "But one thing like with it, even if it is not a test, it comes up in networks view. 8c37d0f1-9036-4468-ad66-e23a366d6f00 \n",
      "\n",
      "You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack. 62be212b-dc64-434c-9f02-3f8f759807e1 \n",
      "\n",
      "But the main aim was to use it in the front end where we can irritate people. d397bc8c-9796-4de8-aa4b-a9e405cad05e \n",
      "\n",
      "--------------\n",
      "Actually view the meeting as a tile in the Netflix you maybe it is a good idea from from there. 3842acb8-9ded-4ef9-a6c8-f65f7386b0b2 \n",
      "\n",
      "Also, we can provide a shaper done is not a different Channel. 3842acb8-9ded-4ef9-a6c8-f65f7386b0b2 \n",
      "\n",
      "First iteration we can we can have a shareable from the email then we can together. d2d5571c-901a-4e76-ac4f-034ed100e442 \n",
      "\n",
      "So even if that they are viewing the playback and it is not associated. 2b60be6b-b710-46a8-ac08-b9ea6224aad2 \n",
      "\n",
      "We can add the same functionality on like internet review end playback. 2b60be6b-b710-46a8-ac08-b9ea6224aad2 \n",
      "\n",
      "Well make the email like the link to which works from email and second. 2b60be6b-b710-46a8-ac08-b9ea6224aad2 \n",
      "\n",
      "--------------\n",
      "But once this Zoom thing also Contracting the worm she is using the same API right? 303735b4-c1ec-48b2-bcf5-f1bbc913448a \n",
      "\n",
      "--------------\n",
      "We have the pretext as still as the potential important moment the study of history rather than highlight so we can make more than that. 4310d857-1b78-49ba-a9af-0b9a4acdab07 \n",
      "\n",
      "And then once the cast is done the summary will get pushed now. b7368240-9b6c-4726-a6ae-ecb4f1c5b27e \n",
      "\n",
      "I do not know how hard that is to handle the handle the scenario of you know, not pushing manual markers Etc or interim messages back into slack, but only forecast. b7368240-9b6c-4726-a6ae-ecb4f1c5b27e \n",
      "\n",
      "So in that case, let us take both of these on right forecast. a680e1c8-3b1f-45ee-a40c-e6eaf852c9a3 \n",
      "\n",
      "But before taking this class, I was thinking of having the summary year there was one issue in summary a period so we do not push back the topic or actions time at the type what time they spoke like the offset is not being sent in the AP response. eabc573d-4c77-4ec1-8aba-d2459c043464 \n",
      "\n",
      "So by then exhume is also approved then it will actually be nice, you know. bc420bc9-7cef-4474-99a0-f1f633ef9523 \n",
      "\n",
      "So anyway, we will pick back up any Zoom or notes related marketing only after the beginning of the year. bc420bc9-7cef-4474-99a0-f1f633ef9523 \n",
      "\n",
      "So I can just create like a new you need a new email address or new areas new email at the scoreboard. f616a264-fa75-44b9-b917-5315b0b9083c \n",
      "\n",
      "--------------\n",
      "Okay, so we can push that the production we need to discuss. 5edfcb56-7b96-48d1-9def-6a8c847ebce0 \n",
      "\n",
      "--------------\n",
      "So that is the reason we need we need that second is sometimes transcripts. 871c87b7-095c-4f4b-b688-a01f907607cd \n",
      "\n",
      "Okay, so I think those are the big ones the one big user story that we need to pick up. 871c87b7-095c-4f4b-b688-a01f907607cd \n",
      "\n",
      "show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every 871c87b7-095c-4f4b-b688-a01f907607cd \n",
      "\n",
      "Maybe I do not know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we cannot get rid of the header. 871c87b7-095c-4f4b-b688-a01f907607cd \n",
      "\n",
      "So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders. 99666ff3-e998-423a-a761-ab8c9cc60b14 \n",
      "\n",
      "Listen since say when Karen and I had a discussion yesterday when we find them we were coming. bb97dad3-65f5-40fc-abda-456dc1b8a261 \n",
      "\n",
      "I will actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you are running recording time. bb97dad3-65f5-40fc-abda-456dc1b8a261 \n",
      "\n",
      "ER whether it is because if you get more finegrained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together. bb97dad3-65f5-40fc-abda-456dc1b8a261 \n",
      "\n",
      "We can use that now Vixens communities move to a different, you know sentence based approach, but we want You just test it with the the transcription from uni passed a full meeting wave to the segment. bb97dad3-65f5-40fc-abda-456dc1b8a261 \n",
      "\n",
      "--------------\n",
      "So the big ones then we will just kind of run through the others Joshua morning on the front and side. 87d32185-bfed-43a1-b64e-72c6ebef29f3 \n",
      "\n",
      "--------------\n",
      "See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback. cff93d89-53d9-4d37-865e-b03fc7c2a175 \n",
      "\n",
      "So then if it is a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing. d5f6b164-8cd2-4c5b-9af8-fa7fc726b982 \n",
      "\n",
      "In a meeting to a particular channel, that will be inside me try. d5f6b164-8cd2-4c5b-9af8-fa7fc726b982 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I will have a discussion with one key after this thing called. d5f6b164-8cd2-4c5b-9af8-fa7fc726b982 \n",
      "\n",
      "So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode? a48a753b-e77f-4fd2-9ad9-dc03c68e5e26 \n",
      "\n",
      "We are either calendar you will get an email and the email will have a summary and then they will be a share into slack button. 9fc378b0-a4a9-4927-a1b7-370675beb5e5 \n",
      "\n",
      "There will be like select slack Channel and share like the screen design there are that is a fly. d67ce22a-89d8-40ba-8c3b-48d4d64b1ae7 \n",
      "\n",
      "Yeah, it will open the me tap there will be a drop down of there will be you know at a minimum. d67ce22a-89d8-40ba-8c3b-48d4d64b1ae7 \n",
      "\n",
      "--------------\n",
      "Shouldnt take much time since it is all in modules will be easy. acd23bb0-2029-4971-a9e1-b5962a4e313c \n",
      "\n",
      "--------------\n",
      "so actually we each room meeting is actually attached to the DM channel for the b32dbe78-35c8-4c25-aecc-d0d7046bab80 \n",
      "\n",
      "--------------\n",
      "Yeah, let us let us just do this the email one first part. bc0fd7fd-7ef1-47ec-850e-2f1a0e5bf767 \n",
      "\n",
      "--------------\n",
      "Well do that first and we will pick up the women will be. c7ac1a35-0dbb-4581-9429-d6fc02ba2b33 \n",
      "\n",
      "--------------\n",
      "No, not that we can we can work within can go down the car. f3ed6496-e88f-4d9e-86c5-65faed42b76a \n",
      "\n",
      "<---------------->\n",
      "order difference: 1\n",
      "Relevant sentence:  Yeah, if you can we please the ram of that laptop, it would be great because otherwise it takes a lot of time to load.    =====    So there we have the other one, right the one that time which is my Microsoft Surface.\n",
      "order difference: 1\n",
      "Relevant sentence:  So there we have the other one, right the one that time which is my Microsoft Surface.    =====    Thatll help we can just give you do that on this side.\n",
      "order difference: 0\n",
      "Relevant sentence:  Thatll help we can just give you do that on this side.    =====    By the way, the other one also, I told him to increase the ram.\n",
      "Not Relevant sentence:  By the way, the other one also, I told him to increase the ram.    !=    What we are currently doing this we just tested it an Essie before deployment.\n",
      "order difference: 2\n",
      "order difference: 0\n",
      "Relevant sentence:  What we are currently doing this we just tested it an Essie before deployment.    =====    Yeah, two things I run one is clapping that is in the K that is directly based on the the Mind association with the summaries.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, two things I run one is clapping that is in the K that is directly based on the the Mind association with the summaries.    =====    Were trying to test out on Multi all the if not all at least most of them most of the domain mind so that we have consistent is across once that is done.\n",
      "order difference: 0\n",
      "Relevant sentence:  Were trying to test out on Multi all the if not all at least most of them most of the domain mind so that we have consistent is across once that is done.    =====    So if he and it is unlikely to have life more than cleverness summaries if we filter out with the mines, so even if you have we are just wrapping it to the five to seven depending upon the confidence of each of the community.\n",
      "Not Relevant sentence:  So if he and it is unlikely to have life more than cleverness summaries if we filter out with the mines, so even if you have we are just wrapping it to the five to seven depending upon the confidence of each of the community.    !=    Let me log out and the sign in page which we are saying is already signing trying to sign into some particular workspace from which we had blocked.\n",
      "order difference: 2\n",
      "Not Relevant sentence:  It is just that we have to write a bunch of conditions.    !=    So I am looking at not actually using I am using not using the entire response from the summary right now.\n",
      "order difference: 8\n",
      "order difference: 0\n",
      "Relevant sentence:  So I am looking at not actually using I am using not using the entire response from the summary right now.    =====    There are few things that we can add or remove the somebody.\n",
      "order difference: 1\n",
      "Relevant sentence:  There are few things that we can add or remove the somebody.    =====    So whatever was discussed for single node is all done for XnumberX node.\n",
      "order difference: 0\n",
      "Relevant sentence:  So whatever was discussed for single node is all done for XnumberX node.    =====    Also it is okay meaning and in modules we can still send it to create it in the Creator XnumberX node cluster also hope that once we needed we can again start looking good.\n",
      "order difference: 0\n",
      "Relevant sentence:  Also it is okay meaning and in modules we can still send it to create it in the Creator XnumberX node cluster also hope that once we needed we can again start looking good.    =====    So you have EBS volume and snapshots are also creating created.\n",
      "order difference: 0\n",
      "Relevant sentence:  So you have EBS volume and snapshots are also creating created.    =====    Di gusting right now, whatever we have discussed earlier ate the whole thing is implemented like any easy to you can bring it up and the volume remains always the same EBS volume so will not end up recreating EBS volume or anything like that.\n",
      "Not Relevant sentence:  Di gusting right now, whatever we have discussed earlier ate the whole thing is implemented like any easy to you can bring it up and the volume remains always the same EBS volume so will not end up recreating EBS volume or anything like that.    !=    Well have to run a few experiments to see if that transcriptions are acceptable for performing are related workloads that we currently support.\n",
      "order difference: 17\n",
      "Not Relevant sentence:  Clicks on the actions, but you will not get at what time it was spoken by the race with the whole screen.    !=    Pleasing to all and bleeding from production board at people as if I go all the image will come through her.\n",
      "order difference: 13\n",
      "order difference: 1\n",
      "Relevant sentence:  Pleasing to all and bleeding from production board at people as if I go all the image will come through her.    =====    Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work.\n",
      "order difference: 1\n",
      "Relevant sentence:  Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work.    =====    Only thing that I think would take a bit of time.\n",
      "order difference: 0\n",
      "Relevant sentence:  Only thing that I think would take a bit of time.    =====    Let me think the app flow faster on whenever somebody opens the app for the first time.\n",
      "order difference: 0\n",
      "Relevant sentence:  Let me think the app flow faster on whenever somebody opens the app for the first time.    =====    Yes, I am working on the adding the react router navigation and creating.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yes, I am working on the adding the react router navigation and creating.    =====    Otherwise, you will be able to see the sturgeon screen quickly.\n",
      "order difference: 0\n",
      "Relevant sentence:  Otherwise, you will be able to see the sturgeon screen quickly.    =====    So I will so there is only I think I guess there will be just one delay when we are looking the app that is like were to check for code push with any new bundle or not.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, but the problem will be if I am doing it and then I am canceling the cast, right?    =====    Okay, the the other there is a couple of other things that will require, you know, maybe some like joint work between Trenton and platform team that is for the cast and Truman is right one is handling the consul of cast right?\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay, the the other there is a couple of other things that will require, you know, maybe some like joint work between Trenton and platform team that is for the cast and Truman is right one is handling the consul of cast right?    =====    So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right?    =====    Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do.    =====    Okay in the other one that Colin brought up yesterday was in terms of slide into a way, you know forecast, you know, you started the cost.\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay in the other one that Colin brought up yesterday was in terms of slide into a way, you know forecast, you know, you started the cost.    =====    So we should figure out kind of and then that That requires some backend work as well.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we should figure out kind of and then that That requires some backend work as well.    =====    Like for example, we do not show who started the cast and then sorry we do not show it when you start the cast and then it shows something like cast has been started or something like that.\n",
      "order difference: 0\n",
      "Relevant sentence:  Like for example, we do not show who started the cast and then sorry we do not show it when you start the cast and then it shows something like cast has been started or something like that.    =====    So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that.\n",
      "order difference: 0\n",
      "Relevant sentence:  We need to put in place the chances of them looking into that you can add more other than that.    =====    Yeah, it is pretty much finished from commercial vehicle for the single instance thing.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, it is pretty much finished from commercial vehicle for the single instance thing.    =====    This is one of the priorities changed a staging to mind.\n",
      "order difference: 0\n",
      "Relevant sentence:  This is one of the priorities changed a staging to mind.    =====    It is looking as expected for one of those delinquents meeting and there are few debts.\n",
      "Not Relevant sentence:  So in that case my turn what you do is once like you can if the DeGraff things ready like a basic DeGraff single note thing is ready just wrap that up and then you can help with the cast.    !=    We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event.\n",
      "order difference: 2\n",
      "order difference: 1\n",
      "Relevant sentence:  We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event.    =====    So those things we can truly, you know added as an input.\n",
      "order difference: 0\n",
      "Relevant sentence:  So those things we can truly, you know added as an input.    =====    Going to implement really upon the like, you know early yesterday we discussed that we will more except that place.\n",
      "order difference: 0\n",
      "Relevant sentence:  Going to implement really upon the like, you know early yesterday we discussed that we will more except that place.    =====    Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there are not there to bunch of small small things.\n",
      "order difference: 1\n",
      "Relevant sentence:  Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there are not there to bunch of small small things.    =====    On my side which has to be connected by two languages most and try to submit the resume.\n",
      "order difference: 0\n",
      "Relevant sentence:  On my side which has to be connected by two languages most and try to submit the resume.    =====    Not sure if they are going to accept it because it is under the year.\n",
      "order difference: 1\n",
      "Relevant sentence:  Not sure if they are going to accept it because it is under the year.    =====    Let is let us wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year.\n",
      "order difference: 0\n",
      "Relevant sentence:  Like when when when we put the met somebody to slab earlier we used to call the somebody has potentially important moment.    =====    And there are two arguments to this message one is like XnumberX is actually displayed in notifications have notifications.\n",
      "order difference: 0\n",
      "Relevant sentence:  And there are two arguments to this message one is like XnumberX is actually displayed in notifications have notifications.    =====    Okay, but first, so if you see the current if you see the current notifications, they still say potentially important moment, but if You go to the slack at there is nothing called.\n",
      "order difference: 0\n",
      "Relevant sentence:  A few things one has four slash notes read a couple of tweaks to the slack messages that we sent it posted it in platforms yesterday.    =====    Do you think we can kind of get those dumb like there is a couple of things here, I think as\n",
      "order difference: 1\n",
      "Relevant sentence:  Do you think we can kind of get those dumb like there is a couple of things here, I think as    =====    Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let us have a quick calls day and see is As expected and then you can push the product, okay.\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let us have a quick calls day and see is As expected and then you can push the product, okay.    =====    I think this these things are already done or whatever these things about time you had to cut this thing to production areas.\n",
      "Not Relevant sentence:  If you are here any kind of update on the capping the summary segments.    !=    Whenever using the summary APA right now, we are not using right now.\n",
      "order difference: 25\n",
      "order difference: 1\n",
      "Relevant sentence:  Okay, so we do not need to handle it in Netflix video playback.    =====    Actually, it is you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel.\n",
      "order difference: 1\n",
      "Relevant sentence:  Actually, it is you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel.    =====    But one thing like with it, even if it is not a test, it comes up in networks view.\n",
      "Not Relevant sentence:  But one thing like with it, even if it is not a test, it comes up in networks view.    !=    You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack.\n",
      "order difference: 7\n",
      "Not Relevant sentence:  You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack.    !=    But the main aim was to use it in the front end where we can irritate people.\n",
      "order difference: 8\n",
      "order difference: 0\n",
      "Relevant sentence:  Actually view the meeting as a tile in the Netflix you maybe it is a good idea from from there.    =====    Also, we can provide a shaper done is not a different Channel.\n",
      "order difference: 1\n",
      "Relevant sentence:  Also, we can provide a shaper done is not a different Channel.    =====    First iteration we can we can have a shareable from the email then we can together.\n",
      "order difference: 1\n",
      "Relevant sentence:  First iteration we can we can have a shareable from the email then we can together.    =====    So even if that they are viewing the playback and it is not associated.\n",
      "order difference: 0\n",
      "Relevant sentence:  So even if that they are viewing the playback and it is not associated.    =====    We can add the same functionality on like internet review end playback.\n",
      "order difference: 0\n",
      "Relevant sentence:  We can add the same functionality on like internet review end playback.    =====    Well make the email like the link to which works from email and second.\n",
      "Not Relevant sentence:  We have the pretext as still as the potential important moment the study of history rather than highlight so we can make more than that.    !=    And then once the cast is done the summary will get pushed now.\n",
      "order difference: 26\n",
      "order difference: 0\n",
      "Relevant sentence:  And then once the cast is done the summary will get pushed now.    =====    I do not know how hard that is to handle the handle the scenario of you know, not pushing manual markers Etc or interim messages back into slack, but only forecast.\n",
      "Not Relevant sentence:  I do not know how hard that is to handle the handle the scenario of you know, not pushing manual markers Etc or interim messages back into slack, but only forecast.    !=    So in that case, let us take both of these on right forecast.\n",
      "order difference: 2\n",
      "order difference: 1\n",
      "Relevant sentence:  So in that case, let us take both of these on right forecast.    =====    But before taking this class, I was thinking of having the summary year there was one issue in summary a period so we do not push back the topic or actions time at the type what time they spoke like the offset is not being sent in the AP response.\n",
      "Not Relevant sentence:  But before taking this class, I was thinking of having the summary year there was one issue in summary a period so we do not push back the topic or actions time at the type what time they spoke like the offset is not being sent in the AP response.    !=    So by then exhume is also approved then it will actually be nice, you know.\n",
      "order difference: 15\n",
      "order difference: 0\n",
      "Relevant sentence:  So by then exhume is also approved then it will actually be nice, you know.    =====    So anyway, we will pick back up any Zoom or notes related marketing only after the beginning of the year.\n",
      "Not Relevant sentence:  So anyway, we will pick back up any Zoom or notes related marketing only after the beginning of the year.    !=    So I can just create like a new you need a new email address or new areas new email at the scoreboard.\n",
      "order difference: 2\n",
      "order difference: 0\n",
      "Relevant sentence:  So that is the reason we need we need that second is sometimes transcripts.    =====    Okay, so I think those are the big ones the one big user story that we need to pick up.\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay, so I think those are the big ones the one big user story that we need to pick up.    =====    show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every\n",
      "order difference: 0\n",
      "Relevant sentence:  show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every    =====    Maybe I do not know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we cannot get rid of the header.\n",
      "order difference: 1\n",
      "Relevant sentence:  Maybe I do not know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we cannot get rid of the header.    =====    So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders.\n",
      "order difference: 1\n",
      "Relevant sentence:  So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders.    =====    Listen since say when Karen and I had a discussion yesterday when we find them we were coming.\n",
      "order difference: 0\n",
      "Relevant sentence:  Listen since say when Karen and I had a discussion yesterday when we find them we were coming.    =====    I will actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you are running recording time.\n",
      "order difference: 0\n",
      "Relevant sentence:  I will actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you are running recording time.    =====    ER whether it is because if you get more finegrained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together.\n",
      "order difference: 0\n",
      "Relevant sentence:  ER whether it is because if you get more finegrained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together.    =====    We can use that now Vixens communities move to a different, you know sentence based approach, but we want You just test it with the the transcription from uni passed a full meeting wave to the segment.\n",
      "order difference: 1\n",
      "Relevant sentence:  See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback.    =====    So then if it is a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing.\n",
      "order difference: 0\n",
      "Relevant sentence:  So then if it is a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing.    =====    In a meeting to a particular channel, that will be inside me try.\n",
      "order difference: 0\n",
      "Relevant sentence:  In a meeting to a particular channel, that will be inside me try.    =====    Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I will have a discussion with one key after this thing called.\n",
      "order difference: 1\n",
      "Relevant sentence:  Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I will have a discussion with one key after this thing called.    =====    So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode?\n",
      "order difference: 1\n",
      "Relevant sentence:  So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode?    =====    We are either calendar you will get an email and the email will have a summary and then they will be a share into slack button.\n",
      "order difference: 1\n",
      "Relevant sentence:  We are either calendar you will get an email and the email will have a summary and then they will be a share into slack button.    =====    There will be like select slack Channel and share like the screen design there are that is a fly.\n",
      "order difference: 0\n",
      "Relevant sentence:  There will be like select slack Channel and share like the screen design there are that is a fly.    =====    Yeah, it will open the me tap there will be a drop down of there will be you know at a minimum.\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (9, 7), (8, 8), (10, 9), (11, 10), (12, 11), (13, 12), (17, 12), (18, 12), (14, 13), (15, 14), (16, 15)]\n",
      "[[[\"Come on credit later, because in the citational logic we have to add about whether it's shared already or not. You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack. So there's a bunch of things. We have to be careful about. Let's do that. Let's just do the email and share from email. Got it. \"], '2019-12-19T06:13:08Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '62be212b-dc64-434c-9f02-3f8f759807e1']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['Okay. Okay, so we do not need to handle it in Netflix video playback. '], '2019-12-19T06:11:35Z', '0bbbfe84c66145af8d0ffcd5258bba38', '83738537-2323-496c-9886-92e41438d2e8'], [[\"Actually, it's you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel. \"], '2019-12-19T06:11:42Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'd8e03669-d04a-4ce6-a780-29295eb694a4'], [[\"But one thing like with it, even if it's not a test, it comes up in networks view. He had them from Netflix me. \"], '2019-12-19T06:11:52Z', '0bbbfe84c66145af8d0ffcd5258bba38', '8c37d0f1-9036-4468-ad66-e23a366d6f00']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"So I'm looking at not actually using I'm using not using the entire response from the summary right now. Okay, all we go. We can go to the cash. There are few things that we can add or remove the somebody. But okay. \"], '2019-12-19T06:17:17Z', '1a21542584494fcaba957d768b595b80', '8f566d3d-b209-4e8f-bac7-00835cc1c63d'], [['Di gusting right now, whatever we have discussed earlier ate the whole thing is implemented like any easy to you can bring it up and the volume remains always the same EBS volume so will not end up recreating EBS volume or anything like that. So you have EBS volume and snapshots are also creating created. So whatever was discussed for single node is all done for 3 node. Also it is okay meaning and in modules we can still send it to create it in the Creator 3 node cluster also hope that once we needed we can again start looking good. '], '2019-12-19T06:17:39Z', '84fbaa66a2474ea29ae053f3a2e519d6', '59155015-2164-4f00-9c5f-1c52cec88b6c']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['Pleasing to all and bleeding from production board at people as if I go all the image will come through her. '], '2019-12-19T06:21:49Z', '1a21542584494fcaba957d768b595b80', 'c33633c5-1972-4fee-8244-0d02d8487ce8'], [[\"Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work. But let's see what is actually doing. \"], '2019-12-19T06:22:13Z', '1a21542584494fcaba957d768b595b80', '742bcce9-b938-4184-af8f-d24bba61b6b9'], [[\"Yes, I am working on the adding the react router navigation and creating. Let me think the app flow faster on whenever somebody opens the app for the first time. So I will so there's only I think I guess there will be just one delay when we're looking the app that is like were to check for code push with any new bundle or not. That is new. Only thing that I think would take a bit of time. Otherwise, you'll be able to see the sturgeon screen quickly. We assign them so this okay. \"], '2019-12-19T06:22:47Z', 'b4a57b25de68446cac990f856d3fe4d5', '19bc16e0-243b-4a3d-9358-db204346e352']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yeah, we so we actually run a interest today. This is one of the priorities changed a staging to mind. It's looking as expected for one of those delinquents meeting and there are few debts. We need to put in place the chances of them looking into that you can add more other than that. Yeah, it's pretty much finished from commercial vehicle for the single instance thing. You can we can really push it to production. Maybe next time we can have a sink on you. \"], '2019-12-19T06:18:51Z', '1a21542584494fcaba957d768b595b80', 'acb8bdc5-af26-4666-b96e-7efde8c37d83']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"So that's one and that's what things I like all the new notification that we get in forms like an Android and iOS. We have the pretext as still as the potential important moment the study of history rather than highlight so we can make more than that. \"], '2019-12-19T06:04:52Z', '1a21542584494fcaba957d768b595b80', '4310d857-1b78-49ba-a9af-0b9a4acdab07']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"And then once the cast is done the summary will get pushed now. I don't know how hard that is to handle the handle the scenario of you know, not pushing manual markers Etc or interim messages back into slack, but only forecast. \"], '2019-12-19T06:15:18Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'b7368240-9b6c-4726-a6ae-ecb4f1c5b27e']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yeah, two things I run one is clapping that is in the K that is directly based on the the Mind association with the summaries. So this way we need not Brute Force fabric. So if he and it's unlikely to have life more than cleverness summaries if we filter out with the mines, so even if you have we are just wrapping it to the five to seven depending upon the confidence of each of the community. What we are currently doing this we just tested it an Essie before deployment. We're trying to test out on Multi all the if not all at least most of them most of the domain mind so that we have consistent is across once that is done. We will deploy it into staging too. \"], '2019-12-19T06:07:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a854a0cd-64e5-4a43-8dce-edec3341a4e8']] \n",
      "\n",
      "\n",
      "[[[\"Okay. Alright. So in that case, let's take both of these on right forecast. So that that cost related things are completed. Okay. All right sigh I can take up that path but \"], '2019-12-19T06:15:43Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'a680e1c8-3b1f-45ee-a40c-e6eaf852c9a3'], [[\"But before taking this class, I was thinking of having the summary year there was one issue in summary a period so we don't push back the topic or actions time at the type what time they spoke like the offset is not being sent in the AP response. \"], '2019-12-19T06:16:05Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'eabc573d-4c77-4ec1-8aba-d2459c043464']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Okay, so I think those are the big ones the one big user story that we need to pick up. Maybe I don't know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we can't get rid of the header. So that's the reason we need we need that second is sometimes transcripts. show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every \"], '2019-12-19T06:23:37Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '871c87b7-095c-4f4b-b688-a01f907607cd'], [['Missing transcription of the last segment in a call and then audio clips in playback. So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders. '], '2019-12-19T06:24:25Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '99666ff3-e998-423a-a761-ab8c9cc60b14'], [[\"Listen since say when Karen and I had a discussion yesterday when we find them we were coming. I'll actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you're running recording time. We can use that now Vixens communities move to a different, you know sentence based approach, but we want You just test it with the the transcription from uni passed a full meeting wave to the segment. ER whether it is because if you get more fine-grained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together. \"], '2019-12-19T06:24:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bb97dad3-65f5-40fc-abda-456dc1b8a261']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Exactly. Yeah because anyways is no point doing marketing during holidays. Also, nobody will be seeing it. So anyway, we'll pick back up any Zoom or notes related marketing only after the beginning of the year. So by then exhume is also approved then it will actually be nice, you know. \"], '2019-12-19T06:20:58Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'bc420bc9-7cef-4474-99a0-f1f633ef9523']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"A few things one has four slash notes read a couple of tweaks to the slack messages that we sent it posted it in platforms yesterday. Do you think we can kind of get those dumb like there's a couple of things here, I think as \"], '2019-12-19T06:03:47Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '1b81d6f2-d369-402c-b62a-a990c213ea7b'], [[\"I think this these things are already done or whatever these things about time you had to cut this thing to production areas. Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let's have a quick calls day and see is As expected and then you can push the product, okay. \"], '2019-12-19T06:04:08Z', '1a21542584494fcaba957d768b595b80', '12420e65-ef60-4f60-8e96-76dedfbb2e23']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['Okay. Yeah, if you can we please the ram of that laptop, it would be great because otherwise it takes a lot of time to load. '], '2019-12-19T06:06:51Z', '0bbbfe84c66145af8d0ffcd5258bba38', '003673f8-1106-4bcb-88de-0eb0b74edd8d'], [['So there we have the other one, right the one that time which is my Microsoft Surface. '], '2019-12-19T06:06:58Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '334821e3-99f9-4a56-80b4-95ed9b722acd'], [[\"By the way, the other one also, I told him to increase the ram. That another one. Yeah. I told him to just give it an even crazier than I am. That'll help we can just give you do that on this side. Anyway, yeah. \"], '2019-12-19T06:07:16Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'fd3309b7-4121-440a-a8c1-e82694547075']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Actually view the meeting as a tile in the Netflix you maybe it's a good idea from from there. Also, we can provide a shaper done is not a different Channel. \"], '2019-12-19T06:12:11Z', '1a21542584494fcaba957d768b595b80', '3842acb8-9ded-4ef9-a6c8-f65f7386b0b2'], [['First iteration we can we can have a shareable from the email then we can together. '], '2019-12-19T06:12:32Z', '1a21542584494fcaba957d768b595b80', 'd2d5571c-901a-4e76-ac4f-034ed100e442'], [[\"You can have all three states first. We'll make the email like the link to which works from email and second. We can add the same functionality on like internet review end playback. So even if that they are viewing the playback and it's not associated. They can just click on the button and associated. \"], '2019-12-19T06:12:41Z', '0bbbfe84c66145af8d0ffcd5258bba38', '2b60be6b-b710-46a8-ac08-b9ea6224aad2']] \n",
      "\n",
      "\n",
      "[[['Plenty of work. What a partial. What do you guys plan to take on next? See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback. That will be good. '], '2019-12-19T06:09:38Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'cff93d89-53d9-4d37-865e-b03fc7c2a175'], [[\"Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I'll have a discussion with one key after this thing called. So then if it's a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing. In a meeting to a particular channel, that will be inside me try. \"], '2019-12-19T06:09:55Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'd5f6b164-8cd2-4c5b-9af8-fa7fc726b982'], [['So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode? '], '2019-12-19T06:10:32Z', '0bbbfe84c66145af8d0ffcd5258bba38', 'a48a753b-e77f-4fd2-9ad9-dc03c68e5e26'], [[\"The flow is like this. The flow is like this. So Zone called will happen. You will invite Zoom. We are either calendar you will get an email and the email will have a summary and then they'll be a share into slack button. \"], '2019-12-19T06:11:01Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '9fc378b0-a4a9-4927-a1b7-370675beb5e5'], [[\"Click on the share and dislike button. Yeah, it will open the me tap there will be a drop down of there will be you know at a minimum. There will be like select slack Channel and share like the screen design there are that's a fly. \"], '2019-12-19T06:11:19Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'd67ce22a-89d8-40ba-8c3b-48d4d64b1ae7']] \n",
      "\n",
      "\n",
      "[[['Like when when when we put the met somebody to slab earlier we used to call the somebody has potentially important moment. Correct? And there are two arguments to this message one is like 350 is actually displayed in notifications have notifications. Okay, but first, so if you see the current if you see the current notifications, they still say potentially important moment, but if You go to the slack at there is nothing called. '], '2019-12-19T06:05:23Z', '1a21542584494fcaba957d768b595b80', '0bde7f12-fd9a-4f55-b459-6e19910db096']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Got it. Yeah. Okay cool. That's pretty good. We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event. Yes. Those are small. \"], '2019-12-19T06:19:35Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '27eb7db0-3eec-443d-95de-414296c002c3'], [[\"Going to implement really upon the like, you know early yesterday we discussed that we will more except that place. Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there aren't there to bunch of small small things. So those things we can truly, you know added as an input. \"], '2019-12-19T06:19:50Z', '1a21542584494fcaba957d768b595b80', '72ddba77-7fa4-469a-a784-4dbc4b543d74'], [[\"On my side which has to be connected by two languages most and try to submit the resume. Not sure if they are going to accept it because it's under the year. \"], '2019-12-19T06:20:21Z', '1a21542584494fcaba957d768b595b80', '0967de49-c222-4ea0-8735-f537f67b6d39'], [[\"Yeah, let's do one thing. Let's let's wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year. \"], '2019-12-19T06:20:42Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', 'a01c0450-6894-464a-a305-ceabb23d2457']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['Okay. So in that case my turn what you do is once like you can if the DeGraff things ready like a basic DeGraff single note thing is ready just wrap that up and then you can help with the cast. Okay, then we can pick up the other ones. '], '2019-12-19T06:18:27Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '38ba0c61-9167-4198-bea1-f027587600f9']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Okay, the the other there's a couple of other things that will require, you know, maybe some like joint work between Trenton and platform team that is for the cast and Truman's right one is handling the consul of cast right? So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that. So we should figure out kind of and then that That requires some back-end work as well. I think maternal Gothic were discussing this yesterday. Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do. Okay in the other one that Colin brought up yesterday was in terms of slide into a way, you know forecast, you know, you started the cost. And then today we kind of show some messages. Right? Like for example, we don't show who started the cast and then sorry we don't show it when you start the cast and then it shows something like cast has been started or something like that. And then the markers start to show up. Right? Yeah, but the problem will be if I am doing it and then I'm canceling the cast, right? Then there are cases like that. So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right? So you start a car. \"], '2019-12-19T06:13:32Z', '8d6db5f7d9b74c54ba38fe710ffcaf3f', '8e139327-69d6-440f-8600-21763e906b4c']] \n",
      "\n",
      "\n",
      "15\n",
      "Before Merging 19\n",
      "[]\n",
      "After Merging 19\n"
     ]
    }
   ],
   "source": [
    "from main import handler\n",
    "\n",
    "res = handler(request, None)\n",
    "group = json.loads(res['body'])\n",
    "\n",
    "group_sorted = {}\n",
    "group_sorted [\"group\"] = {}\n",
    "temp_group = sorted(group['group'].items(), key= lambda kv:kv[1][0]['startTime'], reverse=False)\n",
    "for g in temp_group:\n",
    "    group_sorted[\"group\"][g[0]] = g[1]\n",
    "\n",
    "group = group_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "12\n",
      "17\n",
      "1\n",
      "13\n",
      "9\n",
      "2\n",
      "14\n",
      "3\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for g in group['group'].keys():\n",
    "    if len(group['group'][g])>1:\n",
    "        print (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:28:47  to  23 days, 20:29:08 \n",
      "\n",
      "\n",
      "A few things one has four slash notes read a couple of tweaks to the slack messages that we sent it posted it in platforms yesterday. Do you think we can kind of get those dumb like there's a couple of things here, I think as  \n",
      "\n",
      "I think this these things are already done or whatever these things about time you had to cut this thing to production areas. Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let's have a quick calls day and see is As expected and then you can push the product, okay.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:29:52 \n",
      "\n",
      "\n",
      "So that's one and that's what things I like all the new notification that we get in forms like an Android and iOS. We have the pretext as still as the potential important moment the study of history rather than highlight so we can make more than that.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:30:23 \n",
      "\n",
      "\n",
      "Like when when when we put the met somebody to slab earlier we used to call the somebody has potentially important moment. Correct? And there are two arguments to this message one is like 350 is actually displayed in notifications have notifications. Okay, but first, so if you see the current if you see the current notifications, they still say potentially important moment, but if You go to the slack at there is nothing called.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:31:51  to  23 days, 20:32:16 \n",
      "\n",
      "\n",
      "Okay. Yeah, if you can we please the ram of that laptop, it would be great because otherwise it takes a lot of time to load.  \n",
      "\n",
      "So there we have the other one, right the one that time which is my Microsoft Surface.  \n",
      "\n",
      "By the way, the other one also, I told him to increase the ram. That another one. Yeah. I told him to just give it an even crazier than I am. That'll help we can just give you do that on this side. Anyway, yeah.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:32:46 \n",
      "\n",
      "\n",
      "Yeah, two things I run one is clapping that is in the K that is directly based on the the Mind association with the summaries. So this way we need not Brute Force fabric. So if he and it's unlikely to have life more than cleverness summaries if we filter out with the mines, so even if you have we are just wrapping it to the five to seven depending upon the confidence of each of the community. What we are currently doing this we just tested it an Essie before deployment. We're trying to test out on Multi all the if not all at least most of them most of the domain mind so that we have consistent is across once that is done. We will deploy it into staging too.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:34:38  to  23 days, 20:36:19 \n",
      "\n",
      "\n",
      "Plenty of work. What a partial. What do you guys plan to take on next? See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback. That will be good.  \n",
      "\n",
      "Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I'll have a discussion with one key after this thing called. So then if it's a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing. In a meeting to a particular channel, that will be inside me try.  \n",
      "\n",
      "So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode?  \n",
      "\n",
      "The flow is like this. The flow is like this. So Zone called will happen. You will invite Zoom. We are either calendar you will get an email and the email will have a summary and then they'll be a share into slack button.  \n",
      "\n",
      "Click on the share and dislike button. Yeah, it will open the me tap there will be a drop down of there will be you know at a minimum. There will be like select slack Channel and share like the screen design there are that's a fly.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:36:35  to  23 days, 20:36:52 \n",
      "\n",
      "\n",
      "Okay. Okay, so we do not need to handle it in Netflix video playback.  \n",
      "\n",
      "Actually, it's you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel.  \n",
      "\n",
      "But one thing like with it, even if it's not a test, it comes up in networks view. He had them from Netflix me.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:37:11  to  23 days, 20:37:41 \n",
      "\n",
      "\n",
      "Actually view the meeting as a tile in the Netflix you maybe it's a good idea from from there. Also, we can provide a shaper done is not a different Channel.  \n",
      "\n",
      "First iteration we can we can have a shareable from the email then we can together.  \n",
      "\n",
      "You can have all three states first. We'll make the email like the link to which works from email and second. We can add the same functionality on like internet review end playback. So even if that they are viewing the playback and it's not associated. They can just click on the button and associated.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:38:08 \n",
      "\n",
      "\n",
      "Come on credit later, because in the citational logic we have to add about whether it's shared already or not. You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack. So there's a bunch of things. We have to be careful about. Let's do that. Let's just do the email and share from email. Got it.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:38:32 \n",
      "\n",
      "\n",
      "Okay, the the other there's a couple of other things that will require, you know, maybe some like joint work between Trenton and platform team that is for the cast and Truman's right one is handling the consul of cast right? So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that. So we should figure out kind of and then that That requires some back-end work as well. I think maternal Gothic were discussing this yesterday. Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do. Okay in the other one that Colin brought up yesterday was in terms of slide into a way, you know forecast, you know, you started the cost. And then today we kind of show some messages. Right? Like for example, we don't show who started the cast and then sorry we don't show it when you start the cast and then it shows something like cast has been started or something like that. And then the markers start to show up. Right? Yeah, but the problem will be if I am doing it and then I'm canceling the cast, right? Then there are cases like that. So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right? So you start a car.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:40:18 \n",
      "\n",
      "\n",
      "And then once the cast is done the summary will get pushed now. I don't know how hard that is to handle the handle the scenario of you know, not pushing manual markers Etc or interim messages back into slack, but only forecast.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:40:43  to  23 days, 20:41:05 \n",
      "\n",
      "\n",
      "Okay. Alright. So in that case, let's take both of these on right forecast. So that that cost related things are completed. Okay. All right sigh I can take up that path but  \n",
      "\n",
      "But before taking this class, I was thinking of having the summary year there was one issue in summary a period so we don't push back the topic or actions time at the type what time they spoke like the offset is not being sent in the AP response.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:42:17  to  23 days, 20:42:39 \n",
      "\n",
      "\n",
      "So I'm looking at not actually using I'm using not using the entire response from the summary right now. Okay, all we go. We can go to the cash. There are few things that we can add or remove the somebody. But okay.  \n",
      "\n",
      "Di gusting right now, whatever we have discussed earlier ate the whole thing is implemented like any easy to you can bring it up and the volume remains always the same EBS volume so will not end up recreating EBS volume or anything like that. So you have EBS volume and snapshots are also creating created. So whatever was discussed for single node is all done for 3 node. Also it is okay meaning and in modules we can still send it to create it in the Creator 3 node cluster also hope that once we needed we can again start looking good.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:43:27 \n",
      "\n",
      "\n",
      "Okay. So in that case my turn what you do is once like you can if the DeGraff things ready like a basic DeGraff single note thing is ready just wrap that up and then you can help with the cast. Okay, then we can pick up the other ones.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:43:51 \n",
      "\n",
      "\n",
      "Yeah, we so we actually run a interest today. This is one of the priorities changed a staging to mind. It's looking as expected for one of those delinquents meeting and there are few debts. We need to put in place the chances of them looking into that you can add more other than that. Yeah, it's pretty much finished from commercial vehicle for the single instance thing. You can we can really push it to production. Maybe next time we can have a sink on you.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:44:35  to  23 days, 20:45:42 \n",
      "\n",
      "\n",
      "Got it. Yeah. Okay cool. That's pretty good. We need to and then once the basic thing is done we can do other things right like that thing email address and recurring event. Yes. Those are small.  \n",
      "\n",
      "Going to implement really upon the like, you know early yesterday we discussed that we will more except that place. Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there aren't there to bunch of small small things. So those things we can truly, you know added as an input.  \n",
      "\n",
      "On my side which has to be connected by two languages most and try to submit the resume. Not sure if they are going to accept it because it's under the year.  \n",
      "\n",
      "Yeah, let's do one thing. Let's let's wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:45:58 \n",
      "\n",
      "\n",
      "Exactly. Yeah because anyways is no point doing marketing during holidays. Also, nobody will be seeing it. So anyway, we'll pick back up any Zoom or notes related marketing only after the beginning of the year. So by then exhume is also approved then it will actually be nice, you know.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:46:49  to  23 days, 20:47:47 \n",
      "\n",
      "\n",
      "Pleasing to all and bleeding from production board at people as if I go all the image will come through her.  \n",
      "\n",
      "Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work. But let's see what is actually doing.  \n",
      "\n",
      "Yes, I am working on the adding the react router navigation and creating. Let me think the app flow faster on whenever somebody opens the app for the first time. So I will so there's only I think I guess there will be just one delay when we're looking the app that is like were to check for code push with any new bundle or not. That is new. Only thing that I think would take a bit of time. Otherwise, you'll be able to see the sturgeon screen quickly. We assign them so this okay.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   23 days, 20:48:37  to  23 days, 20:49:40 \n",
      "\n",
      "\n",
      "Okay, so I think those are the big ones the one big user story that we need to pick up. Maybe I don't know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we can't get rid of the header. So that's the reason we need we need that second is sometimes transcripts. show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every  \n",
      "\n",
      "Missing transcription of the last segment in a call and then audio clips in playback. So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders.  \n",
      "\n",
      "Listen since say when Karen and I had a discussion yesterday when we find them we were coming. I'll actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you're running recording time. We can use that now Vixens communities move to a different, you know sentence based approach, but we want You just test it with the the transcription from uni passed a full meeting wave to the segment. ER whether it is because if you get more fine-grained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "from backports.datetime_fromisoformat import MonkeyPatch\n",
    "MonkeyPatch.patch_fromisoformat()\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True) #eng_19\n",
    "#m_time = formatTime(\"2019-09-20T07:12:00Z\", True) #eng_front_end_20\n",
    "#m_time = formatTime(\"2019-09-24T06:11:00Z\", True) #eng_24\n",
    "#m_time = formatTime(\"2019-10-04T05:44:00Z\", True)  #podcast_04\n",
    "#m_time = formatTime(\"2019-10-08T11:55:00Z\", True)  #podcast_08\n",
    "#m_time = formatTime(\"2019-10-14T06:04:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "#m_time = formatTime(\"2019-11-26T09:03:00Z\", True)  # set_1\n",
    "#m_time = formatTime(\"2019-11-21T06:30:00Z\", True) # sync_11_21\n",
    "m_time = formatTime(\"2019-11-25T09:35:00Z\", True) # sync_11_25_ml\n",
    "#m_time = formatTime(\"2019-11-26T06:15:00Z\", True) # sync_11_26\n",
    "for i in group['group'].keys():\n",
    "    if len(group['group'][i])!=1:\n",
    "        print (\"\\n\\n Chapter Discussion:  \", formatTime(group['group'][i][0]['startTime'], True) - m_time, \" to \", formatTime(group['group'][i][-1]['startTime'], True) - m_time, \"\\n\\n\")\n",
    "        for seg in group['group'][i]:\n",
    "            #print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "            print (seg['originalText'],\"\\n\")\n",
    "    \n",
    "#     elif len(group['group'][i])==1:\n",
    "#         print (\"\\n\\n Chapter Discussion:  \", formatTime(group['group'][i][0]['startTime'], True) - m_time , \"\\n\\n\")\n",
    "#         for seg in group['group'][i]:\n",
    "#             #print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "#             print (seg['originalText'],\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Group Id:  15\n",
      "Krishna Sai, Vamshi Krishna Discussed \n",
      "\n",
      " Text: \n",
      "A few things one has four slash notes read a couple of tweaks to the slack messages that we sent it posted it in platforms yesterday. Do you think we can kind of get those dumb like there's a couple of things here, I think as \n",
      "\n",
      "I think this these things are already done or whatever these things about time you had to cut this thing to production areas. Okay, my problem staring to one maybe model is Will deploy and develop stable consistent reading to and let's have a quick calls day and see is As expected and then you can push the product, okay. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  0\n",
      "Vamshi Krishna Discussed \n",
      "\n",
      " Text: \n",
      "So that's one and that's what things I like all the new notification that we get in forms like an Android and iOS. We have the pretext as still as the potential important moment the study of history rather than highlight so we can make more than that. \n",
      "\n",
      "Like when when when we put the met somebody to slab earlier we used to call the somebody has potentially important moment. Correct? And there are two arguments to this message one is like 350 is actually displayed in notifications have notifications. Okay, but first, so if you see the current if you see the current notifications, they still say potentially important moment, but if You go to the slack at there is nothing called. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  14\n",
      "Parshwa Nemi Jain, Krishna Sai, Venkata Dikshit Discussed \n",
      "\n",
      " Text: \n",
      "Okay. Yeah, if you can we please the ram of that laptop, it would be great because otherwise it takes a lot of time to load. \n",
      "\n",
      "So there we have the other one, right the one that time which is my Microsoft Surface. \n",
      "\n",
      "By the way, the other one also, I told him to increase the ram. That another one. Yeah. I told him to just give it an even crazier than I am. That'll help we can just give you do that on this side. Anyway, yeah. \n",
      "\n",
      "Okay, baby, then SRI. I don't know like that. If you're here any kind of update on the capping the summary segments. Yeah. \n",
      "\n",
      "Yeah, two things I run one is clapping that is in the K that is directly based on the the Mind association with the summaries. So this way we need not Brute Force fabric. So if he and it's unlikely to have life more than cleverness summaries if we filter out with the mines, so even if you have we are just wrapping it to the five to seven depending upon the confidence of each of the community. What we are currently doing this we just tested it an Essie before deployment. We're trying to test out on Multi all the if not all at least most of them most of the domain mind so that we have consistent is across once that is done. We will deploy it into staging too. \n",
      "\n",
      "So the big ones then we'll just kind of run through the others Joshua morning on the front and side. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  3\n",
      "Vani Discussed \n",
      "\n",
      " Text: \n",
      "Yesterday I was working on the box. Let me log out and the sign in page which we are saying is already signing trying to sign into some particular workspace from which we had blocked. It should be generic. I worked on it today stankin can test tissue. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  1\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Plenty of work. What a partial. What do you guys plan to take on next? See my suggestion is if we can at least like for the cast if we can look at how we can handle the past resume during playback. That will be good. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  16\n",
      "Parshwa Nemi Jain Discussed \n",
      "\n",
      " Text: \n",
      "Yes, I so I think adding this the cast was resumed and the zoom pages so we can like bunny can start on the pause resume part and I think if Zoom like for I'll have a discussion with one key after this thing called. So then if it's a pH like WordPress related work, then I work on the zoom page first and then move on to meet and regarding the sharing. In a meeting to a particular channel, that will be inside me try. \n",
      "\n",
      "So I was thinking that maybe we can like if the meeting is not associated with the channel we can have like in the Netflix view we can have a button there for that meeting to like the I did take the user can share it directly from there or also in a fleabag mode? \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  13\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "The flow is like this. The flow is like this. So Zone called will happen. You will invite Zoom. We are either calendar you will get an email and the email will have a summary and then they'll be a share into slack button. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  17\n",
      "Krishna Sai, Parshwa Nemi Jain Discussed \n",
      "\n",
      " Text: \n",
      "Click on the share and dislike button. Yeah, it will open the me tap there will be a drop down of there will be you know at a minimum. There will be like select slack Channel and share like the screen design there are that's a fly. \n",
      "\n",
      "Okay. Okay, so we do not need to handle it in Netflix video playback. \n",
      "\n",
      "Actually, it's you see the the other reason that may or may not make sense is in general anything that appears on Netflix you is already attached to a channel. \n",
      "\n",
      "But one thing like with it, even if it's not a test, it comes up in networks view. He had them from Netflix me. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  18\n",
      "Vamshi Krishna Discussed \n",
      "\n",
      " Text: \n",
      "Actually view the meeting as a tile in the Netflix you maybe it's a good idea from from there. Also, we can provide a shaper done is not a different Channel. \n",
      "\n",
      "First iteration we can we can have a shareable from the email then we can together. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  11\n",
      "Parshwa Nemi Jain, Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "You can have all three states first. We'll make the email like the link to which works from email and second. We can add the same functionality on like internet review end playback. So even if that they are viewing the playback and it's not associated. They can just click on the button and associated. \n",
      "\n",
      "Okay. Yeah, let's let's just do this the email one first part. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  7\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Come on credit later, because in the citational logic we have to add about whether it's shared already or not. You have to differentiate that from other calls that we have abundance direct messaging which inviolate slack. So there's a bunch of things. We have to be careful about. Let's do that. Let's just do the email and share from email. Got it. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  10\n",
      "Krishna Sai, Karthik Muralidharan Discussed \n",
      "\n",
      " Text: \n",
      "Okay, the the other there's a couple of other things that will require, you know, maybe some like joint work between Trenton and platform team that is for the cast and Truman's right one is handling the consul of cast right? So when when you start a car cast and you want to cancel and start again, right you should be should give people the option to do that. So we should figure out kind of and then that That requires some back-end work as well. I think maternal Gothic were discussing this yesterday. Yeah, so that required some design thinking so maybe we can just think through that little bit and do some design before we decide what to do. Okay in the other one that Colin brought up yesterday was in terms of slide into a way, you know forecast, you know, you started the cost. And then today we kind of show some messages. Right? Like for example, we don't show who started the cast and then sorry we don't show it when you start the cast and then it shows something like cast has been started or something like that. And then the markers start to show up. Right? Yeah, but the problem will be if I am doing it and then I'm canceling the cast, right? Then there are cases like that. So one yesterday I was going back and forth Cullen and said that forecasts can be kind of completely eliminate in call messaging into slack, right? So you start a car. \n",
      "\n",
      "And then once the cast is done the summary will get pushed now. I don't know how hard that is to handle the handle the scenario of you know, not pushing manual markers Etc or interim messages back into slack, but only forecast. \n",
      "\n",
      "You can do that. It's just that we have to write a bunch of conditions. \n",
      "\n",
      "Okay. Alright. So in that case, let's take both of these on right forecast. So that that cost related things are completed. Okay. All right sigh I can take up that path but \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  6\n",
      "Mithun, Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "But before taking this class, I was thinking of having the summary year there was one issue in summary a period so we don't push back the topic or actions time at the type what time they spoke like the offset is not being sent in the AP response. \n",
      "\n",
      "Whenever using the summary APA right now, we're not using right now. We are not using but right. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  2\n",
      "Mithun, Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Di gusting right now, whatever we have discussed earlier ate the whole thing is implemented like any easy to you can bring it up and the volume remains always the same EBS volume so will not end up recreating EBS volume or anything like that. So you have EBS volume and snapshots are also creating created. So whatever was discussed for single node is all done for 3 node. Also it is okay meaning and in modules we can still send it to create it in the Creator 3 node cluster also hope that once we needed we can again start looking good. \n",
      "\n",
      "Shouldn't take much time since it's all in modules will be easy. \n",
      "\n",
      "Okay. So in that case my turn what you do is once like you can if the DeGraff things ready like a basic DeGraff single note thing is ready just wrap that up and then you can help with the cast. Okay, then we can pick up the other ones. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  4\n",
      "Vamshi Krishna Discussed \n",
      "\n",
      " Text: \n",
      "Yeah, we so we actually run a interest today. This is one of the priorities changed a staging to mind. It's looking as expected for one of those delinquents meeting and there are few debts. We need to put in place the chances of them looking into that you can add more other than that. Yeah, it's pretty much finished from commercial vehicle for the single instance thing. You can we can really push it to production. Maybe next time we can have a sink on you. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  12\n",
      "Vamshi Krishna, Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Going to implement really upon the like, you know early yesterday we discussed that we will more except that place. Yeah formatting data set we can do because we are actually reading from the middle school and then going to the calendar notes Roddick there aren't there to bunch of small small things. So those things we can truly, you know added as an input. \n",
      "\n",
      "On my side which has to be connected by two languages most and try to submit the resume. Not sure if they are going to accept it because it's under the year. \n",
      "\n",
      "Yeah, let's do one thing. Let's let's wrap up our work and then, you know try to give as complete a thing as possible and then submit it at the beginning of the year. \n",
      "\n",
      "Exactly. Yeah because anyways is no point doing marketing during holidays. Also, nobody will be seeing it. So anyway, we'll pick back up any Zoom or notes related marketing only after the beginning of the year. So by then exhume is also approved then it will actually be nice, you know. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  9\n",
      "Vamshi Krishna, Krishna Sai Discussed \n",
      "\n",
      " Text: \n",
      "Yes, one more thing is I we need to create a new email for staging because if you use the bottle because that is the staging also will be reading like production mean besides product. \n",
      "\n",
      "So I can just create like a new you need a new email address or new areas new email at the scoreboard. \n",
      "\n",
      "Pleasing to all and bleeding from production board at people as if I go all the image will come through her. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  5\n",
      "Vamshi Krishna, Deep Discussed \n",
      "\n",
      " Text: \n",
      "Sobbing of chrome and stopping example, I had a digital seconds in staging to learning one apostasy is actually making any difference just one second just to you know, make it work. But let's see what is actually doing. \n",
      "\n",
      "Yes, I am working on the adding the react router navigation and creating. Let me think the app flow faster on whenever somebody opens the app for the first time. So I will so there's only I think I guess there will be just one delay when we're looking the app that is like were to check for code push with any new bundle or not. That is new. Only thing that I think would take a bit of time. Otherwise, you'll be able to see the sturgeon screen quickly. We assign them so this okay. \n",
      "\n",
      "\n",
      "\n",
      "User Group Id:  8\n",
      "Krishna Sai, Karthik Muralidharan Discussed \n",
      "\n",
      " Text: \n",
      "Okay, so I think those are the big ones the one big user story that we need to pick up. Maybe I don't know when we do it but maybe after the cost related changes and zoom related changes are done are all the miscellaneous audio issues rights is a bunch of them that we need to do is not something that we need to think through right now, but would love to pick it up one is put transcripts of jitsi that one he was working on without that we can't get rid of the header. So that's the reason we need we need that second is sometimes transcripts. show up at all because of the gain issue I guess and then there is a missing first portion of the audio segments in every \n",
      "\n",
      "Missing transcription of the last segment in a call and then audio clips in playback. So is a bunch of audio speech related issues that you have to get a bundle together and work on after after these two orders. \n",
      "\n",
      "Listen since say when Karen and I had a discussion yesterday when we find them we were coming. I'll actually take a look at how the wisdom so the we have we will remember we were working on the body CB aside current process that you're running recording time. We can use that now Vixens communities move to a different, you know sentence based approach, but we want You just test it with the the transcription from uni passed a full meeting wave to the segment. ER whether it is because if you get more fine-grained segments of audio, whether it is acceptable for performing action item with action and make films like the communities that we do right now if they working fine, then you can even buy move into that room so that we can avoid loop back together. \n",
      "\n",
      "We'll have to run a few experiments to see if that transcriptions are acceptable for performing are related workloads that we currently support. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id_map = {}\n",
    "user_id_map = {\"2c94451217a049129a166a3408da807c\":\"Sai\",\"3f01f2032f584b178fafde6b437058ae\":\"Venkat\",\"8fff81b5b2f14aa5ad67405f3e8127f3\":\"Sai\",\"60d2ea6bed8c48269c8c024202a4148d\":\"Shubham\",\"70caa6269d8e4869a45f7ea91ade3472\":\"Ether\",\"3e1a008f734448b0ad9190778449af81\":\"Cullen\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep\",\"716067a60a1a4034abc49a12ecafb39b\":\"Cullen\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Cullen\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "text_list = []\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    print (\"User\", end=\" \")\n",
    "#     if len(seg_list) == 1 :\n",
    "#         continue\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \")\n",
    "    print ( *seg_list, sep=\"\\n\\n\", end=\"\\n\\n\")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\")\n",
    "    text_list.append(\" \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm really excited about this series demystifying Docker. I'm doing it because I've had so many conversations with other developers people. I meet at conferences where that people will say. I'm really excited about Docker because everybody keeps saying Dockers awesome, but I can't seem to wrap my head around it and I can't seem to find any resources online that help me actually get started with Docker and understand you know what it's actually good for. So we're going to kind of cover that we're going to start off with a high-level overview. What is Docker then we're going to show you with really quick. Just a few lines of code how you can deploy applications and then some kind of various thoughts on it along the way so let's get into it demystifying Docker. First thing we're going to do is we're going to compare Docker to vagrant or Docker to a virtual machine since this seems to be the hangout that I keep hearing from people. Okay, so I get vagrant but I don't get Docker. Well, that's because they're really different. Here's got a very visual people visual demonstration. What vagrant is I'm going to kind of show you real quickly vagrant for those you guys aren't familiar with it. And I'm going to show you how it's not really a fair comparison. So vagrant is the goal is to solve the problem of it works on my machine. It doesn't work on production or it works on my machine. It doesn't work on this other developers machine that happens because somewhere along the road you might be on a different operating system say your machine is a Mac or Windows machine and you're pushing it out to a Linux, you know server that alone could cause problems you might be running Wham form and on your It's a PHP application and these guys are actually running a full, you know, just native installation of an Apache stack or you have a different tool set that you're using then another developer. But any rate your environments are not the same so we solve that by spinning up a virtual machine in our computer. That's the exact same thing. We're going to be pushing to staging or production. So we'll use Virtual Willy's virtualbox and vagrant to spin up one saying a bunch of 1404 machine, which is  Are you using in staging and production? So here that that is it's an empty machine and then you run your provisioning script against your virtual machine exactly as you would against a chair production. So the provisioning script will install the correct version of node.js or rails or PHP. It'll set up all the user permissions. It'll it'll stall any other software configure anything that needs to be configured. So at the end of the day, these are basically the same environment. So now I know that if I dump my project Coding to here and run it in this machine and it works. It's pretty much going to work when I push it out to GitHub and these servers pull it or I push it. However, you do your deployments when the code gets dumped into these it's going to run the same. So that's vagrant in a nutshell different boxes. We dumped our code into each box. Let's look at Docker and see why doctors actually different so for Docker, we got our machine. We've got our project code and Docker runs off of containers. So I use Docker file which is usually five to maybe 30 line fired file Docker files are really small the dockerfile bills once called the docker image that Docker image contains all my projects code it contains, you know saying installation of node.js has a node.js app, it contains any in installments of programs that I need. And so it's basically my complete application wrapped up in an image now, it's not a full say of bun to machine because I don't need that this image is designed to sit on top of a machine. So from that image, I can then run as many containers as I want until I run out of processing power in RAM on my machine. So this is the virtual machine on my Mac again, and I have my Docker image on the machine and I can run that Docker image and it runs as a container and I can run many many containers in the machine once again till I run out of stuff. So this image is  My projects go so instead of on vagrant where I put my projects code into environments with Docker you're going to actually build your environment. And now I can run that environment anywhere if a machine has Docker on it. My container is going to run and it's going to work. So then you push that Docker image up to say Docker Hub or queda I/O which are kind of like the GitHub Docker images and there's a bunch out there. You can have your own private Repository. Three the image goes out there that's like your GitHub repository so to speak and now any other machine can run your image. So let's say I call this image. My user name is will our Stern. Let's say I did will our Stern / mind, you know tap that's the name of it. So now on any computer I can say Docker run will our Stern / my new node at and this whole image source code and all will run with the complete environment. I didn't install node.js on this machine. I didn't provision this machine. Because the image has everything it has a complete environment all contained into one so I could run a node js image on this machine this container than has nodejs installed has anything else installed and p.m. And I can also run a rails app on the same machine rails is installed on that container but rails is not installed in this container. So they act like virtual machines, but the really self-contained processes so to speak let me go To show you an image here that I found somewhere online. I have no idea what this puppy dog is about but this is basically the anatomy of a Docker container. So this is your actual web server. You've got your web server yet the host operating system, which is a bun two or even something lighter and it has Docker installed. That's all you need. Docker is installed and then all the apps run as Docker containers and they all sit on top of your host operating system.  Sources so they all sit on top of the Linux kernel, they all access the same computer's processor and RAM and that's basically a Docker container you build your image once push it out and now you can run anywhere so kind of in a large-scale production environment. Here's what that looks like. I've got this big cloud cluster of say 10 computers. They're all running either core offs or mezzos. These are kind of some of the big players. Hours, basically with these two operating systems do is they allow all the computers to act as one they share all their resources. And so now all you have to do is spin up containers and they all run within your cluster and then if you start running out of overall cluster memory for overall cluster Computing, you just add more nodes. So let's say okay. I'm just going to add 10 more computers to this cluster and now I can run 30 more containers so you can just say Let's once again, let's say this image is called my note app. I can run my note app for times boom. Boom. Boom. Boom. Then I can spin up an nginx container and have it load balance these four and then expose a private portal to the real world. So then the real world can access my app. This is our doctor Works. Its really awesome for cloud computing really awesome for cluster Computing and that's where it really really starts to shine. But actually I think Docker is one of my favorite uses of docker. Docker is to just provision a single machine and deploy with no provisioning at all. It just spin up a machine make sure doctors installed and then you can run your containers on it. So that's kind of your brief overview. If you're not a visual person. This is probably confusing. \",\n",
       " \"Summer my family and I visited Russia, even though none of us could read Russian. We did not have any trouble and figuring our way out all things to Google's real-time translation of Russian boards into English. This is just one of the several applications of neural networks neural networks from the pace of people earning a subfield a machine learning where the algorithms are inspired by the structure of the human brain neural networks take in data train themselves to recognize the patterns in the data and then predict the outputs where a new set of similar data. Let's understand how this is done. Let's construct a neural network that differentiates between a square circle and triangle neural networks are made up of layers of neurons. These neurons are the core processing units of the network first. We have the input layer which receives the input the output layer predicts our final output in between exists a hidden layers, which perform most of the As required by our Network, here's an image of a circle. This image is composed of 28 by 28 x cells which make up for 784 pixels. Each pixel is fed as input to each neuron of the first layer neurons have one layer are connected to neurons of the next layer through channels. Each of these channels is assigned a numerical value known as wait the inputs are multiplied to the corresponding weights and their sum is sent. as input to the neurons in the hidden layer, each of these neurons is associated with a numerical value called the bias, which is then added to the inputs of this value is then passed through a threshold function called the activation function the result of the activation function determines if the particular neuron will get activated or not and activate a neuron transmits data do the neurons of the next layer over the channels in  The data is propagated through the network. This is called forward propagation in the output layer the neuron with the highest value fires in determines the output the values are basically a probability. For example, here are neurons associated with square at the highest probability. Hence. That's the output predicted by the neural network. Of course just by a look at it. We know our neural network has made a wrong prediction, but top of the The Network's figured this out note that our network is yet to be trained during this training process along with the input. Our Network also has the output fed to it. The predicted output is compared against the actual output to realize the error in prediction the magnitude of the error indicates how wrong we are in the sign suggestive of our predicted values are higher or lower than expected the arrows here given indication of the direction and magnitude of change too. Use the error this information is then transferred backward through our Network. This is known as backpropagation now based on this information. The weights are adjusted this cycle of forward propagation and back propagation is iteratively performed with multiple inputs this process continues until our weights are assigned such that the network can predict the shapes correctly in most of the cases this brings our training process to an and you might wonder how long this training process takes honestly neural networks may take hours or even months to train but time is a reasonable trade off when compared to its scope. Let us look at some of the crime applications of neural networks facial recognition cameras on smartphones. These days can estimate the age of the person based on their facial features. This is neural networks that play first differentiating the base from the background and then correlating.  Lines and spots on your face to a possible H forecasting neural networks are trained to understand the patterns and detect the possibility of rain fall or rise in stock prices with high accuracy music composition neural networks, and even learn patterns and music constrain itself enough to compose a fresh too. So here's a question for you, which of the following statements does not hold true a activation functions are threshold fungus. The error is calculated at each layer of the neural network see both forward and back propagation take place during the training process of a neural network. The most of the data processing is carried out in the hidden layers leave your answers in the comment section below three of you standing cheap. \",\n",
       " \"Introduction is from 7 Minutes training video with details on what you need to start using scrum today.  This video is intended for people just getting started with the scrum framework in need a quick primer. Hi, my name is Steve Steadman and I'm the founder of utility software in this video. We will cover the basics behind scrum. We'll take a look at how scrum compares to Waterfall development and will examine the three roles three artifacts and three ceremonies that make up scrum.  let's take a look at how scrum compares the older alternative of waterfall development waterfall typically goes through a lengthy planning process. S which can take several months followed by building the product which again can take many months and then testing the product.  Doing and eventually deploying the product and this point you may end up bringing the wrong product to Market if market demand or technology has changed since the original plan was developed. There are several problems with this method. First of all, the planning must be completed before any work begins and in most cases the planning is done without entirely understanding the project once development is being done often times things get sent back to the planning phase and the project either means to start over or the developers are has criticized for not understanding the plan. This cycle can happen many times. What development is done building the product gets thrown over the fence of tests where when problems are encountered. It bounces back to development and sometimes back to planning the same issues occur in the next few steps with lots of back stepping and doing over this can lead to length times and many months to several years in order to get a product out the door with scrum and implementation of agile. The process is broken. The smaller pieces first when you just not planning to get started with building the minimum feature set. We build what was planned next we test and review that small feature set and get it ready to ship. When that cycle is complete we end up with a potentially shippable product. This process usually occurs in a time period of one to three weeks. This is then repeated time and time again reducing the time from planning to development to testing each time through the planning process. We're doing just enough planning to complete the next incremental release you end up with several incremental releases called Springs a Sprint usually takes from one to three weeks and you just keep repeating these Sprint's until your product is feature complete.  Times you may end up shipping your product after the second Sprint or the third or the fourth or even further, but you eventually end up with a shipping product.  From there are three key rules that are needed for the framework to work. Well. First the product owner. This is the person responsible for defining the features that are needed in the product. The product owner has the right ideas that turn into products.  Servant leader to the team responsible for protecting the team and the process running the meetings and keep things going the team can be made up of developers testers writers and anyone else that helps in building the product. Team members often play multiple roles some days developers may end up doing tests or testers may end up right either way the team Works to get the product done.  Three artifacts for documents that are used in scrum first the product backlog. This is where product owners create a prioritized list of features known as user stories. They could go into the product this list evolves and changes priority with every Sprint user stories our own way of describing the feature set that follows the as a Sir, I need something so that reason format. This will way of phrasing is her story allows the product owner to specify the right amount of detail for the team to estimate the size of the task. The highest priority user stories going to the Sprint backlog these get estimated for size and are committed to for the next Sprint burndown charts show the progress during a spring on the completion of tasks in the Sprint backlog. This charge should approach zero points as the work is being completed.  Three ceremonies that make up scrum think of these as meetings or discussions Sprint planning is where the product owner scrum master and team meet discuss the user stories and estimate the relative sizes. Daily scrum is a brief stand-up meeting where the team discusses what they have completed since the previous meeting what they're working on and anything that might be blocked or need help the Sprint review and retrospective occurs at the end of the Sprint. This is where the team demonstrates the related work to the product owner and then the team discusses what they can do to improve the process going forward.  Bring it all together and take a look at the scrum workflow start with the product backlog, which is where the product owner builds a list of the bright ideas and features that could go into the product the product owner prioritises the list and brings the top items to the team.  Planning is where the team product owner and scrum Master discussed the top priority user stories determining what can go into the next breath the output from the Sprint planning meeting is the Sprint backlog. This is a list of user stories that have been committed to for the next print the entire team and product owner have a solid understanding of what each of the user stories involves based on the discussions for the Sprint planning means the Sprint is a 1-2-3 week time box where the work committed to in this meant backlog is worked on through completion during the Sprint the daily scrum occurs as a stand-up meeting where the team discusses what they have completed and what they are working on as well as any blocked items the outcome of this print is a potentially shippable product potentially shippable means is a product owner can decide if it's ready to ship or if there are any additional features needed before it ships.  The end of the Sprint a Sprint review and Sprint retrospective meeting occurs. The Sprint review is where the team showcases their work to the product owner and the retrospective is where the team works on what they can do to improve their process.  For a software solution to help manage the workflow utility has been built around the scrum process to help people filling the three scrum roles manage the three artifacts and better run the three ceremonies. \",\n",
       " \"Come to this tutorial series on SQL and database. But before we learn about database, let's understand. What is data? In simple words data can be faxed related to any object in consideration. For example, your name age height weight Etc are some data related to you a picture image file PDF Etc and all being considered data. Now, what is a database? We already know what data is but this data could be random a database is a systematic collection of That since the data in a database is organized. It makes data management easy. What is a database management system dbms? Database management system or dbms is a collection of programs which enables its users to access a database manipulate data and help in the representation of data. It also helps control access to the database by various users. Let's discuss a few examples and online telephone directory would definitely use database management system to store data pertaining to people phone numbers and other contact details. Your electricity service provider is obviously using a dbms to manage billing client related issues to handle fault data Etc. Let's consider the Facebook. It needs to store manipulate and present data related to members their friends member activities messages advertisements and a lot more we can provide countless numbers of examples for usage of dbms. Database Management systems are not A New Concept and as such had been first implemented in the 1960s.  Girls Bachman's integrated data store where IDs is said to be the first dbms in history. With time database Technologies evolved a lot while usage and expected functionalities of databases have been increased immensely times of dbms. Let's see how the dbms family of with time. the following diagram shows the evolution of dbms categories  Are four major types of dbms. Let's look into them in detail hierarchical this type of dbms employees the parent-child relationship of storing data. This type of dbms is rarely used nowadays is structure is like a tree with nodes representing records and branches representing fields. The Windows registry used in Windows XP is an example of a hierarchical database configuration settings are stored as tree structures with nodes. Network dbms This type of dbms supports many to many relationships this usually results in complex database structures RDM server is an example of a database management system that implements the network model relational dbms. This type of dbms defines database relationships in forms of tables also known as relations unlike the network dbms. Rdbms does not support many to many. Shows relational dbms usually have predefined data types that they can support. This is the most popular dbms type in the market examples of relational database Management Systems include MySQL Oracle and Microsoft SQL Server object-oriented relational dbms this type support storage of new data types. The data to be stored is in the form of objects the objects to be stored in the database. Debase have attributes for example gender or age and methods that Define what to do with the data postgresql is an example of object-oriented relational dbms. So what is SQL?  To query language SQL pronounced as SQL or sometimes as SQL is actually the standard language for dealing with relational databases SQL can be effectively used to insert search update and delete database records. That doesn't mean SQL cannot do things beyond that. In fact, it helps in optimizing and maintenance of databases and much more. Relational databases like MySQL Oracle mssql sybase Etc. Use SQL SQL syntax is used in these databases are almost similar except the fact that some databases use different syntaxes and even proprietary SQL syntax has an example of an SQL statement. \"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Group Id:  15\n",
      "Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  right now because of kotas the way we handle plans right now is If you want paid and you you get three. The end of the month, we don't tell them like sorry. Let me just think come back. So if you aren't free there's nothing to do if you go to pay which is basic plan. We tried to renew every month in won't has no problem saying that you're in free tier subscription is over. But let's see if you're interesting what happens is after 10 hours of live calls and Tenors are like all we start to reject saying that he looks like a user uses code has exceeded at this time. We don't send an email, right? When we send usage quotas experience.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  2\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text:  So far now because you don't send an email immediately even right now do we have to make the changes all the I'm not saying we need him? That's not the problem. The problem is I want to make sure that the usage related monitoring Etc. The Rollo fusions partial like we talked about is there's no need for a top of plan roll. If you exceed the $25 you get rejected after that and if you want to upgrade you upgrade to the hundred dollar plan. That's it. Okay.  Excuse and we don't need to do a lot of yeah, let's addition the platform side.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  3\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text:  Let's not even like consider all that keep it really simple. All we're doing is exactly the same. The only thing that I want to make sure is that Before we had a free plan, of course, there's always free and limited and then there is a basic or paid plan right again that was based on number of users. And then we had an Enterprise plan. So Enterprise line, we don't need to worry about because we don't have any users, but for the page planning now, there are two different variations of that based on one parameter called 25 and hundred. Or the platform the question is like as you go through and you know before the way it used to work as a day every day there used to be this job that goes in tells how many times has that are right and then based on that we will do whatever we need to do. How does that work based on Usage Now the station need to go and change that thing to say every day. There is going to be an indication of how much has been used how much that has much of usage has been consumed. How much as me so my point being like all the work related to getting this to work? Yeah. Can we just list them together? You know, who's week's work on what? Yeah, okay. So part for any other things that need to be clarified on the servants clear.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  7\n",
      "Vani, Krishna Sai Discussed \n",
      "\n",
      " Text:  Totally cool it on and push this these features to production and work one.  Get it current functionality get it all the way to production.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  14\n",
      "Vani, Krishna Sai Discussed \n",
      "\n",
      " Text:  Like the major all those are working on the speaker's logic, which I had implemented was bit wrong. Like I'll modified and address the comments Josh Wise raised today and then push it up. I'll try to push it to production.  I know what you do is once you've done all the children's push it this aging.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  0\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text:  Another cost being able to parse skip the pass portions and Playback, right?  Also, we need to figure out how to do cancel and start and bunch of other things the bunch of things that we have to do forecast.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  8\n",
      "Trishanth Diwate Discussed \n",
      "\n",
      " Text:  Yes, I so the first part where we omit the event is done. So we myself and um, she didn't get a chance on Friday to discuss on the table structure for Zoom even service. So today we'll discuss this on Friday. We did a project deploy and there were few minor issues. Like there are few Panic switch which via text and there was one more issue like for action and as enhancements if if the An item was on the first segment of the call. We used to ignore from back end so that I have fixed and it's already in production now, so once funds from she is--and will discuss on the zoom service site. Sorry.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  13\n",
      "Krishna Sai, Nisha Yadav Discussed \n",
      "\n",
      " Text:  Let's talk about like iOS so the bunch of things happening with iOS. I finish share deep. You guys want to go links?  So I have pushed the changes of me because most production and looking in the that thumbnail thing. So if we enter you are really not so along with the Tamil also showing the topic of the video now, but  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  4\n",
      "Nisha Yadav, Krishna Sai Discussed \n",
      "\n",
      " Text:  Yes, so the next task on my list rifles handling the navigation flow into the IOS app. So that will also help us like the main thing is it will help us remove box and passed in this process because the repetitive steps like token check permission for camera. Mic all these are happening whenever we open the up. So so we'll remove this will also speed up say when we click on watch any reason Call then also since the app is already in foreground still the token check and all that happens. So create the navigation like will correct the navigation flow. So that limbs over.  Okay, I just spent the time length should be fairly simple. Right that was just like logic before we check for suggested FYI. Now we need to check for suggested topics. And then instead of showing FYI to show highlight, right? That's it. Yeah the and then you you know, I think it'll be good for you to focus on the the navigation flow to speak from here. Come back. Preview thing later like a background task, you know.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  12\n",
      "Deep Discussed \n",
      "\n",
      " Text:  So I have things in the flipping the Red Bar the network issue and like the rosary creation of menu living problem engine starts. We'll call it used to come out even though like it was closed the 6 goes to there's one more like a bug that I faced intermittently like when we join adjusted see call it looks somehow. Time doesn't mean joining like we'll just shows us why screen like it doesn't it starts connecting but it doesn't end of the connecting screen. It doesn't and so I look into that and then in the in this sweet, like we had planned to configure like es linked for JavaScript and ties typescript and like web and iOS projects.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  10\n",
      "Krishna Sai Discussed \n",
      "\n",
      " Text:  Particular regions, so I did take a creative blue team's recording today. Okay, but unfortunately once the recording is over the basic account the personal basis gone, there's no way to share it with others.  Immediately start with there's no sharing of your recording URL right in the personal account your go for Enterprise. I see so first of all before yourself, I think Alan has purchasing teams account in the team's one has to in order to be able to share go to the unlimited recording feature, which is an interface. So we have to go mystical how to I see if there's an all DHL blue team's thing we can do is we can start working like entire record in public for film. Just let it alone. Oh, yeah.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  5\n",
      "Krishna Sai, Venkata Dikshit Discussed \n",
      "\n",
      " Text:  This will talk about this is a few things right one was few things that we saw with respect to action items. Yeah, that was one on the second was the aggressiveness of the community summaries and the third was and tweaking the community summaries based on the mind the my gift.  Yeah on the on the on the Akshay. I think it's illogical but that that I just fixed and tested it and the reply disk into production. So at that addresses the ones where this logic bugs there and then the other aspect of it and couple of action items got missed out due to the model confidence itself. So that needs a training so which currently such scenarios are not not that common. Usually the model is aggressive that If you pick up most of the action items, so we are not we are not currently addressing that because that's kind of not a mainstream case. Otherwise, I mean Shivam is not here, but he's trying to model.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  11\n",
      "Venkata Dikshit, Krishna Sai Discussed \n",
      "\n",
      " Text:  Yeah, so those specifics and then the other the other next steps on the action item sugar may still trying to figure out the possible improvements for for the current action items based on the testing that he's doing.  Okay, ask him by the way. I don't know how he is doing is actually them testing right last two we do the kinds of things that we do during this conversation. We do, you know, yeah just talk naturally. See we're able to capture those types of things, you know, as you would normally see in a typical meeting, you know.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  9\n",
      "Venkata Dikshit, Krishna Sai Discussed \n",
      "\n",
      " Text:  Yep, Chef, I think mostly mostly we've been testing on the recordings. So also I have a initially when I deployed the first pass, I have a list of spoken out sentences that I use. I'm not sure if that's enough. Maybe we might want to update that and then test it this way.  I thought it and the way I normally is interspersed action items with descriptions and then just like talking 50 and actually items just to see if there are any variations, right?  I think that makes sense is if it if we speak out all the action items in like one after the other it may the transmission could be bad and then it can just go for it.  Yeah, that's it. You know, so maybe we need that said like he can kind of keep that in mind. Yeah. chef  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  1\n",
      "Reagan Rewop Discussed \n",
      "\n",
      " Text:  With respect to community aggression as the final concentration has and the mind condition. We are trying to handle both of them together for now and we have one or two approaches. So I actually wanted to put that on stage on Friday, but I had to changes so I will do it by today and I will do some color testing to see what and all it kind of throws out and what a knowledge. has  And the main thing is like whatever algorithm we have in the production the kind of assume one thing that we need more than one segments like continuously for it to identify it as a proper a topic like some relative understanding so that is actually kind of taking in the current stressful which we saw. So we assume we don't want to assume that it is kind of a rare condition. So we are also taking upon that which would actually reduce the accuracy bonus in the final communities.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "User Group Id:  6\n",
      "Shashank Discussed \n",
      "\n",
      " Text:  yeah, and this time okay action so with respect to recommended watches, so I've been testing over the weekend about how to put to suggest if it is completely unrelated. So so I'm still testing few more things. And so I plan to click deploy to production today so that I can test on our simples. So but otherwise so like right now for debugging debugging purposes. What I'm doing is like for every key phrase request like chapters or highlights or anything. I'm printing the suggested watches. So if you if you look at it a little more on The currency is quite good like I've tested on validation data as well. It's like around 70 75 person. But but the related words which I am also putting it there like to know why it suggested the users that is kind of buggy right now. So it is it has a lot of noise and it's sometimes very unrelated thing is I'm looking at the stuff as well how to be nice then maybe by using like minds or and entity graph or something like at least like a reference data so that we can remove those phrases and just show entities which are common to what has been discussed in the meeting or something.  \n",
      "\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id_map = {}\n",
    "user_id_map = {\"3f01f2032f584b178fafde6b437058ae\":\"Venkat\",\"8fff81b5b2f14aa5ad67405f3e8127f3\":\"Sai\",\"60d2ea6bed8c48269c8c024202a4148d\":\"Shubham\",\"70caa6269d8e4869a45f7ea91ade3472\":\"Ether\",\"3e1a008f734448b0ad9190778449af81\":\"Cullen\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep\",\"716067a60a1a4034abc49a12ecafb39b\":\"Cullen\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Cullen\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "text_list = []\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    print (\"User\", end=\" \")\n",
    "#     if len(seg_list) == 1 :\n",
    "#         continue\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\")\n",
    "    text_list.append(\" \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /tmp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /tmp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  01DAAYHEKY5F4E02QVRJPTFTXV  for feature extraction\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 122, \"module\": \"scorer\", \"batches count\": 1, \"number of sentences\": 81, \"ts\": \"2019-12-06T11:23:57.078283Z\", \"msg\": \"computing in batches\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 125, \"module\": \"scorer\", \"iteration count:\": 0, \"ts\": \"2019-12-06T11:23:57.078710Z\", \"msg\": \"getting feature vector\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 133, \"module\": \"scorer\", \"iteration count\": 0, \"ts\": \"2019-12-06T11:23:58.185178Z\", \"msg\": \"Request Sent\"}\n",
      "('If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.', '2019-11-05T06:35:50Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'f621ac9d6aba42159cb4a49132967749') ('So then we started to gather this, you know, this body called communitycentric tests that we have.', '2019-11-05T06:36:22Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e4331d0b261b4239a82fba773bf0301c')\n",
      "('So then we started to gather this, you know, this body called communitycentric tests that we have.', '2019-11-05T06:36:22Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e4331d0b261b4239a82fba773bf0301c') ('So I am a little aggressive there just to be sure that we are getting good sleep.', '2019-11-05T06:37:00Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a7d82816e0d24b9dbe4f43645f5f0384')\n",
      "('And yeah on the action items, I just spoke to pressure on top Christian.', '2019-11-05T06:37:00Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a7d82816e0d24b9dbe4f43645f5f0384') ('So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.', '2019-11-05T06:38:13Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'd578d8a89fb24790970910c74f5a98a4')\n",
      "('So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality.', '2019-11-05T06:37:00Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a7d82816e0d24b9dbe4f43645f5f0384') ('So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.', '2019-11-05T06:38:13Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'd578d8a89fb24790970910c74f5a98a4')\n",
      "('But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad.', '2019-11-05T06:38:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3f528d8706c342adadc1177e4fa8f2c4') ('Well find out but that is also we have seen we have seen few noises segments.', '2019-11-05T06:38:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '8dad9074cc044d00817d35e39186ef72')\n",
      "('Yeah, if the community is good and I like like they have enough content.', '2019-11-05T06:40:39Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '0c87b0d6af3f4cb79f39a025c3fdfd9b') ('Yeah, so yeah, pretty much those were the things those are the things that I am working on.', '2019-11-05T06:42:13Z', '7e7ccbba232d411aa95ad3f244a35f40', '2bf145322e4d421484c5be3d34c45a58')\n",
      "('So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.', '2019-11-05T06:44:42Z', '7e7ccbba232d411aa95ad3f244a35f40', '03bdb0a4e7ae4e3985582c5bd2dd4dca') ('So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.', '2019-11-05T06:45:34Z', '75bdf310110b4b8fab88b16fafce920e', '212eb9ca06d04dec9f8928e34bd595d3')\n",
      "('So Google those got filtered but these who still came up.', '2019-11-05T06:44:42Z', '7e7ccbba232d411aa95ad3f244a35f40', '03bdb0a4e7ae4e3985582c5bd2dd4dca') ('So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.', '2019-11-05T06:45:34Z', '75bdf310110b4b8fab88b16fafce920e', '212eb9ca06d04dec9f8928e34bd595d3')\n",
      "('So so something like some fun videos that I am checking on me like an ideal way to remove.', '2019-11-05T06:44:42Z', '7e7ccbba232d411aa95ad3f244a35f40', '03bdb0a4e7ae4e3985582c5bd2dd4dca') ('So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.', '2019-11-05T06:45:34Z', '75bdf310110b4b8fab88b16fafce920e', '212eb9ca06d04dec9f8928e34bd595d3')\n",
      "('It is a new service analysis service and even the schema thing.', '2019-11-05T06:46:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c41fd0e424e349f2b52789f4d4c73117') ('So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.', '2019-11-05T06:46:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '7b400835c1eb473391b033c4b0ec9755')\n",
      "('It is a new service analysis service and even the schema thing.', '2019-11-05T06:46:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c41fd0e424e349f2b52789f4d4c73117') ('Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever.', '2019-11-05T06:46:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '7b400835c1eb473391b033c4b0ec9755')\n",
      "('Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.', '2019-11-05T06:47:51Z', '84fbaa66a2474ea29ae053f3a2e519d6', '979467829a7a4b19a856890922031440') ('So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.', '2019-11-05T06:48:25Z', '0bbbfe84c66145af8d0ffcd5258bba38', '9bf5fd91a17a4f0f89b202d8e9a03baf')\n",
      "('Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.', '2019-11-05T06:49:26Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '1f21ff88317e4cdd8492ef55f0dd4de1') ('I just staggered a bit or for adding that bug snack logs the issues.', '2019-11-05T06:51:53Z', 'c66797a92e6d46ad9573926e57f7dac3', 'e04864365d1949b0a9f3ebedcefd59e9')\n",
      "('Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.', '2019-11-05T06:49:26Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '1f21ff88317e4cdd8492ef55f0dd4de1') ('So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.', '2019-11-05T06:51:53Z', 'c66797a92e6d46ad9573926e57f7dac3', 'e04864365d1949b0a9f3ebedcefd59e9')\n",
      "('So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.', '2019-11-05T06:55:16Z', '1a21542584494fcaba957d768b595b80', '353c7be408ed49cfa9bb90a35c8d6ca1') ('So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.', '2019-11-05T06:56:01Z', '1a21542584494fcaba957d768b595b80', '6a565c02d9304106ab038ad6c21e686c')\n",
      "('So we need to spend a little bit more time on that.', '2019-11-05T06:56:44Z', '1a21542584494fcaba957d768b595b80', '2e2647dded0c4765b33cbe192410e4a5') ('Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.', '2019-11-05T06:57:38Z', '1a21542584494fcaba957d768b595b80', 'e708f000baeb40c0be30454cd6edb3c5')\n",
      "('Yeah, so sorry said like let us find out on this room thing.', '2019-11-05T06:57:38Z', '1a21542584494fcaba957d768b595b80', 'e708f000baeb40c0be30454cd6edb3c5') ('So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.', '2019-11-05T06:58:11Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9b60758a5c6945ef821942903414bf11')\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 390, \"module\": \"grouper_segments\", \"outlier threshold is : \": 0.2529652714729309, \"ts\": \"2019-12-06T11:23:58.375291Z\", \"msg\": \"Outlier Score\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 951, \"module\": \"grouper_segments\", \"edges before prunning\": 216, \"edges after prunning\": 216, \"modularity\": 0.8609170703934522, \"ts\": \"2019-12-06T11:23:58.562516Z\", \"msg\": \"Meeting Graph results\"}\n",
      "cluster before alteration=========>\n",
      "Is there a like a test case of something that we can build to validate the performance or say consistently.\n",
      "If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.\n",
      "Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we are developing currently what all the tested all the tests meetings that we have our segment Centre, right?\n",
      "So then we started to gather this, you know, this body called communitycentric tests that we have.\n",
      "cluster before alteration=========>\n",
      "Yeah, a couple of things right on the on the community based teams.\n",
      "We had seen some somewhat off of the track pins yesterday.\n",
      "So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films.\n",
      "We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive.\n",
      "Actually So currently it is very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation.\n",
      "And they and also the body called the Dead the relationship formation the graph Community formation.\n",
      "But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control.\n",
      "We should not be doing like a blanket formation so which which is the problem that we have.\n",
      "I mean currently solving a tap from a more technical standpoint.\n",
      "cluster before alteration=========>\n",
      "So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality.\n",
      "So I am a little aggressive there just to be sure that we are getting good sleep.\n",
      "And yeah on the action items, I just spoke to pressure on top Christian.\n",
      "The trans at least whatever it detects would be highly confident and can be reliable.\n",
      "And so I think we can enable that for The Ether engineering Channel.\n",
      "So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.\n",
      "cluster before alteration=========>\n",
      "So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.\n",
      "It is actually pretty decent terms if this is a detective, yeah.\n",
      "So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.\n",
      "I will just add all the information to document whatever I find a husband.\n",
      "My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not.\n",
      "Just need to see even even with the believability cave might need to associate one workspace to XnumberX inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association.\n",
      "cluster before alteration=========>\n",
      "So we need to spend a little bit more time on that.\n",
      "A lot of losing out on the data because now through God we cannot even capture history as its history.\n",
      "I think whatever we see for the pins would reflect their so let us go God.\n",
      "Yeah, so sorry said like let us find out on this room thing.\n",
      "The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working.\n",
      "So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free.\n",
      "Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.\n",
      "So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.\n",
      "cluster before alteration=========>\n",
      "But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad.\n",
      "Well find out but that is also we have seen we have seen few noises segments.\n",
      "That is why God or whether you are in an open.\n",
      "Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the\n",
      "Like I am constantly seeing the red network error going back and forth to the canteen.\n",
      "I think the biggest issue we are facing is with operate like being able to use the app at all.\n",
      "cluster before alteration=========>\n",
      "Now what I have done is the key phrase since it does not have the popular graph flag red line has just commented it out because I am not sure whether it works or not if I sent a text.\n",
      "Little feature flag thing with popular graph is equal to false.\n",
      "But now I think in the request before you also get different modified text.\n",
      "So these were like hardcoded in the current key phrase except he faces function so I need okay.\n",
      "cluster before alteration=========>\n",
      "Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.\n",
      "I just staggered a bit or for adding that bug snack logs the issues.\n",
      "So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.\n",
      "What recent call was Capcom was kept on loading right spinning.\n",
      "Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,\n",
      "cluster before alteration=========>\n",
      "So because of that there is actually an overlap on the segments.\n",
      "Yeah, there is no there is a there is no breakage between two kind of two segments.\n",
      "Yeah, I saw that for some reason this duplication postprocessing thing did not catch a right way of loading lower case in all the people is.\n",
      "cluster before alteration=========>\n",
      "Actually we were just it is to is already well informed discussion like in our mind and we just discussing to and fro and it would be similar to alakazoom recording where it is just play back and there is no miss a stronger silence points between signals.\n",
      "cluster before alteration=========>\n",
      "So whether there is a way to improve the quality of key phrases, I think we should not see any difference between the pins and communities from the key phrase quality perspective if I think because the input to them is different and then the inherently the communities were back.\n",
      "So otherwise if the community algorithm is good at the key phrases would be at least as good as the pin pin ches.\n",
      "cluster before alteration=========>\n",
      "Yeah, if the community is good and I like like they have enough content.\n",
      "Yeah, so yeah, pretty much those were the things those are the things that I am working on.\n",
      "So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings.\n",
      "And the other thing is I will make the changes for the communitybased summary.\n",
      "So we had this question that you are going to get you that list of groups and with analyzed take all right.\n",
      "cluster before alteration=========>\n",
      "It is a new service analysis service and even the schema thing.\n",
      "So I have mode all the analysis code from transcription service.\n",
      "So the changes are there like it still yet to be tested or that it was.\n",
      "So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.\n",
      "Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever.\n",
      "So slick if it is a segment strategy will go with volt annulment analyzer.\n",
      "cluster before alteration=========>\n",
      "So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.\n",
      "So where there was like sea and Earth has capitals and small and everything.\n",
      "So Google those got filtered but these who still came up.\n",
      "So so something like some fun videos that I am checking on me like an ideal way to remove.\n",
      "So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.\n",
      "So basically, I mean since there was no Stables, you are not maintaining any tables for actions.\n",
      "So by end of day today, I will end up dating curtain on my status.\n",
      "cluster before alteration=========>\n",
      "Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.\n",
      "So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.\n",
      "So currently I am working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it is done, I will deploy it on stage in two.\n",
      "cluster before alteration=========>\n",
      "Okay, but should you need any assistance from the front thinking of testing or evaluating certain part pieces of the yeah.\n",
      "cluster before alteration=========>\n",
      "So mostly like maybe like we will do it together and this chain XnumberX E both will help with the testing.\n",
      "cluster before alteration=========>\n",
      "Anytime your places where we need to call the apis and we need to figure out a way what they do what Zoom Force when they when somebody installs an apple with zoom account.\n",
      "So you need to get the account ID and last term if I remember there are few things missing.\n",
      "So even if I will check if they have change in there because they are not giving the parent account ID.\n",
      "Eid are U second to have multiple sub accounts, so we need to understand a little bit about\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Is there a like a test case of something that we can build to validate the performance or say consistently.\n",
      "If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.\n",
      "Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we are developing currently what all the tested all the tests meetings that we have our segment Centre, right?\n",
      "So then we started to gather this, you know, this body called communitycentric tests that we have.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yeah, a couple of things right on the on the community based teams.\n",
      "We had seen some somewhat off of the track pins yesterday.\n",
      "So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films.\n",
      "We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive.\n",
      "Actually So currently it is very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation.\n",
      "And they and also the body called the Dead the relationship formation the graph Community formation.\n",
      "But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control.\n",
      "We should not be doing like a blanket formation so which which is the problem that we have.\n",
      "I mean currently solving a tap from a more technical standpoint.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality.\n",
      "So I am a little aggressive there just to be sure that we are getting good sleep.\n",
      "And yeah on the action items, I just spoke to pressure on top Christian.\n",
      "The trans at least whatever it detects would be highly confident and can be reliable.\n",
      "And so I think we can enable that for The Ether engineering Channel.\n",
      "So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.\n",
      "So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.\n",
      "I will just add all the information to document whatever I find a husband.\n",
      "My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not.\n",
      "Just need to see even even with the believability cave might need to associate one workspace to XnumberX inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So we need to spend a little bit more time on that.\n",
      "A lot of losing out on the data because now through God we cannot even capture history as its history.\n",
      "Yeah, so sorry said like let us find out on this room thing.\n",
      "The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working.\n",
      "So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free.\n",
      "Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.\n",
      "So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad.\n",
      "Well find out but that is also we have seen we have seen few noises segments.\n",
      "That is why God or whether you are in an open.\n",
      "Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the\n",
      "Like I am constantly seeing the red network error going back and forth to the canteen.\n",
      "I think the biggest issue we are facing is with operate like being able to use the app at all.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Now what I have done is the key phrase since it does not have the popular graph flag red line has just commented it out because I am not sure whether it works or not if I sent a text.\n",
      "Little feature flag thing with popular graph is equal to false.\n",
      "But now I think in the request before you also get different modified text.\n",
      "So these were like hardcoded in the current key phrase except he faces function so I need okay.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.\n",
      "I just staggered a bit or for adding that bug snack logs the issues.\n",
      "So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.\n",
      "What recent call was Capcom was kept on loading right spinning.\n",
      "Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So because of that there is actually an overlap on the segments.\n",
      "Yeah, there is no there is a there is no breakage between two kind of two segments.\n",
      "Yeah, I saw that for some reason this duplication postprocessing thing did not catch a right way of loading lower case in all the people is.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Actually we were just it is to is already well informed discussion like in our mind and we just discussing to and fro and it would be similar to alakazoom recording where it is just play back and there is no miss a stronger silence points between signals.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So whether there is a way to improve the quality of key phrases, I think we should not see any difference between the pins and communities from the key phrase quality perspective if I think because the input to them is different and then the inherently the communities were back.\n",
      "So otherwise if the community algorithm is good at the key phrases would be at least as good as the pin pin ches.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yeah, if the community is good and I like like they have enough content.\n",
      "Yeah, so yeah, pretty much those were the things those are the things that I am working on.\n",
      "So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings.\n",
      "And the other thing is I will make the changes for the communitybased summary.\n",
      "So we had this question that you are going to get you that list of groups and with analyzed take all right.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "It is a new service analysis service and even the schema thing.\n",
      "So I have mode all the analysis code from transcription service.\n",
      "So the changes are there like it still yet to be tested or that it was.\n",
      "So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.\n",
      "Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever.\n",
      "So slick if it is a segment strategy will go with volt annulment analyzer.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.\n",
      "So where there was like sea and Earth has capitals and small and everything.\n",
      "So Google those got filtered but these who still came up.\n",
      "So so something like some fun videos that I am checking on me like an ideal way to remove.\n",
      "So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.\n",
      "So basically, I mean since there was no Stables, you are not maintaining any tables for actions.\n",
      "So by end of day today, I will end up dating curtain on my status.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.\n",
      "So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.\n",
      "So currently I am working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it is done, I will deploy it on stage in two.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Okay, but should you need any assistance from the front thinking of testing or evaluating certain part pieces of the yeah.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So mostly like maybe like we will do it together and this chain XnumberX E both will help with the testing.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Anytime your places where we need to call the apis and we need to figure out a way what they do what Zoom Force when they when somebody installs an apple with zoom account.\n",
      "So you need to get the account ID and last term if I remember there are few things missing.\n",
      "So even if I will check if they have change in there because they are not giving the parent account ID.\n",
      "Eid are U second to have multiple sub accounts, so we need to understand a little bit about\n",
      "\n",
      "\n",
      "Checking Timerange --------------\n",
      "--------------\n",
      "If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help. f621ac9d6aba42159cb4a49132967749 \n",
      "\n",
      "Is there a like a test case of something that we can build to validate the performance or say consistently. f621ac9d6aba42159cb4a49132967749 \n",
      "\n",
      "So then we started to gather this, you know, this body called communitycentric tests that we have. e4331d0b261b4239a82fba773bf0301c \n",
      "\n",
      "Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we are developing currently what all the tested all the tests meetings that we have our segment Centre, right? e4331d0b261b4239a82fba773bf0301c \n",
      "\n",
      "--------------\n",
      "But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "And they and also the body called the Dead the relationship formation the graph Community formation. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "I mean currently solving a tap from a more technical standpoint. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "We should not be doing like a blanket formation so which which is the problem that we have. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "Yeah, a couple of things right on the on the community based teams. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "We had seen some somewhat off of the track pins yesterday. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "Actually So currently it is very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation. 516dce6af97741929a1da5e52d0d4a16 \n",
      "\n",
      "--------------\n",
      "So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "The trans at least whatever it detects would be highly confident and can be reliable. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "And so I think we can enable that for The Ether engineering Channel. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "So I am a little aggressive there just to be sure that we are getting good sleep. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "And yeah on the action items, I just spoke to pressure on top Christian. a7d82816e0d24b9dbe4f43645f5f0384 \n",
      "\n",
      "So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. d578d8a89fb24790970910c74f5a98a4 \n",
      "\n",
      "--------------\n",
      "I will just add all the information to document whatever I find a husband. 353c7be408ed49cfa9bb90a35c8d6ca1 \n",
      "\n",
      "So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. 353c7be408ed49cfa9bb90a35c8d6ca1 \n",
      "\n",
      "So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. 6a565c02d9304106ab038ad6c21e686c \n",
      "\n",
      "My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. 6a565c02d9304106ab038ad6c21e686c \n",
      "\n",
      "Just need to see even even with the believability cave might need to associate one workspace to XnumberX inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. 6a565c02d9304106ab038ad6c21e686c \n",
      "\n",
      "--------------\n",
      "So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. 2e2647dded0c4765b33cbe192410e4a5 \n",
      "\n",
      "So we need to spend a little bit more time on that. 2e2647dded0c4765b33cbe192410e4a5 \n",
      "\n",
      "The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. 2e2647dded0c4765b33cbe192410e4a5 \n",
      "\n",
      "Yeah, so sorry said like let us find out on this room thing. e708f000baeb40c0be30454cd6edb3c5 \n",
      "\n",
      "Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way. e708f000baeb40c0be30454cd6edb3c5 \n",
      "\n",
      "A lot of losing out on the data because now through God we cannot even capture history as its history. 9b60758a5c6945ef821942903414bf11 \n",
      "\n",
      "So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore. 9b60758a5c6945ef821942903414bf11 \n",
      "\n",
      "--------------\n",
      "But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad. 3f528d8706c342adadc1177e4fa8f2c4 \n",
      "\n",
      "That is why God or whether you are in an open. 8dad9074cc044d00817d35e39186ef72 \n",
      "\n",
      "Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the 8dad9074cc044d00817d35e39186ef72 \n",
      "\n",
      "Well find out but that is also we have seen we have seen few noises segments. 8dad9074cc044d00817d35e39186ef72 \n",
      "\n",
      "Like I am constantly seeing the red network error going back and forth to the canteen. 92b083bc074d4c25b746d9e63d265fec \n",
      "\n",
      "I think the biggest issue we are facing is with operate like being able to use the app at all. 92b083bc074d4c25b746d9e63d265fec \n",
      "\n",
      "--------------\n",
      "So these were like hardcoded in the current key phrase except he faces function so I need okay. 10c80968772c4b4c839a3caa4a847342 \n",
      "\n",
      "But now I think in the request before you also get different modified text. 10c80968772c4b4c839a3caa4a847342 \n",
      "\n",
      "Little feature flag thing with popular graph is equal to false. 10c80968772c4b4c839a3caa4a847342 \n",
      "\n",
      "Now what I have done is the key phrase since it does not have the popular graph flag red line has just commented it out because I am not sure whether it works or not if I sent a text. a978434d3ba34453884c6ef07c763b85 \n",
      "\n",
      "--------------\n",
      "Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail. 1f21ff88317e4cdd8492ef55f0dd4de1 \n",
      "\n",
      "Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know, e04864365d1949b0a9f3ebedcefd59e9 \n",
      "\n",
      "So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task. e04864365d1949b0a9f3ebedcefd59e9 \n",
      "\n",
      "What recent call was Capcom was kept on loading right spinning. e04864365d1949b0a9f3ebedcefd59e9 \n",
      "\n",
      "I just staggered a bit or for adding that bug snack logs the issues. e04864365d1949b0a9f3ebedcefd59e9 \n",
      "\n",
      "--------------\n",
      "Yeah, there is no there is a there is no breakage between two kind of two segments. d7529d570c774cb6b87adef4784f9e26 \n",
      "\n",
      "So because of that there is actually an overlap on the segments. d7529d570c774cb6b87adef4784f9e26 \n",
      "\n",
      "Yeah, I saw that for some reason this duplication postprocessing thing did not catch a right way of loading lower case in all the people is. e82eda1dec5d46caa0d9bd0bb34b6453 \n",
      "\n",
      "--------------\n",
      "Actually we were just it is to is already well informed discussion like in our mind and we just discussing to and fro and it would be similar to alakazoom recording where it is just play back and there is no miss a stronger silence points between signals. f8d20183a3e34389865f1df3f2003b98 \n",
      "\n",
      "--------------\n",
      "So otherwise if the community algorithm is good at the key phrases would be at least as good as the pin pin ches. 348f137b708a456f8a134dd7268afee6 \n",
      "\n",
      "So whether there is a way to improve the quality of key phrases, I think we should not see any difference between the pins and communities from the key phrase quality perspective if I think because the input to them is different and then the inherently the communities were back. 348f137b708a456f8a134dd7268afee6 \n",
      "\n",
      "--------------\n",
      "Yeah, if the community is good and I like like they have enough content. 0c87b0d6af3f4cb79f39a025c3fdfd9b \n",
      "\n",
      "So we had this question that you are going to get you that list of groups and with analyzed take all right. 2bf145322e4d421484c5be3d34c45a58 \n",
      "\n",
      "So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. 2bf145322e4d421484c5be3d34c45a58 \n",
      "\n",
      "And the other thing is I will make the changes for the communitybased summary. 2bf145322e4d421484c5be3d34c45a58 \n",
      "\n",
      "Yeah, so yeah, pretty much those were the things those are the things that I am working on. 2bf145322e4d421484c5be3d34c45a58 \n",
      "\n",
      "--------------\n",
      "So the changes are there like it still yet to be tested or that it was. c41fd0e424e349f2b52789f4d4c73117 \n",
      "\n",
      "So I have mode all the analysis code from transcription service. c41fd0e424e349f2b52789f4d4c73117 \n",
      "\n",
      "It is a new service analysis service and even the schema thing. c41fd0e424e349f2b52789f4d4c73117 \n",
      "\n",
      "So slick if it is a segment strategy will go with volt annulment analyzer. 7b400835c1eb473391b033c4b0ec9755 \n",
      "\n",
      "So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. 7b400835c1eb473391b033c4b0ec9755 \n",
      "\n",
      "Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever. 7b400835c1eb473391b033c4b0ec9755 \n",
      "\n",
      "--------------\n",
      "So Google those got filtered but these who still came up. 03bdb0a4e7ae4e3985582c5bd2dd4dca \n",
      "\n",
      "So where there was like sea and Earth has capitals and small and everything. 03bdb0a4e7ae4e3985582c5bd2dd4dca \n",
      "\n",
      "So so something like some fun videos that I am checking on me like an ideal way to remove. 03bdb0a4e7ae4e3985582c5bd2dd4dca \n",
      "\n",
      "So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. 03bdb0a4e7ae4e3985582c5bd2dd4dca \n",
      "\n",
      "So by end of day today, I will end up dating curtain on my status. 212eb9ca06d04dec9f8928e34bd595d3 \n",
      "\n",
      "So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. 212eb9ca06d04dec9f8928e34bd595d3 \n",
      "\n",
      "So basically, I mean since there was no Stables, you are not maintaining any tables for actions. 212eb9ca06d04dec9f8928e34bd595d3 \n",
      "\n",
      "--------------\n",
      "Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue. 979467829a7a4b19a856890922031440 \n",
      "\n",
      "So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. 9bf5fd91a17a4f0f89b202d8e9a03baf \n",
      "\n",
      "So currently I am working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it is done, I will deploy it on stage in two. 9bf5fd91a17a4f0f89b202d8e9a03baf \n",
      "\n",
      "--------------\n",
      "Okay, but should you need any assistance from the front thinking of testing or evaluating certain part pieces of the yeah. 33291fe1c24442308d90c7ef54f23696 \n",
      "\n",
      "--------------\n",
      "So mostly like maybe like we will do it together and this chain XnumberX E both will help with the testing. 41d1a59fd6b249c3a4820673184b0598 \n",
      "\n",
      "--------------\n",
      "Anytime your places where we need to call the apis and we need to figure out a way what they do what Zoom Force when they when somebody installs an apple with zoom account. 495198df58aa4f4f99110e8b84e27e9f \n",
      "\n",
      "So even if I will check if they have change in there because they are not giving the parent account ID. 495198df58aa4f4f99110e8b84e27e9f \n",
      "\n",
      "Eid are U second to have multiple sub accounts, so we need to understand a little bit about 495198df58aa4f4f99110e8b84e27e9f \n",
      "\n",
      "So you need to get the account ID and last term if I remember there are few things missing. 495198df58aa4f4f99110e8b84e27e9f \n",
      "\n",
      "<---------------->\n",
      "order difference: 0\n",
      "Relevant sentence:  If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.    =====    Is there a like a test case of something that we can build to validate the performance or say consistently.\n",
      "order difference: 1\n",
      "Relevant sentence:  Is there a like a test case of something that we can build to validate the performance or say consistently.    =====    So then we started to gather this, you know, this body called communitycentric tests that we have.\n",
      "order difference: 0\n",
      "Relevant sentence:  So then we started to gather this, you know, this body called communitycentric tests that we have.    =====    Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we are developing currently what all the tested all the tests meetings that we have our segment Centre, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control.    =====    We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive.\n",
      "order difference: 0\n",
      "Relevant sentence:  We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive.    =====    And they and also the body called the Dead the relationship formation the graph Community formation.\n",
      "order difference: 0\n",
      "Relevant sentence:  And they and also the body called the Dead the relationship formation the graph Community formation.    =====    I mean currently solving a tap from a more technical standpoint.\n",
      "order difference: 0\n",
      "Relevant sentence:  I mean currently solving a tap from a more technical standpoint.    =====    We should not be doing like a blanket formation so which which is the problem that we have.\n",
      "order difference: 0\n",
      "Relevant sentence:  We should not be doing like a blanket formation so which which is the problem that we have.    =====    Yeah, a couple of things right on the on the community based teams.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, a couple of things right on the on the community based teams.    =====    So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films.\n",
      "order difference: 0\n",
      "Relevant sentence:  So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it is illogical book, so he is going to fix that today and And that s  or at least improve improve the way we are seeing the community based films.    =====    We had seen some somewhat off of the track pins yesterday.\n",
      "order difference: 0\n",
      "Relevant sentence:  We had seen some somewhat off of the track pins yesterday.    =====    Actually So currently it is very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation.\n",
      "order difference: 0\n",
      "Relevant sentence:  So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality.    =====    The trans at least whatever it detects would be highly confident and can be reliable.\n",
      "order difference: 0\n",
      "Relevant sentence:  The trans at least whatever it detects would be highly confident and can be reliable.    =====    And so I think we can enable that for The Ether engineering Channel.\n",
      "order difference: 0\n",
      "Relevant sentence:  And so I think we can enable that for The Ether engineering Channel.    =====    So I am a little aggressive there just to be sure that we are getting good sleep.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I am a little aggressive there just to be sure that we are getting good sleep.    =====    And yeah on the action items, I just spoke to pressure on top Christian.\n",
      "order difference: 1\n",
      "Relevant sentence:  And yeah on the action items, I just spoke to pressure on top Christian.    =====    So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is.\n",
      "order difference: 0\n",
      "Relevant sentence:  I will just add all the information to document whatever I find a husband.    =====    So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.\n",
      "order difference: 1\n",
      "Relevant sentence:  So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate.    =====    So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I am just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords.    =====    My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not.\n",
      "order difference: 0\n",
      "Relevant sentence:  My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not.    =====    Just need to see even even with the believability cave might need to associate one workspace to XnumberX inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free.    =====    So we need to spend a little bit more time on that.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we need to spend a little bit more time on that.    =====    The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working.\n",
      "order difference: 1\n",
      "Relevant sentence:  The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working.    =====    Yeah, so sorry said like let us find out on this room thing.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, so sorry said like let us find out on this room thing.    =====    Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.\n",
      "order difference: 1\n",
      "Relevant sentence:  Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so Were just gonna put this way.    =====    A lot of losing out on the data because now through God we cannot even capture history as its history.\n",
      "order difference: 0\n",
      "Relevant sentence:  A lot of losing out on the data because now through God we cannot even capture history as its history.    =====    So at least we should start getting data as my concern you can in a soil to check but that is why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.\n",
      "order difference: 1\n",
      "Relevant sentence:  But the bim is did look, okay, like if you look at the films as opposed to the chapters, yeah, there is not necessarily bad.    =====    That is why God or whether you are in an open.\n",
      "order difference: 0\n",
      "Relevant sentence:  That is why God or whether you are in an open.    =====    Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the\n",
      "order difference: 0\n",
      "Relevant sentence:  Well, you are on the actual headphones are on the open window the own societies that a call and iOS and you just get the    =====    Well find out but that is also we have seen we have seen few noises segments.\n",
      "Not Relevant sentence:  Well find out but that is also we have seen we have seen few noises segments.    !=    Like I am constantly seeing the red network error going back and forth to the canteen.\n",
      "order difference: 19\n",
      "order difference: 0\n",
      "Relevant sentence:  Like I am constantly seeing the red network error going back and forth to the canteen.    =====    I think the biggest issue we are facing is with operate like being able to use the app at all.\n",
      "order difference: 0\n",
      "Relevant sentence:  So these were like hardcoded in the current key phrase except he faces function so I need okay.    =====    But now I think in the request before you also get different modified text.\n",
      "order difference: 0\n",
      "Relevant sentence:  But now I think in the request before you also get different modified text.    =====    Little feature flag thing with popular graph is equal to false.\n",
      "Not Relevant sentence:  Little feature flag thing with popular graph is equal to false.    !=    Now what I have done is the key phrase since it does not have the popular graph flag red line has just commented it out because I am not sure whether it works or not if I sent a text.\n",
      "order difference: 6\n",
      "order difference: 1\n",
      "Relevant sentence:  Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.    =====    Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,\n",
      "order difference: 0\n",
      "Relevant sentence:  Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,    =====    So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.\n",
      "order difference: 0\n",
      "Relevant sentence:  So once the build is done, we will just test it again and then a sinking I have not yet started on the localization task.    =====    What recent call was Capcom was kept on loading right spinning.\n",
      "order difference: 0\n",
      "Relevant sentence:  What recent call was Capcom was kept on loading right spinning.    =====    I just staggered a bit or for adding that bug snack logs the issues.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, there is no there is a there is no breakage between two kind of two segments.    =====    So because of that there is actually an overlap on the segments.\n",
      "Not Relevant sentence:  So because of that there is actually an overlap on the segments.    !=    Yeah, I saw that for some reason this duplication postprocessing thing did not catch a right way of loading lower case in all the people is.\n",
      "order difference: 6\n",
      "order difference: 0\n",
      "Relevant sentence:  So otherwise if the community algorithm is good at the key phrases would be at least as good as the pin pin ches.    =====    So whether there is a way to improve the quality of key phrases, I think we should not see any difference between the pins and communities from the key phrase quality perspective if I think because the input to them is different and then the inherently the communities were back.\n",
      "order difference: 1\n",
      "Relevant sentence:  Yeah, if the community is good and I like like they have enough content.    =====    So we had this question that you are going to get you that list of groups and with analyzed take all right.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we had this question that you are going to get you that list of groups and with analyzed take all right.    =====    So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings.\n",
      "order difference: 0\n",
      "Relevant sentence:  So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I am going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings.    =====    And the other thing is I will make the changes for the communitybased summary.\n",
      "order difference: 0\n",
      "Relevant sentence:  And the other thing is I will make the changes for the communitybased summary.    =====    Yeah, so yeah, pretty much those were the things those are the things that I am working on.\n",
      "order difference: 0\n",
      "Relevant sentence:  So the changes are there like it still yet to be tested or that it was.    =====    So I have mode all the analysis code from transcription service.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I have mode all the analysis code from transcription service.    =====    It is a new service analysis service and even the schema thing.\n",
      "order difference: 1\n",
      "Relevant sentence:  It is a new service analysis service and even the schema thing.    =====    So slick if it is a segment strategy will go with volt annulment analyzer.\n",
      "order difference: 0\n",
      "Relevant sentence:  So slick if it is a segment strategy will go with volt annulment analyzer.    =====    So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.\n",
      "order difference: 0\n",
      "Relevant sentence:  So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer.    =====    Otherwise, we will go with their Community segment analyzer the the that is all like and also the summary we also moved to a different schema all those push the code now Cody is first time ever.\n",
      "order difference: 0\n",
      "Relevant sentence:  So Google those got filtered but these who still came up.    =====    So where there was like sea and Earth has capitals and small and everything.\n",
      "order difference: 0\n",
      "Relevant sentence:  So where there was like sea and Earth has capitals and small and everything.    =====    So so something like some fun videos that I am checking on me like an ideal way to remove.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so something like some fun videos that I am checking on me like an ideal way to remove.    =====    So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.\n",
      "order difference: 1\n",
      "Relevant sentence:  So in before postprocessing like in the original list that it got it had two more slack Channel slack and slack Channel keywords.    =====    So by end of day today, I will end up dating curtain on my status.\n",
      "order difference: 0\n",
      "Relevant sentence:  So by end of day today, I will end up dating curtain on my status.    =====    So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.\n",
      "order difference: 0\n",
      "Relevant sentence:  So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this.    =====    So basically, I mean since there was no Stables, you are not maintaining any tables for actions.\n",
      "order difference: 1\n",
      "Relevant sentence:  Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.    =====    So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.\n",
      "order difference: 0\n",
      "Relevant sentence:  So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out.    =====    So currently I am working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it is done, I will deploy it on stage in two.\n",
      "order difference: 0\n",
      "Relevant sentence:  Anytime your places where we need to call the apis and we need to figure out a way what they do what Zoom Force when they when somebody installs an apple with zoom account.    =====    So even if I will check if they have change in there because they are not giving the parent account ID.\n",
      "order difference: 0\n",
      "Relevant sentence:  So even if I will check if they have change in there because they are not giving the parent account ID.    =====    Eid are U second to have multiple sub accounts, so we need to understand a little bit about\n",
      "order difference: 0\n",
      "Relevant sentence:  Eid are U second to have multiple sub accounts, so we need to understand a little bit about    =====    So you need to get the account ID and last term if I remember there are few things missing.\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 959, \"module\": \"grouper_segments\", \"PIMs\": {\"0\": {\"segment0\": [[\"Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail. \"], \"2019-11-05T06:49:26Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"1f21ff88317e4cdd8492ef55f0dd4de1\"], \"segment1\": [[\"I just staggered a bit or for adding that bug snack logs the issues. I was with me yesterday. What recent call was Capcom was kept on loading right spinning. So once the build is done, we'll just test it again and then a sinking I haven't yet started on the localization task. Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know, \"], \"2019-11-05T06:51:53Z\", \"c66797a92e6d46ad9573926e57f7dac3\", \"e04864365d1949b0a9f3ebedcefd59e9\"]}, \"1\": {\"segment0\": [[\"Yeah, a couple of things right on the on the community based teams. We had seen some somewhat off of the track pins yesterday. So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it's illogical book, so he's going to fix that today and And that s*** - or at least improve improve the way we are seeing the community based films. I mean it wouldn't be so off but still parallely. We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive. Actually So currently it's very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation. And they and also the body called the Dead the relationship formation the graph Community formation. So it needs some experimentation. We are we are discussing on that and also parallel. We are what you call experimenting so we should have when we will keep you posted on this. But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control. So it's like a blanket hierarchy for Direction. So we have to take control of that. That means we should be fuzzy about it. We shouldn't be doing like a blanket formation so which which is the problem that we have. I mean currently solving a tap from a more technical standpoint. \"], \"2019-11-05T06:33:54Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"516dce6af97741929a1da5e52d0d4a16\"]}, \"2\": {\"segment0\": [[\"The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. So we need to spend a little bit more time on that. So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. I can also look into upgrading that JavaScript. \"], \"2019-11-05T06:56:44Z\", \"1a21542584494fcaba957d768b595b80\", \"2e2647dded0c4765b33cbe192410e4a5\"], \"segment1\": [[\"Yeah, so sorry said like let's find out on this room thing. Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so We're just gonna put this way. \"], \"2019-11-05T06:57:38Z\", \"1a21542584494fcaba957d768b595b80\", \"e708f000baeb40c0be30454cd6edb3c5\"], \"segment2\": [[\"A lot of losing out on the data because now through God we cannot even capture history as its history. So at least we should start getting data as my concern you can in a soil to check but that's why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore. \"], \"2019-11-05T06:58:11Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"9b60758a5c6945ef821942903414bf11\"]}, \"3\": {\"segment0\": [[\"Yogurt for somebody new the new community-based summary, right? So I have mode all the analysis code from transcription service. It's a new service analysis service and even the schema thing. So the changes are there like it still yet to be tested or that it was. \"], \"2019-11-05T06:46:19Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"c41fd0e424e349f2b52789f4d4c73117\"], \"segment1\": [[\"So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. So slick if it is a segment strategy will go with volt annulment analyzer. Otherwise, we'll go with their Community segment analyzer the the that's all like and also the summary we also moved to a different schema all those push the code now Cody's first time ever. \"], \"2019-11-05T06:46:42Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"7b400835c1eb473391b033c4b0ec9755\"]}, \"4\": {\"segment0\": [[\"Let's say we even do this. Is there a like a test case of something that we can build to validate the performance or say consistently. This is based on this these test cases. This is better than the what we have right now. Yes. If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help. \"], \"2019-11-05T06:35:50Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"f621ac9d6aba42159cb4a49132967749\"], \"segment1\": [[\"Yeah, we have the test set. Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we're developing currently what all the tested all the tests meetings that we have our segment Centre, right? So then we started to gather this, you know, this body called community-centric tests that we have. Going to build so there is also parallel going on. So any validation would happen on that. W? \"], \"2019-11-05T06:36:22Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"e4331d0b261b4239a82fba773bf0301c\"]}, \"5\": {\"segment0\": [[\"So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. So let me see what I can find. I'll just add all the information to document whatever I find a husband. \"], \"2019-11-05T06:55:16Z\", \"1a21542584494fcaba957d768b595b80\", \"353c7be408ed49cfa9bb90a35c8d6ca1\"], \"segment1\": [[\"My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. So I'm just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. Just need to see even even with the believability cave might need to associate one workspace to 1 inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. Okay. \"], \"2019-11-05T06:56:01Z\", \"1a21542584494fcaba957d768b595b80\", \"6a565c02d9304106ab038ad6c21e686c\"]}, \"6\": {\"segment0\": [[\"Yeah, because eventually that's what we see, right? Yeah, if the community is good and I like like they have enough content. I think whatever we see for the pins would reflect their so let's go God. Yeah. \"], \"2019-11-05T06:40:39Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"0c87b0d6af3f4cb79f39a025c3fdfd9b\"], \"segment1\": [[\"Yeah, so yeah, pretty much those were the things those are the things that I'm working on. So like converting. So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I'm going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. How's it going? What is the approach and what it requires as input? And the other thing is I'll make the changes for the community-based summary. So we had this question that you're going to get you that list of groups and with analyzed take all right. \"], \"2019-11-05T06:42:13Z\", \"7e7ccbba232d411aa95ad3f244a35f40\", \"2bf145322e4d421484c5be3d34c45a58\"]}, \"7\": {\"segment0\": [[\"So in before post-processing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. So where there was like sea and Earth has capitals and small and everything. So Google those got filtered but these who still came up. So so something like some fun videos that I'm checking on me like an ideal way to remove. \"], \"2019-11-05T06:44:42Z\", \"7e7ccbba232d411aa95ad3f244a35f40\", \"03bdb0a4e7ae4e3985582c5bd2dd4dca\"], \"segment1\": [[\"So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. So basically, I mean since there was no Stables, you're not maintaining any tables for actions. No, it's taking some time. So by end of day today, I'll end up dating curtain on my status. \"], \"2019-11-05T06:45:34Z\", \"75bdf310110b4b8fab88b16fafce920e\", \"212eb9ca06d04dec9f8928e34bd595d3\"]}, \"8\": {\"segment0\": [[\"But the bim's did look, okay, like if you look at the films as opposed to the chapters, yeah, there's not necessarily bad. It's actually pretty decent terms if this is a detective, yeah. \"], \"2019-11-05T06:38:40Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"3f528d8706c342adadc1177e4fa8f2c4\"], \"segment1\": [[\"We'll find out but that's also we have seen we have seen few noises segments. That's why God or whether you are in an open. Mike. Well, you're on the actual headphones are on the open window the own societies that a call and iOS and you just get the \"], \"2019-11-05T06:38:54Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"8dad9074cc044d00817d35e39186ef72\"]}, \"9\": {\"segment0\": [[\"And yeah on the action items, I just spoke to pressure on top Christian. So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. Whereas I think we fairly have good. The trans at least whatever it detects would be highly confident and can be reliable. So I'm a little aggressive there just to be sure that we are getting good sleep. And so I think we can enable that for The Ether engineering Channel. \"], \"2019-11-05T06:37:00Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"a7d82816e0d24b9dbe4f43645f5f0384\"], \"segment1\": [[\"So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. Yeah. \"], \"2019-11-05T06:38:13Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"d578d8a89fb24790970910c74f5a98a4\"]}, \"10\": {\"segment0\": [[\"Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue. \"], \"2019-11-05T06:47:51Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"979467829a7a4b19a856890922031440\"], \"segment1\": [[\"So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. So currently I'm working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it's done, I'll deploy it on stage in two. \"], \"2019-11-05T06:48:25Z\", \"0bbbfe84c66145af8d0ffcd5258bba38\", \"9bf5fd91a17a4f0f89b202d8e9a03baf\"]}}, \"ts\": \"2019-12-06T11:23:58.622472Z\", \"msg\": \"Final PIMs\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail. '], '2019-11-05T06:49:26Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '1f21ff88317e4cdd8492ef55f0dd4de1'], [[\"I just staggered a bit or for adding that bug snack logs the issues. I was with me yesterday. What recent call was Capcom was kept on loading right spinning. So once the build is done, we'll just test it again and then a sinking I haven't yet started on the localization task. Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know, \"], '2019-11-05T06:51:53Z', 'c66797a92e6d46ad9573926e57f7dac3', 'e04864365d1949b0a9f3ebedcefd59e9']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yeah, a couple of things right on the on the community based teams. We had seen some somewhat off of the track pins yesterday. So Shri was looking into that and he said there is a small bug in the recent deployment that he did from the error perspective, but from the logic it's illogical book, so he's going to fix that today and And that s*** - or at least improve improve the way we are seeing the community based films. I mean it wouldn't be so off but still parallely. We are also discussing on how to how to take more control of the communities instead of relying on this, you know sensitive instead of making making it more or less sensitive. Actually So currently it's very sensitive to any any Community formation and other aspects so at a high level like a posted in the engineering Channel We are looking at ways to take take more control of the graph formation. And they and also the body called the Dead the relationship formation the graph Community formation. So it needs some experimentation. We are we are discussing on that and also parallel. We are what you call experimenting so we should have when we will keep you posted on this. But as of this is this what it is we have we have to address some of the The problems with the community formation for the wherein you know hierarchies are not really a currently hierarchies are not in our control. So it's like a blanket hierarchy for Direction. So we have to take control of that. That means we should be fuzzy about it. We shouldn't be doing like a blanket formation so which which is the problem that we have. I mean currently solving a tap from a more technical standpoint. \"], '2019-11-05T06:33:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '516dce6af97741929a1da5e52d0d4a16']]\n",
      "====================Group Cluster=========================\n",
      "[[['The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. So we need to spend a little bit more time on that. So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. I can also look into upgrading that JavaScript. '], '2019-11-05T06:56:44Z', '1a21542584494fcaba957d768b595b80', '2e2647dded0c4765b33cbe192410e4a5'], [[\"Yeah, so sorry said like let's find out on this room thing. Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so We're just gonna put this way. \"], '2019-11-05T06:57:38Z', '1a21542584494fcaba957d768b595b80', 'e708f000baeb40c0be30454cd6edb3c5'], [[\"A lot of losing out on the data because now through God we cannot even capture history as its history. So at least we should start getting data as my concern you can in a soil to check but that's why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore. \"], '2019-11-05T06:58:11Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9b60758a5c6945ef821942903414bf11']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yogurt for somebody new the new community-based summary, right? So I have mode all the analysis code from transcription service. It's a new service analysis service and even the schema thing. So the changes are there like it still yet to be tested or that it was. \"], '2019-11-05T06:46:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c41fd0e424e349f2b52789f4d4c73117'], [[\"So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. So slick if it is a segment strategy will go with volt annulment analyzer. Otherwise, we'll go with their Community segment analyzer the the that's all like and also the summary we also moved to a different schema all those push the code now Cody's first time ever. \"], '2019-11-05T06:46:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '7b400835c1eb473391b033c4b0ec9755']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"Let's say we even do this. Is there a like a test case of something that we can build to validate the performance or say consistently. This is based on this these test cases. This is better than the what we have right now. Yes. If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help. \"], '2019-11-05T06:35:50Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'f621ac9d6aba42159cb4a49132967749'], [[\"Yeah, we have the test set. Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we're developing currently what all the tested all the tests meetings that we have our segment Centre, right? So then we started to gather this, you know, this body called community-centric tests that we have. Going to build so there is also parallel going on. So any validation would happen on that. W? \"], '2019-11-05T06:36:22Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e4331d0b261b4239a82fba773bf0301c']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. So let me see what I can find. I'll just add all the information to document whatever I find a husband. \"], '2019-11-05T06:55:16Z', '1a21542584494fcaba957d768b595b80', '353c7be408ed49cfa9bb90a35c8d6ca1'], [[\"My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. So I'm just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. Just need to see even even with the believability cave might need to associate one workspace to 1 inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. Okay. \"], '2019-11-05T06:56:01Z', '1a21542584494fcaba957d768b595b80', '6a565c02d9304106ab038ad6c21e686c']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yeah, because eventually that's what we see, right? Yeah, if the community is good and I like like they have enough content. I think whatever we see for the pins would reflect their so let's go God. Yeah. \"], '2019-11-05T06:40:39Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '0c87b0d6af3f4cb79f39a025c3fdfd9b'], [[\"Yeah, so yeah, pretty much those were the things those are the things that I'm working on. So like converting. So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I'm going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. How's it going? What is the approach and what it requires as input? And the other thing is I'll make the changes for the community-based summary. So we had this question that you're going to get you that list of groups and with analyzed take all right. \"], '2019-11-05T06:42:13Z', '7e7ccbba232d411aa95ad3f244a35f40', '2bf145322e4d421484c5be3d34c45a58']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"So in before post-processing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. So where there was like sea and Earth has capitals and small and everything. So Google those got filtered but these who still came up. So so something like some fun videos that I'm checking on me like an ideal way to remove. \"], '2019-11-05T06:44:42Z', '7e7ccbba232d411aa95ad3f244a35f40', '03bdb0a4e7ae4e3985582c5bd2dd4dca'], [[\"So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. So basically, I mean since there was no Stables, you're not maintaining any tables for actions. No, it's taking some time. So by end of day today, I'll end up dating curtain on my status. \"], '2019-11-05T06:45:34Z', '75bdf310110b4b8fab88b16fafce920e', '212eb9ca06d04dec9f8928e34bd595d3']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"But the bim's did look, okay, like if you look at the films as opposed to the chapters, yeah, there's not necessarily bad. It's actually pretty decent terms if this is a detective, yeah. \"], '2019-11-05T06:38:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3f528d8706c342adadc1177e4fa8f2c4'], [[\"We'll find out but that's also we have seen we have seen few noises segments. That's why God or whether you are in an open. Mike. Well, you're on the actual headphones are on the open window the own societies that a call and iOS and you just get the \"], '2019-11-05T06:38:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '8dad9074cc044d00817d35e39186ef72']]\n",
      "====================Group Cluster=========================\n",
      "[[[\"And yeah on the action items, I just spoke to pressure on top Christian. So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. Whereas I think we fairly have good. The trans at least whatever it detects would be highly confident and can be reliable. So I'm a little aggressive there just to be sure that we are getting good sleep. And so I think we can enable that for The Ether engineering Channel. \"], '2019-11-05T06:37:00Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a7d82816e0d24b9dbe4f43645f5f0384'], [['So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. Yeah. '], '2019-11-05T06:38:13Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'd578d8a89fb24790970910c74f5a98a4']]\n",
      "====================Group Cluster=========================\n",
      "[[['Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue. '], '2019-11-05T06:47:51Z', '84fbaa66a2474ea29ae053f3a2e519d6', '979467829a7a4b19a856890922031440'], [[\"So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. So currently I'm working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it's done, I'll deploy it on stage in two. \"], '2019-11-05T06:48:25Z', '0bbbfe84c66145af8d0ffcd5258bba38', '9bf5fd91a17a4f0f89b202d8e9a03baf']]\n"
     ]
    }
   ],
   "source": [
    "from main import handler\n",
    "\n",
    "res = handler(request, None)\n",
    "group2 = json.loads(res['body'])\n",
    "\n",
    "group_sorted = {}\n",
    "group_sorted [\"group\"] = {}\n",
    "temp_group = sorted(group2['group'].items(), key= lambda kv:kv[1][0]['startTime'], reverse=False)\n",
    "for g in temp_group:\n",
    "    group_sorted[\"group\"][g[0]] = g[1]\n",
    "\n",
    "group2 = group_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "9\n",
      "8\n",
      "6\n",
      "7\n",
      "3\n",
      "10\n",
      "0\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for g in group2['group'].keys():\n",
    "    if len(group2['group'][g])>1:\n",
    "        print (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:20:50  to  -21 days, 0:21:22 \n",
      "\n",
      "\n",
      "Let's say we even do this. Is there a like a test case of something that we can build to validate the performance or say consistently. This is based on this these test cases. This is better than the what we have right now. Yes. If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.  \n",
      "\n",
      "Yeah, we have the test set. Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we're developing currently what all the tested all the tests meetings that we have our segment Centre, right? So then we started to gather this, you know, this body called community-centric tests that we have. Going to build so there is also parallel going on. So any validation would happen on that. W?  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:22:00  to  -21 days, 0:23:13 \n",
      "\n",
      "\n",
      "And yeah on the action items, I just spoke to pressure on top Christian. So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. Whereas I think we fairly have good. The trans at least whatever it detects would be highly confident and can be reliable. So I'm a little aggressive there just to be sure that we are getting good sleep. And so I think we can enable that for The Ether engineering Channel.  \n",
      "\n",
      "So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. Yeah.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:23:40  to  -21 days, 0:23:54 \n",
      "\n",
      "\n",
      "But the bim's did look, okay, like if you look at the films as opposed to the chapters, yeah, there's not necessarily bad. It's actually pretty decent terms if this is a detective, yeah.  \n",
      "\n",
      "We'll find out but that's also we have seen we have seen few noises segments. That's why God or whether you are in an open. Mike. Well, you're on the actual headphones are on the open window the own societies that a call and iOS and you just get the  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:25:39  to  -21 days, 0:27:13 \n",
      "\n",
      "\n",
      "Yeah, because eventually that's what we see, right? Yeah, if the community is good and I like like they have enough content. I think whatever we see for the pins would reflect their so let's go God. Yeah.  \n",
      "\n",
      "Yeah, so yeah, pretty much those were the things those are the things that I'm working on. So like converting. So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I'm going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. How's it going? What is the approach and what it requires as input? And the other thing is I'll make the changes for the community-based summary. So we had this question that you're going to get you that list of groups and with analyzed take all right.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:29:42  to  -21 days, 0:30:34 \n",
      "\n",
      "\n",
      "So in before post-processing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. So where there was like sea and Earth has capitals and small and everything. So Google those got filtered but these who still came up. So so something like some fun videos that I'm checking on me like an ideal way to remove.  \n",
      "\n",
      "So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. So basically, I mean since there was no Stables, you're not maintaining any tables for actions. No, it's taking some time. So by end of day today, I'll end up dating curtain on my status.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:31:19  to  -21 days, 0:31:42 \n",
      "\n",
      "\n",
      "Yogurt for somebody new the new community-based summary, right? So I have mode all the analysis code from transcription service. It's a new service analysis service and even the schema thing. So the changes are there like it still yet to be tested or that it was.  \n",
      "\n",
      "So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. So slick if it is a segment strategy will go with volt annulment analyzer. Otherwise, we'll go with their Community segment analyzer the the that's all like and also the summary we also moved to a different schema all those push the code now Cody's first time ever.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:32:51  to  -21 days, 0:33:25 \n",
      "\n",
      "\n",
      "Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.  \n",
      "\n",
      "So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. So currently I'm working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it's done, I'll deploy it on stage in two.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:34:26  to  -21 days, 0:36:53 \n",
      "\n",
      "\n",
      "Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.  \n",
      "\n",
      "I just staggered a bit or for adding that bug snack logs the issues. I was with me yesterday. What recent call was Capcom was kept on loading right spinning. So once the build is done, we'll just test it again and then a sinking I haven't yet started on the localization task. Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:40:16  to  -21 days, 0:41:01 \n",
      "\n",
      "\n",
      "So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. So let me see what I can find. I'll just add all the information to document whatever I find a husband.  \n",
      "\n",
      "My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. So I'm just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. Just need to see even even with the believability cave might need to associate one workspace to 1 inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. Okay.  \n",
      "\n",
      "\n",
      "\n",
      " Chapter Discussion:   -21 days, 0:41:44  to  -21 days, 0:43:11 \n",
      "\n",
      "\n",
      "The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. So we need to spend a little bit more time on that. So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. I can also look into upgrading that JavaScript.  \n",
      "\n",
      "Yeah, so sorry said like let's find out on this room thing. Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so We're just gonna put this way.  \n",
      "\n",
      "A lot of losing out on the data because now through God we cannot even capture history as its history. So at least we should start getting data as my concern you can in a soil to check but that's why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "from backports.datetime_fromisoformat import MonkeyPatch\n",
    "MonkeyPatch.patch_fromisoformat()\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True) #eng_19\n",
    "#m_time = formatTime(\"2019-09-20T07:12:00Z\", True) #eng_front_end_20\n",
    "#m_time = formatTime(\"2019-09-24T06:11:00Z\", True) #eng_24\n",
    "#m_time = formatTime(\"2019-10-04T05:44:00Z\", True)  #podcast_04\n",
    "#m_time = formatTime(\"2019-10-08T11:55:00Z\", True)  #podcast_08\n",
    "#m_time = formatTime(\"2019-10-14T06:04:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "#m_time = formatTime(\"2019-11-26T09:03:00Z\", True)  # set_1\n",
    "#m_time = formatTime(\"2019-11-21T06:30:00Z\", True) # sync_11_21\n",
    "#m_time = formatTime(\"2019-11-25T09:35:00Z\", True) # sync_11_25_ml\n",
    "m_time = formatTime(\"2019-11-26T06:15:00Z\", True) # sync_11_26\n",
    "for i in group2['group'].keys():\n",
    "    if len(group2['group'][i])!=1:\n",
    "        print (\"\\n\\n Chapter Discussion:  \", formatTime(group2['group'][i][0]['startTime'], True) - m_time, \" to \", formatTime(group2['group'][i][-1]['startTime'], True) - m_time, \"\\n\\n\")\n",
    "        for seg in group2['group'][i]:\n",
    "            #print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "            print (seg['originalText'],\"\\n\")\n",
    "    \n",
    "#     elif len(group['group'][i])==1:\n",
    "#         print (\"\\n\\n Chapter Discussion:  \", formatTime(group['group'][i][0]['startTime'], True) - m_time , \"\\n\\n\")\n",
    "#         for seg in group['group'][i]:\n",
    "#             #print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "#             print (seg['originalText'],\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Id:  4\n",
      "Karthik Muralidharan, Venkata Dikshit Discussed \n",
      "\n",
      " Text:  Let's say we even do this. Is there a like a test case of something that we can build to validate the performance or say consistently. This is based on this these test cases. This is better than the what we have right now. Yes. If you give you a set of tests we take the same meeting transcripts again, and it is funded through a processor that compares different help.  Yeah, we have the test set. Actually we can we can we will continue to increase the number of you know test calls our test a transcripts that we have and that is also driven by the algorithm or the first is that we're developing currently what all the tested all the tests meetings that we have our segment Centre, right? So then we started to gather this, you know, this body called community-centric tests that we have. Going to build so there is also parallel going on. So any validation would happen on that. W?  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  9\n",
      "Venkata Dikshit, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  And yeah on the action items, I just spoke to pressure on top Christian. So he said he has got something to update on his side one studies in if we if we enable the if we enable it for ether engineering Channel, I think it will be easy for us to take feedback and then and then improve on top of it and I unlock one for the on the quality. Whereas I think we fairly have good. The trans at least whatever it detects would be highly confident and can be reliable. So I'm a little aggressive there just to be sure that we are getting good sleep. And so I think we can enable that for The Ether engineering Channel.  So maybe once he fixes that eyeshadow from the meeting ID for which the this thing we have if you want to fix it, maybe let him run it against the same system and see what food is. Yeah.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  8\n",
      "Karthik Muralidharan, Venkata Dikshit Discussed \n",
      "\n",
      " Text:  But the bim's did look, okay, like if you look at the films as opposed to the chapters, yeah, there's not necessarily bad. It's actually pretty decent terms if this is a detective, yeah.  We'll find out but that's also we have seen we have seen few noises segments. That's why God or whether you are in an open. Mike. Well, you're on the actual headphones are on the open window the own societies that a call and iOS and you just get the  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  6\n",
      "Venkata Dikshit, Shashank Discussed \n",
      "\n",
      " Text:  Yeah, because eventually that's what we see, right? Yeah, if the community is good and I like like they have enough content. I think whatever we see for the pins would reflect their so let's go God. Yeah.  Yeah, so yeah, pretty much those were the things those are the things that I'm working on. So like converting. So removing this network X in the middle and having everything I need for meeting level and topics markers everything and and yeah, so so I'm going to continue working on that and so I will create a new issue where I will put the specs for the rick wanted watches and related meetings. How's it going? What is the approach and what it requires as input? And the other thing is I'll make the changes for the community-based summary. So we had this question that you're going to get you that list of groups and with analyzed take all right.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  7\n",
      "Shashank, Trishanth Diwate Discussed \n",
      "\n",
      " Text:  So in before post-processing like in the original list that it got it had two more slack Channel slack and slack Channel keywords. So where there was like sea and Earth has capitals and small and everything. So Google those got filtered but these who still came up. So so something like some fun videos that I'm checking on me like an ideal way to remove.  So our interest you to be comments in my beard so I can be can merge this change and then I started looking on this service implementation of this. So basically, I mean since there was no Stables, you're not maintaining any tables for actions. No, it's taking some time. So by end of day today, I'll end up dating curtain on my status.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  3\n",
      "Mithun Discussed \n",
      "\n",
      " Text:  Yogurt for somebody new the new community-based summary, right? So I have mode all the analysis code from transcription service. It's a new service analysis service and even the schema thing. So the changes are there like it still yet to be tested or that it was.  So now the logical summary services like aggregator as you expand the right so it calls the analysis are with to start analyzed based on the analyzer. So slick if it is a segment strategy will go with volt annulment analyzer. Otherwise, we'll go with their Community segment analyzer the the that's all like and also the summary we also moved to a different schema all those push the code now Cody's first time ever.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  10\n",
      "Mithun, Parshwa Nemi Jain Discussed \n",
      "\n",
      " Text:  Sign stating so once he is done, I will just we can do a new PR or whatever if it if we are delayed with the pr we can address that issue.  So like I have completed the basic integration plus the participant list and have completed active speaker part, but need to test it out. So currently I'm working on the recorder and so like I think I should be able to complete it in couple of hours and Then once it's done, I'll deploy it on stage in two.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  0\n",
      "Karthik Muralidharan, Nisha Yadav Discussed \n",
      "\n",
      " Text:  Why did you want to go ahead with the oh by the way past my have made the changes for box Eden staging in jail.  I just staggered a bit or for adding that bug snack logs the issues. I was with me yesterday. What recent call was Capcom was kept on loading right spinning. So once the build is done, we'll just test it again and then a sinking I haven't yet started on the localization task. Just thinking maybe I can put refactor on hold for some time and then either start localization or take a pig roasting GitHub issues regarding the time taken from splash screen to the mesh will pay, you know,  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  5\n",
      "Vamshi Krishna Discussed \n",
      "\n",
      " Text:  So I will focus on getting showed it and sort of how the zoom option works and other things we need to look at to the tokens also because the tokens are expiring though considering the cooperate. So let me see what I can find. I'll just add all the information to document whatever I find a husband.  My birthday Carrie how they are we how we are not sure if you are going to be use the web SDK or not. So I'm just want to find out all the details and then we can proceed we can because we have clear understanding how to disable Decay passwords. Just need to see even even with the believability cave might need to associate one workspace to 1 inch and when Zoom account so still need to do this, this is something that we are in we have to do account to slack, you know some Association. Okay.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Group Id:  2\n",
      "Vamshi Krishna, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  The best Decay is something like with the weather latest Rebels because we need to rework on our client because just by upgrading the JS library is not working. So we need to spend a little bit more time on that. So I once Parsha finishes on walks it we can you can you can directly find every after like once this is free. I can also look into upgrading that JavaScript.  Yeah, so sorry said like let's find out on this room thing. Once we are clear and we are we are clear about if you need more permissions with respect to Z more any other fruit implementations will just park it and if you need anything any new changes will Loot and they submit later because we are finding new things as we are implementing new things, right, so We're just gonna put this way.  A lot of losing out on the data because now through God we cannot even capture history as its history. So at least we should start getting data as my concern you can in a soil to check but that's why I mean more main concern actually with this one because we realize that we are not able to use the body butter going to capture Channel History right anymore.  \n",
      "\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id_map = {}\n",
    "user_id_map = {\"8fff81b5b2f14aa5ad67405f3e8127f3\":\"Sai\",\"70caa6269d8e4869a45f7ea91ade3472\":\"Ether\",\"3e1a008f734448b0ad9190778449af81\":\"Deep\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep\",\"716067a60a1a4034abc49a12ecafb39b\":\"Cullen\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Cullen\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group2['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group2['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    if len(seg_list) == 1 :\n",
    "        continue\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for g in group['group'].keys():\n",
    "    if len(group['group'][g])>1:\n",
    "        print (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  Nautical elements and behavior then we are taking of installation at ID is equal to 10. That means same as insulation status not in sir.  I'm starting bar token as same value.  If it was not in not installed State then we go inside and check if it is deleted. We still set the port access token. if it is not deleted that means there's only one set remaining which is  Hey use, the same installation access code.  And if we was all not already installed, it was never installed before then. We said customer ID to installation of customer idea, but the problem is because in else case if it is not installed customized still be empty.  Let's not find putting it in an SQL. So I took it out. I said customer identical do insulation or customer rating because it's the same thing either ways.  One of the cases it will still be empty.  Okay, in one case it will be empty because if there is no installation at all, not even one day so that time it will be empty.  Else it will not reduce insulation. So it is same as either being empty or an example. So for this put it out.  So this function I broke it down to check. Okay, if that you're using what access token and do cases that means the state is not okay, what access token with setting only one is installation is when it's not installed or it  so the more some state is not installed on the extent that  I'm still thinking that what if he has not provided board token.  Instant cash rate. I don't know how we ended it.  So this L scale bar token insulation access token, which is not needed because it's insulation is already present. That means insulation is valid object then it is already present in the right place, but I don't have the set is condition. Right the bot CTX set access token uses the installation objects exist open field only.  Ruby where are we going getting access token every time? No, right. No for even if the installation exist.  That part that's why I check so we're not actually building users are upsetting users actually are not present.  Reading user roles for customer ID getting the usual for customers and we generating an outspoken and responding. These are the common things creating user cetera. The only thing is if the admins folks are not present.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  This is the same as a customer or customer of the customer ID integration it is okay. So we create an installation object. here with the  This is pertaining so Bart is not being used certainly.  What are you see is that that use case ready for installation is deleted and user is doing a normal login, right? I think it still crashes. I see I think once she added that extra length blind for betokened, right? You're you're trying to get user input. Can you go to that place like authorized or to go authenticate method?  Yeah.  Yeah, she can taste it out.  No, not this one after you're setting that bot access token, right?  board context  You're doing that. Yeah, after that you call user that user info this. This line that get user info was updated like recently after some time like after my changes from she added that change.  Somebody at this you scream and then I don't know. Check for cops is a right. That's not install is there but where are we doing this check for sports?  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Mithun, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  They were once again on the one thing. I'm really see Nick for example user remote installation. And then this trying to do a normal login make a joint link.  Yeah, that's it will go into exception here.  it's only when  Was installation is removed here. We are setting a empty access to condemn.  only setting this when the state is not installed or  We are removed as in the sense like installation was deleted. Right like if app is removed. We say installation don't deleted is true. Correct.  At which point the token is also invited.  But bought access token is something which he has authorized right? Like if he has not authorized for the required things will not get the bot token then.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  It's not technical schools. Check for Scopes validate Scopes mayor because of our Expose and we say users groups guarded over at Muskoka granted.  If install state is not installed. And he has not granted admin Scopes. We are saying ether Meet app not installed.  And then we this is relatively still.  Environment scope is granted.  And uses for planted false reading if you use a scope insufficients hopes authorized by users.  also farted scopes  Not granted and not install them is not installed either with uninstall your dough into case. We are into doing it. Yeah, and as well as this court has struck the right. Yeah. Okay then thing.  this is  Is there I wonder if we should have just checked?  validates Cooks  before violets quotes Oh, yeah, we want to check if they have currently provided insulation level Scopes. That's why we did not return only thing if it is not installed.  We know that well risk of before that before installation process.  The moment I call get instruction set. I used to call that are valued cook same same way. This should be fine.  If it is, so you're saying that we should we check if installation CD is equal to not. Install or remove and admin scope is not granted directly nature.  We are doing inside that validates group it all those things. We are returning an error rate. That is what check for scopes.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  So I just use that but direct message may I won't get it. So I'm using that. I know that's about direct messages, but I'm just adding that they're just so that it doesn't break in the future, but  Act was the  Remember some conversation.  This one when their friends effect and is remember this is the slacks negatives informational Channel contains everything about everything that is present in good conditions whether this is a channel is General remember? So I'm using this determines with the access token that was used to make the call because I'm passing the Bots access token here. It is.  always remember there  You guys since I was I think I can just print it out.  Have you known for this Direct?  markers  I mean, I'm public-private direct privacy thing.  Gifted if you can get rid of additional emails.  So that is what slack is using. Is it 0 1 2 Legacy time?  Now we are mapping actually.  So entertaining get Roman for your mercy.  Yeah.  Community Channel not  Okay.  this is  Yeah is the public channel for directors? That is?  Well, they have holes there is private.  See ya. That's like there have a flag in bullsháá.  They also have a thing that detectives on like the start position if it is G or if it's CEO, isn't that so we should probably just have a more clear.  Yeah, okay. Let me let our add more locks Inferno.  Also, there's one thing I just want to take the authorized we were.  And get installation from her room or something. I remove that matter because the part on the base contacts already do the same thing.  I'll take that beer its newly updated is it?  Yeah, I'm gonna need last night. So I build the bar context here, which was integration team ID same same parameters a depositor and I create a board level context. Okay, and they're very appalling get installation for room 14.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  My horse barn validator, right? So added / the man. Okay. I create a bar context. Okay. It's sort of with the base context that means case workspace in.  Yeah, it's other perpendicular.  Then after validating it doesn't give an error.  points working for book meeting. Okay, but doesn't seem to have for summarize. I'll check actually, maybe some book for me like validate for room right - okay, I take it customer not active then. I'm gonna defend myself.  What is the error this year for the user? It's not a summarizing or qualifications?  It's there is not. So it should be a validation error flag. You should say if I'm inviting if I don't invite about and I do / come on any command besides hell. I should see the void. Like I need to run all the basic validation that the bottle of you know, you're not doing something the DL.  The only for summarized it is skipping Z.  No, I think it's happening for meeting. Also, I think it's the pit Isabel. I need so the bar context is the bot is present in the serum. This is sort of either returning his suffering.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "Karthik Muralidharan, Mithun Discussed \n",
      "\n",
      " Text:  Correct. So basically we were coupling in book validate meeting check for presence all the checks that we do right now at command level and whether the provider is supported or not. But so I had to separate that valet create it meeting to remove all the prior checks ready check if the comet is present Etc. Like what happened in the room Etc. And move it to higher level like to bot contacts. So yeah slacks.  The meeting we just called by the API.  Again, will the base context and I check valid for whom?  Yes, I think this is the thing.  It is very far from Texas.  He'll test it out and fight. Yes.  For The Ether castrate I have almost similar same files getting changed.  Somebody asked for my birthday. Let's see.  audience  I think yeah, it's just you know.  They once you tested you just let me know then we can then I can rebase or whatever it is. Yeah mind. There are.  Here's our love Geneva III. This is getting hard so our time because I have lot of small small commits that I have built up.  What happens is when I rebates it goes supplies on top of every commit and have the kids.  I just take the current development mode it to my Visa bans because all the comments in one shot and then merge it back to dollar.  You do get it much. Okay, okay.  So I had the problem I think last time also because I generally keep small small combats with more descriptive anymore what's changing but I have a lot of comment generally in a feature Branch. So when I went everywhere be in a very committed I'm getting rebates or acts like conflicts. Correct? Pretty much resolve all the commit history in my teacher, but who did much develop that means from a feature branch? I was at the other Branch into my feature Branch resolve the conflicts in one shot and then  one more coming  As a magic away, that's the most common and then feature branch is resolved. So then the dimension we March back.  A lot of people say it's better because you don't know destructive editing. That means you're not changing the commit history because of rebase and just try to avoid the next recommend impossible. That's one of the better side.  But at some point you can still do it gets crash, right?  We can squash the question is do squash after the reviewer before the so for me I prefer to people to see like small small keep committing incrementally. So people see the changes so I don't squash before.  Better you must because a lot of code changes exact similar file similar lines.  reading in the museum  Yeah, yeah - inter-korea have to commit symbol.  And also like it'll help you because I'm screwing some of the checks and validation if you need it. Anyways, neither.  I understand that. Barbara Nation I do with all entry points and disaster man and the book meeting. We're headed for a wherever board level validation is required because you can go lower already clicked a civilization bottle variation. We need to do meeting you can do beating neural. We can follow the same we can end up following the same patterns, okay.  \n",
      "\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id_map = {}\n",
    "user_id_map = {\"3e1a008f734448b0ad9190778449af81\":\"Deep\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep\",\"716067a60a1a4034abc49a12ecafb39b\":\"Cullen\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Cullen\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "#     if len(seg_list) == 1 :\n",
    "#         continue\n",
    "    #print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T12:10:08.092248Z",
     "start_time": "2019-10-16T12:09:56.539286Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "user_id_map = {\"716067a60a1a4034abc49a12ecafb39b\":\"Ether\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"ether\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_result = {}\n",
    "pim_response = {}\n",
    "pim_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\"}\n",
    "pim_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\", \"segments\": []}\n",
    "temp = \"\"\n",
    "temp_users = []\n",
    "for groupid in group['group'].keys():\n",
    "    temp = \"\"\n",
    "    temp_users = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        temp+=segi[\"originalText\"]\n",
    "        temp_users.append(segi[\"spokenBy\"])\n",
    "    pim_response[\"segments\"].append({\"id\":\"abc\",\"originalText\":temp,\"spokenBy\":temp_users})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_pims_score({\"body\":pim_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pim = json.loads(result)['d2vResult']\n",
    "pim = sorted(pim, key=lambda kv:kv[\"distance\"], reverse=False)\n",
    "for seg in pim:\n",
    "    print ( \" , \".join(list(set(user_id_map[i] for i in seg[\"speaker\"]))), \" discussed: \\n\", seg[\"text\"], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "with open(\"para_graph\", \"rb\") as f:\n",
    "    nodes, edges, graph_list = pickle.load(f)  \n",
    "G = nx.Graph()  \n",
    "G.add_nodes_from(nodes)  \n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      " [[[\"It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences? \"], '2019-11-25T10:00:03Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4b071181e837421397b43105aab313bd'], [[\"From my test. I thought we could use the refresh similarity as a start where the key phrase is given as it is as it takes feature, not the sentence. It's a part of \"], '2019-11-25T10:00:31Z', '81a3e15469374fceba1cf972faa209b2', 'e87dde57d82c4d4b95fe801494025a55']] \n",
      "\n",
      "\n",
      "1 \n",
      "\n",
      " [[[\"So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at. \"], '2019-11-25T09:41:09Z', '81a3e15469374fceba1cf972faa209b2', '788c2d15650749c68f8108aca0a5500e']] \n",
      "\n",
      "\n",
      "2 \n",
      "\n",
      " [[[\"We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine. \"], '2019-11-25T10:21:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '37365403bd9b40f5bd9d212b9959c205'], [[\"Okay, got it. At least we'll start populating then we'll think of where to use the event unless the mind or something. Yeah. Got it. \"], '2019-11-25T10:21:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4b5d8559bb82405dba16aeaec45f4a5a']] \n",
      "\n",
      "\n",
      "3 \n",
      "\n",
      " [[[\"From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise. \"], '2019-11-25T09:48:29Z', '81a3e15469374fceba1cf972faa209b2', '12b5618f1c764d1f8150cad42776aaab'], [['If there is an entity with only two sentences, there is there is there is there is a very good chance that this most similar entities would have got 200 sentences. It has no relation. '], '2019-11-25T09:49:05Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '17d06e1f3aeb4884a05949fed71cc21e'], [[\"Yep. Okay, that is good. So that is interesting. Yeah. So the basic thing is if suppose you encounter an entity in a sentence if the sentence has more than one new entity in a then you are essentially comparing the same sentence for both entities like yeah, hence it is bad. So I thought in that case continued use the query has like a combination of both as in cosine similarity of the entity as it is. Plus like the center said it's a part of in case of similar entity. That's what I'm saying. \"], '2019-11-25T09:49:39Z', '81a3e15469374fceba1cf972faa209b2', 'dac2f5245bfd42ac8bc013b9b6baf80a'], [['Okay now coming back to what what SRI was pointing about comparing two sentences. He says that they are there douche must be related. Like like if entities it has improved it should also improve on the gel in a totally unrelated sentences. '], '2019-11-25T09:50:39Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '53bc47e0a23746b483ea34e13056486c']] \n",
      "\n",
      "\n",
      "4 \n",
      "\n",
      " [[[\"That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say. \"], '2019-11-25T09:50:56Z', '81a3e15469374fceba1cf972faa209b2', '9dd38ee0a73048d68ffe58f362afdfe8'], [['But with so when we are doing all these aggregation of sentences, right? So that means that all these entities features get either added up or get zoomed in while other public testing these kind of phrases or words get Lift Away. '], '2019-11-25T09:51:42Z', 'fb52cb663aec4795aee38ccfd904d315', 'e0fa078a2e384cbfaec422f71fb7c15f'], [[\"So instead of aggregating is it possible to select particular set of features for us, which is dominating. For that sentence like instead of like if you create a new sentence, which has a new NPP somehow we should be able to reproduce it as if it is already present in the hole if it already doesn't like in 10 to 20 sentences. \"], '2019-11-25T09:52:15Z', 'fb52cb663aec4795aee38ccfd904d315', '8642dfd5703c4bb2a3807eaa5be3538b']] \n",
      "\n",
      "\n",
      "5 \n",
      "\n",
      " [[['We need to do similarity measure. Now. The problem is when I checked on the staging to data the drawer there were 29 users with key phrases and are they around five or six of them had at least 1200 key phrases as '], '2019-11-25T10:32:22Z', '7e7ccbba232d411aa95ad3f244a35f40', 'e7306ec37a2e4b91988e3de98feddc66'], [[\"So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but \"], '2019-11-25T10:32:41Z', '7e7ccbba232d411aa95ad3f244a35f40', 'd3791a390d6640e5afbc53a238d2e462'], [['So the search engine so Jen comparison parties working finals faster than just cosine work dries cosine similarity. Okay, the result is not conclusive because of skewed is to data. Yeah. '], '2019-11-25T10:33:36Z', '7e7ccbba232d411aa95ad3f244a35f40', 'f6c40b6541f5406f8ee8c2f6ec6a990a']] \n",
      "\n",
      "\n",
      "6 \n",
      "\n",
      " [[['but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because '], '2019-11-25T09:56:39Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '8241d1ad10a34bee9a55de2f95f6e722'], [[\"That is different. But let's assume that for two entities effect. If you can rank the features, but you cannot subset the pages as soon as the subset the features out of 768 you lose the ability to compare because you will always compare you have to compare against those feature in this. He's not others. \"], '2019-11-25T09:56:51Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'dd0bd835048c42a68568e3a19bef9445']] \n",
      "\n",
      "\n",
      "7 \n",
      "\n",
      " [[['Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah. '], '2019-11-25T10:19:15Z', 'fb52cb663aec4795aee38ccfd904d315', '143c3ac9f3d44becbef3abb4ce4c3682'], [[\"Under the separation keep to keep it simple. It could be separate. If you want to you want to be optimal about the computation. Then we have to think of the right spot in the key phrases section service on where it should be happening because rest of the pre or post processing things are very negligible here because their sentence level in you're just aggregating dictionary of something and then they are not ankle. They are not bottleneck tasks. \"], '2019-11-25T10:19:57Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'b158a51386e244b383bb389e3035cf2f'], [['You want to optimize competition one one thing we can do is keep her service when it calls entity and it gets entities in the key phrase service can position our stop it. And so this this entity graph service will be listening to that topic and so it will basically get segment and entities it is no call for that. '], '2019-11-25T10:20:29Z', '7e7ccbba232d411aa95ad3f244a35f40', 'dcc373952c7e42c8b97cbba3c6cdea31']] \n",
      "\n",
      "\n",
      "8 \n",
      "\n",
      " [[[\"But I'm which one are you trying to address the the models ability to learn A/C and heater or your you to test that you're using the entity similarity as a repository task? \"], '2019-11-25T09:42:26Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ee57b27ce92749cca5e47445ea436ade'], [[\"I'm choosing the latter. Actually. I'm testing testing both models using this entity to similarity because that's something that came up recently as a requirement for the moderate. So trying to use that as a test to see whether okay, you know, the engineering model is able to capture so \"], '2019-11-25T09:42:43Z', '81a3e15469374fceba1cf972faa209b2', '4fa3c94fd14d43d9a96aac1ccbbd9e9f']] \n",
      "\n",
      "\n",
      "9 \n",
      "\n",
      " [[[\"So what I was trying to say is like you have a hundred sentences of 1800 sentences, you know that there are some particular entities for example, like Docker which is kept on beating in all the hundred sentences. So now we take the aggregated feature Vector for this entity. Yes, not all these sentences right now. If you get a new entity something called as an eternal then we don't have some repeated understand sentences where the heat is being presented. So, but if we are able to find the dominating feature vector Our official of features which would be equal to using that same word ether in hundreds and Cancers. Okay. \"], '2019-11-25T09:53:39Z', 'fb52cb663aec4795aee38ccfd904d315', '915cc438c5c34776b68061f30d5042e3'], [[\"You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context. \"], '2019-11-25T09:54:21Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '33c7f1545803448db80588e9f6cacb16'], [['For something like entity called his dog when you take all its sentences by Rocker is being present in then if you take an aggregator feature Vector of all the sentences, then there will be set of features which would be dominating all these sentences in digits, right? '], '2019-11-25T09:55:31Z', 'fb52cb663aec4795aee38ccfd904d315', 'a095de9c1ebe414095d68df183abcb00'], [[\"That's what I'm going to do it. So if we can find a subset assume that it is been pointing to some kind of a common pattern in all those in multiple cases then instead of trying to find a hundred sentences sentences for particular intervening. We can take the pattern of subsets for one single sentence itself. \"], '2019-11-25T09:56:05Z', 'fb52cb663aec4795aee38ccfd904d315', '371361b3cb1c492bb4875115a75cbdae']] \n",
      "\n",
      "\n",
      "10 \n",
      "\n",
      " [[[\"Identity similarity if you're talking about literal entity similarity, which means the string of the entity. I'm not sure if that's the right right way to answer your question. But if you don't know what the sentence well, maybe yes, I mean that the in DC Community feature is nothing but the aggregation of all the sentences that we that it is part of \"], '2019-11-25T09:45:07Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '83363541221b47f88122467066eddc5a'], [['Yeah, sorry. Anyway, I think both of these tests. So one was a literal string comparison of entities as well as the aggregated sentences. So while comparing these two methods are found that the aggregated sentences work better because JP has a tendency to select more similar words that start with the same letter. So ether it will sort of pick all tokens that are there in its reputation that start Withey similarly for Docker and stuff, yeah '], '2019-11-25T09:45:44Z', '81a3e15469374fceba1cf972faa209b2', '04daee2ad57442779efef38f292f1a3d'], [[\"Because when it's up when it updates a language model, it updates on a token level not on a word level. So see ya. So if you get Docker you'll get the and cker. Yeah, so it will also pick words that have Bo in it like the okay. I will be very similar to talker. \"], '2019-11-25T09:46:28Z', '81a3e15469374fceba1cf972faa209b2', '1bad0e3ca1b44441a4f1e2f832f2ce17']] \n",
      "\n",
      "\n",
      "11 \n",
      "\n",
      " [[['And like butter salt collecting false negative and I thought that was able to find out and I end I end users. '], '2019-11-25T10:40:40Z', '7e7ccbba232d411aa95ad3f244a35f40', '61e9df1dd0854370a7b4a877f505cfbd'], [[\"No, actually we thought you you're going to find out some test calls tested data set up for the web to validate this right? \"], '2019-11-25T10:40:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ab91bd38db874a32ace7338698f796f8']] \n",
      "\n",
      "\n",
      "12 \n",
      "\n",
      " [[[\"Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not. \"], '2019-11-25T10:27:26Z', 'fb52cb663aec4795aee38ccfd904d315', 'cdb0de417eff4855a54961d71a54c8eb'], [[\"Nothing specific. So that the main reason was we were initially having some either because all the plumbing right now is only is three days away. We just copy some mindset or model side and push it there. Yeah, so it's easy to lose track of where we are copying or pasting it. So and it's not like a staging to environment directly push to production it still copy-pasting substrates, including multiple testing to production. So even there some problem might occur. So I just wanted to make sure that every time you push in just six with some basic validation scheme whether people to the right path. \"], '2019-11-25T10:28:03Z', 'fb52cb663aec4795aee38ccfd904d315', 'fd763bdc144e4b999add674996ac6a90'], [['So for example, like if you push some ice in mind or SE model to production and then what it does is like because there is a new push to the GitHub. Then it would automatically have a gift of fashion which could trigger a script which would internally call Lambda. So with this land ourselves would get requests. Like what was what was the kind of the model or particular term starting from servers? We get some wine service been what model online that it needs to chill. And then it would pull the model of mine from bs3 then have some validations from behind planet and then push back to school. '], '2019-11-25T10:28:54Z', 'fb52cb663aec4795aee38ccfd904d315', 'd62e80a00c1945e7aad8fa6ee4135f6b']] \n",
      "\n",
      "\n",
      "13 \n",
      "\n",
      " [[[\"So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of \"], '2019-11-25T10:11:41Z', '7e7ccbba232d411aa95ad3f244a35f40', '51e910ab50b142e2b6928f67fdc6feb9'], [['Yeah, if it is, like for mind representation of any kind of thing, then we should be capturing all this information so later it is up to us. We can control which which one we want to keep it or remove but it is better if we think from now self what all things we might use it for and capture all of them. '], '2019-11-25T10:12:17Z', '7e7ccbba232d411aa95ad3f244a35f40', '3b13daf16b7c4fe4be27f1192cc93d22'], [[\"I thought of it but I was which means all you're trying to say is you capture all the key phrases and everything. \"], '2019-11-25T10:12:36Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '3b30d499e6ec45a4a82e109b03673cba']] \n",
      "\n",
      "\n",
      "14 \n",
      "\n",
      " [[[\"Try hittin it is just to be sure. I mean, I just he's done it again plus saying happened with that Curative on all sides. I didn't get the entities earlier, but now I got I don't know it just to look at it. \"], '2019-11-25T10:25:42Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'c7635ea2677644a9aba36de8f2013d7d'], [[\"And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it. \"], '2019-11-25T10:26:11Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '565a4f54dab447538e082aba37f1f4a6']] \n",
      "\n",
      "\n",
      "15 \n",
      "\n",
      " [[[\"You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris. \"], '2019-11-25T10:04:57Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '21a7f9b470984a59b7c15cd0bcee15c5'], [[\"Now if you are actually building the stick to God because that's like let's assume that they have done enough experiments on that and then came up with the specialty right so that way you can be alive. \"], '2019-11-25T10:05:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '57b5b9323a234d4295527c1458712462'], [[\"Yeah, that's what so if that is if that model is performing way better than what we have right now. It's respect to sentencing levity. So it means that the entity should be given very much high priority over others in a particular sentence. Yeah. \"], '2019-11-25T10:06:02Z', 'fb52cb663aec4795aee38ccfd904d315', '874ae1201d3545278f3e72ae3241e594']] \n",
      "\n",
      "\n",
      "16 \n",
      "\n",
      " [[[\"So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works. \"], '2019-11-25T10:31:08Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '1923ad595df44b51a2531505dd6f8875'], [[\"Yeah, so now right now I'm not advocating any feature vectors or anything. So the way I'm testing it right now is so say in summary we get a highlight right so that the set of keywords in those in that highlight will be the query will be against which we want to check what other similar works. And the complete list of similar words comes from the D graph query for all the users. \"], '2019-11-25T10:31:35Z', '7e7ccbba232d411aa95ad3f244a35f40', '0d97e07156084295b6eecd4e48df048f'], [['so now what happens is and then so if we have each other because for this highlight key words and then we get features actors for all the keywords of the users. '], '2019-11-25T10:32:09Z', '7e7ccbba232d411aa95ad3f244a35f40', '75242d46cda744ac98f6af191c7cccec']] \n",
      "\n",
      "\n",
      "17 \n",
      "\n",
      " [[[\"I've got that gets populated during which service should be accurately or should the platform. Victor should the platforms then the segment to this Louis has feel like every other service. \"], '2019-11-25T10:16:49Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '6683397b55324b53bc6e3b0c55f96440'], [['We can have it as Lambda but like right now the easiest one would be to have it but to have it communicate with Nets but and but if we can because the performers so called that it is not a big thing to write a proxy for night service so you can write it so they can Implement that so we can have it as a Lambda and it can listen to this Nats topics and do everything normally the egg. '], '2019-11-25T10:17:33Z', '7e7ccbba232d411aa95ad3f244a35f40', '419786a5c6b54ef08e58a1de798e4973'], [[\"Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated. \"], '2019-11-25T10:18:02Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '6668dd8ef4b144488f3f31795677fda8'], [['So how different is it for the O of the Lambda to be waiting for that? And then as soon as it gets the segment it just it just extracts the key phrase the entities and then populate the graph and then and then we there am I missing something. '], '2019-11-25T10:18:23Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'c0199c99d7f94654b332c536b5203049']] \n",
      "\n",
      "\n",
      "18 \n",
      "\n",
      " [[['No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service. '], '2019-11-25T10:14:40Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '08fae38348474eab9fd4ab66703f544f'], [[\"Okay. Cool. Okay. Yeah, so maybe if we if we if you do that the immediate thing would be like what we were discussing this morning right for the the known domains or under man's lips will just only will attach all the current Minds at least in the current state to to this entity graphs. \"], '2019-11-25T10:15:12Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '2bc3e2aa5f204e33984d887046529592']] \n",
      "\n",
      "\n",
      "19 \n",
      "\n",
      " [[['Even if we capture just send text and entities even that should be fine if you just like a backfill. '], '2019-11-25T10:12:46Z', '7e7ccbba232d411aa95ad3f244a35f40', '7b171151aabc41f58a266a16716b6dbb'], [['Yeah, yeah. Yeah we can do back we can do the back self apart as fit as we start thinking because currently what is established is only the entity features. '], '2019-11-25T10:12:53Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a493037c4fbd4492b77db851e2be6df8']] \n",
      "\n",
      "\n",
      "20 \n",
      "\n",
      " [[[\"yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone. \"], '2019-11-25T09:37:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '499e809ad0354b02a00b399b1225f0e8'], [[\"Fine actually, so we are discussing this morning about how to go about filtration. That means we're trying to find out if they're to two places to optimize that action items. Right one is the model L2 at the post processing level. So the model we are just using the 50% conference threshold. I think that's fine for now the biggest One potential Improvement is that even your back? Right? So one potential Improvement is to find out the leakage is where in you you have you have confidence for a an action item? But it just got just got out because there is now there is the subject isn't really qualitative. So for that currently again again under that we have we are addressing only the sentences that are having self-contained subjects, right? So so if they're not if they are referring to prop up pronouns and we are just filtering out so that's one one candidate for improvement. So which which I think show em should be working on and then and then the other other one is there is there is a there is a The sentence is self-contained. But still we are we are not we are just filtering it out. So we just need to find out the Mist Outpost. I mean the post-processing steps that are causing this and then see how you can fix that. like so and on the model part, we haven't I don't think we need anything right now to I think the current model is suffice. It is giving enough false positives and true positive. So, so it's all about reducing the false positives and bye. \"], '2019-11-25T09:38:31Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '41708d237fe642be8cea7ef3a3501cf9']] \n",
      "\n",
      "\n",
      "21 \n",
      "\n",
      " [[['For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls. '], '2019-11-25T10:29:34Z', 'fb52cb663aec4795aee38ccfd904d315', '506d98d1fded4ca084f52079196cf08c'], [['Then it may be like a mix playlist or then it would take better after publication. It has been happening on but if it happens and it would say that resources healthy orders. It will just put that it is unhealthy and we have chicken. '], '2019-11-25T10:29:46Z', 'fb52cb663aec4795aee38ccfd904d315', 'bc8f4af90421429780653dbd35b5b57a']] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in G:\n",
    "    print (node, \"\\n\\n\", graph_list[node], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (list(map(lambda kv: (kv[1][\"weight\"]).tolist(), G[4].items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0979940970388943\n",
      "0.09745418054971748\n",
      "0.009602843054468234\n",
      "0.009497317306616933\n",
      "0.4889771941598955\n",
      "0.5864313747096129\n",
      "0.5338221192359924\n",
      "0.6467412859201431\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "print (statistics.stdev(weights))\n",
    "print (statistics.pstdev(weights))\n",
    "print (statistics.variance(weights))\n",
    "print (statistics.pvariance(weights))\n",
    "print (statistics.mean(weights))\n",
    "print (statistics.mean(weights)+statistics.pstdev(weights))\n",
    "\n",
    "q3 = np.percentile(weights, 75)\n",
    "print (q3)\n",
    "iqr = np.subtract(*np.percentile(weights, [75, 25]))\n",
    "outlier = q3 + 1.5 * iqr\n",
    "print(q3+iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4., 14., 16., 31., 19.,  3.,  2.,  1.,  0.,  1.]),\n",
       " array([0.3205182 , 0.38846639, 0.45641458, 0.52436277, 0.59231097,\n",
       "        0.66025916, 0.72820735, 0.79615554, 0.86410373, 0.93205193,\n",
       "        1.00000012]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "#sns.set(color_codes=True)\n",
    "\n",
    "matplotlib.pyplot.hist(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/arjun/BERT_Similarity_experiments/code/\")\n",
    "from gpt_feat_utils import GPT_Inference\n",
    "#\n",
    "# #gpt_model = gpt_feat_utils.GPT_SimInference(\"/home/arjun/gpt_experiments/models/model_lm+sim_ep3/\", device=\"cuda\")\n",
    "# #gpt_model = gpt_feat_utils.GPT_SimInference(\"/home/arjun/gpt_experiments/models/model_lm+nsp_sim_ep3/\", device=\"cuda\")\n",
    "#gpt_model = GPT_Inference(\"/home/arjun/gpt_experiments/engg_models/se+ether_2+1s_ep5_#2/\", device=\"cuda\")\n",
    "gpt_model = GPT_Inference(\"/home/shubham/projects/domain_minds_v2_gpt/se/model/epoch3/\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5472243428230286"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "text1 = \"Is it is an open source tool that allows you to take advantage of onpremises hybrid or public Cloud infrastructure giving you the freedom to move workloads where ever you want it offers security networking and storage services and can manage more than one cluster at a time kubernetes makes more efficient use of hard work allowing you to maximize your resources and save money, but here is where things get tricky use a container orchestration tool like kubernetes.\"\n",
    "text2 =  \"so, There are guardrails and brand building blocks confining the process but it is mostly just me being myself is the brand this has in turn created.\"\n",
    "1- cosine(gpt_model.get_text_feats(text1), gpt_model.get_text_feats(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "with open(\"para_graph\", \"rb\") as f:\n",
    "    nodes, edges, graph_list = pickle.load(f)  \n",
    "G = nx.Graph()  \n",
    "G.add_nodes_from(nodes)  \n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 0,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 0,\n",
       " 8: 6,\n",
       " 9: 0,\n",
       " 10: 7,\n",
       " 11: 8,\n",
       " 12: 9,\n",
       " 13: 10,\n",
       " 14: 9,\n",
       " 15: 11,\n",
       " 16: 12,\n",
       " 17: 13,\n",
       " 18: 12,\n",
       " 19: 14,\n",
       " 20: 15}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import community\n",
    "community.best_partition(G, resolution=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "{'weight': 0.92328954} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "{'weight': 0.8328446} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "{'weight': 0.88329726} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 0.77467877} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.91811305} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.89699703} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.777256} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.8738942} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.8928244} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.7341685} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.82322294} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.78939074} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.7762697} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.8665182} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.8141417} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.7597266} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.7245356} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.823713} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.7947237} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "It's not about if a similarity but but instead of trying to compare the whole sentence for to form the cosine distance between them. Is there a better way like one obvious way is to do the entity comparison. Can we can we do? Augmenting the data comparison is wanting to when there is no entity. How do you compare to keep two sentences?  2 b 4 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.76237845} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "{'weight': 0.8993241} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "{'weight': 0.92887914} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 0.8496546} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.92803895} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.9341834} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.7196365} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.91499746} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.85081244} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.8164714} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.8925918} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.8779402} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.8626029} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.8946911} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.8878992} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.855345} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8086537} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.8968499} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.872483} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So I started testing GPT is ability to capture either data along with SE data by combining the data sets and then painting the model. So we found that training with a combination of two plus one second sentences in the IROC manner allowed it to capture context as update some of the tokens but this order to capture context or an entity level. Whereas as a new directly Feed The Entity and you get it. A decent enough representation this I double-checked by comparing giving an entity and taking the most similar entity. So this works well for the most part but in terms of actual sentence to sentence comparisons, it doesn't make that much of a difference whether we use the in incremental approach or this approach. So the only place actually see a difference is in this entities comparison. So that's something we want to take a look at.  2 8 7 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.823006} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "{'weight': 0.9159603} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 0.90287524} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.8629291} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.91617274} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.6786895} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.9005708} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.79057086} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.90341854} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.8981212} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.93115956} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.91279477} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9150223} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.9283157} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.87245333} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8588382} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9399267} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8228537} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And we will be discussing about possible improvements or I mean the cases where we should look at this morning. So so we keep waiting will make the observation base will as we get more calls and we'll see where it is working out and we should look at it.  2 b 5 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8874168} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 0.846638} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.92478186} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.92416906} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.7418453} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.9013027} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.8647404} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.8284235} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.9032241} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.8852914} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.85443413} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9147646} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.9093653} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.8581683} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8264689} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.90325797} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.81833154} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So the way I was doing it initially was a so I was using like a proximate search kind of thing which reduces such things initially. So if I agree at all the key phrases of the users, then it comes out to be around like 4,000 5,000. The next video is so space to 1,000 or 2,000 something based on threshold and then from like proper cosine similarity match. So the in stage Going to I was testing right? So the that's what it shows. Yeah, when it shows the top three users. So those top three are based on the approximate such thing. Then I take the key phases of all these top three users and then make a like proper comparison. Okay, and then I show you related keywords, but  2 7 d \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.85632324} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 0.8264507} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.87423164} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.6110558} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.9002441} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.7464302} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.86269397} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.8939672} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.92030627} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.91263956} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.8722543} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.9012274} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9010484} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8796459} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9153882} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8295256} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "We'll start it that way maybe we can talk to Karthik once and see if he has any inputs and then we'll do it this way and if this is fine.  2 b 3 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8839631} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.9318245} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.72150284} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.91954875} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.91769403} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.7710582} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.90761256} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.8369133} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.8217574} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9053838} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.8849815} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.8580924} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.825349} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.87670135} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8495423} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "From what I've seen I also did the number of sentences check and there isn't a correlation between number of sentences and relation to the entity. So that was actually pretty surprising. So if you have one thing it's not necessary that there isn't any correlation like if I take two entities, yeah, if I take two entities, even if they have like very few sentences in common, they may still get a higher score than two. Entities with like many more sentences in common. This is I will ratio-wise.  2 8 1 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8317523} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "{'weight': 0.9999999} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 0.7456162} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.93661755} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.88635} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.8403528} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.9251913} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.90646595} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.8963443} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.92750955} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.91138977} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.8801544} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.85176015} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9231866} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8660093} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "That need not be true because if you're talking about contexts, then you're not only talking about Docker and kubernetes are also talking about a verb like context like testing and deployment right which doesn't really account for the end piece itself. So in that case the two models May differ because one is based on, you know, two plus one and neither has more context with four plus one sentences. So it need not be just entities is what I'm trying to say.  2 8 9 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.87084967} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 0.7251331} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.7375643} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.56380635} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.67211443} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.6630176} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.6149763} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.7118748} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.6313942} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.61478823} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.6045831} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.6397539} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.5896895} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "but how do you select the subset that keeps changing then you will end up not being able to compare that with the other entity features because  2 b 8 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.61334467} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 0.84857786} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.8393849} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.94927} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.9134601} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.90691715} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9212214} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.91255206} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9312906} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.887371} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9188649} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.88705975} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Does that mean that we have to give one more call to The Entity service and get the entities for it or flip the question is there is always that is currently giving making a call to entity service only keep the only key phrases. Oh, so now your question is whether we should call it again. Yeah.  2 f 1 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8816016} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 0.6955854} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.81745654} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.74966216} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.72867966} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.85997224} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.7901722} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.7452622} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.7118756} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.79074764} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.76456875} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You know what you're trying to say if I have to codify what you're trying to say, you're asking you're asking to do the same similarity between this current sentence and all the candidates sentences from which it is function separately and then take the top 10 or 15 in deities to find out context.  2 b 3 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.7445951} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 0.8423488} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.91389763} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.90745723} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.8783389} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.8942388} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.834108} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.8302275} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.91389555} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8055003} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "And like butter salt collecting false negative and I thought that was able to find out and I end I end users.  2 7 6 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.873123} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 0.91938496} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.9128424} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.91348535} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.93157107} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.94382703} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.9073216} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.93044055} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.86840326} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Some disconnect it's not about whether we do it this way or not. But small disconnect for me is what if I am big Dumbo what all these things and then I do the same way every time as if for the summary service also, we get all the segments like as soon as the segment is generated.  2 b 6 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8991719} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 0.94006604} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.923592} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.92838436} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9202186} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.9006554} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9495855} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.85074526} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Don't ever say I'm just giving an extra so just for see a CD for us so that whenever we deploy some either new model - or some algorithm it would just invoke that gland and then some variations and then push it to slack saying whether it is healthy or not.  2 f c \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.9292982} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "{'weight': 1.0000001} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.91213304} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.94006187} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9185777} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.9219902} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.95762223} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8863065} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So we can continue the way we are capturing it right now like Network X based or anything. Okay, and maybe for like few meeting if it is if you are capturing live then we can like Observer like couple of meetings and it's easy to convert from Network X 2D graphs. Okay, or any other kind of need that is not a problem. We can do that. So, how do you think of the use cases that we might need of  2 7 5 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.93315864} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "{'weight': 0.9999999} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 0.927358} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.88287854} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.87636125} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.94851345} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8774245} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "You're masking lot of context. Maybe you should reduce the just try to align with the 15% and fry. That means take firefight. Well example and see how many noun phrase becoming and if they are more than 50 percent. It would be hard visual like like a mask only you have to do some observations based thresholding on that and then mask only those with the with like maybe 80% probability Mass call the not Damascus from Paris.  2 b 2 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.9220265} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "{'weight': 1.0000001} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 0.9353381} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.92013484} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.97347444} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.890964} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "So Sunday on the recommended Roger Fisher any observation because last time you wanted to share some you. This we had if we had a discussion which would include site because the way you are getting the whatever I don't I vaguely remember but the way of aggregation there was conflict whether it works or not works.  2 b 1 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.9345485} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 0.94143337} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9249534} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.8690697} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "No, I think that should happen independent of the service if it happens. It should happen at the place where which is calling the services stuff within the service.  2 b 0 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.91480136} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "{'weight': 1.0000001} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 0.9152199} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.84585977} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Even if we capture just send text and entities even that should be fine if you just like a backfill.  2 7 7 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.90727204} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.9040195} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "yeah, I think we discussed almost like both their action items and communities, but but you can just so sugarman's action template so Can we? Okay, just give it to everyone update everyone.  2 b 4 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.9438234} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "{'weight': 0.99999994} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "Faces are still inconclusive. So what we should do is I think we should start capturing the all the entities and then try to I don't know where that should be is it should it be going into the existing graph or we should take ittake separately?  2 b 2 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 0.8507762} \n",
      "\n",
      "\n",
      "------- sentence ---------\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "For example, like if you have like two or three calls where they man, very targeted. What are the likely top concerns which we might get we always go because it is specific set of calls.  2 f 5 \n",
      "\n",
      "{'weight': 1.0} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for nodea, nodeb, weight in G.edges.data():\n",
    "    if nodea not in scores.keys():\n",
    "        scores[nodea] = [(nodeb, weight)]\n",
    "    else:\n",
    "        scores[nodea].append((nodeb, weight))\n",
    "        scores[nodea] = sorted(scores[nodea], key=lambda kv:kv[1]['weight'], reverse=True)\n",
    "    #if nodea==4:\n",
    "        #if weight[\"weight\"]> 0.5864313747096129:\n",
    "    print (\"------- sentence ---------\")\n",
    "    print (\" \".join([seg[0] for seg in graph_list[nodea][0]]), \"\\n\")\n",
    "    print (\" \".join([seg[0] for seg in graph_list[nodeb][0]]), \"\\n\")\n",
    "    print (weight, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------sentence------- \n",
      "\n",
      "What do you say like run an ETL pipeline detail code for the for around a hundred graph dumps from staircase to data. \n",
      "\n",
      "comparison sentence:  What do you say like run an ETL pipeline detail code for the for around a hundred graph dumps from staircase to data. ====>  1.0 \n",
      "\n",
      "comparison sentence:  If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. ====>  0.7805325 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.7801076 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.7797588 \n",
      "\n",
      "comparison sentence:  You summaries for which we need a entity model, which Arjun is improving one and then mystery and I are working on experimenting with some approaches where we can aggregate this just segments or the sentences instead of going only by the segment. ====>  0.7793624 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So there is like that there is locally now and I am like populating them with degree of bulk method and everything. \n",
      "\n",
      "comparison sentence:  So there is like that there is locally now and I am like populating them with degree of bulk method and everything. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. ====>  0.90093464 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8862273 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8794582 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8794336 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "The one that we still have in staging is do we know that is it better than what we have is Tim is in \n",
      "\n",
      "comparison sentence:  The one that we still have in staging is do we know that is it better than what we have is Tim is in ====>  1.0 \n",
      "\n",
      "comparison sentence:  And I protect sales in the sales wind is and staging I tested out then if it is fine, then we will move it to production. ====>  0.8841187 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8530063 \n",
      "\n",
      "comparison sentence:  So is the release version running find on the yeah the release version? ====>  0.8527691 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.84945464 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Their communities started the summary and the under Community with summaries. \n",
      "\n",
      "comparison sentence:  Their communities started the summary and the under Community with summaries. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Itll be interesting to see what chapters gives the communities approaches by perceiving with production. ====>  0.6350874 \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  0.618715 \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  0.5624383 \n",
      "\n",
      "comparison sentence:  I know you are busy with the past implementation, but they want to jump in on setting up with the data Macedonia. ====>  0.56091696 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So we are we are working on the what you call the then symbol for that like like them the back and model needed and then and then the processor so Shri Arjun and I are trying to work together on that to see where you know, how we can make the entity. \n",
      "\n",
      "comparison sentence:  So we are we are working on the what you call the then symbol for that like like them the back and model needed and then and then the processor so Shri Arjun and I are trying to work together on that to see where you know, how we can make the entity. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.88333106 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8777002 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8762465 \n",
      "\n",
      "comparison sentence:  So and also the entity model it is in it is a it is in staging to so so Arjun is working with Russian to have it in our tin production. ====>  0.87427205 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "You summaries for which we need a entity model, which Arjun is improving one and then mystery and I are working on experimenting with some approaches where we can aggregate this just segments or the sentences instead of going only by the segment. \n",
      "\n",
      "comparison sentence:  You summaries for which we need a entity model, which Arjun is improving one and then mystery and I are working on experimenting with some approaches where we can aggregate this just segments or the sentences instead of going only by the segment. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.83886904 \n",
      "\n",
      "comparison sentence:  So there are fewer of them changes required on that path for both for both for this entity model and for sales mind. ====>  0.8357606 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8158475 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.81569505 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We might we will we might conclude on at least couple of approaches by by next week. \n",
      "\n",
      "comparison sentence:  We might we will we might conclude on at least couple of approaches by by next week. ====>  1.0 \n",
      "\n",
      "comparison sentence:  You know even with I will share some things that I got from today is call with action, I think. ====>  0.8394194 \n",
      "\n",
      "comparison sentence:  It would be the it would be that approach which we can actually can achieve what you want with that approach. ====>  0.83692014 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.8348489 \n",
      "\n",
      "comparison sentence:  We might have some some insights and then we can work on it. ====>  0.8284428 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Well, it works really well on few cases and then and then it just Falls flat. \n",
      "\n",
      "comparison sentence:  Well, it works really well on few cases and then and then it just Falls flat. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  This is not possible like using this as using it as as they can because it works almost everything in the back and it only provides the apis. ====>  0.794613 \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.7453964 \n",
      "\n",
      "comparison sentence:  We might have some some insights and then we can work on it. ====>  0.73192495 \n",
      "\n",
      "comparison sentence:  On a local machine we are able to debug the app like run both the debug and release versions, but on the device debug version we are not able to do. ====>  0.7298552 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So we just do not just do not have any reason to deploy it into to take it all the way to Productions. \n",
      "\n",
      "comparison sentence:  So we just do not just do not have any reason to deploy it into to take it all the way to Productions. ====>  1.0 \n",
      "\n",
      "comparison sentence:  We just do not want to we have to handle it says study to go all the way to see all the it is subjects around it so that we can that is one fix that we will have it in so that you become would be testing and then we should that should improve the at least the existing action items. ====>  0.8976565 \n",
      "\n",
      "comparison sentence:  So we are trying to extend that a little so that you do not miss out the sentence endings, which I eventually it also depends on the transcript, but whatever can be done from our side for these are abrupt ending we can we can handle that. ====>  0.8854183 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.8662958 \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.846234 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "You know even with I will share some things that I got from today is call with action, I think. \n",
      "\n",
      "comparison sentence:  You know even with I will share some things that I got from today is call with action, I think. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.9125148 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.90298927 \n",
      "\n",
      "comparison sentence:  Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. ====>  0.9006855 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.8998433 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Itll be interesting to see what chapters gives the communities approaches by perceiving with production. \n",
      "\n",
      "comparison sentence:  Itll be interesting to see what chapters gives the communities approaches by perceiving with production. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I do not think it is worth the effort right now, honestly, unless we find something working really well. ====>  0.7399583 \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  0.7166699 \n",
      "\n",
      "comparison sentence:  I know you are busy with the past implementation, but they want to jump in on setting up with the data Macedonia. ====>  0.7005648 \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  0.689796 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But even if you even if you try to compare current segments with the with the communities that we have right it is better not to proceed without without any conclusion on the current communities. \n",
      "\n",
      "comparison sentence:  But even if you even if you try to compare current segments with the with the communities that we have right it is better not to proceed without without any conclusion on the current communities. ====>  1.0 \n",
      "\n",
      "comparison sentence:  It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? ====>  0.8052279 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.80049515 \n",
      "\n",
      "comparison sentence:  So there are fewer of them changes required on that path for both for both for this entity model and for sales mind. ====>  0.7994112 \n",
      "\n",
      "comparison sentence:  If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. ====>  0.7961692 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I do not think it is worth the effort right now, honestly, unless we find something working really well. \n",
      "\n",
      "comparison sentence:  I do not think it is worth the effort right now, honestly, unless we find something working really well. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.7897733 \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  0.7845767 \n",
      "\n",
      "comparison sentence:  But so, let us see if it is enough data on. ====>  0.78273445 \n",
      "\n",
      "comparison sentence:  But attacking there were some points that maybe it is because of Internet issue or something but did not work out like for us. ====>  0.7573882 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So so sugar makes working on improvements for those things like like instead of abruptly ending the sentence like we have seen some cases. \n",
      "\n",
      "comparison sentence:  So so sugar makes working on improvements for those things like like instead of abruptly ending the sentence like we have seen some cases. ====>  1.0 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.89114696 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.88200027 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.8649752 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8599686 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So we are trying to extend that a little so that you do not miss out the sentence endings, which I eventually it also depends on the transcript, but whatever can be done from our side for these are abrupt ending we can we can handle that. \n",
      "\n",
      "comparison sentence:  So we are trying to extend that a little so that you do not miss out the sentence endings, which I eventually it also depends on the transcript, but whatever can be done from our side for these are abrupt ending we can we can handle that. ====>  1.0 \n",
      "\n",
      "comparison sentence:  We just do not want to we have to handle it says study to go all the way to see all the it is subjects around it so that we can that is one fix that we will have it in so that you become would be testing and then we should that should improve the at least the existing action items. ====>  0.9081117 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.9006758 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8484097 \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.8464556 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Let the subject ending at the end without like a noun phrase if there is a noun phrase with two words if we currently tend to end it with the first for itself. \n",
      "\n",
      "comparison sentence:  Let the subject ending at the end without like a noun phrase if there is a noun phrase with two words if we currently tend to end it with the first for itself. ====>  1.0 \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  0.6742957 \n",
      "\n",
      "comparison sentence:  So right now we just take the final table type in segments. ====>  0.6128769 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.6085311 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.59846836 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We just do not want to we have to handle it says study to go all the way to see all the it is subjects around it so that we can that is one fix that we will have it in so that you become would be testing and then we should that should improve the at least the existing action items. \n",
      "\n",
      "comparison sentence:  We just do not want to we have to handle it says study to go all the way to see all the it is subjects around it so that we can that is one fix that we will have it in so that you become would be testing and then we should that should improve the at least the existing action items. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.89856434 \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.8562451 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8336064 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.8143942 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, that is one obvious observation from some of the test calls and the production calls that have seen. \n",
      "\n",
      "comparison sentence:  Yeah, that is one obvious observation from some of the test calls and the production calls that have seen. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.8775055 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8723551 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.85949236 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.8503166 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I mean, at least this way we can have more visibility even after this call. \n",
      "\n",
      "comparison sentence:  I mean, at least this way we can have more visibility even after this call. ====>  1.0 \n",
      "\n",
      "comparison sentence:  We might have some some insights and then we can work on it. ====>  0.86321884 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.8424406 \n",
      "\n",
      "comparison sentence:  If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. ====>  0.8265507 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.82498705 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We might have some some insights and then we can work on it. \n",
      "\n",
      "comparison sentence:  We might have some some insights and then we can work on it. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.82589865 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.82042336 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8138594 \n",
      "\n",
      "comparison sentence:  Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. ====>  0.8097114 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So and also the entity model it is in it is a it is in staging to so so Arjun is working with Russian to have it in our tin production. \n",
      "\n",
      "comparison sentence:  So and also the entity model it is in it is a it is in staging to so so Arjun is working with Russian to have it in our tin production. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8808867 \n",
      "\n",
      "comparison sentence:  And I protect sales in the sales wind is and staging I tested out then if it is fine, then we will move it to production. ====>  0.87765247 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.8621177 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.8588982 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So there are fewer of them changes required on that path for both for both for this entity model and for sales mind. \n",
      "\n",
      "comparison sentence:  So there are fewer of them changes required on that path for both for both for this entity model and for sales mind. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.827658 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8206023 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8195918 \n",
      "\n",
      "comparison sentence:  It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? ====>  0.81938034 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah for now it is only for key phrase but it will also be used for it is definitely going to be used for the communities. \n",
      "\n",
      "comparison sentence:  Yeah for now it is only for key phrase but it will also be used for it is definitely going to be used for the communities. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8720393 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.8630226 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.86284024 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8527612 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So once that is done, then I will be working on the getting setting up a complete pipeline starting from creating the these hundred grafts gums and using that data for Downstream costly recommended vultures and rated \n",
      "\n",
      "comparison sentence:  So once that is done, then I will be working on the getting setting up a complete pipeline starting from creating the these hundred grafts gums and using that data for Downstream costly recommended vultures and rated ====>  1.0 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.799971 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.7977954 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.7870965 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.7802407 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So I did not like once the pipeline is set then I will basically run need to has as part of key phrase or some other service and log d results. \n",
      "\n",
      "comparison sentence:  So I did not like once the pipeline is set then I will basically run need to has as part of key phrase or some other service and log d results. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.9040317 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.82619995 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.8200663 \n",
      "\n",
      "comparison sentence:  But much more than the feel like I have recipe are and like it is take a lot of time. ====>  0.81802946 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So right now we just take the final table type in segments. \n",
      "\n",
      "comparison sentence:  So right now we just take the final table type in segments. ====>  1.0 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.7569195 \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  0.75078404 \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  0.73169255 \n",
      "\n",
      "comparison sentence:  So whenever they come along with the key phases or they will be like all separate service which will check for recommended watches and then I will just log it so that I can see it. ====>  0.71964407 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So whenever they come along with the key phases or they will be like all separate service which will check for recommended watches and then I will just log it so that I can see it. \n",
      "\n",
      "comparison sentence:  So whenever they come along with the key phases or they will be like all separate service which will check for recommended watches and then I will just log it so that I can see it. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.8940114 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8688184 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8673093 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.85762364 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I know you are busy with the past implementation, but they want to jump in on setting up with the data Macedonia. \n",
      "\n",
      "comparison sentence:  I know you are busy with the past implementation, but they want to jump in on setting up with the data Macedonia. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  But so, let us see if it is enough data on. ====>  0.7901658 \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  0.7697591 \n",
      "\n",
      "comparison sentence:  And also it is not that does not show up in the join list like the front end in the clients. ====>  0.71857196 \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.707919 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, so I think probably today I will be done with a Turkish changes and then I will work on the infrastructure part for decaf I try there to ECS approach for setting of the graph instance. \n",
      "\n",
      "comparison sentence:  Yeah, so I think probably today I will be done with a Turkish changes and then I will work on the infrastructure part for decaf I try there to ECS approach for setting of the graph instance. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.8681121 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.86342275 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8631541 \n",
      "\n",
      "comparison sentence:  Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. ====>  0.8606209 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. \n",
      "\n",
      "comparison sentence:  If you really want we can we still have one instance which is running the graph is not the idealistic infrastructure that we have set up. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8647046 \n",
      "\n",
      "comparison sentence:  It would be the it would be that approach which we can actually can achieve what you want with that approach. ====>  0.85892135 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.8581814 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.85050786 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. \n",
      "\n",
      "comparison sentence:  Now folks right now just to get an idea and I am using mind doing everything locally and just using like a hundred grams. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.91029185 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.90423775 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.89365757 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.8879648 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But so, let us see if it is enough data on. \n",
      "\n",
      "comparison sentence:  But so, let us see if it is enough data on. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.77640724 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.776276 \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  0.7712242 \n",
      "\n",
      "comparison sentence:  And also it is not that does not show up in the join list like the front end in the clients. ====>  0.7707466 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "And I protect sales in the sales wind is and staging I tested out then if it is fine, then we will move it to production. \n",
      "\n",
      "comparison sentence:  And I protect sales in the sales wind is and staging I tested out then if it is fine, then we will move it to production. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.88873523 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8754037 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.86805767 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.8578063 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Okay, he is going to hyphenate it from his side, but it is for us to do it then take this task. \n",
      "\n",
      "comparison sentence:  Okay, he is going to hyphenate it from his side, but it is for us to do it then take this task. ====>  1.0 \n",
      "\n",
      "comparison sentence:  It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? ====>  0.8327133 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.82826686 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8219878 \n",
      "\n",
      "comparison sentence:  But much more than the feel like I have recipe are and like it is take a lot of time. ====>  0.8213264 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Like yesterday, I was working on connecting the same is not as is breaking. \n",
      "\n",
      "comparison sentence:  Like yesterday, I was working on connecting the same is not as is breaking. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.8974169 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.89559627 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.89034307 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8687934 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "This is not possible like using this as using it as as they can because it works almost everything in the back and it only provides the apis. \n",
      "\n",
      "comparison sentence:  This is not possible like using this as using it as as they can because it works almost everything in the back and it only provides the apis. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.8180413 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.8159762 \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  0.78930295 \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.78846246 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We should at least be able to toggle at least are being on the show The Speaker stacks and then \n",
      "\n",
      "comparison sentence:  We should at least be able to toggle at least are being on the show The Speaker stacks and then ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8334735 \n",
      "\n",
      "comparison sentence:  Basically that if we want we can do it in the front and also ====>  0.82589126 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.82520306 \n",
      "\n",
      "comparison sentence:  So is the release version running find on the yeah the release version? ====>  0.8185135 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Click there is no way using like customizing the UI of the Seagate we can have the knitted C library and put the all the components as lik done by the did see me people and compile our own and you further up. \n",
      "\n",
      "comparison sentence:  Click there is no way using like customizing the UI of the Seagate we can have the knitted C library and put the all the components as lik done by the did see me people and compile our own and you further up. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.8803953 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.84427404 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.8425867 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.84153306 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It would be the it would be that approach which we can actually can achieve what you want with that approach. \n",
      "\n",
      "comparison sentence:  It would be the it would be that approach which we can actually can achieve what you want with that approach. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.88951993 \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  0.885751 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8731067 \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  0.87211734 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Like if you see also did if we clone the Gypsy meet we make some modify in the did simic file when we run in the local. \n",
      "\n",
      "comparison sentence:  Like if you see also did if we clone the Gypsy meet we make some modify in the did simic file when we run in the local. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Basically that if we want we can do it in the front and also ====>  0.89710355 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.87200826 \n",
      "\n",
      "comparison sentence:  So is the release version running find on the yeah the release version? ====>  0.85552144 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.852442 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It shows all those strangers, but when you build it and give the same source to our app. \n",
      "\n",
      "comparison sentence:  It shows all those strangers, but when you build it and give the same source to our app. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.6848122 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.6767761 \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  0.6660399 \n",
      "\n",
      "comparison sentence:  But when I saw that I am not able to run that in the device. ====>  0.66271836 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Zoom that did not show the same UI or functionality which we used to run in the local because everything again it becomes ice remnants will be there Rebel. \n",
      "\n",
      "comparison sentence:  Zoom that did not show the same UI or functionality which we used to run in the local because everything again it becomes ice remnants will be there Rebel. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.81290823 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.80842894 \n",
      "\n",
      "comparison sentence:  And also it is not that does not show up in the join list like the front end in the clients. ====>  0.8074536 \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.80159724 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. \n",
      "\n",
      "comparison sentence:  Today, I will just go through like ones to know that like whether we can implement it or not, like whether it is feasible on and then I will just raise the pr for it. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.9073943 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.89898676 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.897452 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.89403766 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. \n",
      "\n",
      "comparison sentence:  Yeah, so anything if you want to make the changes in the UI, like custom you are very should use the a little bit sing it and on top of it like building the components and having the UI and the connecting the conference and everything should follow up to Dixie need Behavior, like keeping all those architecture and everything so that we can achieve the Gypsy need benefits using lived its in it. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.88387406 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.87913644 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8790082 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It is also depends on how much knowledge you guys have on signaling on its take and how much information you know, how to Multiplex the you know, it is not the sweetest in my platoon is also and Link Network. \n",
      "\n",
      "comparison sentence:  It is also depends on how much knowledge you guys have on signaling on its take and how much information you know, how to Multiplex the you know, it is not the sweetest in my platoon is also and Link Network. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.7618458 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.760654 \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  0.7493282 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.7260725 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? \n",
      "\n",
      "comparison sentence:  It is everything that they do on top of the Gypsy meet since you maybe if you want to go through the code base little bit and then you get instant it is better but an alternate approach could be ironic sustainable want is that do all right approach? ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.88347435 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.8592164 \n",
      "\n",
      "comparison sentence:  But much more than the feel like I have recipe are and like it is take a lot of time. ====>  0.8551204 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.83696586 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "This one is we can host their own with simic server. \n",
      "\n",
      "comparison sentence:  This one is we can host their own with simic server. ====>  1.0 \n",
      "\n",
      "comparison sentence:  You can launch a WPA will support it but joining never showed. ====>  0.8159941 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.81196314 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.8026819 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.7945014 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. \n",
      "\n",
      "comparison sentence:  The reaching meet with the other is just raise if we can know we can add a configuration disappear and emergent. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  0.8650516 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8634286 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.85954493 \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  0.84442043 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But much more than the feel like I have recipe are and like it is take a lot of time. \n",
      "\n",
      "comparison sentence:  But much more than the feel like I have recipe are and like it is take a lot of time. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.892966 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.872345 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.8677631 \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  0.8555602 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. \n",
      "\n",
      "comparison sentence:  But that is like now they have like they have some doubts but making that change now they have said like to modify the name so that they can proceed for the but it is not that straightforward like by changing the name and on it will not do it immediately. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8822585 \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  0.87687564 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.8752989 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. \n",
      "\n",
      "comparison sentence:  I can raise up your for that also if we can spend some time on using legitimate and mimicking or gypsum. ====>  1.0 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8706241 \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  0.86147636 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8551856 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.85463876 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "It would be easier for us to fall in like the photo. \n",
      "\n",
      "comparison sentence:  It would be easier for us to fall in like the photo. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.7238345 \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.7122862 \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.6981353 \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  0.6943024 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. \n",
      "\n",
      "comparison sentence:  Yeah, but from what I have tested it is not straightforward and people have said the same thing and it is not even consistent with the telling on the network errors that you see, it is Amin handles. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.8938504 \n",
      "\n",
      "comparison sentence:  So with the other negation that I am testing the slack connectors and the other thing is being able to unify all the basic validations at the bottom level for things like whether the bot is present in the meeting. ====>  0.88342863 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.87119406 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We were facing a lot of issues and a lot of comments on this. \n",
      "\n",
      "comparison sentence:  We were facing a lot of issues and a lot of comments on this. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But attacking there were some points that maybe it is because of Internet issue or something but did not work out like for us. ====>  0.7944021 \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.7342586 \n",
      "\n",
      "comparison sentence:  Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. ====>  0.73103476 \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  0.7224962 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. \n",
      "\n",
      "comparison sentence:  We are saying that you know, it is not as easy as it sounds so just letting you know think if it is easy to just provide an option like in the Json. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8371394 \n",
      "\n",
      "comparison sentence:  So with the other negation that I am testing the slack connectors and the other thing is being able to unify all the basic validations at the bottom level for things like whether the bot is present in the meeting. ====>  0.8271075 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.82343316 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "to hide the config in a CPR Just make it high double like in the sense that option to hide the top portion. \n",
      "\n",
      "comparison sentence:  to hide the config in a CPR Just make it high double like in the sense that option to hide the top portion. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.7347824 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.70591915 \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  0.69368523 \n",
      "\n",
      "comparison sentence:  Let is treat this as a higher priority than the product support because if you are not able to test upgradability of anything the app on the physical device and cremation deploy anyways. ====>  0.69032556 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "That is good that we the faster we do it for now always ask for thing and it seemed to me that part. \n",
      "\n",
      "comparison sentence:  That is good that we the faster we do it for now always ask for thing and it seemed to me that part. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.90101564 \n",
      "\n",
      "comparison sentence:  So maybe you can check because I know we had but two bucks integration implemented so far we should send it if that is an exception. ====>  0.88943624 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.88326776 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "For the month like I just went through like it is not a stable version It is Alpha version of something and when I navigate about information, it says company Google and also the Dozer name as Firefox. \n",
      "\n",
      "comparison sentence:  For the month like I just went through like it is not a stable version It is Alpha version of something and when I navigate about information, it says company Google and also the Dozer name as Firefox. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8633429 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.8515751 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.84793633 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.8422221 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So I think once the stable version comes with it will be buggy and it because it fails to load our application. \n",
      "\n",
      "comparison sentence:  So I think once the stable version comes with it will be buggy and it because it fails to load our application. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.8451611 \n",
      "\n",
      "comparison sentence:  The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. ====>  0.83302623 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But attacking there were some points that maybe it is because of Internet issue or something but did not work out like for us. \n",
      "\n",
      "comparison sentence:  But attacking there were some points that maybe it is because of Internet issue or something but did not work out like for us. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.7983915 \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  0.79764533 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. \n",
      "\n",
      "comparison sentence:  And once that means was wrong then with other libraries also because it is not reaching you until our AB dot J is before that only it says undefined some binding is undefined. ====>  1.0 \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  0.83118814 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.8183796 \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  0.8172293 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8156877 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So when you get undefined errors, do we capture these errors and bugs and Atkins about science and them with socks not? \n",
      "\n",
      "comparison sentence:  So when you get undefined errors, do we capture these errors and bugs and Atkins about science and them with socks not? ====>  1.0 \n",
      "\n",
      "comparison sentence:  Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. ====>  0.74834996 \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.6873695 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. \n",
      "\n",
      "comparison sentence:  Okay, so I definitely Inspire respect of this we need to get better at capturing errors and being able to look at them differently. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.8050018 \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  0.78637606 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So maybe you can check because I know we had but two bucks integration implemented so far we should send it if that is an exception. \n",
      "\n",
      "comparison sentence:  So maybe you can check because I know we had but two bucks integration implemented so far we should send it if that is an exception. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8624521 \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.8605583 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.85438824 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. \n",
      "\n",
      "comparison sentence:  I can see if this able to resort to using Source maps to some file or library or some location in the whole Base by expelling and then we can take the center. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.8243169 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.8175967 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. \n",
      "\n",
      "comparison sentence:  Yeah, so like we facing this issue, so I wanted to test the upgrade in the physical device. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.8596265 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.8541281 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.85332525 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But when I saw that I am not able to run that in the device. \n",
      "\n",
      "comparison sentence:  But when I saw that I am not able to run that in the device. ====>  1.0 \n",
      "\n",
      "comparison sentence:  On a local machine we are able to debug the app like run both the debug and release versions, but on the device debug version we are not able to do. ====>  0.76197255 \n",
      "\n",
      "comparison sentence:  I was able to install receive events and the able to generate the token you too. ====>  0.7498472 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.72956306 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.72018623 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So like I am working on it and we will get to know you get on a call. \n",
      "\n",
      "comparison sentence:  So like I am working on it and we will get to know you get on a call. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.91713494 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.9018492 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.88098305 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Let is treat this as a higher priority than the product support because if you are not able to test upgradability of anything the app on the physical device and cremation deploy anyways. \n",
      "\n",
      "comparison sentence:  Let is treat this as a higher priority than the product support because if you are not able to test upgradability of anything the app on the physical device and cremation deploy anyways. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.76627 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "On a local machine we are able to debug the app like run both the debug and release versions, but on the device debug version we are not able to do. \n",
      "\n",
      "comparison sentence:  On a local machine we are able to debug the app like run both the debug and release versions, but on the device debug version we are not able to do. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  0.69745207 \n",
      "\n",
      "comparison sentence:  We need to create a separate email address for each and every board quickly verify that if you get set up. ====>  0.68609357 \n",
      "\n",
      "comparison sentence:  They have added it in the user list is a response. ====>  0.6851982 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So is the release version running find on the yeah the release version? \n",
      "\n",
      "comparison sentence:  So is the release version running find on the yeah the release version? ====>  1.0 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.8445156 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8443142 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.83755434 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.83638525 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. \n",
      "\n",
      "comparison sentence:  Hello, so I just applied since Lambda in staging to have asked him to test if it works fine L applied the same on brought to So currently I do not have any other tasso Muriel look take a look at the API and additions list and click something from that. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.8617314 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. \n",
      "\n",
      "comparison sentence:  Is asking me because he needs he is doing a continuous ETL of all the data that we captured during the meeting level certain IDs that are still not high fat cell. ====>  0.9999999 \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  0.859672 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.85055417 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. \n",
      "\n",
      "comparison sentence:  The same similar to what we did for meeting it is right like great ladies have a struct called meeting you ID and and recording uuid in which we already have just need to convert them to you. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.85487723 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "And also it is not that does not show up in the join list like the front end in the clients. \n",
      "\n",
      "comparison sentence:  And also it is not that does not show up in the join list like the front end in the clients. ====>  1.0 \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.7825554 \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  0.7745512 \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.7700623 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "You can launch a WPA will support it but joining never showed. \n",
      "\n",
      "comparison sentence:  You can launch a WPA will support it but joining never showed. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  0.8363667 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.82283753 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, you cannot in front and the other the API will support it. \n",
      "\n",
      "comparison sentence:  Yeah, you cannot in front and the other the API will support it. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Basically that if we want we can do it in the front and also ====>  0.89141256 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.8673457 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. \n",
      "\n",
      "comparison sentence:  Yeah, that will be shown that will be shown here cast will be shown in the recent meetings, but we do not have any like there are no two lists, like only costs and meetings. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  0.8058135 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Basically that if we want we can do it in the front and also \n",
      "\n",
      "comparison sentence:  Basically that if we want we can do it in the front and also ====>  1.0 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.87001747 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.85122854 \n",
      "\n",
      "comparison sentence:  Oops, mr. Scopes that you needed because and then get user by user ID. ====>  0.8193083 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, but we should not show the trait which we are not even replying back in the active meetings list. \n",
      "\n",
      "comparison sentence:  Yeah, but we should not show the trait which we are not even replying back in the active meetings list. ====>  1.0 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.8541121 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.8453989 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Source like a wrapper around that first to want to use a Google aps looks like in at the pole that is one thing and there are few things that I need to check on the event list you can see there are two calendars the to APS we can use so you are you want to use only the calendar things Google Calendar eraser there you want to go through the emails a Google Gmail appear so there I think we can start with The calendar EPs and then you can see if you can all the people of all the things that were neither getting from this AP this APA then calendar equation will be enough for us get started. \n",
      "\n",
      "comparison sentence:  Source like a wrapper around that first to want to use a Google aps looks like in at the pole that is one thing and there are few things that I need to check on the event list you can see there are two calendars the to APS we can use so you are you want to use only the calendar things Google Calendar eraser there you want to go through the emails a Google Gmail appear so there I think we can start with The calendar EPs and then you can see if you can all the people of all the things that were neither getting from this AP this APA then calendar equation will be enough for us get started. ====>  1.0 \n",
      "\n",
      "comparison sentence:  Oops, mr. Scopes that you needed because and then get user by user ID. ====>  0.75370747 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.7465507 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.7168822 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.68876415 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. \n",
      "\n",
      "comparison sentence:  I created a new sample app, which is like a mix of even we could based on the and what app Zoom it could be expected. ====>  1.0 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.86137855 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8217551 \n",
      "\n",
      "comparison sentence:  The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. ====>  0.8133593 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I was able to install receive events and the able to generate the token you too. \n",
      "\n",
      "comparison sentence:  I was able to install receive events and the able to generate the token you too. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.82748747 \n",
      "\n",
      "comparison sentence:  The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. ====>  0.80069995 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.7657545 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.76114976 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. \n",
      "\n",
      "comparison sentence:  The one one good thing is like when we tested last time a few months back with there was no way to get the account account ID for the insulation right Zoom account ID. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8723883 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.84328675 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "They have added it in the user list is a response. \n",
      "\n",
      "comparison sentence:  They have added it in the user list is a response. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.73341936 \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  0.7313473 \n",
      "\n",
      "comparison sentence:  We need to create a separate email address for each and every board quickly verify that if you get set up. ====>  0.72984797 \n",
      "\n",
      "comparison sentence:  Oops, mr. Scopes that you needed because and then get user by user ID. ====>  0.72523767 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. \n",
      "\n",
      "comparison sentence:  So so now it is possible to be in at least at least we can have a Mapping of Zoom account to our installation earlier. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  0.8530575 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. \n",
      "\n",
      "comparison sentence:  I was just going through some stack Overflow things know where it is mention that we can you know, add a hook so that go sense events to that. ====>  1.0 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.8767249 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So you can put your second events also was working for unexpected ones out then that I have like there is a dissipation Industries now, then there are few Sports. \n",
      "\n",
      "comparison sentence:  So you can put your second events also was working for unexpected ones out then that I have like there is a dissipation Industries now, then there are few Sports. ====>  1.0 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.8407777 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Oops, mr. Scopes that you needed because and then get user by user ID. \n",
      "\n",
      "comparison sentence:  Oops, mr. Scopes that you needed because and then get user by user ID. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  0.80031 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. \n",
      "\n",
      "comparison sentence:  And so those things all sorry check it out once but I bought it there yesterday and I started looking in this calendar integration. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.8650484 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "But Google base is a is it looks like there is no way through kind of thing. \n",
      "\n",
      "comparison sentence:  But Google base is a is it looks like there is no way through kind of thing. ====>  0.99999994 \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  0.8476606 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. \n",
      "\n",
      "comparison sentence:  Yeah, I think I think there are technical of the polling themself and they are pushing the north deficient was I will go through the EPA Google apis a little bit. ====>  1.0 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.8777228 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.86982197 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "There are ways can do push notifications also, let me let me go through the months. \n",
      "\n",
      "comparison sentence:  There are ways can do push notifications also, let me let me go through the months. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  0.76341444 \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  0.7284176 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I just wanted to see if you are getting the Alias email lady. \n",
      "\n",
      "comparison sentence:  I just wanted to see if you are getting the Alias email lady. ====>  1.0 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Also, if you do not get it, then like it will be huge overhead for us first. \n",
      "\n",
      "comparison sentence:  Also, if you do not get it, then like it will be huge overhead for us first. ====>  0.99999994 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "We need to create a separate email address for each and every board quickly verify that if you get set up. \n",
      "\n",
      "comparison sentence:  We need to create a separate email address for each and every board quickly verify that if you get set up. ====>  1.0000001 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "One more thing is I was added to change to print out every one the channel when someone issues a summarize. \n",
      "\n",
      "comparison sentence:  One more thing is I was added to change to print out every one the channel when someone issues a summarize. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  0.87516874 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "I am just working on a bi that address the bunch of issues right now. \n",
      "\n",
      "comparison sentence:  I am just working on a bi that address the bunch of issues right now. ====>  1.0000001 \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  0.87215364 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. \n",
      "\n",
      "comparison sentence:  There are diversities in cases where Zoom or to summarization of failing so I fix them added deleted. ====>  0.99999994 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So with the other negation that I am testing the slack connectors and the other thing is being able to unify all the basic validations at the bottom level for things like whether the bot is present in the meeting. \n",
      "\n",
      "comparison sentence:  So with the other negation that I am testing the slack connectors and the other thing is being able to unify all the basic validations at the bottom level for things like whether the bot is present in the meeting. ====>  0.99999994 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "Present in the room is if it is a DM and the other stuff that we commonly do for any kind of operations at from slack to compare when they are issued from commands or when we issue slack API call to create a meeting Etc. \n",
      "\n",
      "comparison sentence:  Present in the room is if it is a DM and the other stuff that we commonly do for any kind of operations at from slack to compare when they are issued from commands or when we issue slack API call to create a meeting Etc. ====>  1.0 \n",
      "\n",
      "------sentence------- \n",
      "\n",
      "So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. \n",
      "\n",
      "comparison sentence:  So I am just testing the changes line on fixing some bugs and PR is that And once it is Valerie, we can merge it so that will help solve some of the bugs that we have right now with respect to Auto summarization and just handling the summer. ====>  1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nodea in scores.keys():\n",
    "    print (\"------sentence-------\", \"\\n\")\n",
    "    print (graph_list[nodea][0], \"\\n\")\n",
    "    for values in scores[nodea][:5]:\n",
    "        print (\"comparison sentence: \", graph_list[values[0]][0], \"====> \", values[1]['weight'], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PIMs for the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:32:07.101125Z",
     "start_time": "2019-10-16T09:32:07.014546Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import client\n",
    "from botocore.client import Config\n",
    "import numpy as np\n",
    "import json\n",
    "aws_config = Config(\n",
    "        connect_timeout=60,\n",
    "        read_timeout=300,\n",
    "        retries={\"max_attempts\": 0},\n",
    "        region_name=\"us-east-1\",\n",
    "    )\n",
    "lambda_client = client(\"lambda\", config=aws_config)\n",
    "\n",
    "def get_pims_score(req):\n",
    "\n",
    "    #if req_data is None:\n",
    "    #    lambda_payload = {\"body\": input_list}\n",
    "    #    print (json.dumps(lambda_payload))\n",
    "    #else:\n",
    "    #    lambda_payload = {\"body\": {\"request\": req_data, \"text_input\": input_list}}\n",
    "        \n",
    "    try:\n",
    "        #logger.info(\"Invoking lambda function\")\n",
    "        invoke_response = lambda_client.invoke(\n",
    "            FunctionName=\"pim\",\n",
    "            InvocationType=\"RequestResponse\",\n",
    "            Payload=json.dumps(req),\n",
    "        )\n",
    "        lambda_output = (\n",
    "            invoke_response[\"Payload\"].read().decode(\"utf8\")\n",
    "        )\n",
    "        response = json.loads(lambda_output)\n",
    "        status_code = response[\"statusCode\"]\n",
    "        response_body = response[\"body\"]\n",
    "\n",
    "        #if status_code == 200:\n",
    "        #    result = json.loads(response_body)['d2vResult'][0]['distance']\n",
    "        return response_body\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:32:55.418939Z",
     "start_time": "2019-10-16T09:32:07.762456Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pim_result = {}\n",
    "pim_response = {}\n",
    "pim_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\"}\n",
    "pim_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\", \"segments\": []}\n",
    "temp = {}\n",
    "for seg in request['body']['segments']:\n",
    "    pim_request[\"segments\"] = [seg]\n",
    "    # get_pims_score({\"body\":pim_request})\n",
    "    pim_result[seg[\"recordingId\"]] =  get_pims_score({\"body\":pim_request})\n",
    "    temp = seg\n",
    "    temp[\"distance\"] = pim_result[seg[\"recordingId\"]]\n",
    "    pim_response[\"segments\"].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:47.292227Z",
     "start_time": "2019-10-16T09:33:47.205140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for seg in pim_response[\"segments\"]:\n",
    "    result.append( (seg[\"originalText\"], seg[\"distance\"], seg[\"recordingId\"]))\n",
    "result = sorted(result, key=lambda kv:kv[1])\n",
    "for (text, score, segid) in result:\n",
    "    print (text , \" =====> \", score, segid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T07:16:12.948463Z",
     "start_time": "2019-10-16T07:16:12.892361Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract topic level pims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:49.539609Z",
     "start_time": "2019-10-16T09:33:49.494149Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import extract_topic_pims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:52.577313Z",
     "start_time": "2019-10-16T09:33:52.520939Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from extract_topic_pims.main import handler\n",
    "\n",
    "res = handler({\"body\":{\"groups\": group[\"group\"], \"pims\": pim_response}}, None)\n",
    "final_pims = json.loads(res)[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:56.517504Z",
     "start_time": "2019-10-16T09:33:56.462922Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "user_id_map = {\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Shubham\",\"2cd90f0674f348cc922acd6b8782ba0f\":\"Shubham\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep Moradia\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ai-engine/pkg/\")\n",
    "\n",
    "from graphrank.core import GraphRank\n",
    "from graphrank.utils import GraphUtils, TextPreprocess\n",
    "\n",
    "gr = GraphRank()\n",
    "tp = TextPreprocess()\n",
    "gu = GraphUtils()\n",
    "\n",
    "def get_desc(sentence):\n",
    "    original_tokens, pos_tuple, filtered_pos_tuple = tp.preprocess_text(sentence, filter_by_pos=True, stop_words=False)\n",
    "    word_graph = gr.build_word_graph(graph_obj=None, input_pos_text=pos_tuple, window=4, preserve_common_words=False)\n",
    "    normal_keyphrase = gr.get_keyphrases(word_graph, pos_tuple, post_process=True)\n",
    "    desc_keyphrase = gr.get_keyphrases(word_graph, pos_tuple, descriptive=True, post_process_descriptive=True)\n",
    "    desc_keyphrase = sorted(desc_keyphrase, key=lambda kv:kv[1], reverse=True)\n",
    "    normal_kp = [phrase for phrase, score in normal_keyphrase]\n",
    "    desc_kp = [phrase for phrase, score in desc_keyphrase]\n",
    "    \n",
    "    return normal_kp, desc_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:34:06.058534Z",
     "start_time": "2019-10-16T09:34:05.255435Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for groupid in final_pims:\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in groupid:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    print (\"Keyphrases: \", end=\"\")\n",
    "    print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:34:01.892976Z",
     "start_time": "2019-10-16T09:34:01.837042Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "user_id_map = {\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing hierarchy community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:02:27.110487Z",
     "start_time": "2019-09-30T15:02:27.050494Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('topic_testing/podcast_28.txt', 'rb') as f:\n",
    "    request = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:04:15.380539Z",
     "start_time": "2019-09-30T15:02:27.410077Z"
    }
   },
   "outputs": [],
   "source": [
    "from main import handler\n",
    "\n",
    "res = handler(request, None)\n",
    "group = json.loads(res['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:05:44.525847Z",
     "start_time": "2019-09-30T15:05:44.435681Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "m_time = formatTime(\"2019-09-28T05:34:21Z\", True)\n",
    "#m_time = formatTime(\"2019-09-30T10:28:00Z\", True)\n",
    "for i in group['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:16:21.322195Z",
     "start_time": "2019-09-30T15:16:21.261435Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = []\n",
    "for i in group['group'].keys():\n",
    "    if len(group['group'][i])==1:\n",
    "        continue\n",
    "    else:\n",
    "        temp = []\n",
    "        for seg in group['group'][i]:\n",
    "            temp.append(seg['originalText'])\n",
    "        groups.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:17:35.047968Z",
     "start_time": "2019-09-30T15:16:21.757535Z"
    }
   },
   "outputs": [],
   "source": [
    "group_result = {}\n",
    "#group_response = {}\n",
    "group_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01daaqyn9gbebc92aywnxedp0c\", \"instanceId\": \"xyz\"}\n",
    "#group_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DADP74WFV607KNPCB6VVXGTG\", \"segments\": []}\n",
    "temp = {}\n",
    "group_itr = None\n",
    "for segments_id in group['group'].keys():\n",
    "    if len(group['group'][segments_id]) > 2:\n",
    "        group_request['segments'] = group['group'][segments_id]\n",
    "        res = handler({\"body\":group_request}, None)\n",
    "        group_itr = json.loads(res['body'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:21:36.916596Z",
     "start_time": "2019-09-30T15:21:36.514422Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:28:00Z\", True)\n",
    "m_time = formatTime(\"2019-09-28T05:34:21Z\", True)\n",
    "for i in group_itr['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group_itr['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:29:39.535024Z",
     "start_time": "2019-09-30T14:29:07.063968Z"
    }
   },
   "outputs": [],
   "source": [
    "group_result = {}\n",
    "#group_response = {}\n",
    "group_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DADP74WFV607KNPCB6VVXGTG\", \"instanceId\": \"xyz\"}\n",
    "#group_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DADP74WFV607KNPCB6VVXGTG\", \"segments\": []}\n",
    "temp = {}\n",
    "group_itr_2 = None\n",
    "for segments_id in group_itr['group'].keys():\n",
    "    if len(group_itr['group'][segments_id]) > 2:\n",
    "        group_request['segments'] = group_itr['group'][segments_id]\n",
    "        res = handler({\"body\":group_request}, None)\n",
    "        group_itr_2 = json.loads(res['body'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:30:41.736210Z",
     "start_time": "2019-09-30T14:30:41.595388Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:28:00Z\", True)\n",
    "for i in group_itr_2['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group_itr_2['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:12:14.592267Z",
     "start_time": "2019-09-30T14:12:14.446839Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:08:00Z\", True)\n",
    "for i in group['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ai-engine/pkg/\")\n",
    "import math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from boto3 import client as boto3_client\n",
    "import json\n",
    "import logging\n",
    "from botocore.client import Config\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "config = Config(connect_timeout=240, read_timeout=240, retries={'max_attempts': 0} )\n",
    "lambda_client = boto3_client('lambda', config=config,     aws_access_key_id=\"AKIA5SUS6MWO4MP7KDEJ\",\n",
    "    aws_secret_access_key=\"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\"\n",
    ")\n",
    "\n",
    "def get_output(input_sent, req_data=None):\n",
    "    #aws_config = Config(\n",
    "    #    connect_timeout=60,\n",
    "    ##    read_timeout=300,\n",
    "    #    retries={\"max_attempts\": 0},\n",
    "    #    region_name=\"us-east-1\",\n",
    "    #)\n",
    "    #lambda_client = boto3_client(\"lambda\", config=aws_config)\n",
    "    if req_data is None:\n",
    "        lambda_payload = input_sent\n",
    "    #logger.info(\"Invoking lambda function\")\n",
    "    invoke_response = lambda_client.invoke(\n",
    "        FunctionName=\"arn:aws:lambda:us-east-1:933389821341:function:group-segments\",\n",
    "        InvocationType=\"RequestResponse\",\n",
    "        Payload=lambda_payload\n",
    "    )\n",
    "    print (\"response recieved\", invoke_response)\n",
    "    lambda_output = (\n",
    "        invoke_response[\"Payload\"].read().decode(\"utf8\").replace(\"'\", '\"')\n",
    "    )\n",
    "    response = json.loads(lambda_output)\n",
    "    status_code = response[\"statusCode\"]\n",
    "    response_body = response[\"body\"]\n",
    "\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"topic_testing/sync_eng_21_10.txt\",\"rb\") as f:\n",
    "    request = json.load(f)\n",
    "response = get_output(json.dumps(request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = response\n",
    "user_id_map = {}\n",
    "user_id_map = {\"716067a60a1a4034abc49a12ecafb39b\":\"Ether\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"ether\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
