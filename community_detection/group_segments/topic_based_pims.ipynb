{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T10:00:32.508599Z",
     "start_time": "2019-10-14T10:00:32.471648Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T10:00:32.908196Z",
     "start_time": "2019-10-14T10:00:32.654982Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T07:40:18.128408Z",
     "start_time": "2019-10-15T07:40:17.658160Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('topic_testing/validation_set.txt', 'rb') as f:\n",
    "    request = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T07:40:23.191387Z",
     "start_time": "2019-10-15T07:40:19.752138Z"
    }
   },
   "outputs": [],
   "source": [
    "from main import handler\n",
    "\n",
    "res = handler(request, None)\n",
    "group = json.loads(res['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T10:35:32.826188Z",
     "start_time": "2019-10-03T10:35:18.213Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:08:00Z\", True)\n",
    "for i in group['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T13:10:47.227956Z",
     "start_time": "2019-10-08T13:10:14.001Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import client\n",
    "from botocore.client import Config\n",
    "import numpy as np\n",
    "import json\n",
    "aws_config = Config(\n",
    "        connect_timeout=60,\n",
    "        read_timeout=300,\n",
    "        retries={\"max_attempts\": 0},\n",
    "        region_name=\"us-east-1\",\n",
    "    )\n",
    "lambda_client = client(\"lambda\", config=aws_config)\n",
    "\n",
    "def get_pims_score(req):\n",
    "\n",
    "    #if req_data is None:\n",
    "    #    lambda_payload = {\"body\": input_list}\n",
    "    #    print (json.dumps(lambda_payload))\n",
    "    #else:\n",
    "    #    lambda_payload = {\"body\": {\"request\": req_data, \"text_input\": input_list}}\n",
    "        \n",
    "    try:\n",
    "        #logger.info(\"Invoking lambda function\")\n",
    "        invoke_response = lambda_client.invoke(\n",
    "            FunctionName=\"pim\",\n",
    "            InvocationType=\"RequestResponse\",\n",
    "            Payload=json.dumps(req),\n",
    "        )\n",
    "        lambda_output = (\n",
    "            invoke_response[\"Payload\"].read().decode(\"utf8\")\n",
    "        )\n",
    "        response = json.loads(lambda_output)\n",
    "        status_code = response[\"statusCode\"]\n",
    "        response_body = response[\"body\"]\n",
    "\n",
    "        if status_code == 200:\n",
    "            result = json.loads(response_body)['d2vResult'][0]['distance']\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T13:10:47.229189Z",
     "start_time": "2019-10-08T13:10:42.510Z"
    }
   },
   "outputs": [],
   "source": [
    "pim_result = {}\n",
    "pim_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01daaqyn9gbebc92aywnxedp0c\"}\n",
    "for seg in request['body']['segments']:\n",
    "    pim_request[\"segments\"] = [seg]\n",
    "    # get_pims_score({\"body\":pim_request})\n",
    "    pim_result[seg[\"recordingId\"]] =  get_pims_score({\"body\":pim_request})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:28:32.051879Z",
     "start_time": "2019-09-26T16:28:14.172Z"
    }
   },
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:28:32.053215Z",
     "start_time": "2019-09-26T16:28:20.726Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_pim = {\n",
    "}\n",
    "group_result = {}\n",
    "for keys in group['group'].keys():\n",
    "    for seg in group['group'][keys]:\n",
    "        group_result[seg['recordingId']] = keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:28:32.054521Z",
     "start_time": "2019-09-26T16:28:23.077Z"
    }
   },
   "outputs": [],
   "source": [
    "ranked_pims = sorted([(k,v) for (k,v) in pim_result.items()], key= lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:28:32.055869Z",
     "start_time": "2019-09-26T16:28:25.308Z"
    }
   },
   "outputs": [],
   "source": [
    "used_topics = []\n",
    "group_no = None\n",
    "index = 0\n",
    "for (rec_id, distance) in ranked_pims:\n",
    "    if rec_id in group_result.keys():\n",
    "        group_no = group_result[rec_id]\n",
    "        \n",
    "        if group_no not in used_topics:\n",
    "            topic_pim[index] = group_no\n",
    "            used_topics.append(group_no)\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T12:24:15.350052Z",
     "start_time": "2019-09-24T12:24:15.315045Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_pim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T12:27:53.496456Z",
     "start_time": "2019-09-24T12:27:53.452298Z"
    }
   },
   "outputs": [],
   "source": [
    "final_output = []\n",
    "final_output = list(map(lambda x: group['group'][x] , topic_pim.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T12:29:57.846996Z",
     "start_time": "2019-09-24T12:29:57.814595Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T12:30:55.676310Z",
     "start_time": "2019-09-24T12:30:55.644859Z"
    }
   },
   "outputs": [],
   "source": [
    "users = []\n",
    "for result in final_output:\n",
    "    temp_users = []\n",
    "    for seg in result:\n",
    "        if seg['spokenBy'] not in temp_users:\n",
    "            temp_users.append(seg['spokenBy'])\n",
    "    users.append(temp_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T12:30:57.563763Z",
     "start_time": "2019-09-24T12:30:57.531893Z"
    }
   },
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing topic level pims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read json Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T12:08:19.066028Z",
     "start_time": "2019-10-16T12:08:15.539283Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "import json\n",
    "\n",
    "with open('topic_testing/sync_ml_24_10.txt', 'rb') as f:\n",
    "    request = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment:  Train your wicked. \n",
      "Segment:  Karthik is not giant it right. \n",
      "Segment:  three \n",
      "Segment:  that tree \n",
      "Segment:  That so I just sharing the screen of one of the meeting read just now. It happened on engineering Channel. Yeah. \n",
      "Segment:  The third eye. \n",
      "Segment:  It is the same problem again. \n",
      "Segment:  If you see the screen, right, I have one log. it says so these are the input segmented is which have got we are able to see right when that \n",
      "Segment:  Can you hear me? Yeah, these are they win today? \n",
      "Segment:  Yeah, the group segmented is her like mostly like to two segments are grouped. And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than 120 seconds. Yeah, that's the reason. \n",
      "Segment:  I don't know the meeting duration total duration. What does it on all let me see eight minutes. \n",
      "Segment:  28 minutes and then there are there are enough. Subject of peace and humanely tell that we should have expected. \n",
      "Segment:  in any call they \n",
      "Segment:  At least one chapter coming out right like I mean if I'm wrong. \n",
      "Segment:  No, at least in my code. I haven't written like that. If it is less than 120 just there's no fallback mechanism or anything. \n",
      "Segment:  We try to take the larger segment. You larger segment like for Alpha larger segments. \n",
      "Segment:  Farm back from the chapters of should be there, you know. \n",
      "Segment:  This is doing is just what happened and get it for you didn't see that the mostly less than 120 seconds with them. So they have filters. Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like 120 seconds is a hard limit. \n",
      "Segment:  I would say I would like you somewhere to find this is a qualitative group and which is not \n",
      "Segment:  Okay. Yeah so that you don't have to hard limit based on time true. \n",
      "Segment:  Okay. So right now I can remove that hard limit is \n",
      "Segment:  Yes, you can it's make the product magnetic sensor consists for the names of my service itself. If it's 10 seconds, if you want to remove the condition make it make it less than threshold for now. We'll until we finalize something. \n",
      "Segment:  Well one threshold that same 10 seconds. \n",
      "Segment:  Maybe 10 seconds or something as a placeholder. So inside or today's call it happen. \n",
      "Segment:  Okay, its production rate so it's not even updated. Yeah, I have to like like four to five watches. \n",
      "Segment:  It's like I didn't have enough time to test so I just kept introductions. \n",
      "Segment:  Let's discuss on the community thing, right? So so I had looked at that tart that flowchart Witcher 3 had sent rate on the earlier. The design-wise it's fine. But with respect to the API a signature ways. I wanted to discuss like what are the request response those things basically? \n",
      "Segment:  It would be the same like whatever you give for scorer service, right? Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right? \n",
      "Segment:  Now instead of distance core, we would just send an acknowledgement that we have analyzed it. \n",
      "Segment:  Okay, okay, he won't be expecting any scores. But the name Remains the Same or itself should be different, right? \n",
      "Segment:  AP name should be different. \n",
      "Segment:  Yeah, because we will be using interchangeable if we want to use that courting ritual. \n",
      "Segment:  You create a new one will create a whole service Revenue Service. So I would be so it's a new URL. \n",
      "Segment:  But the APA signature and everything would change a peer response will remain a little bit different which could be same response would be different. Okay? \n",
      "Segment:  With respect to the first one the second the API. What is the request is nothing right only the instance ID unit meeting insensitive or whatever. \n",
      "Segment:  Yes, I'm flag with the value that song. \n",
      "Segment:  no, we need you need the \n",
      "Segment:  BB we need all the signals or segments \n",
      "Segment:  Yes. Because I'm storing only the feature vectors. \n",
      "Segment:  Group Services Under Equus right now. Is it like girl you same way same way you have to send for the new service. \n",
      "Segment:  No, not like first 10 or 10 20 or something different. \n",
      "Segment:  And just dump everything on Tinder like the current chapters like four chapters chapter summary. You sent a request with the same request you present for new service. \n",
      "Segment:  Okay that new Services. It's a different name or it's a shame. It's already done. \n",
      "Segment:  Colonel be the should create like first we wanted to discuss with how the December after that. \n",
      "Segment:  Find anything so we can do it. Yeah, so that is also Lambda is \n",
      "Segment:  First one is also Lambda or it's a service rate the current service on this end. The team's core service. \n",
      "Segment:  Lentils and we are creating new ones service which would replace the current room service. Okay. Okay. Thank you. \n",
      "Segment:  So you would make a pair called the landlord be same for both APA Falls, except the page the input changes. \n",
      "Segment:  So just so that we're all on the same page. Let me just reiterate what has been mentioned in the \n",
      "Segment:  Won't let me discuss share the speech. \n",
      "Segment:  So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary. These are the some regeneration process. But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one. \n",
      "Segment:  Yes, it's a segment analyzer service, right? That's the one. \n",
      "Segment:  Depends. Oh, is that so? \n",
      "Segment:  So maybe then we need to be able to configure which one to liquid at least inject which analyzer to choose at least you can start off with staging and select one analyzer in production. You can use Channel mind itself. \n",
      "Segment:  But the problem here is we should not be working. Actually, there is some more work here with it because they're actually returning some data and the original one the second one. They're not attending any data. \n",
      "Segment:  Currently, but we will have to update some default values or some. \n",
      "Segment:  Some default like -1 or something like the score so that will not pick that values. \n",
      "Segment:  I'll be your video using those values. \n",
      "Segment:  We will be using those where we were using only the older version like to get the score the only top 10 in kind of thing, right but in this new one, we don't need anything because we don't have any data, right? \n",
      "Segment:  For example, let's say when I call this new servers on let's do this. We Implement in your analyzer right B it information and return. Okay object or datum status. Okay Android if nothing is written in their objective some pre-processing error. There's something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code \n",
      "Segment:  But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there. \n",
      "Segment:  There is no interpreter time. \n",
      "Segment:  Okay. \n",
      "Segment:  Bass holder, but do we fill with something the end of the meeting at least that? \n",
      "Segment:  It depends if we know what segment ideas we should probably update the key phrases like video right now because we use it. \n",
      "Segment:  So we'll update that keywords or something. Is there at that field will have to update once we get it? \n",
      "Segment:  now \n",
      "Segment:  But we need to know the mapping for that. Whatever the text they give right? We need to know the segment ready for. \n",
      "Segment:  DWS. Yeah, here is the same thing. That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here. The next sentence is a text when a field called text and a hiding with the sentence belong funny. \n",
      "Segment:  Under the we like we need to purchase those sentences for one segment. It was pretty to some for sentences. \n",
      "Segment:  Why do we need that purses the sentences? \n",
      "Segment:  Can one leader key phrases extracted? \n",
      "Segment:  For each no because of the people we don't need two sentences for anything. \n",
      "Segment:  Come back to school we call this analyzer and staging we just created as a subject in the current table as it is and they hate us and the actual NLP readers empty. Let's say 4 is minus 1 are some negative value meaning that they're not even anything correctly. We had already doing for visits. \n",
      "Segment:  Knowing that a pending State I use some value actually, which is actually float64 value, right? \n",
      "Segment:  Do some huge number actually add some Randomness and final value basically that waking up. \n",
      "Segment:  That will be what it is and let's do this is over. Yeah. \n",
      "Segment:  Analyze menu, and then we also have mid-segment analyzed and we pass analysis object left with it. \n",
      "Segment:  We evident even definitely girl second analyzed. Is it only for triggering summary or is it about doing anything? \n",
      "Segment:  No, nothing else only for somebody on there. \n",
      "Segment:  So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted. All segments have been transcribed. The Randy is over recording available. We will trigger somebody header like with the new strategy. Yeah, and it's one. What'd you do is 3/4 gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth. that they using for grouping the \n",
      "Segment:  I'm assuming this is not the same as the current one. \n",
      "Segment:  It would be different. \n",
      "Segment:  okay, becoming a different service for grouping the \n",
      "Segment:  Gil Gil just call everything a segment on a laser it's the same service so I think so. \n",
      "Segment:  Replace the film service during the live call in. All it does is like it analyzes the segment each segment separately stores if each other Vector area so setting \n",
      "Segment:  the same land \n",
      "Segment:  They do the same land up like at the end of the call. You will give give them. \n",
      "Segment:  Isn't separate Lambda deployment or is the same Lumber deployment? \n",
      "Segment:  Different different rate. Is it the separate language requirement of the same Lambda to promote the to to little methods is the same language. \n",
      "Segment:  Yeah. \n",
      "Segment:  Going to call and well and the second number is no number service. Yeah, let's let's discuss this in the next. \n",
      "Segment:  Community let's assume it's the same deployment because what you're doing is you're accepting features and you're just using those features and breaking the sentence article with somebody right to deserve. This is what your goal is. So in this one so but is it up' can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective. \n",
      "Segment:  Like if you want to change the input and asking whether it can be used for anything. \n",
      "Segment:  I'm saying one is doing feature extraction one is we during the call are doing protects pre-processing on each segment and doing feature extraction and returning okay of error. Yes at the end of the curve you getting all the segments and you're doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment's to which they belong right? \n",
      "Segment:  So are they very tightly coupled with each other. That means they cannot be reused for the second one. \n",
      "Segment:  Not necessarily think we can just call the second part separately, too. \n",
      "Segment:  No, no, it is ends that can is it a reusable they give you? \n",
      "Segment:  Everybody don't use exact as tomorrow the same thing can be used. \n",
      "Segment:  It's just parameters and then we have to like the feature extraction would be like a single step instead of only that's all. \n",
      "Segment:  Okay, then for now just keep it as the same Lambda but have distinct, you know code structure so that they are not necessarily. \n",
      "Segment:  It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now. It's this right the rapper service or on both of them. \n",
      "Segment:  Okay inmates are mean is different. \n",
      "Segment:  Yes, it's over. \n",
      "Segment:  Okay, so then we'll come to deployment separately less assuming. Let's assume that I'm hitting the a Lambda function with all the segments and I'm getting a group set set of groupings with each object. Let's say in group 1 it's an array of Group 1 is an array of objects embolism, right? Yes, Each of which would contain the segment ID as a field and the text and the sentence. To which another field called sentence? \n",
      "Segment:  It would contain all the information of the original segment. \n",
      "Segment:  Plus alter takes as a key and the value. \n",
      "Segment:  Okay, you are okay. \n",
      "Segment:  Afraid you don't have to. \n",
      "Segment:  I have that. I am carrying all that information at that point. If you want me to give I can give it your all. \n",
      "Segment:  Do what you want to use then give it? and is of the altered X. Okay, so and it'll also add a new field called feel call or text in each object. Yeah. \n",
      "Segment:  I'm not really in a one single group for you can have duplicate segments, right? \n",
      "Segment:  Oh, no, no bill group it right so each. \n",
      "Segment:  what I was like \n",
      "Segment:  Beginnings segment sadness \n",
      "Segment:  No, no from oneself pantyhose. You can split into multiple sentences, right? \n",
      "Segment:  So if one segment splits, it has multiple sentences. Yeah, that would be grouped as a single segment only we want again spread that. \n",
      "Segment:  They are giving the or text as three three sentences separated by full stops. Yes. Okay, so that means everything. \n",
      "Segment:  Valium which all right. It's like key is a segment segment and value is ASL. Just a string. \n",
      "Segment:  Actually, he's saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text. We will not contain all the sentences from the original segment, but only the Filter Works. \n",
      "Segment:  So this anything current sub to service its you have the response which you get would be the same as this new service. \n",
      "Segment:  One more field in the same segment object itself is it? \n",
      "Segment:  But as we can we'll have to create a temporary structure in that format then. \n",
      "Segment:  But we don't need to store all the will just take whatever they want from. Okay? \n",
      "Segment:  Let's create Embrace such as the strategy package, okay? \n",
      "Segment:  Slipping so do you are or would it be easier? I don't know. It would definitely be using the anything else great, except the Alta text. So what if the format is just a group list of segments and the associated alter text. \n",
      "Segment:  Giving right now, it's fine. Whatever. You said earlier this maybe change all the text to something more. \n",
      "Segment:  Exactly. So included you have group 0 and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative. \n",
      "Segment:  Okay, so once that is done. For each group then do we extract the key phrases for all the segments in a group? \n",
      "Segment:  the altar text \n",
      "Segment:  What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service. Yes generation field called Don't extract don't populate the graph. He will go give us a key phrases for that. And you want us to make basically they were in groups. We make any concurrent calls to get the key phases for each group. \n",
      "Segment:  So once that is done, let's assume we got all the for each group. We get key places. What do we do do we? Need to filter or reduce any counter. We just take medication. \n",
      "Segment:  I think if it goes with I think the same logic that's going to intense actress currently a which session is a concept called here. Also, that means he pick up the number of pieces you can see. \n",
      "Segment:  That is that is our first group a number of key phrases, right? Yeah, like so you have some 20 groups if you have done right do we? \n",
      "Segment:  No, we would give you only top five. \n",
      "Segment:  Okay. Okay. So, let's see. \n",
      "Segment:  But five and then if you see if we have a better way of making it have adaptive we will we will only take care of that. It need not be filtered there. \n",
      "Segment:  Just so that we're on the same page because this is a replacement chapter. This will be Topic in his essentially. \n",
      "Segment:  But it would be it would have more depth than the chapters. \n",
      "Segment:  Okay. Love you want. \n",
      "Segment:  Number of groups we would actually have like very high number of groups we would again use the rankings to take on it outside. \n",
      "Segment:  I know but does that help because we want to give them topics in the connotation. \n",
      "Segment:  Are you talking about topics as the markers or The Pimps idea? \n",
      "Segment:  Okay, that's no difference. Now the new summary it's there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create. That's the that's what we discussed earlier also. \n",
      "Segment:  If you go with it. \n",
      "Segment:  Otherwise this Remains the Same. I mean end user experience will not change much. \n",
      "Segment:  No, not not that big a dick. So what happens is like it's similar to Chapters. You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights. So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion. \n",
      "Segment:  Let me put it this way. If I had to push back to slack with two sections one is topics and one of the actions. Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that. \n",
      "Segment:  What are giving the abdomen? \n",
      "Segment:  Okay, then there is. No then we have to be real should not hard limit on Facebook. \n",
      "Segment:  If you had limit on five you want to cover the whole years is at least as a big thing. Let's assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics. They are like either is relevant or something, but it's that's what so if that is it on high level of difference between chapters. \n",
      "Segment:  It's the same. It's the same. \n",
      "Segment:  And do the end of the cannot distinguish, baby. \n",
      "Segment:  It's the same so good. So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important. Is that whether it is five or six or seven? \n",
      "Segment:  We thought we will stick to five for now and then do that but that's not really that doesn't stop anything. I say so even even now that still remain so what are we return you will show everything or if you don't want it to be clever put an upper limit put a upper limit to better manage the space. \n",
      "Segment:  space \n",
      "Segment:  Yeah, if you don't want to know if we wait. \n",
      "Segment:  Stayed out and seeding will only enable strategy for space. So let's put a full limit me on this. But essentially the idea is the same thing, right if we could use the highlighter topics. Nobody comes. \n",
      "Segment:  Yeah, I got it. Yeah, so we we we are just limiting it 5-4 to be in line with with this but we can doesn't mean anything. Yes. Here's the challenge. \n",
      "Segment:  Runs, let's assume we do get groupings, right? \n",
      "Segment:  Be may need to reject some items that don't that overlap with the manual markers. \n",
      "Segment:  Maybe not immediately, but that's if you go to production that might be needed. We need to First other words coming back and then decide how this will be. But just you have to keep that in mind. \n",
      "Segment:  Karthik one one thing. So how is that rejection associated with \n",
      "Segment:  Improving service array basically if you're giving a segments, yeah, you can see that there are some between this time range. We found something for you as a topic and within that time range itself be graded on someone read a manual marker. Hmm. It should prefer that to this one. \n",
      "Segment:  Yeah, but when we say we found topic we give them a list of subtopics and everything, right? But the mile marker doesn't contain those things. \n",
      "Segment:  But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye. Okay, you just by looking at them even slap. \n",
      "Segment:  Okay, so then don't don't show it in the slack, but you still have to propagate that to the graphs and every other turn same class that uses this. \n",
      "Segment:  That might be true, but that's finding somebody else will ever do. \n",
      "Segment:  Yeah, it's a bird watching than fine. \n",
      "Segment:  Yeah that we can take it up right Karthik the the market. \n",
      "Segment:  That's so yeah, you don't have to do in the pool right now. Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later. We can side of correlate. Okay, let's do overlap macon's do we remove this or do we keep this or what makes sense? \n",
      "Segment:  But generally the idea was if you had sections of topics actions and decisions and we just did a great job on discovering them and someone had given some signals we take that and use that instead of words automatically. \n",
      "Segment:  We do the same for actions as well. So we'll have to have like a pipeline for that like in each section that we publish. \n",
      "Segment:  Karthik event got the laptop chargers down. Actually, there's no power from two or three hours. I think I am trying to connect some iOS but it is fairly. \n",
      "Segment:  Yeah, okay. Thanks Martin. So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready? So that method can start working on it. Right? You mean the response structure? Yeah. \n",
      "Segment:  It's clear, but you can put it in the other you have another issue right in the APA GitHub itself. You create another show post with them. I think the other one. \n",
      "Segment:  let's finish this fish tank with a gas station credit, but the \n",
      "Segment:  Hey would have commented yeah. \n",
      "Segment:  third busy response at the end of the call \n",
      "Segment:  Is that groups? Can you just call them? \n",
      "Segment:  What are the topics? \n",
      "Segment:  Now it becomes very confusing when you use them. \n",
      "Segment:  Let's stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions. There is also acceptable anymore if you have this. \n",
      "Segment:  And we have to have something else. We don't have anything to do with the only thing somebody. \n",
      "Segment:  Ideally table of contents can only be found in the book is complete. Yeah, right. So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part. You don't necessarily have to correlate to a topic. So let's separate that and I like that idea from this video. Maybe not caught not listen call them chapters. \n",
      "Segment:  Security my whole idea was like been in future. Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics. Then what is does is like for every discussion just give the highlights. But your again separating it into two groups right now. They're not kill groups. Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters. Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it's okay. So if you if you want to know Or even nine third chapters as well. You can be seen before member this becomes different. But that your engine anything right now, right? So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it won't let us see what happens, right? \n",
      "Segment:  No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they're two different age is one is just by minute highlights five-minute keywords essential keywords within a specific time period they don't all of it. So it's like recurring every five minutes. We'll come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you're doing right now you're trying to To distinguish the essential topics in a Convent in a complete conversation. If you to make real time, it would still more or less work in the way you currently intended. But with some caveats here and there but it's not necessarily going to be completed the same as every five minute keywords that we do right wrong. So we had to make it real time. We'll figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let's not, you know. They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation? \n",
      "Segment:  I think it is. Okay. I'll \n",
      "Segment:  Cause this update this one say topics and maybe put this comment at the other one some a service because that's what method is following and Link both of them this issue that open. So initially, what we'll do in staging we will not be markers in the new summary the way we push things somebody. \n",
      "Segment:  What if you want every sent back to us in what we push back in slab in staging? \n",
      "Segment:  So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production. We're going to use it. Whatever you use right now. Hmm that very comfortable that this is working as intended. We can include that make sense. So even for now just so that we can observe what's coming out from the grouping and what we expect in the keywords. We're not going to intersperse the topics with the manual markers that have been created or not. \n",
      "Segment:  Okay. Okay. Yep. \n",
      "Segment:  Okay. \n",
      "Segment:  let people know that these are or we can just push both but it's up to we will. \n",
      "Segment:  Good to be prepared. So you know that everyone knows the difference we can always Google. \n",
      "Segment:  And then we really wanted confident of this is working as expected. We can merge and remove any choppers that go inside. within the time Ridge so okay, please find anything is okay for actions now just only top \n",
      "Segment:  Then comes actions are we do need to do anything with post call for actions? \n",
      "Segment:  Both call you can you can just you can just show whatever whatever that Action Service returns. \n",
      "Segment:  Okay, one wheel. So the action markers has they were greater in life. \n",
      "Segment:  Yeah. \n",
      "Segment:  Do we yeah. \n",
      "Segment:  So you will okay it gets populated using the light cord itself. Is it in the timeline? \n",
      "Segment:  That's what are you doing on you doing it at life essentially? \n",
      "Segment:  Okay, so that's fine. That's yeah, but we try to call fate action items with groups. Definitely once we establish dress. Yeah other thing I asked Richard. I mean I have I have them. Deployment package ready, but ask the shun to change the because you have to change the way except response rate coming included on the response of is working on that once it's there L Death. \n",
      "Segment:  Okay, that's okay that that can be done depends. \n",
      "Segment:  So that's actually topics. \n",
      "Segment:  Decision decisions. We're not touching for the sky. \n",
      "Segment:  Missions. Yeah, I have a placeholder need to work on it for now. I'm just setting that empty basically empty. \n",
      "Segment:  So the right option topics and actions. Yep. \n",
      "Segment:  Thank you. \n"
     ]
    }
   ],
   "source": [
    "seg_list = []\n",
    "for seg in request[\"body\"][\"segments\"]:\n",
    "    seg_list.append((seg[\"originalText\"], seg[\"startTime\"]))\n",
    "seg_list = sorted(seg_list, key=lambda kv:kv[1], reverse=False)\n",
    "\n",
    "for seg in seg_list:\n",
    "    print (\"Segment: \", seg[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Groups for the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T12:09:56.535906Z",
     "start_time": "2019-10-16T12:08:19.069721Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing ele\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 40, \"module\": \"scorer\", \"batches count\": 1, \"number of sentences\": 180, \"ts\": \"2019-10-25T12:40:29.728369Z\", \"msg\": \"computing in batches\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 45, \"module\": \"scorer\", \"iteration count:\": 0, \"ts\": \"2019-10-25T12:40:29.729091Z\", \"msg\": \"getting feature vector from mind service\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 47, \"module\": \"scorer\", \"iteration count\": 0, \"ts\": \"2019-10-25T12:42:04.678945Z\", \"msg\": \"Request Sent\"}\n",
      "Recieved Response. Checking if it's valid.\n",
      "Valid Response from mind service.\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 57, \"module\": \"scorer\", \"ts\": \"2019-10-25T12:42:04.977551Z\", \"msg\": \"Response Recieved\"}\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 162, \"module\": \"grouper_segments\", \"nodes: \": 180, \"edges: \": 16110, \"ts\": \"2019-10-25T12:42:06.232314Z\", \"msg\": \"Normalising the Graph\"}\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 169, \"module\": \"grouper_segments\", \"nodes: \": 180, \"edges: \": 16284, \"ts\": \"2019-10-25T12:42:06.287935Z\", \"msg\": \"Completed Normalization\"}\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 171, \"module\": \"grouper_segments\", \"nodes: \": 180, \"edges: \": 16104, \"ts\": \"2019-10-25T12:42:06.288501Z\", \"msg\": \"Completed Normalization and after removing diagonal values\"}\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 190, \"module\": \"grouper_segments\", \"outlier threshold is : \": 0.0009066627604845935, \"ts\": \"2019-10-25T12:42:06.302290Z\", \"msg\": \"Outlier Score\"}\n",
      "0 16104\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 482, \"module\": \"grouper_segments\", \"edges before prunning\": 16104, \"edges after prunning\": 16104, \"modularity\": 0.06213869167529953, \"ts\": \"2019-10-25T12:42:06.581721Z\", \"msg\": \"Meeting Graph results\"}\n",
      "So we will update that keywords or something.\n",
      "Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.\n",
      "You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.\n",
      "So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion.\n",
      "So I would be so it is a new URL.\n",
      "So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready?\n",
      "it says so these are the input segmented is which have got we are able to see right when that\n",
      "Yeah, the group segmented is her like mostly like to two segments are grouped.\n",
      "And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.\n",
      "So once that is done, let us assume we got all the for each group.\n",
      "Need to filter or reduce any counter.\n",
      "This will be Topic in his essentially.\n",
      "We try to take the larger segment.\n",
      "You larger segment like for Alpha larger segments.\n",
      "Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.\n",
      "Yes, Each of which would contain the segment ID as a field and the text and the sentence.\n",
      "Also, that means he pick up the number of pieces you can see.\n",
      "Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.\n",
      "So in this one so but is it up can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective.\n",
      "But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.\n",
      "We need to know the segment ready for.\n",
      "Under the we like we need to purchase those sentences for one segment.\n",
      "With respect to the first one the second the API.\n",
      "Now the new summary it is there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create.\n",
      "We Implement in your analyzer right B it information and return.\n",
      "Okay, so and it will also add a new field called feel call or text in each object.\n",
      "We evident even definitely girl second analyzed.\n",
      "All it does is like it analyzes the segment each segment separately stores if each other Vector area so setting\n",
      "I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.\n",
      "So if one segment splits, it has multiple sentences.\n",
      "Yeah, that would be grouped as a single segment only we want again spread that.\n",
      "Yes generation field called Dont extract do not populate the graph.\n",
      "We make any concurrent calls to get the key phases for each group.\n",
      "That means they cannot be reused for the second one.\n",
      "Come back to school we call this analyzer and staging we just created as a subject in the current table as it is and they hate us and the actual NLP readers empty.\n",
      "If I had to push back to slack with two sections one is topics and one of the actions.\n",
      "Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.\n",
      "So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted.\n",
      "Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.\n",
      "We found something for you as a topic and within that time range itself be graded on someone read a manual marker.\n",
      "It should prefer that to this one.\n",
      "Actually, he is saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text.\n",
      "We will not contain all the sentences from the original segment, but only the Filter Works.\n",
      "Let is assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics.\n",
      "They are like either is relevant or something, but it is that is what so if that is it on high level of difference between chapters.\n",
      "But essentially the idea is the same thing, right if we could use the highlighter topics.\n",
      "So what if the format is just a group list of segments and the associated alter text.\n",
      "So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important.\n",
      "Yeah, but when we say we found topic we give them a list of subtopics and everything, right?\n",
      "But the mile marker does not contain those things.\n",
      "We need to First other words coming back and then decide how this will be.\n",
      "Ideally table of contents can only be found in the book is complete.\n",
      "So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.\n",
      "You do not necessarily have to correlate to a topic.\n",
      "Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics.\n",
      "Then what is does is like for every discussion just give the highlights.\n",
      "But your again separating it into two groups right now.\n",
      "Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay.\n",
      "You can be seen before member this becomes different.\n",
      "So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?\n",
      "Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.\n",
      "But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong.\n",
      "Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know.\n",
      "They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?\n",
      "Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.\n",
      "So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody.\n",
      "So even for now just so that we can observe what is coming out from the grouping and what we expect in the keywords.\n",
      "Were not going to intersperse the topics with the manual markers that have been created or not.\n",
      "cluster -=======>  1\n",
      "Is there at that field will have to update once we get it?\n",
      "You create a new one will create a whole service Revenue Service.\n",
      "Yes, you can it is make the product magnetic sensor consists for the names of my service itself.\n",
      "I do not know the meeting duration total duration.\n",
      "What does it on all let me see eight minutes.\n",
      "Okay, its production rate so it is not even updated.\n",
      "Okay, so then we will come to deployment separately less assuming.\n",
      "Let is discuss on the community thing, right?\n",
      "What is the request is nothing right only the instance ID unit meeting insensitive or whatever.\n",
      "Is it only for triggering summary or is it about doing anything?\n",
      "Replace the film service during the live call in.\n",
      "What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service.\n",
      "So are they very tightly coupled with each other.\n",
      "It is this right the rapper service or on both of them.\n",
      "Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.\n",
      "But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.\n",
      "I am carrying all that information at that point.\n",
      "If you had limit on five you want to cover the whole years is at least as a big thing.\n",
      "Stayed out and seeding will only enable strategy for space.\n",
      "Slipping so do you are or would it be easier?\n",
      "It is clear, but you can put it in the other you have another issue right in the APA GitHub itself.\n",
      "Actually, there is no power from two or three hours.\n",
      "Is that whether it is five or six or seven?\n",
      "I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space.\n",
      "Maybe not immediately, but that is if you go to production that might be needed.\n",
      "So if you if you want to know Or even nine third chapters as well.\n",
      "No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.\n",
      "So it is like recurring every five minutes.\n",
      "If you to make real time, it would still more or less work in the way you currently intended.\n",
      "So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production.\n",
      "Deployment package ready, but ask the shun to change the because you have to change the way except response rate coming included on the response of is working on that once it is there L Death.\n",
      "We can merge and remove any choppers that go inside.\n",
      "cluster -=======>  2\n",
      "There is also acceptable anymore if you have this.\n",
      "We do not have anything to do with the only thing somebody.\n",
      "So we will have to have like a pipeline for that like in each section that we publish.\n",
      "So that method can start working on it.\n",
      "Yeah, let us let us discuss this in the next.\n",
      "Let me just reiterate what has been mentioned in the\n",
      "But we need to know the mapping for that.\n",
      "That is the that is what we discussed earlier also.\n",
      "But the problem here is we should not be working.\n",
      "Actually, there is some more work here with it because they are actually returning some data and the original one the second one.\n",
      "And you want us to make basically they were in groups.\n",
      "So let us put a full limit me on this.\n",
      "We thought we will stick to five for now and then do that but that is not really that does not stop anything.\n",
      "So let us separate that and I like that idea from this video.\n",
      "And then we really wanted confident of this is working as expected.\n",
      "cluster -=======>  3\n",
      "No, not not that big a dick.\n",
      "So what happens is like it is similar to Chapters.\n",
      "If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now.\n",
      "XnumberX minutes and then there are there are enough.\n",
      "Subject of peace and humanely tell that we should have expected.\n",
      "And we have to have something else.\n",
      "We do the same for actions as well.\n",
      "Maybe XnumberX seconds or something as a placeholder.\n",
      "So inside or today is call it happen.\n",
      "If you see the screen, right, I have one log.\n",
      "Just so that we are on the same page because this is a replacement chapter.\n",
      "This is doing is just what happened and get it for you did not see that the mostly less than XnumberX seconds with them.\n",
      "Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like XnumberX seconds is a hard limit.\n",
      "Going to call and well and the second number is no number service.\n",
      "Yeah, I have to like like four to five watches.\n",
      "Let is say in group XnumberX it is an array of Group XnumberX is an array of objects embolism, right?\n",
      "So so I had looked at that tart that flowchart Witcher XnumberX had sent rate on the earlier.\n",
      "But with respect to the API a signature ways.\n",
      "I wanted to discuss like what are the request response those things basically?\n",
      "I think if it goes with I think the same logic that is going to intense actress currently a which session is a concept called here.\n",
      "It would be the same like whatever you give for scorer service, right?\n",
      "Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?\n",
      "So just so that we are all on the same page.\n",
      "So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.\n",
      "That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here.\n",
      "The next sentence is a text when a field called text and a hiding with the sentence belong funny.\n",
      "It was pretty to some for sentences.\n",
      "Okay, okay, he will not be expecting any scores.\n",
      "But the name Remains the Same or itself should be different, right?\n",
      "Find anything so we can do it.\n",
      "Yeah, so that is also Lambda is\n",
      "For example, let us say when I call this new servers on let us do this.\n",
      "Okay Android if nothing is written in their objective some preprocessing error.\n",
      "There is something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code\n",
      "Do what you want to use then give it?\n",
      "And just dump everything on Tinder like the current chapters like four chapters chapter summary.\n",
      "You sent a request with the same request you present for new service.\n",
      "Yes at the end of the curve you getting all the segments and you are doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment is to which they belong right?\n",
      "He will go give us a key phrases for that.\n",
      "It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now.\n",
      "Let is say XnumberX is minus XnumberX are some negative value meaning that they are not even anything correctly.\n",
      "We will trigger somebody header like with the new strategy.\n",
      "Okay, you just by looking at them even slap.\n",
      "If you want me to give I can give it your all.\n",
      "It would definitely be using the anything else great, except the Alta text.\n",
      "That is that is our first group a number of key phrases, right?\n",
      "Yeah, like so you have some XnumberX groups if you have done right do we?\n",
      "You create another show post with them.\n",
      "That is so yeah, you do not have to do in the pool right now.\n",
      "Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.\n",
      "Okay, let us do overlap macon is do we remove this or do we keep this or what makes sense?\n",
      "Karthik event got the laptop chargers down.\n",
      "I think I am trying to connect some iOS but it is fairly.\n",
      "But just you have to keep that in mind.\n",
      "Maybe not caught not listen call them chapters.\n",
      "Security my whole idea was like been in future.\n",
      "Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters.\n",
      "But that your engine anything right now, right?\n",
      "So we had to make it real time.\n",
      "Hmm that very comfortable that this is working as intended.\n",
      "That is yeah, but we try to call fate action items with groups.\n",
      "I mean I have I have them.\n",
      "within the time Ridge so okay, please find anything is okay for actions now just only top\n",
      "Yeah, I have a placeholder need to work on it for now.\n",
      "I am just setting that empty basically empty.\n",
      "[[('it says so these are the input segmented is which have got we are able to see right when that', '2019-10-24T09:37:08Z', '84fbaa66a2474ea29ae053f3a2e519d6', '3be57485efb14ff8be6d23ecd62dabd2'), ('And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.', '2019-10-24T09:37:30Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f4c5c03c2e924de9847e0f2a65095d8c'), ('Yeah, the group segmented is her like mostly like to two segments are grouped.', '2019-10-24T09:37:30Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f4c5c03c2e924de9847e0f2a65095d8c'), ('You larger segment like for Alpha larger segments.', '2019-10-24T09:38:40Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'a92f243fef7248478467fff8d97ca486'), ('We try to take the larger segment.', '2019-10-24T09:38:40Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'a92f243fef7248478467fff8d97ca486'), ('So I would be so it is a new URL.', '2019-10-24T09:41:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '269125104ee7483690ec2bc6b6f27e7e'), ('With respect to the first one the second the API.', '2019-10-24T09:42:05Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'b3d10173ca17432e8e5ae3c1071fe323'), ('But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.', '2019-10-24T09:44:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '765f426547244837a63c95746c5c45be'), ('We Implement in your analyzer right B it information and return.', '2019-10-24T09:45:49Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f1896133539433fa78f4e836897f526'), ('So we will update that keywords or something.', '2019-10-24T09:46:58Z', '84fbaa66a2474ea29ae053f3a2e519d6', '0983ef203b5248559376addb96cc125d'), ('We need to know the segment ready for.', '2019-10-24T09:47:06Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f2cac8169c05439fb45fc8055192e1f0'), ('Under the we like we need to purchase those sentences for one segment.', '2019-10-24T09:47:31Z', '84fbaa66a2474ea29ae053f3a2e519d6', '2be222ed2f79468d8fdae5cac0be38fb'), ('Come back to school we call this analyzer and staging we just created as a subject in the current table as it is and they hate us and the actual NLP readers empty.', '2019-10-24T09:48:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'af44ede593da494f8a2eb21ebcd7970f'), ('We evident even definitely girl second analyzed.', '2019-10-24T09:49:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a6ae53fc1f394851847a296b97189be9'), ('Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.', '2019-10-24T09:49:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8e4abf19839e41c1ad14ec83b08da03c'), ('So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted.', '2019-10-24T09:49:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8e4abf19839e41c1ad14ec83b08da03c'), ('All it does is like it analyzes the segment each segment separately stores if each other Vector area so setting', '2019-10-24T09:50:08Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'd9a3e4a5632747abb7cae234597eac5b'), ('So in this one so but is it up can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective.', '2019-10-24T09:51:06Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bd3dc1b663b147a886fe0b9ef9d10b2a'), ('Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.', '2019-10-24T09:51:06Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bd3dc1b663b147a886fe0b9ef9d10b2a'), ('I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.', '2019-10-24T09:51:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '131db9a5cba54cedac7d976b77e41b8e'), ('That means they cannot be reused for the second one.', '2019-10-24T09:52:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '49ae050d6a3341e9867cf4ce257bf5c2'), ('Yes, Each of which would contain the segment ID as a field and the text and the sentence.', '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6'), ('Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.', '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6'), ('Okay, so and it will also add a new field called feel call or text in each object.', '2019-10-24T09:54:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '52bdaab6df324ca0bccf8ce34c35db12'), ('Yeah, that would be grouped as a single segment only we want again spread that.', '2019-10-24T09:54:40Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '67a84321aff94e3591e883b26c947dcb'), ('So if one segment splits, it has multiple sentences.', '2019-10-24T09:54:40Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '67a84321aff94e3591e883b26c947dcb'), ('Actually, he is saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text.', '2019-10-24T09:55:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '08cb5accf2cf4fe4819da499718e6a8a'), ('We will not contain all the sentences from the original segment, but only the Filter Works.', '2019-10-24T09:55:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '08cb5accf2cf4fe4819da499718e6a8a'), ('So what if the format is just a group list of segments and the associated alter text.', '2019-10-24T09:56:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '280eccf326464766a80e1aca7ee18c3e'), ('We make any concurrent calls to get the key phases for each group.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669'), ('Yes generation field called Dont extract do not populate the graph.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669'), ('Need to filter or reduce any counter.', '2019-10-24T09:58:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '86f39c46e153416ca86e69002db48097'), ('So once that is done, let us assume we got all the for each group.', '2019-10-24T09:58:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '86f39c46e153416ca86e69002db48097'), ('Also, that means he pick up the number of pieces you can see.', '2019-10-24T09:58:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '9d13652561494be78e32872df4d2f179'), ('This will be Topic in his essentially.', '2019-10-24T09:59:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7e0ed18332e74a0091c7d3c4300a1f60'), ('Now the new summary it is there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create.', '2019-10-24T10:00:08Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cec9d9832cd24135a14e1b7a936f2b7e'), ('So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion.', '2019-10-24T10:00:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ef9b701a62ea481485ad23db01cbd776'), ('You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.', '2019-10-24T10:00:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ef9b701a62ea481485ad23db01cbd776'), ('If I had to push back to slack with two sections one is topics and one of the actions.', '2019-10-24T10:01:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e51c3385ccc6405193808ec2711dc293'), ('Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.', '2019-10-24T10:01:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e51c3385ccc6405193808ec2711dc293'), ('Let is assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics.', '2019-10-24T10:01:50Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '65d3a52e005f469d8cba97bcafa2739c'), ('They are like either is relevant or something, but it is that is what so if that is it on high level of difference between chapters.', '2019-10-24T10:01:50Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '65d3a52e005f469d8cba97bcafa2739c'), ('So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important.', '2019-10-24T10:02:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'beff02d81e604638939892b1b784d4b2'), ('But essentially the idea is the same thing, right if we could use the highlighter topics.', '2019-10-24T10:03:15Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'af09fd64cfbc4b3dae3f8f2b054316c1'), ('We need to First other words coming back and then decide how this will be.', '2019-10-24T10:04:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f00ada973054f28b67c4669d9be9e23'), ('We found something for you as a topic and within that time range itself be graded on someone read a manual marker.', '2019-10-24T10:04:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cd7717a085d0444f8fe3ee598fe81417'), ('It should prefer that to this one.', '2019-10-24T10:04:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cd7717a085d0444f8fe3ee598fe81417'), ('But the mile marker does not contain those things.', '2019-10-24T10:04:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a4c5cf81924e4ad7864d61a7c5f1b1e3'), ('Yeah, but when we say we found topic we give them a list of subtopics and everything, right?', '2019-10-24T10:04:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a4c5cf81924e4ad7864d61a7c5f1b1e3'), ('So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready?', '2019-10-24T10:06:45Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e697609e7e8b4de19a556a6e49471518'), ('Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.', '2019-10-24T10:08:21Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bd04b29039e14e0aba93598cde210dc5'), ('So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928'), ('Ideally table of contents can only be found in the book is complete.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928'), ('You do not necessarily have to correlate to a topic.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928'), ('So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('You can be seen before member this becomes different.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('Then what is does is like for every discussion just give the highlights.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('But your again separating it into two groups right now.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4'), ('But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4'), ('Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4'), ('Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4'), ('Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.', '2019-10-24T10:11:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9648c443a927463daeb63edf81915bb7'), ('So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody.', '2019-10-24T10:11:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9648c443a927463daeb63edf81915bb7'), ('Were not going to intersperse the topics with the manual markers that have been created or not.', '2019-10-24T10:12:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '5c526d59a4ce4528abc88397f77dd539'), ('So even for now just so that we can observe what is coming out from the grouping and what we expect in the keywords.', '2019-10-24T10:12:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '5c526d59a4ce4528abc88397f77dd539')], [('What does it on all let me see eight minutes.', '2019-10-24T09:37:50Z', '84fbaa66a2474ea29ae053f3a2e519d6', '9ed735cb95b3412ba38e476837ba0b58'), ('I do not know the meeting duration total duration.', '2019-10-24T09:37:50Z', '84fbaa66a2474ea29ae053f3a2e519d6', '9ed735cb95b3412ba38e476837ba0b58'), ('Yes, you can it is make the product magnetic sensor consists for the names of my service itself.', '2019-10-24T09:39:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '390016daaf6e4634a4be7868593dd57d'), ('Okay, its production rate so it is not even updated.', '2019-10-24T09:40:14Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '738ebdca3bf146d8bb8f974f00560eea'), ('Let is discuss on the community thing, right?', '2019-10-24T09:40:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '531ca88fd1014c94953402ceff5efdb4'), ('You create a new one will create a whole service Revenue Service.', '2019-10-24T09:41:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '269125104ee7483690ec2bc6b6f27e7e'), ('What is the request is nothing right only the instance ID unit meeting insensitive or whatever.', '2019-10-24T09:42:05Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'b3d10173ca17432e8e5ae3c1071fe323'), ('Is there at that field will have to update once we get it?', '2019-10-24T09:46:58Z', '84fbaa66a2474ea29ae053f3a2e519d6', '0983ef203b5248559376addb96cc125d'), ('Is it only for triggering summary or is it about doing anything?', '2019-10-24T09:49:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a6ae53fc1f394851847a296b97189be9'), ('Replace the film service during the live call in.', '2019-10-24T09:50:08Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'd9a3e4a5632747abb7cae234597eac5b'), ('So are they very tightly coupled with each other.', '2019-10-24T09:52:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '49ae050d6a3341e9867cf4ce257bf5c2'), ('It is this right the rapper service or on both of them.', '2019-10-24T09:52:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '755ac6aa613f45d5be5566a5fe1d784d'), ('Okay, so then we will come to deployment separately less assuming.', '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6'), ('I am carrying all that information at that point.', '2019-10-24T09:53:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'fb5f0a0913b94a0491374dd0a0ccfec5'), ('Slipping so do you are or would it be easier?', '2019-10-24T09:56:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '280eccf326464766a80e1aca7ee18c3e'), ('What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669'), ('If you had limit on five you want to cover the whole years is at least as a big thing.', '2019-10-24T10:01:50Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '65d3a52e005f469d8cba97bcafa2739c'), ('Is that whether it is five or six or seven?', '2019-10-24T10:02:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'beff02d81e604638939892b1b784d4b2'), ('I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space.', '2019-10-24T10:02:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e09a73ccea7b4e7d94c2f3992743cded'), ('Stayed out and seeding will only enable strategy for space.', '2019-10-24T10:03:15Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'af09fd64cfbc4b3dae3f8f2b054316c1'), ('Maybe not immediately, but that is if you go to production that might be needed.', '2019-10-24T10:04:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f00ada973054f28b67c4669d9be9e23'), ('Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.', '2019-10-24T10:04:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cd7717a085d0444f8fe3ee598fe81417'), ('But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.', '2019-10-24T10:04:53Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '84da28210d524bbcb0de12b3c068026b'), ('Actually, there is no power from two or three hours.', '2019-10-24T10:06:29Z', '84fbaa66a2474ea29ae053f3a2e519d6', '321dbac48fa440cfa7a0e801bf6d64b1'), ('It is clear, but you can put it in the other you have another issue right in the APA GitHub itself.', '2019-10-24T10:07:12Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e3cfd0caac88481592b8c2623cdfdd8a'), ('So if you if you want to know Or even nine third chapters as well.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4'), ('If you to make real time, it would still more or less work in the way you currently intended.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4'), ('So it is like recurring every five minutes.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4'), ('So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production.', '2019-10-24T10:12:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '5c526d59a4ce4528abc88397f77dd539'), ('We can merge and remove any choppers that go inside.', '2019-10-24T10:13:12Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3dc868cd1f184517ace6449becb87e08'), ('Deployment package ready, but ask the shun to change the because you have to change the way except response rate coming included on the response of is working on that once it is there L Death.', '2019-10-24T10:14:09Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bf11d1b5c35e4d6c8f946f66c85d8538')], [('Let me just reiterate what has been mentioned in the', '2019-10-24T09:43:41Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'c737f43ae1ac4386bd19d78f00c244e2'), ('But the problem here is we should not be working.', '2019-10-24T09:45:01Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'f985c93eb01b4f1cadd2c38fd99e3b05'), ('Actually, there is some more work here with it because they are actually returning some data and the original one the second one.', '2019-10-24T09:45:01Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'f985c93eb01b4f1cadd2c38fd99e3b05'), ('But we need to know the mapping for that.', '2019-10-24T09:47:06Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f2cac8169c05439fb45fc8055192e1f0'), ('Yeah, let us let us discuss this in the next.', '2019-10-24T09:50:52Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '097b4c9b83514256a493de310a07c1b5'), ('And you want us to make basically they were in groups.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669'), ('That is the that is what we discussed earlier also.', '2019-10-24T10:00:08Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cec9d9832cd24135a14e1b7a936f2b7e'), ('We thought we will stick to five for now and then do that but that is not really that does not stop anything.', '2019-10-24T10:02:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e09a73ccea7b4e7d94c2f3992743cded'), ('So let us put a full limit me on this.', '2019-10-24T10:03:15Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'af09fd64cfbc4b3dae3f8f2b054316c1'), ('So we will have to have like a pipeline for that like in each section that we publish.', '2019-10-24T10:06:19Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'ae7dc522e8ff44bda4cbd9aef5811b1a'), ('So that method can start working on it.', '2019-10-24T10:06:45Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e697609e7e8b4de19a556a6e49471518'), ('There is also acceptable anymore if you have this.', '2019-10-24T10:08:21Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bd04b29039e14e0aba93598cde210dc5'), ('We do not have anything to do with the only thing somebody.', '2019-10-24T10:08:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '83fc6652dad543538c9a66dd245120a0'), ('So let us separate that and I like that idea from this video.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928'), ('And then we really wanted confident of this is working as expected.', '2019-10-24T10:13:12Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3dc868cd1f184517ace6449becb87e08')], [('If you see the screen, right, I have one log.', '2019-10-24T09:37:08Z', '84fbaa66a2474ea29ae053f3a2e519d6', '3be57485efb14ff8be6d23ecd62dabd2'), ('Subject of peace and humanely tell that we should have expected.', '2019-10-24T09:37:55Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '12ee4b3dc175408abddadb34bb622606'), ('XnumberX minutes and then there are there are enough.', '2019-10-24T09:37:55Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '12ee4b3dc175408abddadb34bb622606'), ('This is doing is just what happened and get it for you did not see that the mostly less than XnumberX seconds with them.', '2019-10-24T09:38:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '0428e901c7654286a5d593a86228c607'), ('Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like XnumberX seconds is a hard limit.', '2019-10-24T09:38:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '0428e901c7654286a5d593a86228c607'), ('If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now.', '2019-10-24T09:39:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '390016daaf6e4634a4be7868593dd57d'), ('Maybe XnumberX seconds or something as a placeholder.', '2019-10-24T09:40:06Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '835f0f68ff8d4807b9f4a2aabad4f904'), ('So inside or today is call it happen.', '2019-10-24T09:40:06Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '835f0f68ff8d4807b9f4a2aabad4f904'), ('Yeah, I have to like like four to five watches.', '2019-10-24T09:40:14Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '738ebdca3bf146d8bb8f974f00560eea'), ('But with respect to the API a signature ways.', '2019-10-24T09:40:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '531ca88fd1014c94953402ceff5efdb4'), ('So so I had looked at that tart that flowchart Witcher XnumberX had sent rate on the earlier.', '2019-10-24T09:40:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '531ca88fd1014c94953402ceff5efdb4'), ('I wanted to discuss like what are the request response those things basically?', '2019-10-24T09:40:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '531ca88fd1014c94953402ceff5efdb4'), ('It would be the same like whatever you give for scorer service, right?', '2019-10-24T09:41:04Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4102ada43e0844a696cde7a5a1c6b45c'), ('Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?', '2019-10-24T09:41:04Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4102ada43e0844a696cde7a5a1c6b45c'), ('Okay, okay, he will not be expecting any scores.', '2019-10-24T09:41:25Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e759d5051b224ca8ab10e1e625e07a03'), ('But the name Remains the Same or itself should be different, right?', '2019-10-24T09:41:25Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e759d5051b224ca8ab10e1e625e07a03'), ('And just dump everything on Tinder like the current chapters like four chapters chapter summary.', '2019-10-24T09:42:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ab22180c9af64f12974a806f574e0cb2'), ('You sent a request with the same request you present for new service.', '2019-10-24T09:42:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ab22180c9af64f12974a806f574e0cb2'), ('Yeah, so that is also Lambda is', '2019-10-24T09:43:08Z', '84fbaa66a2474ea29ae053f3a2e519d6', '9f9ff946e2b245619f18ff987158dbb9'), ('Find anything so we can do it.', '2019-10-24T09:43:08Z', '84fbaa66a2474ea29ae053f3a2e519d6', '9f9ff946e2b245619f18ff987158dbb9'), ('So just so that we are all on the same page.', '2019-10-24T09:43:41Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'c737f43ae1ac4386bd19d78f00c244e2'), ('So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.', '2019-10-24T09:44:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '765f426547244837a63c95746c5c45be'), ('There is something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code', '2019-10-24T09:45:49Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f1896133539433fa78f4e836897f526'), ('For example, let us say when I call this new servers on let us do this.', '2019-10-24T09:45:49Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f1896133539433fa78f4e836897f526'), ('Okay Android if nothing is written in their objective some preprocessing error.', '2019-10-24T09:45:49Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f1896133539433fa78f4e836897f526'), ('The next sentence is a text when a field called text and a hiding with the sentence belong funny.', '2019-10-24T09:47:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a3cc958237dc46b4bd80e6ac6a7dd499'), ('That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here.', '2019-10-24T09:47:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a3cc958237dc46b4bd80e6ac6a7dd499'), ('It was pretty to some for sentences.', '2019-10-24T09:47:31Z', '84fbaa66a2474ea29ae053f3a2e519d6', '2be222ed2f79468d8fdae5cac0be38fb'), ('Let is say XnumberX is minus XnumberX are some negative value meaning that they are not even anything correctly.', '2019-10-24T09:48:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'af44ede593da494f8a2eb21ebcd7970f'), ('We will trigger somebody header like with the new strategy.', '2019-10-24T09:49:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8e4abf19839e41c1ad14ec83b08da03c'), ('Going to call and well and the second number is no number service.', '2019-10-24T09:50:52Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '097b4c9b83514256a493de310a07c1b5'), ('Yes at the end of the curve you getting all the segments and you are doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment is to which they belong right?', '2019-10-24T09:51:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '131db9a5cba54cedac7d976b77e41b8e'), ('It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now.', '2019-10-24T09:52:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '755ac6aa613f45d5be5566a5fe1d784d'), ('Let is say in group XnumberX it is an array of Group XnumberX is an array of objects embolism, right?', '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6'), ('If you want me to give I can give it your all.', '2019-10-24T09:53:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'fb5f0a0913b94a0491374dd0a0ccfec5'), ('Do what you want to use then give it?', '2019-10-24T09:54:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '52bdaab6df324ca0bccf8ce34c35db12'), ('It would definitely be using the anything else great, except the Alta text.', '2019-10-24T09:56:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '280eccf326464766a80e1aca7ee18c3e'), ('He will go give us a key phrases for that.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669'), ('I think if it goes with I think the same logic that is going to intense actress currently a which session is a concept called here.', '2019-10-24T09:58:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '9d13652561494be78e32872df4d2f179'), ('Yeah, like so you have some XnumberX groups if you have done right do we?', '2019-10-24T09:58:57Z', '84fbaa66a2474ea29ae053f3a2e519d6', '90b04c9a271844e8b2dc332a24c11def'), ('That is that is our first group a number of key phrases, right?', '2019-10-24T09:58:57Z', '84fbaa66a2474ea29ae053f3a2e519d6', '90b04c9a271844e8b2dc332a24c11def'), ('Just so that we are on the same page because this is a replacement chapter.', '2019-10-24T09:59:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7e0ed18332e74a0091c7d3c4300a1f60'), ('So what happens is like it is similar to Chapters.', '2019-10-24T10:00:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ef9b701a62ea481485ad23db01cbd776'), ('No, not not that big a dick.', '2019-10-24T10:00:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ef9b701a62ea481485ad23db01cbd776'), ('But just you have to keep that in mind.', '2019-10-24T10:04:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f00ada973054f28b67c4669d9be9e23'), ('Okay, you just by looking at them even slap.', '2019-10-24T10:04:53Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '84da28210d524bbcb0de12b3c068026b'), ('That is so yeah, you do not have to do in the pool right now.', '2019-10-24T10:05:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7658b0fa8ea14eb8acc62f015032bbeb'), ('Okay, let us do overlap macon is do we remove this or do we keep this or what makes sense?', '2019-10-24T10:05:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7658b0fa8ea14eb8acc62f015032bbeb'), ('Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.', '2019-10-24T10:05:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7658b0fa8ea14eb8acc62f015032bbeb'), ('We do the same for actions as well.', '2019-10-24T10:06:19Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'ae7dc522e8ff44bda4cbd9aef5811b1a'), ('Karthik event got the laptop chargers down.', '2019-10-24T10:06:29Z', '84fbaa66a2474ea29ae053f3a2e519d6', '321dbac48fa440cfa7a0e801bf6d64b1'), ('I think I am trying to connect some iOS but it is fairly.', '2019-10-24T10:06:29Z', '84fbaa66a2474ea29ae053f3a2e519d6', '321dbac48fa440cfa7a0e801bf6d64b1'), ('You create another show post with them.', '2019-10-24T10:07:12Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e3cfd0caac88481592b8c2623cdfdd8a'), ('And we have to have something else.', '2019-10-24T10:08:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '83fc6652dad543538c9a66dd245120a0'), ('Maybe not caught not listen call them chapters.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928'), ('Security my whole idea was like been in future.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('But that your engine anything right now, right?', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'), ('So we had to make it real time.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4'), ('Hmm that very comfortable that this is working as intended.', '2019-10-24T10:12:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '5c526d59a4ce4528abc88397f77dd539'), ('within the time Ridge so okay, please find anything is okay for actions now just only top', '2019-10-24T10:13:12Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3dc868cd1f184517ace6449becb87e08'), ('I mean I have I have them.', '2019-10-24T10:14:09Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bf11d1b5c35e4d6c8f946f66c85d8538'), ('That is yeah, but we try to call fate action items with groups.', '2019-10-24T10:14:09Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bf11d1b5c35e4d6c8f946f66c85d8538'), ('Yeah, I have a placeholder need to work on it for now.', '2019-10-24T10:14:57Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '58e60982017d43d8b2a2d70aaa680b5a'), ('I am just setting that empty basically empty.', '2019-10-24T10:14:57Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '58e60982017d43d8b2a2d70aaa680b5a')]]\n",
      "Relevant sentence:  it says so these are the input segmented is which have got we are able to see right when that    =====    And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.\n",
      "Relevant sentence:  So I would be so it is a new URL.    =====    With respect to the first one the second the API.\n",
      "Relevant sentence:  So we will update that keywords or something.    =====    We need to know the segment ready for.\n",
      "Relevant sentence:  We need to know the segment ready for.    =====    Under the we like we need to purchase those sentences for one segment.\n",
      "Relevant sentence:  We evident even definitely girl second analyzed.    =====    Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.\n",
      "Relevant sentence:  Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.    =====    I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.\n",
      "Relevant sentence:  I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.    =====    That means they cannot be reused for the second one.\n",
      "Relevant sentence:  Yes generation field called Dont extract do not populate the graph.    =====    Need to filter or reduce any counter.\n",
      "Relevant sentence:  So once that is done, let us assume we got all the for each group.    =====    Also, that means he pick up the number of pieces you can see.\n",
      "Relevant sentence:  You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.    =====    If I had to push back to slack with two sections one is topics and one of the actions.\n",
      "Relevant sentence:  We need to First other words coming back and then decide how this will be.    =====    We found something for you as a topic and within that time range itself be graded on someone read a manual marker.\n",
      "Relevant sentence:  It should prefer that to this one.    =====    But the mile marker does not contain those things.\n",
      "Relevant sentence:  Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.    =====    So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.\n",
      "Relevant sentence:  You do not necessarily have to correlate to a topic.    =====    So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?\n",
      "Relevant sentence:  But your again separating it into two groups right now.    =====    They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?\n",
      "Relevant sentence:  Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know.    =====    Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.\n",
      "Relevant sentence:  So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody.    =====    Were not going to intersperse the topics with the manual markers that have been created or not.\n",
      "Relevant sentence:  Okay, its production rate so it is not even updated.    =====    Let is discuss on the community thing, right?\n",
      "Relevant sentence:  You create a new one will create a whole service Revenue Service.    =====    What is the request is nothing right only the instance ID unit meeting insensitive or whatever.\n",
      "Relevant sentence:  Is that whether it is five or six or seven?    =====    I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space.\n",
      "Relevant sentence:  Maybe not immediately, but that is if you go to production that might be needed.    =====    Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.\n",
      "Relevant sentence:  Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.    =====    But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.\n",
      "Relevant sentence:  Actually, there is no power from two or three hours.    =====    It is clear, but you can put it in the other you have another issue right in the APA GitHub itself.\n",
      "Relevant sentence:  So if you if you want to know Or even nine third chapters as well.    =====    No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.\n",
      "Relevant sentence:  So we will have to have like a pipeline for that like in each section that we publish.    =====    So that method can start working on it.\n",
      "Relevant sentence:  There is also acceptable anymore if you have this.    =====    We do not have anything to do with the only thing somebody.\n",
      "Relevant sentence:  We do not have anything to do with the only thing somebody.    =====    So let us separate that and I like that idea from this video.\n",
      "Relevant sentence:  If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now.    =====    Maybe XnumberX seconds or something as a placeholder.\n",
      "Relevant sentence:  So inside or today is call it happen.    =====    Yeah, I have to like like four to five watches.\n",
      "Relevant sentence:  Yeah, I have to like like four to five watches.    =====    But with respect to the API a signature ways.\n",
      "Relevant sentence:  I wanted to discuss like what are the request response those things basically?    =====    It would be the same like whatever you give for scorer service, right?\n",
      "Relevant sentence:  Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?    =====    Okay, okay, he will not be expecting any scores.\n",
      "Relevant sentence:  So just so that we are all on the same page.    =====    So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.\n",
      "Relevant sentence:  That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here.    =====    It was pretty to some for sentences.\n",
      "Relevant sentence:  If you want me to give I can give it your all.    =====    Do what you want to use then give it?\n",
      "Relevant sentence:  He will go give us a key phrases for that.    =====    I think if it goes with I think the same logic that is going to intense actress currently a which session is a concept called here.\n",
      "Relevant sentence:  I think if it goes with I think the same logic that is going to intense actress currently a which session is a concept called here.    =====    Yeah, like so you have some XnumberX groups if you have done right do we?\n",
      "Relevant sentence:  Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.    =====    We do the same for actions as well.\n",
      "Relevant sentence:  We do the same for actions as well.    =====    Karthik event got the laptop chargers down.\n",
      "Relevant sentence:  I think I am trying to connect some iOS but it is fairly.    =====    You create another show post with them.\n",
      "Relevant sentence:  And we have to have something else.    =====    Maybe not caught not listen call them chapters.\n",
      "Relevant sentence:  Maybe not caught not listen call them chapters.    =====    Security my whole idea was like been in future.\n",
      "Relevant sentence:  But that your engine anything right now, right?    =====    So we had to make it real time.\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 586, \"module\": \"grouper_segments\", \"PIMs\": {\"0\": {\"segment0\": [\"it says so these are the input segmented is which have got we are able to see right when that\", \"2019-10-24T09:37:08Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"3be57485efb14ff8be6d23ecd62dabd2\"], \"segment1\": [\"And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.\", \"2019-10-24T09:37:30Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"f4c5c03c2e924de9847e0f2a65095d8c\"]}, \"5\": {\"segment0\": [\"So we will update that keywords or something.\", \"2019-10-24T09:46:58Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"0983ef203b5248559376addb96cc125d\"], \"segment1\": [\"We need to know the segment ready for.\", \"2019-10-24T09:47:06Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"f2cac8169c05439fb45fc8055192e1f0\"], \"segment2\": [\"That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here.\", \"2019-10-24T09:47:14Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"a3cc958237dc46b4bd80e6ac6a7dd499\"], \"segment3\": [\"Under the we like we need to purchase those sentences for one segment.\", \"2019-10-24T09:47:31Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"2be222ed2f79468d8fdae5cac0be38fb\"]}, \"7\": {\"segment0\": [\"We evident even definitely girl second analyzed.\", \"2019-10-24T09:49:05Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"a6ae53fc1f394851847a296b97189be9\"], \"segment1\": [\"Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.\", \"2019-10-24T09:49:14Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"8e4abf19839e41c1ad14ec83b08da03c\"]}, \"9\": {\"segment0\": [\"Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.\", \"2019-10-24T09:51:06Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"bd3dc1b663b147a886fe0b9ef9d10b2a\"], \"segment1\": [\"I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.\", \"2019-10-24T09:51:40Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"131db9a5cba54cedac7d976b77e41b8e\"], \"segment2\": [\"That means they cannot be reused for the second one.\", \"2019-10-24T09:52:05Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"49ae050d6a3341e9867cf4ce257bf5c2\"]}, \"10\": {\"segment0\": [\"Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.\", \"2019-10-24T09:52:59Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"8c4930798f1e4460a3483d12067e10a6\"]}, \"18\": {\"segment0\": [\"You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.\", \"2019-10-24T10:00:46Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"ef9b701a62ea481485ad23db01cbd776\"], \"segment1\": [\"If I had to push back to slack with two sections one is topics and one of the actions.\", \"2019-10-24T10:01:14Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"e51c3385ccc6405193808ec2711dc293\"]}, \"24\": {\"segment0\": [\"Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.\", \"2019-10-24T10:08:21Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"bd04b29039e14e0aba93598cde210dc5\"], \"segment1\": [\"We do not have anything to do with the only thing somebody.\", \"2019-10-24T10:08:38Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"83fc6652dad543538c9a66dd245120a0\"], \"segment2\": [\"So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.\", \"2019-10-24T10:08:46Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"347d89717f7b46ebbc9effada658a928\"], \"segment3\": [\"So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?\", \"2019-10-24T10:09:10Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"5ce3830ac74449cfa0594d9e7e922315\"], \"segment4\": [\"They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?\", \"2019-10-24T10:10:29Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"3e73ba7a1b0543fc97519322f7eb9eb4\"], \"segment5\": [\"Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.\", \"2019-10-24T10:11:56Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"9648c443a927463daeb63edf81915bb7\"], \"segment6\": [\"Were not going to intersperse the topics with the manual markers that have been created or not.\", \"2019-10-24T10:12:27Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"5c526d59a4ce4528abc88397f77dd539\"]}, \"28\": {\"segment0\": [\"You create a new one will create a whole service Revenue Service.\", \"2019-10-24T09:41:43Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"269125104ee7483690ec2bc6b6f27e7e\"], \"segment1\": [\"What is the request is nothing right only the instance ID unit meeting insensitive or whatever.\", \"2019-10-24T09:42:05Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"b3d10173ca17432e8e5ae3c1071fe323\"]}, \"39\": {\"segment0\": [\"Is that whether it is five or six or seven?\", \"2019-10-24T10:02:28Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"beff02d81e604638939892b1b784d4b2\"], \"segment1\": [\"I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space.\", \"2019-10-24T10:02:45Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"e09a73ccea7b4e7d94c2f3992743cded\"]}, \"41\": {\"segment0\": [\"Maybe not immediately, but that is if you go to production that might be needed.\", \"2019-10-24T10:04:05Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"2f00ada973054f28b67c4669d9be9e23\"], \"segment1\": [\"Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.\", \"2019-10-24T10:04:25Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"cd7717a085d0444f8fe3ee598fe81417\"], \"segment2\": [\"But the mile marker does not contain those things.\", \"2019-10-24T10:04:43Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"a4c5cf81924e4ad7864d61a7c5f1b1e3\"], \"segment3\": [\"But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.\", \"2019-10-24T10:04:53Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"84da28210d524bbcb0de12b3c068026b\"]}, \"59\": {\"segment0\": [\"If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now.\", \"2019-10-24T09:39:38Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"390016daaf6e4634a4be7868593dd57d\"], \"segment1\": [\"Maybe XnumberX seconds or something as a placeholder.\", \"2019-10-24T09:40:06Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"835f0f68ff8d4807b9f4a2aabad4f904\"], \"segment2\": [\"Yeah, I have to like like four to five watches.\", \"2019-10-24T09:40:14Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"738ebdca3bf146d8bb8f974f00560eea\"], \"segment3\": [\"But with respect to the API a signature ways.\", \"2019-10-24T09:40:42Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"531ca88fd1014c94953402ceff5efdb4\"], \"segment4\": [\"It would be the same like whatever you give for scorer service, right?\", \"2019-10-24T09:41:04Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"4102ada43e0844a696cde7a5a1c6b45c\"], \"segment5\": [\"Okay, okay, he will not be expecting any scores.\", \"2019-10-24T09:41:25Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"e759d5051b224ca8ab10e1e625e07a03\"]}, \"62\": {\"segment0\": [\"So just so that we are all on the same page.\", \"2019-10-24T09:43:41Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"c737f43ae1ac4386bd19d78f00c244e2\"], \"segment1\": [\"So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.\", \"2019-10-24T09:44:03Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"765f426547244837a63c95746c5c45be\"]}, \"71\": {\"segment0\": [\"If you want me to give I can give it your all.\", \"2019-10-24T09:53:54Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"fb5f0a0913b94a0491374dd0a0ccfec5\"], \"segment1\": [\"Do what you want to use then give it?\", \"2019-10-24T09:54:05Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"52bdaab6df324ca0bccf8ce34c35db12\"]}, \"73\": {\"segment0\": [\"He will go give us a key phrases for that.\", \"2019-10-24T09:57:51Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"aef4d82f30dd4eff9a653c12f091d669\"], \"segment1\": [\"Need to filter or reduce any counter.\", \"2019-10-24T09:58:25Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"86f39c46e153416ca86e69002db48097\"], \"segment2\": [\"I think if it goes with I think the same logic that is going to intense actress currently a which session is a concept called here.\", \"2019-10-24T09:58:43Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"9d13652561494be78e32872df4d2f179\"], \"segment3\": [\"Yeah, like so you have some XnumberX groups if you have done right do we?\", \"2019-10-24T09:58:57Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"90b04c9a271844e8b2dc332a24c11def\"]}, \"78\": {\"segment0\": [\"Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.\", \"2019-10-24T10:05:37Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"7658b0fa8ea14eb8acc62f015032bbeb\"], \"segment1\": [\"We do the same for actions as well.\", \"2019-10-24T10:06:19Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"ae7dc522e8ff44bda4cbd9aef5811b1a\"], \"segment2\": [\"Karthik event got the laptop chargers down.\", \"2019-10-24T10:06:29Z\", \"84fbaa66a2474ea29ae053f3a2e519d6\", \"321dbac48fa440cfa7a0e801bf6d64b1\"], \"segment3\": [\"So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready?\", \"2019-10-24T10:06:45Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"e697609e7e8b4de19a556a6e49471518\"], \"segment4\": [\"You create another show post with them.\", \"2019-10-24T10:07:12Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"e3cfd0caac88481592b8c2623cdfdd8a\"]}, \"82\": {\"segment0\": [\"That is yeah, but we try to call fate action items with groups.\", \"2019-10-24T10:14:09Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"bf11d1b5c35e4d6c8f946f66c85d8538\"]}, \"176\": {\"segment0\": [\"What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service. Yes generation field called Dont extract do not populate the graph. He will go give us a key phrases for that. And you want us to make basically they were in groups. We make any concurrent calls to get the key phases for each group.\", \"2019-10-24T09:57:51Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"aef4d82f30dd4eff9a653c12f091d669\"]}, \"194\": {\"segment0\": [\"So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted. We will trigger somebody header like with the new strategy. Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.\", \"2019-10-24T09:49:14Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"8e4abf19839e41c1ad14ec83b08da03c\"]}, \"245\": {\"segment0\": [\"Security my whole idea was like been in future. Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics. Then what is does is like for every discussion just give the highlights. But your again separating it into two groups right now. Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters. Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay. So if you if you want to know Or even nine third chapters as well. You can be seen before member this becomes different. But that your engine anything right now, right? So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?\", \"2019-10-24T10:09:10Z\", \"b1e8787a9a1f4859ac11cbb6a8124fd9\", \"5ce3830ac74449cfa0594d9e7e922315\"]}, \"247\": {\"segment0\": [\"No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it. So it is like recurring every five minutes. Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation. If you to make real time, it would still more or less work in the way you currently intended. But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong. So we had to make it real time. Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know. They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?\", \"2019-10-24T10:10:29Z\", \"62b6ae1d7f834b0bb2055f7c72bc3368\", \"3e73ba7a1b0543fc97519322f7eb9eb4\"]}}, \"ts\": \"2019-10-25T12:42:06.621559Z\", \"msg\": \"Final PIMs\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after this\n",
      "{0: {'segment0': ['it says so these are the input segmented is which have got we are able to see right when that', '2019-10-24T09:37:08Z', '84fbaa66a2474ea29ae053f3a2e519d6', '3be57485efb14ff8be6d23ecd62dabd2'], 'segment1': ['And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.', '2019-10-24T09:37:30Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f4c5c03c2e924de9847e0f2a65095d8c']}, 5: {'segment0': ['So we will update that keywords or something.', '2019-10-24T09:46:58Z', '84fbaa66a2474ea29ae053f3a2e519d6', '0983ef203b5248559376addb96cc125d'], 'segment1': ['We need to know the segment ready for.', '2019-10-24T09:47:06Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f2cac8169c05439fb45fc8055192e1f0'], 'segment2': ['That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here.', '2019-10-24T09:47:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a3cc958237dc46b4bd80e6ac6a7dd499'], 'segment3': ['Under the we like we need to purchase those sentences for one segment.', '2019-10-24T09:47:31Z', '84fbaa66a2474ea29ae053f3a2e519d6', '2be222ed2f79468d8fdae5cac0be38fb']}, 7: {'segment0': ['We evident even definitely girl second analyzed.', '2019-10-24T09:49:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a6ae53fc1f394851847a296b97189be9'], 'segment1': ['Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.', '2019-10-24T09:49:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8e4abf19839e41c1ad14ec83b08da03c']}, 9: {'segment0': ['Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.', '2019-10-24T09:51:06Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bd3dc1b663b147a886fe0b9ef9d10b2a'], 'segment1': ['I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.', '2019-10-24T09:51:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '131db9a5cba54cedac7d976b77e41b8e'], 'segment2': ['That means they cannot be reused for the second one.', '2019-10-24T09:52:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '49ae050d6a3341e9867cf4ce257bf5c2']}, 10: {'segment0': ['Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.', '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6']}, 18: {'segment0': ['You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.', '2019-10-24T10:00:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ef9b701a62ea481485ad23db01cbd776'], 'segment1': ['If I had to push back to slack with two sections one is topics and one of the actions.', '2019-10-24T10:01:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e51c3385ccc6405193808ec2711dc293']}, 24: {'segment0': ['Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.', '2019-10-24T10:08:21Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bd04b29039e14e0aba93598cde210dc5'], 'segment1': ['We do not have anything to do with the only thing somebody.', '2019-10-24T10:08:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '83fc6652dad543538c9a66dd245120a0'], 'segment2': ['So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928'], 'segment3': ['So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'], 'segment4': ['They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4'], 'segment5': ['Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.', '2019-10-24T10:11:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9648c443a927463daeb63edf81915bb7'], 'segment6': ['Were not going to intersperse the topics with the manual markers that have been created or not.', '2019-10-24T10:12:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '5c526d59a4ce4528abc88397f77dd539']}, 28: {'segment0': ['You create a new one will create a whole service Revenue Service.', '2019-10-24T09:41:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '269125104ee7483690ec2bc6b6f27e7e'], 'segment1': ['What is the request is nothing right only the instance ID unit meeting insensitive or whatever.', '2019-10-24T09:42:05Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'b3d10173ca17432e8e5ae3c1071fe323']}, 39: {'segment0': ['Is that whether it is five or six or seven?', '2019-10-24T10:02:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'beff02d81e604638939892b1b784d4b2'], 'segment1': ['I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space.', '2019-10-24T10:02:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e09a73ccea7b4e7d94c2f3992743cded']}, 41: {'segment0': ['Maybe not immediately, but that is if you go to production that might be needed.', '2019-10-24T10:04:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f00ada973054f28b67c4669d9be9e23'], 'segment1': ['Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.', '2019-10-24T10:04:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cd7717a085d0444f8fe3ee598fe81417'], 'segment2': ['But the mile marker does not contain those things.', '2019-10-24T10:04:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'a4c5cf81924e4ad7864d61a7c5f1b1e3'], 'segment3': ['But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.', '2019-10-24T10:04:53Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '84da28210d524bbcb0de12b3c068026b']}, 59: {'segment0': ['If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now.', '2019-10-24T09:39:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '390016daaf6e4634a4be7868593dd57d'], 'segment1': ['Maybe XnumberX seconds or something as a placeholder.', '2019-10-24T09:40:06Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '835f0f68ff8d4807b9f4a2aabad4f904'], 'segment2': ['Yeah, I have to like like four to five watches.', '2019-10-24T09:40:14Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '738ebdca3bf146d8bb8f974f00560eea'], 'segment3': ['But with respect to the API a signature ways.', '2019-10-24T09:40:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '531ca88fd1014c94953402ceff5efdb4'], 'segment4': ['It would be the same like whatever you give for scorer service, right?', '2019-10-24T09:41:04Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4102ada43e0844a696cde7a5a1c6b45c'], 'segment5': ['Okay, okay, he will not be expecting any scores.', '2019-10-24T09:41:25Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e759d5051b224ca8ab10e1e625e07a03']}, 62: {'segment0': ['So just so that we are all on the same page.', '2019-10-24T09:43:41Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'c737f43ae1ac4386bd19d78f00c244e2'], 'segment1': ['So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.', '2019-10-24T09:44:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '765f426547244837a63c95746c5c45be']}, 71: {'segment0': ['If you want me to give I can give it your all.', '2019-10-24T09:53:54Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'fb5f0a0913b94a0491374dd0a0ccfec5'], 'segment1': ['Do what you want to use then give it?', '2019-10-24T09:54:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '52bdaab6df324ca0bccf8ce34c35db12']}, 73: {'segment0': ['He will go give us a key phrases for that.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669'], 'segment1': ['Need to filter or reduce any counter.', '2019-10-24T09:58:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '86f39c46e153416ca86e69002db48097'], 'segment2': ['I think if it goes with I think the same logic that is going to intense actress currently a which session is a concept called here.', '2019-10-24T09:58:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '9d13652561494be78e32872df4d2f179'], 'segment3': ['Yeah, like so you have some XnumberX groups if you have done right do we?', '2019-10-24T09:58:57Z', '84fbaa66a2474ea29ae053f3a2e519d6', '90b04c9a271844e8b2dc332a24c11def']}, 78: {'segment0': ['Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.', '2019-10-24T10:05:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7658b0fa8ea14eb8acc62f015032bbeb'], 'segment1': ['We do the same for actions as well.', '2019-10-24T10:06:19Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'ae7dc522e8ff44bda4cbd9aef5811b1a'], 'segment2': ['Karthik event got the laptop chargers down.', '2019-10-24T10:06:29Z', '84fbaa66a2474ea29ae053f3a2e519d6', '321dbac48fa440cfa7a0e801bf6d64b1'], 'segment3': ['So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready?', '2019-10-24T10:06:45Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e697609e7e8b4de19a556a6e49471518'], 'segment4': ['You create another show post with them.', '2019-10-24T10:07:12Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e3cfd0caac88481592b8c2623cdfdd8a']}, 82: {'segment0': ['That is yeah, but we try to call fate action items with groups.', '2019-10-24T10:14:09Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bf11d1b5c35e4d6c8f946f66c85d8538']}, 176: {'segment0': ['What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service. Yes generation field called Dont extract do not populate the graph. He will go give us a key phrases for that. And you want us to make basically they were in groups. We make any concurrent calls to get the key phases for each group.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669']}, 194: {'segment0': ['So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted. We will trigger somebody header like with the new strategy. Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.', '2019-10-24T09:49:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8e4abf19839e41c1ad14ec83b08da03c']}, 245: {'segment0': ['Security my whole idea was like been in future. Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics. Then what is does is like for every discussion just give the highlights. But your again separating it into two groups right now. Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters. Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay. So if you if you want to know Or even nine third chapters as well. You can be seen before member this becomes different. But that your engine anything right now, right? So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315']}, 247: {'segment0': ['No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it. So it is like recurring every five minutes. Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation. If you to make real time, it would still more or less work in the way you currently intended. But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong. So we had to make it real time. Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know. They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4']}}\n"
     ]
    }
   ],
   "source": [
    "from main import handler\n",
    "\n",
    "res = handler(request, None)\n",
    "group = json.loads(res['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "7\n",
      "9\n",
      "18\n",
      "24\n",
      "28\n",
      "39\n",
      "41\n",
      "59\n",
      "62\n",
      "71\n",
      "73\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "for g in group['group'].keys():\n",
    "    if len(group['group'][g])>1:\n",
    "        print (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Id:  0\n",
      "Mithun Discussed \n",
      "\n",
      " Text:  If you see the screen, right, I have one log. it says so these are the input segmented is which have got we are able to see right when that  Yeah, the group segmented is her like mostly like to two segments are grouped. And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than 120 seconds. Yeah, that's the reason.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  5\n",
      "Mithun, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  So we'll update that keywords or something. Is there at that field will have to update once we get it?  But we need to know the mapping for that. Whatever the text they give right? We need to know the segment ready for.  DWS. Yeah, here is the same thing. That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here. The next sentence is a text when a field called text and a hiding with the sentence belong funny.  Under the we like we need to purchase those sentences for one segment. It was pretty to some for sentences.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  7\n",
      "Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  We evident even definitely girl second analyzed. Is it only for triggering summary or is it about doing anything?  So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted. All segments have been transcribed. The Randy is over recording available. We will trigger somebody header like with the new strategy. Yeah, and it's one. What'd you do is 3/4 gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth. that they using for grouping the  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  9\n",
      "Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  Community let's assume it's the same deployment because what you're doing is you're accepting features and you're just using those features and breaking the sentence article with somebody right to deserve. This is what your goal is. So in this one so but is it up' can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective.  I'm saying one is doing feature extraction one is we during the call are doing protects pre-processing on each segment and doing feature extraction and returning okay of error. Yes at the end of the curve you getting all the segments and you're doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment's to which they belong right?  So are they very tightly coupled with each other. That means they cannot be reused for the second one.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  18\n",
      "Venkata Dikshit, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  No, not not that big a dick. So what happens is like it's similar to Chapters. You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights. So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion.  Let me put it this way. If I had to push back to slack with two sections one is topics and one of the actions. Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  24\n",
      "Venkata Dikshit, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  Let's stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions. There is also acceptable anymore if you have this.  And we have to have something else. We don't have anything to do with the only thing somebody.  Ideally table of contents can only be found in the book is complete. Yeah, right. So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part. You don't necessarily have to correlate to a topic. So let's separate that and I like that idea from this video. Maybe not caught not listen call them chapters.  Security my whole idea was like been in future. Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics. Then what is does is like for every discussion just give the highlights. But your again separating it into two groups right now. They're not kill groups. Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters. Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it's okay. So if you if you want to know Or even nine third chapters as well. You can be seen before member this becomes different. But that your engine anything right now, right? So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it won't let us see what happens, right?  No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they're two different age is one is just by minute highlights five-minute keywords essential keywords within a specific time period they don't all of it. So it's like recurring every five minutes. We'll come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you're doing right now you're trying to To distinguish the essential topics in a Convent in a complete conversation. If you to make real time, it would still more or less work in the way you currently intended. But with some caveats here and there but it's not necessarily going to be completed the same as every five minute keywords that we do right wrong. So we had to make it real time. We'll figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let's not, you know. They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?  Cause this update this one say topics and maybe put this comment at the other one some a service because that's what method is following and Link both of them this issue that open. So initially, what we'll do in staging we will not be markers in the new summary the way we push things somebody.  So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production. We're going to use it. Whatever you use right now. Hmm that very comfortable that this is working as intended. We can include that make sense. So even for now just so that we can observe what's coming out from the grouping and what we expect in the keywords. We're not going to intersperse the topics with the manual markers that have been created or not.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  28\n",
      "Venkata Dikshit, Mithun Discussed \n",
      "\n",
      " Text:  You create a new one will create a whole service Revenue Service. So I would be so it's a new URL.  With respect to the first one the second the API. What is the request is nothing right only the instance ID unit meeting insensitive or whatever.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  39\n",
      "Venkata Dikshit Discussed \n",
      "\n",
      " Text:  It's the same so good. So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important. Is that whether it is five or six or seven?  We thought we will stick to five for now and then do that but that's not really that doesn't stop anything. I say so even even now that still remain so what are we return you will show everything or if you don't want it to be clever put an upper limit put a upper limit to better manage the space.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  41\n",
      "Karthik Muralidharan, Venkata Dikshit Discussed \n",
      "\n",
      " Text:  Maybe not immediately, but that's if you go to production that might be needed. We need to First other words coming back and then decide how this will be. But just you have to keep that in mind.  Improving service array basically if you're giving a segments, yeah, you can see that there are some between this time range. We found something for you as a topic and within that time range itself be graded on someone read a manual marker. Hmm. It should prefer that to this one.  Yeah, but when we say we found topic we give them a list of subtopics and everything, right? But the mile marker doesn't contain those things.  But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye. Okay, you just by looking at them even slap.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  59\n",
      "Venkata Dikshit, Mithun Discussed \n",
      "\n",
      " Text:  Yes, you can it's make the product magnetic sensor consists for the names of my service itself. If it's 10 seconds, if you want to remove the condition make it make it less than threshold for now. We'll until we finalize something.  Maybe 10 seconds or something as a placeholder. So inside or today's call it happen.  Okay, its production rate so it's not even updated. Yeah, I have to like like four to five watches.  Let's discuss on the community thing, right? So so I had looked at that tart that flowchart Witcher 3 had sent rate on the earlier. The design-wise it's fine. But with respect to the API a signature ways. I wanted to discuss like what are the request response those things basically?  It would be the same like whatever you give for scorer service, right? Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?  Okay, okay, he won't be expecting any scores. But the name Remains the Same or itself should be different, right?  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  62\n",
      "Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  So just so that we're all on the same page. Let me just reiterate what has been mentioned in the  So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary. These are the some regeneration process. But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  71\n",
      "Venkata Dikshit, Karthik Muralidharan Discussed \n",
      "\n",
      " Text:  I have that. I am carrying all that information at that point. If you want me to give I can give it your all.  Do what you want to use then give it? and is of the altered X. Okay, so and it'll also add a new field called feel call or text in each object. Yeah.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  73\n",
      "Karthik Muralidharan, Venkata Dikshit, Mithun Discussed \n",
      "\n",
      " Text:  What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service. Yes generation field called Don't extract don't populate the graph. He will go give us a key phrases for that. And you want us to make basically they were in groups. We make any concurrent calls to get the key phases for each group.  So once that is done, let's assume we got all the for each group. We get key places. What do we do do we? Need to filter or reduce any counter. We just take medication.  I think if it goes with I think the same logic that's going to intense actress currently a which session is a concept called here. Also, that means he pick up the number of pieces you can see.  That is that is our first group a number of key phrases, right? Yeah, like so you have some 20 groups if you have done right do we?  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group Id:  78\n",
      "Karthik Muralidharan, Mithun, Venkata Dikshit Discussed \n",
      "\n",
      " Text:  That's so yeah, you don't have to do in the pool right now. Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later. We can side of correlate. Okay, let's do overlap macon's do we remove this or do we keep this or what makes sense?  We do the same for actions as well. So we'll have to have like a pipeline for that like in each section that we publish.  Karthik event got the laptop chargers down. Actually, there's no power from two or three hours. I think I am trying to connect some iOS but it is fairly.  Yeah, okay. Thanks Martin. So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready? So that method can start working on it. Right? You mean the response structure? Yeah.  It's clear, but you can put it in the other you have another issue right in the APA GitHub itself. You create another show post with them. I think the other one.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id_map = {}\n",
    "user_id_map = {\"b4a57b25de68446cac990f856d3fe4d5\":\"ether\",\"716067a60a1a4034abc49a12ecafb39b\":\"Ether\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"ether\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    if len(seg_list)<=1:\n",
    "        continue\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T12:10:08.092248Z",
     "start_time": "2019-10-16T12:09:56.539286Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "user_id_map = {\"716067a60a1a4034abc49a12ecafb39b\":\"Ether\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"ether\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_result = {}\n",
    "pim_response = {}\n",
    "pim_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\"}\n",
    "pim_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\", \"segments\": []}\n",
    "temp = \"\"\n",
    "temp_users = []\n",
    "for groupid in group['group'].keys():\n",
    "    temp = \"\"\n",
    "    temp_users = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        temp+=segi[\"originalText\"]\n",
    "        temp_users.append(segi[\"spokenBy\"])\n",
    "    pim_response[\"segments\"].append({\"id\":\"abc\",\"originalText\":temp,\"spokenBy\":temp_users})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_pims_score({\"body\":pim_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pim = json.loads(result)['d2vResult']\n",
    "pim = sorted(pim, key=lambda kv:kv[\"distance\"], reverse=False)\n",
    "for seg in pim:\n",
    "    print ( \" , \".join(list(set(user_id_map[i] for i in seg[\"speaker\"]))), \" discussed: \\n\", seg[\"text\"], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PIMs for the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:32:07.101125Z",
     "start_time": "2019-10-16T09:32:07.014546Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import client\n",
    "from botocore.client import Config\n",
    "import numpy as np\n",
    "import json\n",
    "aws_config = Config(\n",
    "        connect_timeout=60,\n",
    "        read_timeout=300,\n",
    "        retries={\"max_attempts\": 0},\n",
    "        region_name=\"us-east-1\",\n",
    "    )\n",
    "lambda_client = client(\"lambda\", config=aws_config)\n",
    "\n",
    "def get_pims_score(req):\n",
    "\n",
    "    #if req_data is None:\n",
    "    #    lambda_payload = {\"body\": input_list}\n",
    "    #    print (json.dumps(lambda_payload))\n",
    "    #else:\n",
    "    #    lambda_payload = {\"body\": {\"request\": req_data, \"text_input\": input_list}}\n",
    "        \n",
    "    try:\n",
    "        #logger.info(\"Invoking lambda function\")\n",
    "        invoke_response = lambda_client.invoke(\n",
    "            FunctionName=\"pim\",\n",
    "            InvocationType=\"RequestResponse\",\n",
    "            Payload=json.dumps(req),\n",
    "        )\n",
    "        lambda_output = (\n",
    "            invoke_response[\"Payload\"].read().decode(\"utf8\")\n",
    "        )\n",
    "        response = json.loads(lambda_output)\n",
    "        status_code = response[\"statusCode\"]\n",
    "        response_body = response[\"body\"]\n",
    "\n",
    "        #if status_code == 200:\n",
    "        #    result = json.loads(response_body)['d2vResult'][0]['distance']\n",
    "        return response_body\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:32:55.418939Z",
     "start_time": "2019-10-16T09:32:07.762456Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pim_result = {}\n",
    "pim_response = {}\n",
    "pim_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\"}\n",
    "pim_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DAAYHEKY5F4E02QVRJPTFTXV\", \"segments\": []}\n",
    "temp = {}\n",
    "for seg in request['body']['segments']:\n",
    "    pim_request[\"segments\"] = [seg]\n",
    "    # get_pims_score({\"body\":pim_request})\n",
    "    pim_result[seg[\"recordingId\"]] =  get_pims_score({\"body\":pim_request})\n",
    "    temp = seg\n",
    "    temp[\"distance\"] = pim_result[seg[\"recordingId\"]]\n",
    "    pim_response[\"segments\"].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:47.292227Z",
     "start_time": "2019-10-16T09:33:47.205140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for seg in pim_response[\"segments\"]:\n",
    "    result.append( (seg[\"originalText\"], seg[\"distance\"], seg[\"recordingId\"]))\n",
    "result = sorted(result, key=lambda kv:kv[1])\n",
    "for (text, score, segid) in result:\n",
    "    print (text , \" =====> \", score, segid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T07:16:12.948463Z",
     "start_time": "2019-10-16T07:16:12.892361Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract topic level pims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:49.539609Z",
     "start_time": "2019-10-16T09:33:49.494149Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import extract_topic_pims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:52.577313Z",
     "start_time": "2019-10-16T09:33:52.520939Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from extract_topic_pims.main import handler\n",
    "\n",
    "res = handler({\"body\":{\"groups\": group[\"group\"], \"pims\": pim_response}}, None)\n",
    "final_pims = json.loads(res)[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:33:56.517504Z",
     "start_time": "2019-10-16T09:33:56.462922Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "user_id_map = {\"2f506a3d9e814de69d46a1fbf949fdc9\":\"Shubham\",\"2cd90f0674f348cc922acd6b8782ba0f\":\"Shubham\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"b4a57b25de68446cac990f856d3fe4d5\":\"Deep Moradia\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ai-engine/pkg/\")\n",
    "\n",
    "from graphrank.core import GraphRank\n",
    "from graphrank.utils import GraphUtils, TextPreprocess\n",
    "\n",
    "gr = GraphRank()\n",
    "tp = TextPreprocess()\n",
    "gu = GraphUtils()\n",
    "\n",
    "def get_desc(sentence):\n",
    "    original_tokens, pos_tuple, filtered_pos_tuple = tp.preprocess_text(sentence, filter_by_pos=True, stop_words=False)\n",
    "    word_graph = gr.build_word_graph(graph_obj=None, input_pos_text=pos_tuple, window=4, preserve_common_words=False)\n",
    "    normal_keyphrase = gr.get_keyphrases(word_graph, pos_tuple, post_process=True)\n",
    "    desc_keyphrase = gr.get_keyphrases(word_graph, pos_tuple, descriptive=True, post_process_descriptive=True)\n",
    "    desc_keyphrase = sorted(desc_keyphrase, key=lambda kv:kv[1], reverse=True)\n",
    "    normal_kp = [phrase for phrase, score in normal_keyphrase]\n",
    "    desc_kp = [phrase for phrase, score in desc_keyphrase]\n",
    "    \n",
    "    return normal_kp, desc_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:34:06.058534Z",
     "start_time": "2019-10-16T09:34:05.255435Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for groupid in final_pims:\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in groupid:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    print (\"Keyphrases: \", end=\"\")\n",
    "    print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T09:34:01.892976Z",
     "start_time": "2019-10-16T09:34:01.837042Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "user_id_map = {\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing hierarchy community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:02:27.110487Z",
     "start_time": "2019-09-30T15:02:27.050494Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('topic_testing/podcast_28.txt', 'rb') as f:\n",
    "    request = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:04:15.380539Z",
     "start_time": "2019-09-30T15:02:27.410077Z"
    }
   },
   "outputs": [],
   "source": [
    "from main import handler\n",
    "\n",
    "res = handler(request, None)\n",
    "group = json.loads(res['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:05:44.525847Z",
     "start_time": "2019-09-30T15:05:44.435681Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "m_time = formatTime(\"2019-09-28T05:34:21Z\", True)\n",
    "#m_time = formatTime(\"2019-09-30T10:28:00Z\", True)\n",
    "for i in group['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:16:21.322195Z",
     "start_time": "2019-09-30T15:16:21.261435Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = []\n",
    "for i in group['group'].keys():\n",
    "    if len(group['group'][i])==1:\n",
    "        continue\n",
    "    else:\n",
    "        temp = []\n",
    "        for seg in group['group'][i]:\n",
    "            temp.append(seg['originalText'])\n",
    "        groups.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:17:35.047968Z",
     "start_time": "2019-09-30T15:16:21.757535Z"
    }
   },
   "outputs": [],
   "source": [
    "group_result = {}\n",
    "#group_response = {}\n",
    "group_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01daaqyn9gbebc92aywnxedp0c\", \"instanceId\": \"xyz\"}\n",
    "#group_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DADP74WFV607KNPCB6VVXGTG\", \"segments\": []}\n",
    "temp = {}\n",
    "group_itr = None\n",
    "for segments_id in group['group'].keys():\n",
    "    if len(group['group'][segments_id]) > 2:\n",
    "        group_request['segments'] = group['group'][segments_id]\n",
    "        res = handler({\"body\":group_request}, None)\n",
    "        group_itr = json.loads(res['body'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:21:36.916596Z",
     "start_time": "2019-09-30T15:21:36.514422Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:28:00Z\", True)\n",
    "m_time = formatTime(\"2019-09-28T05:34:21Z\", True)\n",
    "for i in group_itr['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group_itr['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:29:39.535024Z",
     "start_time": "2019-09-30T14:29:07.063968Z"
    }
   },
   "outputs": [],
   "source": [
    "group_result = {}\n",
    "#group_response = {}\n",
    "group_request = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DADP74WFV607KNPCB6VVXGTG\", \"instanceId\": \"xyz\"}\n",
    "#group_response = {\"contextId\": request[\"body\"][\"contextId\"], \"mindId\": \"01DADP74WFV607KNPCB6VVXGTG\", \"segments\": []}\n",
    "temp = {}\n",
    "group_itr_2 = None\n",
    "for segments_id in group_itr['group'].keys():\n",
    "    if len(group_itr['group'][segments_id]) > 2:\n",
    "        group_request['segments'] = group_itr['group'][segments_id]\n",
    "        res = handler({\"body\":group_request}, None)\n",
    "        group_itr_2 = json.loads(res['body'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:30:41.736210Z",
     "start_time": "2019-09-30T14:30:41.595388Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:28:00Z\", True)\n",
    "for i in group_itr_2['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group_itr_2['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:12:14.592267Z",
     "start_time": "2019-09-30T14:12:14.446839Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualization\n",
    "import iso8601\n",
    "from datetime import datetime\n",
    "# meeting start time.\n",
    "def formatTime(tz_time, datetime_object=False):\n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "\n",
    "    if datetime_object:\n",
    "        ts = datetime.fromisoformat(ts)\n",
    "    return ts\n",
    "\n",
    "#m_time = formatTime(\"2019-09-19T06:05:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-22T09:37:00Z\", True)\n",
    "#m_time = formatTime(\"2019-09-16T09:53:21Z\", True)\n",
    "m_time = formatTime(\"2019-09-30T10:08:00Z\", True)\n",
    "for i in group['group'].keys():\n",
    "    print (\"\\n\\n\\nPIMs \", i)\n",
    "    print (\"\\n\\nDiscussion:\\n\\n \")\n",
    "    for seg in group['group'][i]:\n",
    "        print (\"Minutes from the start of the meeting: \", formatTime(seg['startTime'], True) - m_time , seg['id'],\"\\n\")\n",
    "        print (seg['originalText'],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ai-engine/pkg/\")\n",
    "import math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from boto3 import client as boto3_client\n",
    "import json\n",
    "import logging\n",
    "from botocore.client import Config\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "config = Config(connect_timeout=240, read_timeout=240, retries={'max_attempts': 0} )\n",
    "lambda_client = boto3_client('lambda', config=config,     aws_access_key_id=\"AKIA5SUS6MWO4MP7KDEJ\",\n",
    "    aws_secret_access_key=\"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\"\n",
    ")\n",
    "\n",
    "def get_output(input_sent, req_data=None):\n",
    "    #aws_config = Config(\n",
    "    #    connect_timeout=60,\n",
    "    ##    read_timeout=300,\n",
    "    #    retries={\"max_attempts\": 0},\n",
    "    #    region_name=\"us-east-1\",\n",
    "    #)\n",
    "    #lambda_client = boto3_client(\"lambda\", config=aws_config)\n",
    "    if req_data is None:\n",
    "        lambda_payload = input_sent\n",
    "    #logger.info(\"Invoking lambda function\")\n",
    "    invoke_response = lambda_client.invoke(\n",
    "        FunctionName=\"arn:aws:lambda:us-east-1:933389821341:function:group-segments\",\n",
    "        InvocationType=\"RequestResponse\",\n",
    "        Payload=lambda_payload\n",
    "    )\n",
    "    print (\"response recieved\", invoke_response)\n",
    "    lambda_output = (\n",
    "        invoke_response[\"Payload\"].read().decode(\"utf8\").replace(\"'\", '\"')\n",
    "    )\n",
    "    response = json.loads(lambda_output)\n",
    "    status_code = response[\"statusCode\"]\n",
    "    response_body = response[\"body\"]\n",
    "\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"topic_testing/sync_eng_21_10.txt\",\"rb\") as f:\n",
    "    request = json.load(f)\n",
    "response = get_output(json.dumps(request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = response\n",
    "user_id_map = {}\n",
    "user_id_map = {\"716067a60a1a4034abc49a12ecafb39b\":\"Ether\",\"2f506a3d9e814de69d46a1fbf949fdc9\":\"ether\",\"8d6db5f7d9b74c54ba38fe710ffcaf3f\":\"Krishna Sai\", \"c66797a92e6d46ad9573926e57f7dac3\":\"Nisha Yadav\",\"31a3ba4761854ad9a041ddf1c4c6a1dc\":\"Reagan Rewop\",\"84fbaa66a2474ea29ae053f3a2e519d6\":\"Mithun\",\"75bdf310110b4b8fab88b16fafce920e\":\"Trishanth Diwate\",\"b1e8787a9a1f4859ac11cbb6a8124fd9\": \"Venkata Dikshit\", \"fb52cb663aec4795aee38ccfd904d315\":\"Reagan Rewop\", \"81a3e15469374fceba1cf972faa209b2\":\"Arjun Kini\", \"ecfeeb757f0a4d47af1ebd513929264a\":\"Shubham\", \"62b6ae1d7f834b0bb2055f7c72bc3368\":\"Karthik Muralidharan\", \"1a21542584494fcaba957d768b595b80\":\"Vamshi Krishna\", \"7e7ccbba232d411aa95ad3f244a35f40\":\"Shashank\", \"65bb83952fb54409a4bb59bb707f1375\":\"Vani\", \"0bbbfe84c66145af8d0ffcd5258bba38\":\"Parshwa Nemi Jain\"}\n",
    "\n",
    "for groupid in group['group'].keys():\n",
    "    user_list =[]\n",
    "    seg_list = []\n",
    "    keyphrase = []\n",
    "    for segi in group['group'][groupid]:\n",
    "        if segi['spokenBy'] not in user_list:\n",
    "            user_list.append(segi['spokenBy'])\n",
    "        seg_list.append(segi['originalText'])\n",
    "        #keyphrase.append(get_desc(segi['originalText']))\n",
    "    #print (\"User\", end=\" \")\n",
    "    print (\"Group Id: \", groupid)\n",
    "    print (*[user_id_map[user] for user in user_list], sep=\", \", end=\" \")\n",
    "    print (\"Discussed \\n\\n Text: \", *seg_list, \"\\n\\n  \")\n",
    "    #print (\"Keyphrases: \", end=\"\")\n",
    "    #print (*get_desc(\" \".join(sent for sent in seg_list))[1][:5], sep=\", \")\n",
    "    print ( \"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sri_gpt",
   "language": "python3",
   "name": "sri_gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
