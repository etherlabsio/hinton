{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:14:06.389945Z",
     "start_time": "2020-03-10T20:14:06.210322Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:14:54.539504Z",
     "start_time": "2020-03-10T20:14:07.029289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /tmp/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /tmp/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /tmp/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../helper_functions/\")\n",
    "\n",
    "import recency_util_live\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/ray__/ssd/BERT/\") # gpt model utils location\n",
    "from gpt_feat_utils import GPT_Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:27:49.312459Z",
     "start_time": "2020-03-10T20:27:49.263617Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "## initialise artifacts\n",
    "\n",
    "#gpt_model = GPT_Inference(\"/home/ray__/ssd/BERT/models/se/epoch3/\", device=\"cpu\") # gpt model location.\n",
    "domain = \"ai\"\n",
    "artifacts_dir = \"/home/ray__/ssd/minds/\" + domain + \"/recency_cw/\" # location which contains com_map, sent_dict, kp_entity_graph, gc, lc, entity and label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# During call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:27:51.643407Z",
     "start_time": "2020-03-10T20:27:51.590660Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def computing_groups(request, artifacts_dir):    \n",
    "    group, group_ent_map_rank_lc, group_ent_map_rank_gc, gc, lc, group_ent_map_filtered, group_ent = recency_util_live.compute_groups_new_call(request, artifacts_dir, True)\n",
    "    return group, group_ent_map_rank_lc, group_ent_map_rank_gc, gc, lc, group_ent_map_filtered, group_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:27:52.013360Z",
     "start_time": "2020-03-10T20:27:51.812705Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_filtered_groups(group):\n",
    "    filtered_group = {}\n",
    "    group\n",
    "    count = 0\n",
    "    for groupid, freq in sorted(group_ent_map_rank_lc.items(), key=lambda kv:kv[1], reverse=True):\n",
    "        if count !=5:\n",
    "            filtered_group[groupid] = group[groupid]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    for groupid, freq in sorted(group_ent_map_rank_gc.items(), key=lambda kv:kv[1], reverse=True):\n",
    "        if count !=5:\n",
    "            filtered_group[groupid] = group[groupid]\n",
    "        else:\n",
    "            pass\n",
    "    return filtered_group\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:27:52.448940Z",
     "start_time": "2020-03-10T20:27:52.397865Z"
    }
   },
   "outputs": [],
   "source": [
    "# for groupid, groupobj in filtered_group.items():\n",
    "#     print (\"\\n\\nGroupid: \", groupid, \"\\n\\n\")\n",
    "#     seg_list = [seg[\"originalText\"] for seg in groupobj]\n",
    "#     print (*seg_list, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:27:53.209251Z",
     "start_time": "2020-03-10T20:27:53.160462Z"
    }
   },
   "outputs": [],
   "source": [
    "# lc = pickle.load(open(\"/home/ray__/ssd/minds/se/recency/lc.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post call - graph related updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:28:17.062803Z",
     "start_time": "2020-03-10T20:27:53.636978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"info\", \"filename\": \"file_utils.py\", \"lineno\": 38, \"module\": \"file_utils\", \"ts\": \"2020-03-10T20:27:56.249487Z\", \"msg\": \"PyTorch version 1.1.0 available.\"}\n",
      "{\"level\": \"warning\", \"filename\": \"tokenization_openai.py\", \"lineno\": 96, \"module\": \"tokenization_openai\", \"ts\": \"2020-03-10T20:28:09.772757Z\", \"msg\": \"ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\"}\n",
      "{\"level\": \"info\", \"filename\": \"tokenization_utils.py\", \"lineno\": 416, \"module\": \"tokenization_utils\", \"ts\": \"2020-03-10T20:28:09.953392Z\", \"msg\": \"Adding _start_ to the vocabulary\"}\n",
      "{\"level\": \"info\", \"filename\": \"tokenization_utils.py\", \"lineno\": 416, \"module\": \"tokenization_utils\", \"ts\": \"2020-03-10T20:28:09.954320Z\", \"msg\": \"Adding _delimiter_ to the vocabulary\"}\n",
      "{\"level\": \"info\", \"filename\": \"tokenization_utils.py\", \"lineno\": 416, \"module\": \"tokenization_utils\", \"ts\": \"2020-03-10T20:28:09.955162Z\", \"msg\": \"Adding _classify_ to the vocabulary\"}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ray__/ssd/pos_tag/code/\") # Custom pos tag location.\n",
    "sys.path.append(\"/home/ray__/ssd/\") # ner util code\n",
    "import recency_util_post\n",
    "\n",
    "#from bert_ner_utils_graph import BERT_NER\n",
    "#from distilbert_pos_tagger import DistilBertPosTagger\n",
    "\n",
    "#pos_tagger = DistilBertPosTagger(\"/home/ray__/ssd/pos_tag/model/Distilbert/\",\"cpu\")\n",
    "#ner_model = BERT_NER('/home/ray__/ssd/bert-ner/',labels = [\"O\", \"MISC\", \"MISC\",  \"PER\", \"PER\", \"ORG\", \"ORG\", \"LOC\", \"LOC\"],device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:28:17.142711Z",
     "start_time": "2020-03-10T20:28:17.065598Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_mind_artifacts(filtered_group, artifacts_dir):\n",
    "    master_paragraphs, master_ids = recency_util_post.get_grouped_segments(filtered_group)\n",
    "    multi_label_dict = pickle.load(open(artifacts_dir + \"label_dict.pkl\",\"rb\"))\n",
    "    ent_feat_dict = pickle.load(open(artifacts_dir + \"entity.pkl\",\"rb\"))\n",
    "\n",
    "    ent_sent_dict, kp_sent_dict, label_dict, noun_list, entity_dict = recency_util_post.form_sentence_graph(master_paragraphs, master_ids, multi_label_dict)\n",
    "    ent_single_label_dict, all_sent_dict = recency_util_post.form_single_label_dict(label_dict, ent_sent_dict, kp_sent_dict)\n",
    "    kp_entity_graph = recency_util_post.get_base_graph(artifacts_dir)\n",
    "    kp_entity_graph, node_list = recency_util_post.update_entity_nodes(kp_entity_graph, ent_sent_dict, multi_label_dict)\n",
    "    kp_entity_graph, node_list = recency_util_post.update_kp_nodes(kp_entity_graph, ent_sent_dict, node_list, kp_sent_dict)\n",
    "    kp_entity_graph = recency_util_post.update_edges(kp_entity_graph, node_list, all_sent_dict, artifacts_dir)\n",
    "    kp_entity_graph = recency_util_post.update_kp_tokens(kp_entity_graph, node_list)\n",
    "    ent_kp_graph = recency_util_post.store_final_graph(kp_entity_graph, artifacts_dir)\n",
    "    entity_dict = recency_util_post.update_entity_feat_dict(entity_dict, ent_feat_dict)\n",
    "    return ent_sent_dict, entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:28:17.264359Z",
     "start_time": "2020-03-10T20:28:17.146300Z"
    }
   },
   "outputs": [],
   "source": [
    "# pickle.dump(kp_entity_graph, open(\"/home/ray__/ssd/minds/se/recency/kp_entity_graph.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:28:17.438667Z",
     "start_time": "2020-03-10T20:28:17.267791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sync_ml_24_10.txt',\n",
       " 'sync_ml_11_25.txt',\n",
       " 'sync_ml_03.txt',\n",
       " 'sync_ml_12_19.txt',\n",
       " 'sync_ml_24_10-Copy1.txt',\n",
       " 'sync_ml_30.txt',\n",
       " 'sync_ml_2020_02_12.txt',\n",
       " 'sync_ml_14_10.txt',\n",
       " 'sync_ml_11_28.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../recency_dataset/ai/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipelined Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T20:30:22.780924Z",
     "start_time": "2020-03-10T20:28:17.441811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  None  for feature extraction\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 103, \"module\": \"scorer\", \"batches count\": 1, \"number of sentences\": 167, \"ts\": \"2020-03-10T20:28:22.501735Z\", \"msg\": \"computing in batches\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 106, \"module\": \"scorer\", \"iteration count:\": 0, \"ts\": \"2020-03-10T20:28:22.503968Z\", \"msg\": \"getting feature vector\"}\n",
      "('Is there at that field will have to update once we get it?', '2019-10-24T09:46:58Z', '84fbaa66a2474ea29ae053f3a2e519d6', '0983ef203b5248559376addb96cc125d') ('It depends if we know what segment ideas we should probably update the key phrases like video right now because we use it.', '2019-10-24T09:46:49Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '183b0c4fcb2546aa8479160a6dd8f86c')\n",
      "('I know but does that help because we want to give them topics in the connotation.', '2019-10-24T09:59:57Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '1cf24541a3514a2f86d05f74f62fe6e3') ('You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.', '2019-10-24T10:00:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ef9b701a62ea481485ad23db01cbd776')\n",
      "('Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.', '2019-10-24T10:08:21Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bd04b29039e14e0aba93598cde210dc5') ('So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928')\n",
      "('Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.', '2019-10-24T10:08:21Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bd04b29039e14e0aba93598cde210dc5') ('So let us separate that and I like that idea from this video.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928')\n",
      "('You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.', '2019-10-24T10:00:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ef9b701a62ea481485ad23db01cbd776') ('Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.', '2019-10-24T10:01:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e51c3385ccc6405193808ec2711dc293')\n",
      "('Yes, you can it is make the product magnetic sensor consists for the names of my service itself.', '2019-10-24T09:39:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '390016daaf6e4634a4be7868593dd57d') ('It would be the same like whatever you give for scorer service, right?', '2019-10-24T09:41:04Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4102ada43e0844a696cde7a5a1c6b45c')\n",
      "('So you would make a pair called the landlord be same for both APA Falls, except the page the input changes.', '2019-10-24T09:43:32Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '684d1db8043f4c738409345102d7a044') ('So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.', '2019-10-24T09:44:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '765f426547244837a63c95746c5c45be')\n",
      "('So you would make a pair called the landlord be same for both APA Falls, except the page the input changes.', '2019-10-24T09:43:32Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '684d1db8043f4c738409345102d7a044') ('But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.', '2019-10-24T09:44:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '765f426547244837a63c95746c5c45be')\n",
      "('We do not have anything to do with the only thing somebody.', '2019-10-24T10:08:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '83fc6652dad543538c9a66dd245120a0') ('So let us separate that and I like that idea from this video.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928')\n",
      "('We do not have anything to do with the only thing somebody.', '2019-10-24T10:08:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '83fc6652dad543538c9a66dd245120a0') ('So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315')\n",
      "('Okay, so then do not do not show it in the slack, but you still have to propagate that to the graphs and every other turn same class that uses this.', '2019-10-24T10:05:12Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'b13bb3e8ad7248d59dc4dd16fa81699a') ('That is so yeah, you do not have to do in the pool right now.', '2019-10-24T10:05:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7658b0fa8ea14eb8acc62f015032bbeb')\n",
      "('Okay, so then do not do not show it in the slack, but you still have to propagate that to the graphs and every other turn same class that uses this.', '2019-10-24T10:05:12Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'b13bb3e8ad7248d59dc4dd16fa81699a') ('But generally the idea was if you had sections of topics actions and decisions and we just did a great job on discovering them and someone had given some signals we take that and use that instead of words automatically.', '2019-10-24T10:06:00Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8ec61fc25ef44f1e810b0f17d1422470')\n",
      "('First one is also Lambda or it is a service rate the current service on this end.', '2019-10-24T09:43:17Z', '84fbaa66a2474ea29ae053f3a2e519d6', '7a46bff8ef27494ab87bd13b363feae6') ('You sent a request with the same request you present for new service.', '2019-10-24T09:42:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ab22180c9af64f12974a806f574e0cb2')\n",
      "('We will be using those where we were using only the older version like to get the score the only top XnumberX in kind of thing, right but in this new one, we do not need anything because we do not have any data, right?', '2019-10-24T09:45:34Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'ef05c0a0bc254eb0927a5b41f10e0572') ('Some default like XnumberX or something like the score so that will not pick that values.', '2019-10-24T09:45:25Z', '84fbaa66a2474ea29ae053f3a2e519d6', '14dd6a5daeea4ec3bf59eb567300dcec')\n",
      "('We will be using those where we were using only the older version like to get the score the only top XnumberX in kind of thing, right but in this new one, we do not need anything because we do not have any data, right?', '2019-10-24T09:45:34Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'ef05c0a0bc254eb0927a5b41f10e0572') ('But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there.', '2019-10-24T09:46:21Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'dc9670f4070549c58777cd5762154777')\n",
      "('That so I just sharing the screen of one of the meeting happened just now.', '2019-10-24T09:36:48Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c8ee1afb64f74ec380c133f570084b0b') ('Yeah, the group segmented is her like mostly like to two segments are grouped.', '2019-10-24T09:37:30Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f4c5c03c2e924de9847e0f2a65095d8c')\n",
      "('That so I just sharing the screen of one of the meeting happened just now.', '2019-10-24T09:36:48Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c8ee1afb64f74ec380c133f570084b0b') ('And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.', '2019-10-24T09:37:30Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f4c5c03c2e924de9847e0f2a65095d8c')\n",
      "('it says so these are the input segmented is which have got we are able to see right, it is less than XnumberX secibds.', '2019-10-24T09:37:08Z', '84fbaa66a2474ea29ae053f3a2e519d6', '3be57485efb14ff8be6d23ecd62dabd2') ('Yeah, the group segmented is her like mostly like to two segments are grouped.', '2019-10-24T09:37:30Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f4c5c03c2e924de9847e0f2a65095d8c')\n",
      "('it says so these are the input segmented is which have got we are able to see right, it is less than XnumberX secibds.', '2019-10-24T09:37:08Z', '84fbaa66a2474ea29ae053f3a2e519d6', '3be57485efb14ff8be6d23ecd62dabd2') ('And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.', '2019-10-24T09:37:30Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f4c5c03c2e924de9847e0f2a65095d8c')\n",
      "('So once that is done, let us assume we got all the for each group.', '2019-10-24T09:58:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '86f39c46e153416ca86e69002db48097') ('What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669')\n",
      "('So once that is done, let us assume we got all the for each group.', '2019-10-24T09:58:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '86f39c46e153416ca86e69002db48097') ('That is that is our first group a number of key phrases, right?', '2019-10-24T09:58:57Z', '84fbaa66a2474ea29ae053f3a2e519d6', '90b04c9a271844e8b2dc332a24c11def')\n",
      "('So once that is done, let us assume we got all the for each group.', '2019-10-24T09:58:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '86f39c46e153416ca86e69002db48097') ('Yeah, like so you have some XnumberX groups if you have done right do we?', '2019-10-24T09:58:57Z', '84fbaa66a2474ea29ae053f3a2e519d6', '90b04c9a271844e8b2dc332a24c11def')\n",
      "('Just so that we are on the same page because this is a replacement chapter.', '2019-10-24T09:59:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7e0ed18332e74a0091c7d3c4300a1f60') ('But it would be it would have more depth than the chapters.', '2019-10-24T09:59:37Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'c77a0e26e4d3468e91c08a02c897890d')\n",
      "('If it is less than XnumberX just there is no fallback mechanism or anything.', '2019-10-24T09:38:23Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e966b3da536b49a38ef6f6a8ff986a70') ('Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like XnumberX seconds is a hard limit.', '2019-10-24T09:38:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '0428e901c7654286a5d593a86228c607')\n",
      "('So maybe then we need to be able to configure which one to liquid at least inject which analyzer to choose at least you can start off with staging and select one analyzer in production.', '2019-10-24T09:44:42Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '404c97b0053e426ab34deafa7d73dd36') ('But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.', '2019-10-24T09:44:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '765f426547244837a63c95746c5c45be')\n",
      "('Not necessarily think we can just call the second part separately, too.', '2019-10-24T09:52:11Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '41866e610c7748418a1d2c08817de9b2') ('Like if you want to change the input and asking whether it can be used for anything.', '2019-10-24T09:51:34Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '9b7f46eb8209407486527fa3ad097480')\n",
      "('No, no, it is ends that can is it a reusable they give you?', '2019-10-24T09:52:17Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bd1ba775b4ef449da97e6f5920b3650a') ('It is just parameters and then we have to like the feature extraction would be like a single step instead of only that is all.', '2019-10-24T09:52:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '1b73f903dbc04207968bb2399636a965')\n",
      "('No, no, it is ends that can is it a reusable they give you?', '2019-10-24T09:52:17Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bd1ba775b4ef449da97e6f5920b3650a') ('Everybody do not use exact as tomorrow the same thing can be used.', '2019-10-24T09:52:22Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'd8c052b48ca244068d4b118a427a4289')\n",
      "('Okay, so then we will come to deployment separately less assuming.', '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6') ('I am not really in a one single group for you can have duplicate segments, right?', '2019-10-24T09:54:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'b6c0337409db4578b2689913d942b046')\n",
      "('Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.', '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6') ('It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now.', '2019-10-24T09:52:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '755ac6aa613f45d5be5566a5fe1d784d')\n",
      "('Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.', '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6') ('I am not really in a one single group for you can have duplicate segments, right?', '2019-10-24T09:54:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'b6c0337409db4578b2689913d942b046')\n",
      "('Yes, Each of which would contain the segment ID as a field and the text and the sentence.', '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6') ('I am not really in a one single group for you can have duplicate segments, right?', '2019-10-24T09:54:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'b6c0337409db4578b2689913d942b046')\n",
      "('So so I had looked at that tart that flowchart Witcher XnumberX had sent rate on the earlier.', '2019-10-24T09:40:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '531ca88fd1014c94953402ceff5efdb4') ('It would be the same like whatever you give for scorer service, right?', '2019-10-24T09:41:04Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4102ada43e0844a696cde7a5a1c6b45c')\n",
      "('So so I had looked at that tart that flowchart Witcher XnumberX had sent rate on the earlier.', '2019-10-24T09:40:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '531ca88fd1014c94953402ceff5efdb4') ('Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?', '2019-10-24T09:41:04Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4102ada43e0844a696cde7a5a1c6b45c')\n",
      "('I wanted to discuss like what are the request response those things basically?', '2019-10-24T09:40:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '531ca88fd1014c94953402ceff5efdb4') ('It would be the same like whatever you give for scorer service, right?', '2019-10-24T09:41:04Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4102ada43e0844a696cde7a5a1c6b45c')\n",
      "('Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?', '2019-10-24T09:41:04Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4102ada43e0844a696cde7a5a1c6b45c') ('Now instead of distance score, we would just send an acknowledgement that we have analyzed it.', '2019-10-24T09:41:19Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '062c62fb2baf44b199c6056b64c3265f')\n",
      "('Yeah, because we will be using interchangeable if we want to use that courting ritual.', '2019-10-24T09:41:38Z', '84fbaa66a2474ea29ae053f3a2e519d6', '154dab9127204d0fa2f0ad3aa00b246c') ('But the name Remains the Same or itself should be different, right?', '2019-10-24T09:41:25Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e759d5051b224ca8ab10e1e625e07a03')\n",
      "('Is it like girl you same way same way you have to send for the new service.', '2019-10-24T09:42:35Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'd1112b3c90094ffea1878a898ceb17b8') ('What is the request is nothing right only the instance ID unit meeting insensitive or whatever.', '2019-10-24T09:42:05Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'b3d10173ca17432e8e5ae3c1071fe323')\n",
      "('Is it like girl you same way same way you have to send for the new service.', '2019-10-24T09:42:35Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'd1112b3c90094ffea1878a898ceb17b8') ('But the API signature and everything would change a peer response will remain a little bit different which could be same response would be different.', '2019-10-24T09:41:53Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '3981d9750b194120acfb825466a97ea1')\n",
      "('Is it like girl you same way same way you have to send for the new service.', '2019-10-24T09:42:35Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'd1112b3c90094ffea1878a898ceb17b8') ('You sent a request with the same request you present for new service.', '2019-10-24T09:42:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ab22180c9af64f12974a806f574e0cb2')\n",
      "('Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.', '2019-10-24T09:51:06Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bd3dc1b663b147a886fe0b9ef9d10b2a') ('Yes at the end of the curve you getting all the segments and you are doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment is to which they belong right?', '2019-10-24T09:51:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '131db9a5cba54cedac7d976b77e41b8e')\n",
      "('But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.', '2019-10-24T09:44:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '765f426547244837a63c95746c5c45be') ('Actually, there is some more work here with it because they are actually returning some data and the original one the second one.', '2019-10-24T09:45:01Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'f985c93eb01b4f1cadd2c38fd99e3b05')\n",
      "('But the name Remains the Same or itself should be different, right?', '2019-10-24T09:41:25Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e759d5051b224ca8ab10e1e625e07a03') ('But the API signature and everything would change a peer response will remain a little bit different which could be same response would be different.', '2019-10-24T09:41:53Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '3981d9750b194120acfb825466a97ea1')\n",
      "('It is just parameters and then we have to like the feature extraction would be like a single step instead of only that is all.', '2019-10-24T09:52:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '1b73f903dbc04207968bb2399636a965') ('It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now.', '2019-10-24T09:52:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '755ac6aa613f45d5be5566a5fe1d784d')\n",
      "('Now the new summary it is there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create.', '2019-10-24T10:00:08Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cec9d9832cd24135a14e1b7a936f2b7e') ('Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.', '2019-10-24T10:01:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e51c3385ccc6405193808ec2711dc293')\n",
      "('Currently, but we will have to update some default values or some.', '2019-10-24T09:45:15Z', '84fbaa66a2474ea29ae053f3a2e519d6', '64c9d785e5e54899a58c02a1dc09656a') ('Some default like XnumberX or something like the score so that will not pick that values.', '2019-10-24T09:45:25Z', '84fbaa66a2474ea29ae053f3a2e519d6', '14dd6a5daeea4ec3bf59eb567300dcec')\n",
      "('Okay Android if nothing is written in their objective some preprocessing error.', '2019-10-24T09:45:49Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f1896133539433fa78f4e836897f526') ('But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there.', '2019-10-24T09:46:21Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'dc9670f4070549c58777cd5762154777')\n",
      "('There is something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code', '2019-10-24T09:45:49Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f1896133539433fa78f4e836897f526') ('But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there.', '2019-10-24T09:46:21Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'dc9670f4070549c58777cd5762154777')\n",
      "('Analyze menu, and then we also have midsegment analyzed and we pass analysis object left with it.', '2019-10-24T09:48:57Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cc7f9fa72d6d4325869e86e28286b2cc') ('So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted.', '2019-10-24T09:49:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8e4abf19839e41c1ad14ec83b08da03c')\n",
      "('Yeah, so we we we are just limiting it XnumberX to be in line with with this but we can does not mean anything.', '2019-10-24T10:03:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '8586fa3289cb47a9bdc872e277da29bb') ('We thought we will stick to five for now and then do that but that is not really that does not stop anything.', '2019-10-24T10:02:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e09a73ccea7b4e7d94c2f3992743cded')\n",
      "('Yeah, that would be grouped as a single segment only we want again spread that.', '2019-10-24T09:54:40Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '67a84321aff94e3591e883b26c947dcb') ('I am not really in a one single group for you can have duplicate segments, right?', '2019-10-24T09:54:19Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'b6c0337409db4578b2689913d942b046')\n",
      "('Yeah, that would be grouped as a single segment only we want again spread that.', '2019-10-24T09:54:40Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '67a84321aff94e3591e883b26c947dcb') ('It is like key is a segment segment and value is ASL.', '2019-10-24T09:55:21Z', '84fbaa66a2474ea29ae053f3a2e519d6', '0aa9643d8be34aa98b3059e705200447')\n",
      "('What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669') ('For each group then do we extract the key phrases for all the segments in a group?', '2019-10-24T09:57:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9c911229fa124080bed9320da700aed3')\n",
      "('We make any concurrent calls to get the key phases for each group.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669') ('That is that is our first group a number of key phrases, right?', '2019-10-24T09:58:57Z', '84fbaa66a2474ea29ae053f3a2e519d6', '90b04c9a271844e8b2dc332a24c11def')\n",
      "('We make any concurrent calls to get the key phases for each group.', '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669') ('So included you have group XnumberX and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative.', '2019-10-24T09:57:22Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c1f966917c2449fab372b88f6fb93d23')\n",
      "('Knowing that a pending State I use some value actually, which is actually floatXnumberX value, right?', '2019-10-24T09:48:29Z', '84fbaa66a2474ea29ae053f3a2e519d6', '253223dc3e7b4eb5b268a5c5ed141922') ('Do some huge number actually add some Randomness and final value basically that waking up.', '2019-10-24T09:48:37Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'ca8a45efd9a4482abc5e007681cf75f0')\n",
      "('Knowing that a pending State I use some value actually, which is actually floatXnumberX value, right?', '2019-10-24T09:48:29Z', '84fbaa66a2474ea29ae053f3a2e519d6', '253223dc3e7b4eb5b268a5c5ed141922') ('Let is say XnumberX is minus XnumberX are some negative value meaning that they are not even anything correctly.', '2019-10-24T09:48:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'af44ede593da494f8a2eb21ebcd7970f')\n",
      "('But as we can we will have to create a temporary structure in that format then.', '2019-10-24T09:56:22Z', '84fbaa66a2474ea29ae053f3a2e519d6', '67428c44bf8b4abbbab289b875915fcf') ('One more field in the same segment object itself is it?', '2019-10-24T09:56:17Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e291986fc6a54c099b4181ed52863f9b')\n",
      "('They are giving the or text as three three sentences separated by full stops.', '2019-10-24T09:55:10Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'f55867392efa46819fcbc409edebf99e') ('We will not contain all the sentences from the original segment, but only the Filter Works.', '2019-10-24T09:55:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '08cb5accf2cf4fe4819da499718e6a8a')\n",
      "('So this anything current sub to service its you have the response which you get would be the same as this new service.', '2019-10-24T09:56:01Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '6b8d5545b058410988af52ef181793b7') ('Actually, he is saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text.', '2019-10-24T09:55:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '08cb5accf2cf4fe4819da499718e6a8a')\n",
      "('So this anything current sub to service its you have the response which you get would be the same as this new service.', '2019-10-24T09:56:01Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '6b8d5545b058410988af52ef181793b7') ('One more field in the same segment object itself is it?', '2019-10-24T09:56:17Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e291986fc6a54c099b4181ed52863f9b')\n",
      "('Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.', '2019-10-24T10:01:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e51c3385ccc6405193808ec2711dc293') ('Let is assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics.', '2019-10-24T10:01:50Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '65d3a52e005f469d8cba97bcafa2739c')\n",
      "('Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.', '2019-10-24T10:01:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e51c3385ccc6405193808ec2711dc293') ('They are like either is relevant or something, but it is that is what so if that is it on high level of difference between chapters.', '2019-10-24T10:01:50Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '65d3a52e005f469d8cba97bcafa2739c')\n",
      "('No then we have to be real should not hard limit on Facebook.', '2019-10-24T10:01:43Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '8aa6201fb2374233b1e2a01ea358a1dd') ('If you had limit on five you want to cover the whole years is at least as a big thing.', '2019-10-24T10:01:50Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '65d3a52e005f469d8cba97bcafa2739c')\n",
      "('But five and then if you see if we have a better way of making it have adaptive we will we will only take care of that.', '2019-10-24T09:59:18Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'f8499b9df4e645ada9ac0e38aa7e9771') ('Yeah, like so you have some XnumberX groups if you have done right do we?', '2019-10-24T09:58:57Z', '84fbaa66a2474ea29ae053f3a2e519d6', '90b04c9a271844e8b2dc332a24c11def')\n",
      "('Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.', '2019-10-24T10:04:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cd7717a085d0444f8fe3ee598fe81417') ('But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.', '2019-10-24T10:04:53Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '84da28210d524bbcb0de12b3c068026b')\n",
      "('Actually, he is saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text.', '2019-10-24T09:55:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '08cb5accf2cf4fe4819da499718e6a8a') ('One more field in the same segment object itself is it?', '2019-10-24T09:56:17Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e291986fc6a54c099b4181ed52863f9b')\n",
      "('We will not contain all the sentences from the original segment, but only the Filter Works.', '2019-10-24T09:55:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '08cb5accf2cf4fe4819da499718e6a8a') ('It is like key is a segment segment and value is ASL.', '2019-10-24T09:55:21Z', '84fbaa66a2474ea29ae053f3a2e519d6', '0aa9643d8be34aa98b3059e705200447')\n",
      "('If you had limit on five you want to cover the whole years is at least as a big thing.', '2019-10-24T10:01:50Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '65d3a52e005f469d8cba97bcafa2739c') ('We thought we will stick to five for now and then do that but that is not really that does not stop anything.', '2019-10-24T10:02:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e09a73ccea7b4e7d94c2f3992743cded')\n",
      "('Let is assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics.', '2019-10-24T10:01:50Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '65d3a52e005f469d8cba97bcafa2739c') ('So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important.', '2019-10-24T10:02:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'beff02d81e604638939892b1b784d4b2')\n",
      "('But essentially the idea is the same thing, right if we could use the highlighter topics.', '2019-10-24T10:03:15Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'af09fd64cfbc4b3dae3f8f2b054316c1') ('So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important.', '2019-10-24T10:02:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'beff02d81e604638939892b1b784d4b2')\n",
      "('One more field in the same segment object itself is it?', '2019-10-24T09:56:17Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e291986fc6a54c099b4181ed52863f9b') ('So what if the format is just a group list of segments and the associated alter text.', '2019-10-24T09:56:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '280eccf326464766a80e1aca7ee18c3e')\n",
      "('So what if the format is just a group list of segments and the associated alter text.', '2019-10-24T09:56:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '280eccf326464766a80e1aca7ee18c3e') ('So included you have group XnumberX and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative.', '2019-10-24T09:57:22Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c1f966917c2449fab372b88f6fb93d23')\n",
      "('So you know that everyone knows the difference we can always Google.', '2019-10-24T10:13:06Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '7dbae367c4d04dae8584d290b7c82077') ('And then we really wanted confident of this is working as expected.', '2019-10-24T10:13:12Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3dc868cd1f184517ace6449becb87e08')\n",
      "('So included you have group XnumberX and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative.', '2019-10-24T09:57:22Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c1f966917c2449fab372b88f6fb93d23') ('For each group then do we extract the key phrases for all the segments in a group?', '2019-10-24T09:57:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9c911229fa124080bed9320da700aed3')\n",
      "('Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.', '2019-10-24T10:05:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7658b0fa8ea14eb8acc62f015032bbeb') ('But generally the idea was if you had sections of topics actions and decisions and we just did a great job on discovering them and someone had given some signals we take that and use that instead of words automatically.', '2019-10-24T10:06:00Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8ec61fc25ef44f1e810b0f17d1422470')\n",
      "('Be may need to reject some items that do not that overlap with the manual markers.', '2019-10-24T10:03:53Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '850319c7aab04f49a38fdd9dda7420a2') ('Maybe not immediately, but that is if you go to production that might be needed.', '2019-10-24T10:04:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f00ada973054f28b67c4669d9be9e23')\n",
      "('Be may need to reject some items that do not that overlap with the manual markers.', '2019-10-24T10:03:53Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '850319c7aab04f49a38fdd9dda7420a2') ('We need to First other words coming back and then decide how this will be.', '2019-10-24T10:04:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f00ada973054f28b67c4669d9be9e23')\n",
      "('So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928') ('No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928') ('They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('So let us separate that and I like that idea from this video.', '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928') ('Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315')\n",
      "('Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('Then what is does is like for every discussion just give the highlights.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.', '2019-10-24T10:11:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9648c443a927463daeb63edf81915bb7')\n",
      "('So if you if you want to know Or even nine third chapters as well.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('So if you if you want to know Or even nine third chapters as well.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('So if you if you want to know Or even nine third chapters as well.', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?', '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315') ('But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4')\n",
      "('Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know.', '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4') ('So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody.', '2019-10-24T10:11:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9648c443a927463daeb63edf81915bb7')\n",
      "('So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody.', '2019-10-24T10:11:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9648c443a927463daeb63edf81915bb7') ('So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production.', '2019-10-24T10:12:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '5c526d59a4ce4528abc88397f77dd539')\n",
      "('So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production.', '2019-10-24T10:12:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '5c526d59a4ce4528abc88397f77dd539') ('let people know that these are or we can just push both but it is up to we will.', '2019-10-24T10:12:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a160895632904c3c99206511ef0efe3b')\n",
      "('let people know that these are or we can just push both but it is up to we will.', '2019-10-24T10:12:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a160895632904c3c99206511ef0efe3b') ('And then we really wanted confident of this is working as expected.', '2019-10-24T10:13:12Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3dc868cd1f184517ace6449becb87e08')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 390, \"module\": \"grouper_segments\", \"outlier threshold is : \": 0.5304303765296936, \"ts\": \"2020-03-10T20:28:40.963635Z\", \"msg\": \"Outlier Score\"}\n",
      "Using Community Algorithm\n",
      "cluster before alteration=========>\n",
      "I would say I would like you somewhere to find this is a qualitative group and which is not.\n",
      "Are you talking about topics as the markers or The Pimps idea?\n",
      "We found something for you as a topic and within that time range itself be graded on someone read a manual marker.\n",
      "So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important.\n",
      "I know but does that help because we want to give them topics in the connotation.\n",
      "Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.\n",
      "You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.\n",
      "So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion.\n",
      "That is what are you doing on you doing it at life essentially?\n",
      "At least one chapter coming out right like I mean if I am wrong.\n",
      "But generally the idea was if you had sections of topics actions and decisions and we just did a great job on discovering them and someone had given some signals we take that and use that instead of words automatically.\n",
      "Then comes actions are we do need to do anything with post call for actions?\n",
      "Just so that we are on the same page because this is a replacement chapter.\n",
      "They are like either is relevant or something, but it is that is what so if that is it on high level of difference between chapters.\n",
      "If I had to push back to slack with two sections one is topics and one of the actions.\n",
      "Both call you can you can just you can just show whatever whatever that Action Service returns.\n",
      "Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.\n",
      "But it would be it would have more depth than the chapters.\n",
      "Subject of peace and humanely tell that we should have expected.\n",
      "Let is assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics.\n",
      "Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.\n",
      "If you had limit on five you want to cover the whole years is at least as a big thing.\n",
      "Now the new summary it is there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create.\n",
      "Is it only for triggering summary or is it about doing anything?\n",
      "We thought we will stick to five for now and then do that but that is not really that does not stop anything.\n",
      "But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.\n",
      "cluster before alteration=========>\n",
      "So once that is done, let us assume we got all the for each group.\n",
      "Is there at that field will have to update once we get it?\n",
      "It depends if we know what segment ideas we should probably update the key phrases like video right now because we use it.\n",
      "One more field in the same segment object itself is it?\n",
      "What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service.\n",
      "Actually, he is saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text.\n",
      "Yeah, that would be grouped as a single segment only we want again spread that.\n",
      "We make any concurrent calls to get the key phases for each group.\n",
      "That is that is our first group a number of key phrases, right?\n",
      "For each group then do we extract the key phrases for all the segments in a group?\n",
      "We will not contain all the sentences from the original segment, but only the Filter Works.\n",
      "So what if the format is just a group list of segments and the associated alter text.\n",
      "Actually, there is some more work here with it because they are actually returning some data and the original one the second one.\n",
      "They are giving the or text as three three sentences separated by full stops.\n",
      "Under the we like we need to purchase those sentences for one segment.\n",
      "All it does is like it analyzes the segment each segment separately stores if each other Vector area so setting\n",
      "It is like key is a segment segment and value is ASL.\n",
      "Yes generation field called Dont extract do not populate the graph.\n",
      "And you want us to make basically they were in groups.\n",
      "So included you have group XnumberX and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative.\n",
      "cluster before alteration=========>\n",
      "Yeah, but when we say we found topic we give them a list of subtopics and everything, right?\n",
      "Then what is does is like for every discussion just give the highlights.\n",
      "Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.\n",
      "They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?\n",
      "But essentially the idea is the same thing, right if we could use the highlighter topics.\n",
      "Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay.\n",
      "So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.\n",
      "So let us separate that and I like that idea from this video.\n",
      "Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics.\n",
      "So if you if you want to know Or even nine third chapters as well.\n",
      "We do not have anything to do with the only thing somebody.\n",
      "So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?\n",
      "No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.\n",
      "Yeah so that you do not have to hard limit based on time true.\n",
      "I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space.\n",
      "If you to make real time, it would still more or less work in the way you currently intended.\n",
      "But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong.\n",
      "No, no, it is ends that can is it a reusable they give you?\n",
      "Everybody do not use exact as tomorrow the same thing can be used.\n",
      "Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know.\n",
      "Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters.\n",
      "Ideally table of contents can only be found in the book is complete.\n",
      "Yeah, I have a placeholder need to work on it for now.\n",
      "cluster before alteration=========>\n",
      "What if you want every sent back to us in what we push back in slab in staging?\n",
      "I wanted to discuss like what are the request response those things basically?\n",
      "That is yeah, but we try to call fate action items with groups.\n",
      "It would be the same like whatever you give for scorer service, right?\n",
      "You sent a request with the same request you present for new service.\n",
      "And just dump everything on Tinder like the current chapters like four chapters chapter summary.\n",
      "So so I had looked at that tart that flowchart Witcher XnumberX had sent rate on the earlier.\n",
      "What is the request is nothing right only the instance ID unit meeting insensitive or whatever.\n",
      "So this anything current sub to service its you have the response which you get would be the same as this new service.\n",
      "But the API signature and everything would change a peer response will remain a little bit different which could be same response would be different.\n",
      "Is it like girl you same way same way you have to send for the new service.\n",
      "Deployment package ready, but ask the shun to change the because you have to change the way except response rate coming included on the response of is working on that once it is there L Death.\n",
      "cluster before alteration=========>\n",
      "So you will okay it gets populated using the light cord itself.\n",
      "Yes, you can it is make the product magnetic sensor consists for the names of my service itself.\n",
      "Okay, so then do not do not show it in the slack, but you still have to propagate that to the graphs and every other turn same class that uses this.\n",
      "That is so yeah, you do not have to do in the pool right now.\n",
      "Okay, let us do overlap macon is do we remove this or do we keep this or what makes sense?\n",
      "No then we have to be real should not hard limit on Facebook.\n",
      "So you know that everyone knows the difference we can always Google.\n",
      "And then we really wanted confident of this is working as expected.\n",
      "You said earlier this maybe change all the text to something more.\n",
      "Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.\n",
      "let people know that these are or we can just push both but it is up to we will.\n",
      "within the time Ridge so okay, please find anything is okay for actions now just only top\n",
      "cluster before alteration=========>\n",
      "Number of groups we would actually have like very high number of groups we would again use the rankings to take on it outside.\n",
      "Let is say in group XnumberX it is an array of Group XnumberX is an array of objects embolism, right?\n",
      "Okay, so then we will come to deployment separately less assuming.\n",
      "Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.\n",
      "It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now.\n",
      "So just so that we are all on the same page.\n",
      "It is just parameters and then we have to like the feature extraction would be like a single step instead of only that is all.\n",
      "Yes, Each of which would contain the segment ID as a field and the text and the sentence.\n",
      "I am not really in a one single group for you can have duplicate segments, right?\n",
      "It is this right the rapper service or on both of them.\n",
      "cluster before alteration=========>\n",
      "If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now.\n",
      "If it is less than XnumberX just there is no fallback mechanism or anything.\n",
      "This is doing is just what happened and get it for you did not see that the mostly less than XnumberX seconds with them.\n",
      "Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like XnumberX seconds is a hard limit.\n",
      "Some default like XnumberX or something like the score so that will not pick that values.\n",
      "Yeah, so we we we are just limiting it XnumberX to be in line with with this but we can does not mean anything.\n",
      "That so I just sharing the screen of one of the meeting happened just now.\n",
      "Yeah, the group segmented is her like mostly like to two segments are grouped.\n",
      "And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.\n",
      "it says so these are the input segmented is which have got we are able to see right, it is less than XnumberX secibds.\n",
      "Yes at the end of the curve you getting all the segments and you are doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment is to which they belong right?\n",
      "Yeah, like so you have some XnumberX groups if you have done right do we?\n",
      "Let is say XnumberX is minus XnumberX are some negative value meaning that they are not even anything correctly.\n",
      "Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?\n",
      "Come back to school we call this analyzer and staging we just created as a subject in the current table as it is and they hate us and the actual NLP readers empty.\n",
      "Now instead of distance score, we would just send an acknowledgement that we have analyzed it.\n",
      "I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.\n",
      "Knowing that a pending State I use some value actually, which is actually floatXnumberX value, right?\n",
      "Do some huge number actually add some Randomness and final value basically that waking up.\n",
      "cluster before alteration=========>\n",
      "Lentils and we are creating new ones service which would replace the current room service.\n",
      "I am assuming this is not the same as the current one.\n",
      "So we will have to have like a pipeline for that like in each section that we publish.\n",
      "So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody.\n",
      "Maybe not immediately, but that is if you go to production that might be needed.\n",
      "Yeah, because we will be using interchangeable if we want to use that courting ritual.\n",
      "But the name Remains the Same or itself should be different, right?\n",
      "But as we can we will have to create a temporary structure in that format then.\n",
      "We need to First other words coming back and then decide how this will be.\n",
      "Currently, but we will have to update some default values or some.\n",
      "Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.\n",
      "So even for now just so that we can observe what is coming out from the grouping and what we expect in the keywords.\n",
      "Be may need to reject some items that do not that overlap with the manual markers.\n",
      "Were not going to intersperse the topics with the manual markers that have been created or not.\n",
      "So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production.\n",
      "cluster before alteration=========>\n",
      "So you would make a pair called the landlord be same for both APA Falls, except the page the input changes.\n",
      "So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.\n",
      "But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.\n",
      "It is clear, but you can put it in the other you have another issue right in the APA GitHub itself.\n",
      "First one is also Lambda or it is a service rate the current service on this end.\n",
      "So in this one so but is it up can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective.\n",
      "So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready?\n",
      "Is it the separate language requirement of the same Lambda to promote the to to little methods is the same language.\n",
      "So maybe then we need to be able to configure which one to liquid at least inject which analyzer to choose at least you can start off with staging and select one analyzer in production.\n",
      "Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.\n",
      "cluster before alteration=========>\n",
      "For example, let us say when I call this new servers on let us do this.\n",
      "We will be using those where we were using only the older version like to get the score the only top XnumberX in kind of thing, right but in this new one, we do not need anything because we do not have any data, right?\n",
      "But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there.\n",
      "Not necessarily think we can just call the second part separately, too.\n",
      "Like if you want to change the input and asking whether it can be used for anything.\n",
      "But five and then if you see if we have a better way of making it have adaptive we will we will only take care of that.\n",
      "There is something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code\n",
      "We Implement in your analyzer right B it information and return.\n",
      "Okay Android if nothing is written in their objective some preprocessing error.\n",
      "Analyze menu, and then we also have midsegment analyzed and we pass analysis object left with it.\n",
      "So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted.\n",
      "Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.\n",
      "cluster before alteration=========>\n",
      "That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here.\n",
      "The next sentence is a text when a field called text and a hiding with the sentence belong funny.\n",
      "Okay, so and it will also add a new field called feel call or text in each object.\n",
      "It would definitely be using the anything else great, except the Alta text.\n",
      "cluster before alteration=========>\n",
      "Okay, then for now just keep it as the same Lambda but have distinct, you know code structure so that they are not necessarily.\n",
      "cluster before alteration=========>\n",
      "Gil Gil just call everything a segment on a laser it is the same service so I think so.\n",
      "cluster before alteration=========>\n",
      "I think I am trying to connect some iOS but it is fairly.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "I would say I would like you somewhere to find this is a qualitative group and which is not.\n",
      "Are you talking about topics as the markers or The Pimps idea?\n",
      "We found something for you as a topic and within that time range itself be graded on someone read a manual marker.\n",
      "So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important.\n",
      "I know but does that help because we want to give them topics in the connotation.\n",
      "Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.\n",
      "You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.\n",
      "So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion.\n",
      "That is what are you doing on you doing it at life essentially?\n",
      "At least one chapter coming out right like I mean if I am wrong.\n",
      "But generally the idea was if you had sections of topics actions and decisions and we just did a great job on discovering them and someone had given some signals we take that and use that instead of words automatically.\n",
      "Then comes actions are we do need to do anything with post call for actions?\n",
      "Just so that we are on the same page because this is a replacement chapter.\n",
      "They are like either is relevant or something, but it is that is what so if that is it on high level of difference between chapters.\n",
      "If I had to push back to slack with two sections one is topics and one of the actions.\n",
      "Both call you can you can just you can just show whatever whatever that Action Service returns.\n",
      "Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.\n",
      "But it would be it would have more depth than the chapters.\n",
      "Subject of peace and humanely tell that we should have expected.\n",
      "Let is assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics.\n",
      "Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.\n",
      "If you had limit on five you want to cover the whole years is at least as a big thing.\n",
      "Now the new summary it is there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create.\n",
      "Is it only for triggering summary or is it about doing anything?\n",
      "But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So once that is done, let us assume we got all the for each group.\n",
      "Is there at that field will have to update once we get it?\n",
      "It depends if we know what segment ideas we should probably update the key phrases like video right now because we use it.\n",
      "One more field in the same segment object itself is it?\n",
      "What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service.\n",
      "Actually, he is saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text.\n",
      "Yeah, that would be grouped as a single segment only we want again spread that.\n",
      "We make any concurrent calls to get the key phases for each group.\n",
      "For each group then do we extract the key phrases for all the segments in a group?\n",
      "We will not contain all the sentences from the original segment, but only the Filter Works.\n",
      "Actually, there is some more work here with it because they are actually returning some data and the original one the second one.\n",
      "They are giving the or text as three three sentences separated by full stops.\n",
      "Under the we like we need to purchase those sentences for one segment.\n",
      "All it does is like it analyzes the segment each segment separately stores if each other Vector area so setting\n",
      "It is like key is a segment segment and value is ASL.\n",
      "Yes generation field called Dont extract do not populate the graph.\n",
      "And you want us to make basically they were in groups.\n",
      "So included you have group XnumberX and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Yeah, but when we say we found topic we give them a list of subtopics and everything, right?\n",
      "Then what is does is like for every discussion just give the highlights.\n",
      "Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.\n",
      "They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?\n",
      "But essentially the idea is the same thing, right if we could use the highlighter topics.\n",
      "Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay.\n",
      "So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.\n",
      "So let us separate that and I like that idea from this video.\n",
      "Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics.\n",
      "So if you if you want to know Or even nine third chapters as well.\n",
      "We do not have anything to do with the only thing somebody.\n",
      "So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?\n",
      "No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.\n",
      "Yeah so that you do not have to hard limit based on time true.\n",
      "I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space.\n",
      "If you to make real time, it would still more or less work in the way you currently intended.\n",
      "But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong.\n",
      "No, no, it is ends that can is it a reusable they give you?\n",
      "Everybody do not use exact as tomorrow the same thing can be used.\n",
      "Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know.\n",
      "Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters.\n",
      "Ideally table of contents can only be found in the book is complete.\n",
      "Yeah, I have a placeholder need to work on it for now.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "What if you want every sent back to us in what we push back in slab in staging?\n",
      "I wanted to discuss like what are the request response those things basically?\n",
      "That is yeah, but we try to call fate action items with groups.\n",
      "You sent a request with the same request you present for new service.\n",
      "And just dump everything on Tinder like the current chapters like four chapters chapter summary.\n",
      "So so I had looked at that tart that flowchart Witcher XnumberX had sent rate on the earlier.\n",
      "What is the request is nothing right only the instance ID unit meeting insensitive or whatever.\n",
      "So this anything current sub to service its you have the response which you get would be the same as this new service.\n",
      "But the API signature and everything would change a peer response will remain a little bit different which could be same response would be different.\n",
      "Is it like girl you same way same way you have to send for the new service.\n",
      "Deployment package ready, but ask the shun to change the because you have to change the way except response rate coming included on the response of is working on that once it is there L Death.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So you will okay it gets populated using the light cord itself.\n",
      "Okay, so then do not do not show it in the slack, but you still have to propagate that to the graphs and every other turn same class that uses this.\n",
      "That is so yeah, you do not have to do in the pool right now.\n",
      "Okay, let us do overlap macon is do we remove this or do we keep this or what makes sense?\n",
      "No then we have to be real should not hard limit on Facebook.\n",
      "So you know that everyone knows the difference we can always Google.\n",
      "And then we really wanted confident of this is working as expected.\n",
      "You said earlier this maybe change all the text to something more.\n",
      "Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.\n",
      "let people know that these are or we can just push both but it is up to we will.\n",
      "within the time Ridge so okay, please find anything is okay for actions now just only top\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Number of groups we would actually have like very high number of groups we would again use the rankings to take on it outside.\n",
      "Let is say in group XnumberX it is an array of Group XnumberX is an array of objects embolism, right?\n",
      "Okay, so then we will come to deployment separately less assuming.\n",
      "Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.\n",
      "It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now.\n",
      "So just so that we are all on the same page.\n",
      "It is just parameters and then we have to like the feature extraction would be like a single step instead of only that is all.\n",
      "Yes, Each of which would contain the segment ID as a field and the text and the sentence.\n",
      "I am not really in a one single group for you can have duplicate segments, right?\n",
      "It is this right the rapper service or on both of them.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now.\n",
      "If it is less than XnumberX just there is no fallback mechanism or anything.\n",
      "This is doing is just what happened and get it for you did not see that the mostly less than XnumberX seconds with them.\n",
      "Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like XnumberX seconds is a hard limit.\n",
      "Some default like XnumberX or something like the score so that will not pick that values.\n",
      "Yeah, so we we we are just limiting it XnumberX to be in line with with this but we can does not mean anything.\n",
      "That so I just sharing the screen of one of the meeting happened just now.\n",
      "Yeah, the group segmented is her like mostly like to two segments are grouped.\n",
      "And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.\n",
      "it says so these are the input segmented is which have got we are able to see right, it is less than XnumberX secibds.\n",
      "Yes at the end of the curve you getting all the segments and you are doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment is to which they belong right?\n",
      "Yeah, like so you have some XnumberX groups if you have done right do we?\n",
      "Let is say XnumberX is minus XnumberX are some negative value meaning that they are not even anything correctly.\n",
      "Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?\n",
      "Come back to school we call this analyzer and staging we just created as a subject in the current table as it is and they hate us and the actual NLP readers empty.\n",
      "Now instead of distance score, we would just send an acknowledgement that we have analyzed it.\n",
      "I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.\n",
      "Knowing that a pending State I use some value actually, which is actually floatXnumberX value, right?\n",
      "Do some huge number actually add some Randomness and final value basically that waking up.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Lentils and we are creating new ones service which would replace the current room service.\n",
      "I am assuming this is not the same as the current one.\n",
      "So we will have to have like a pipeline for that like in each section that we publish.\n",
      "So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody.\n",
      "Maybe not immediately, but that is if you go to production that might be needed.\n",
      "Yeah, because we will be using interchangeable if we want to use that courting ritual.\n",
      "But the name Remains the Same or itself should be different, right?\n",
      "But as we can we will have to create a temporary structure in that format then.\n",
      "We need to First other words coming back and then decide how this will be.\n",
      "Currently, but we will have to update some default values or some.\n",
      "Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.\n",
      "So even for now just so that we can observe what is coming out from the grouping and what we expect in the keywords.\n",
      "Be may need to reject some items that do not that overlap with the manual markers.\n",
      "Were not going to intersperse the topics with the manual markers that have been created or not.\n",
      "So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So you would make a pair called the landlord be same for both APA Falls, except the page the input changes.\n",
      "So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.\n",
      "But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.\n",
      "It is clear, but you can put it in the other you have another issue right in the APA GitHub itself.\n",
      "First one is also Lambda or it is a service rate the current service on this end.\n",
      "So in this one so but is it up can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective.\n",
      "So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready?\n",
      "Is it the separate language requirement of the same Lambda to promote the to to little methods is the same language.\n",
      "So maybe then we need to be able to configure which one to liquid at least inject which analyzer to choose at least you can start off with staging and select one analyzer in production.\n",
      "Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "For example, let us say when I call this new servers on let us do this.\n",
      "We will be using those where we were using only the older version like to get the score the only top XnumberX in kind of thing, right but in this new one, we do not need anything because we do not have any data, right?\n",
      "But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there.\n",
      "Not necessarily think we can just call the second part separately, too.\n",
      "Like if you want to change the input and asking whether it can be used for anything.\n",
      "But five and then if you see if we have a better way of making it have adaptive we will we will only take care of that.\n",
      "There is something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code\n",
      "We Implement in your analyzer right B it information and return.\n",
      "Okay Android if nothing is written in their objective some preprocessing error.\n",
      "Analyze menu, and then we also have midsegment analyzed and we pass analysis object left with it.\n",
      "So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted.\n",
      "Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here.\n",
      "The next sentence is a text when a field called text and a hiding with the sentence belong funny.\n",
      "Okay, so and it will also add a new field called feel call or text in each object.\n",
      "It would definitely be using the anything else great, except the Alta text.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Okay, then for now just keep it as the same Lambda but have distinct, you know code structure so that they are not necessarily.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Gil Gil just call everything a segment on a laser it is the same service so I think so.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "I think I am trying to connect some iOS but it is fairly.\n",
      "\n",
      "\n",
      "Checking Timerange --------------\n",
      "--------------\n",
      "Subject of peace and humanely tell that we should have expected. 12ee4b3dc175408abddadb34bb622606 \n",
      "\n",
      "At least one chapter coming out right like I mean if I am wrong. e9096016c7994ee7adac1f309c635781 \n",
      "\n",
      "I would say I would like you somewhere to find this is a qualitative group and which is not. fdb3306e494849febacdb258547162dc \n",
      "\n",
      "Are you talking about topics as the markers or The Pimps idea? fdb3306e494849febacdb258547162dc \n",
      "\n",
      "Is it only for triggering summary or is it about doing anything? a6ae53fc1f394851847a296b97189be9 \n",
      "\n",
      "Just so that we are on the same page because this is a replacement chapter. 7e0ed18332e74a0091c7d3c4300a1f60 \n",
      "\n",
      "But it would be it would have more depth than the chapters. c77a0e26e4d3468e91c08a02c897890d \n",
      "\n",
      "I know but does that help because we want to give them topics in the connotation. 1cf24541a3514a2f86d05f74f62fe6e3 \n",
      "\n",
      "Now the new summary it is there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create. cec9d9832cd24135a14e1b7a936f2b7e \n",
      "\n",
      "So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion. ef9b701a62ea481485ad23db01cbd776 \n",
      "\n",
      "You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights. ef9b701a62ea481485ad23db01cbd776 \n",
      "\n",
      "If I had to push back to slack with two sections one is topics and one of the actions. e51c3385ccc6405193808ec2711dc293 \n",
      "\n",
      "Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that. e51c3385ccc6405193808ec2711dc293 \n",
      "\n",
      "Let is assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics. 65d3a52e005f469d8cba97bcafa2739c \n",
      "\n",
      "They are like either is relevant or something, but it is that is what so if that is it on high level of difference between chapters. 65d3a52e005f469d8cba97bcafa2739c \n",
      "\n",
      "If you had limit on five you want to cover the whole years is at least as a big thing. 65d3a52e005f469d8cba97bcafa2739c \n",
      "\n",
      "So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important. beff02d81e604638939892b1b784d4b2 \n",
      "\n",
      "Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range. cd7717a085d0444f8fe3ee598fe81417 \n",
      "\n",
      "We found something for you as a topic and within that time range itself be graded on someone read a manual marker. cd7717a085d0444f8fe3ee598fe81417 \n",
      "\n",
      "But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye. 84da28210d524bbcb0de12b3c068026b \n",
      "\n",
      "But generally the idea was if you had sections of topics actions and decisions and we just did a great job on discovering them and someone had given some signals we take that and use that instead of words automatically. 8ec61fc25ef44f1e810b0f17d1422470 \n",
      "\n",
      "Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions. bd04b29039e14e0aba93598cde210dc5 \n",
      "\n",
      "Then comes actions are we do need to do anything with post call for actions? bd04b29039e14e0aba93598cde210dc5 \n",
      "\n",
      "Both call you can you can just you can just show whatever whatever that Action Service returns. 7e0f2b0ae42345f283fcdce3c707ce36 \n",
      "\n",
      "That is what are you doing on you doing it at life essentially? 5402a41f3b13432c8c49a456fa29f9cd \n",
      "\n",
      "--------------\n",
      "Actually, there is some more work here with it because they are actually returning some data and the original one the second one. f985c93eb01b4f1cadd2c38fd99e3b05 \n",
      "\n",
      "It depends if we know what segment ideas we should probably update the key phrases like video right now because we use it. 183b0c4fcb2546aa8479160a6dd8f86c \n",
      "\n",
      "Is there at that field will have to update once we get it? 0983ef203b5248559376addb96cc125d \n",
      "\n",
      "Under the we like we need to purchase those sentences for one segment. 2be222ed2f79468d8fdae5cac0be38fb \n",
      "\n",
      "All it does is like it analyzes the segment each segment separately stores if each other Vector area so setting d9a3e4a5632747abb7cae234597eac5b \n",
      "\n",
      "Yeah, that would be grouped as a single segment only we want again spread that. 67a84321aff94e3591e883b26c947dcb \n",
      "\n",
      "They are giving the or text as three three sentences separated by full stops. f55867392efa46819fcbc409edebf99e \n",
      "\n",
      "It is like key is a segment segment and value is ASL. 0aa9643d8be34aa98b3059e705200447 \n",
      "\n",
      "We will not contain all the sentences from the original segment, but only the Filter Works. 08cb5accf2cf4fe4819da499718e6a8a \n",
      "\n",
      "Actually, he is saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text. 08cb5accf2cf4fe4819da499718e6a8a \n",
      "\n",
      "One more field in the same segment object itself is it? e291986fc6a54c099b4181ed52863f9b \n",
      "\n",
      "So included you have group XnumberX and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative. c1f966917c2449fab372b88f6fb93d23 \n",
      "\n",
      "For each group then do we extract the key phrases for all the segments in a group? 9c911229fa124080bed9320da700aed3 \n",
      "\n",
      "What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service. aef4d82f30dd4eff9a653c12f091d669 \n",
      "\n",
      "And you want us to make basically they were in groups. aef4d82f30dd4eff9a653c12f091d669 \n",
      "\n",
      "Yes generation field called Dont extract do not populate the graph. aef4d82f30dd4eff9a653c12f091d669 \n",
      "\n",
      "We make any concurrent calls to get the key phases for each group. aef4d82f30dd4eff9a653c12f091d669 \n",
      "\n",
      "So once that is done, let us assume we got all the for each group. 86f39c46e153416ca86e69002db48097 \n",
      "\n",
      "--------------\n",
      "Yeah so that you do not have to hard limit based on time true. 50032cee9064407db74b23ad3cb0ce5b \n",
      "\n",
      "No, no, it is ends that can is it a reusable they give you? bd1ba775b4ef449da97e6f5920b3650a \n",
      "\n",
      "Everybody do not use exact as tomorrow the same thing can be used. d8c052b48ca244068d4b118a427a4289 \n",
      "\n",
      "I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space. e09a73ccea7b4e7d94c2f3992743cded \n",
      "\n",
      "But essentially the idea is the same thing, right if we could use the highlighter topics. af09fd64cfbc4b3dae3f8f2b054316c1 \n",
      "\n",
      "Yeah, but when we say we found topic we give them a list of subtopics and everything, right? a4c5cf81924e4ad7864d61a7c5f1b1e3 \n",
      "\n",
      "We do not have anything to do with the only thing somebody. 83fc6652dad543538c9a66dd245120a0 \n",
      "\n",
      "So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part. 347d89717f7b46ebbc9effada658a928 \n",
      "\n",
      "Ideally table of contents can only be found in the book is complete. 347d89717f7b46ebbc9effada658a928 \n",
      "\n",
      "So let us separate that and I like that idea from this video. 347d89717f7b46ebbc9effada658a928 \n",
      "\n",
      "So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right? 5ce3830ac74449cfa0594d9e7e922315 \n",
      "\n",
      "Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics. 5ce3830ac74449cfa0594d9e7e922315 \n",
      "\n",
      "Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay. 5ce3830ac74449cfa0594d9e7e922315 \n",
      "\n",
      "Then what is does is like for every discussion just give the highlights. 5ce3830ac74449cfa0594d9e7e922315 \n",
      "\n",
      "So if you if you want to know Or even nine third chapters as well. 5ce3830ac74449cfa0594d9e7e922315 \n",
      "\n",
      "Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters. 5ce3830ac74449cfa0594d9e7e922315 \n",
      "\n",
      "Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation. 3e73ba7a1b0543fc97519322f7eb9eb4 \n",
      "\n",
      "If you to make real time, it would still more or less work in the way you currently intended. 3e73ba7a1b0543fc97519322f7eb9eb4 \n",
      "\n",
      "No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it. 3e73ba7a1b0543fc97519322f7eb9eb4 \n",
      "\n",
      "But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong. 3e73ba7a1b0543fc97519322f7eb9eb4 \n",
      "\n",
      "They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation? 3e73ba7a1b0543fc97519322f7eb9eb4 \n",
      "\n",
      "Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know. 3e73ba7a1b0543fc97519322f7eb9eb4 \n",
      "\n",
      "Yeah, I have a placeholder need to work on it for now. 58e60982017d43d8b2a2d70aaa680b5a \n",
      "\n",
      "--------------\n",
      "So so I had looked at that tart that flowchart Witcher XnumberX had sent rate on the earlier. 531ca88fd1014c94953402ceff5efdb4 \n",
      "\n",
      "I wanted to discuss like what are the request response those things basically? 531ca88fd1014c94953402ceff5efdb4 \n",
      "\n",
      "But the API signature and everything would change a peer response will remain a little bit different which could be same response would be different. 3981d9750b194120acfb825466a97ea1 \n",
      "\n",
      "What is the request is nothing right only the instance ID unit meeting insensitive or whatever. b3d10173ca17432e8e5ae3c1071fe323 \n",
      "\n",
      "Is it like girl you same way same way you have to send for the new service. d1112b3c90094ffea1878a898ceb17b8 \n",
      "\n",
      "You sent a request with the same request you present for new service. ab22180c9af64f12974a806f574e0cb2 \n",
      "\n",
      "And just dump everything on Tinder like the current chapters like four chapters chapter summary. ab22180c9af64f12974a806f574e0cb2 \n",
      "\n",
      "So this anything current sub to service its you have the response which you get would be the same as this new service. 6b8d5545b058410988af52ef181793b7 \n",
      "\n",
      "What if you want every sent back to us in what we push back in slab in staging? ce14435bd9014f45bca267e7d022b8bb \n",
      "\n",
      "Deployment package ready, but ask the shun to change the because you have to change the way except response rate coming included on the response of is working on that once it is there L Death. bf11d1b5c35e4d6c8f946f66c85d8538 \n",
      "\n",
      "That is yeah, but we try to call fate action items with groups. bf11d1b5c35e4d6c8f946f66c85d8538 \n",
      "\n",
      "--------------\n",
      "You said earlier this maybe change all the text to something more. 6bb3d511a944435685e735ab1ec2b1e6 \n",
      "\n",
      "No then we have to be real should not hard limit on Facebook. 8aa6201fb2374233b1e2a01ea358a1dd \n",
      "\n",
      "Okay, so then do not do not show it in the slack, but you still have to propagate that to the graphs and every other turn same class that uses this. b13bb3e8ad7248d59dc4dd16fa81699a \n",
      "\n",
      "Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later. 7658b0fa8ea14eb8acc62f015032bbeb \n",
      "\n",
      "Okay, let us do overlap macon is do we remove this or do we keep this or what makes sense? 7658b0fa8ea14eb8acc62f015032bbeb \n",
      "\n",
      "That is so yeah, you do not have to do in the pool right now. 7658b0fa8ea14eb8acc62f015032bbeb \n",
      "\n",
      "let people know that these are or we can just push both but it is up to we will. a160895632904c3c99206511ef0efe3b \n",
      "\n",
      "So you know that everyone knows the difference we can always Google. 7dbae367c4d04dae8584d290b7c82077 \n",
      "\n",
      "And then we really wanted confident of this is working as expected. 3dc868cd1f184517ace6449becb87e08 \n",
      "\n",
      "within the time Ridge so okay, please find anything is okay for actions now just only top 3dc868cd1f184517ace6449becb87e08 \n",
      "\n",
      "So you will okay it gets populated using the light cord itself. b4520004df1e40daa2cc105d17bedf5a \n",
      "\n",
      "--------------\n",
      "So just so that we are all on the same page. c737f43ae1ac4386bd19d78f00c244e2 \n",
      "\n",
      "It is just parameters and then we have to like the feature extraction would be like a single step instead of only that is all. 1b73f903dbc04207968bb2399636a965 \n",
      "\n",
      "It is this right the rapper service or on both of them. 755ac6aa613f45d5be5566a5fe1d784d \n",
      "\n",
      "It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now. 755ac6aa613f45d5be5566a5fe1d784d \n",
      "\n",
      "Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object. 8c4930798f1e4460a3483d12067e10a6 \n",
      "\n",
      "Okay, so then we will come to deployment separately less assuming. 8c4930798f1e4460a3483d12067e10a6 \n",
      "\n",
      "Yes, Each of which would contain the segment ID as a field and the text and the sentence. 8c4930798f1e4460a3483d12067e10a6 \n",
      "\n",
      "Let is say in group XnumberX it is an array of Group XnumberX is an array of objects embolism, right? 8c4930798f1e4460a3483d12067e10a6 \n",
      "\n",
      "I am not really in a one single group for you can have duplicate segments, right? b6c0337409db4578b2689913d942b046 \n",
      "\n",
      "Number of groups we would actually have like very high number of groups we would again use the rankings to take on it outside. faecc6aaaa4a4d1b8797f2764bac389e \n",
      "\n",
      "--------------\n",
      "That so I just sharing the screen of one of the meeting happened just now. c8ee1afb64f74ec380c133f570084b0b \n",
      "\n",
      "it says so these are the input segmented is which have got we are able to see right, it is less than XnumberX secibds. 3be57485efb14ff8be6d23ecd62dabd2 \n",
      "\n",
      "And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds. f4c5c03c2e924de9847e0f2a65095d8c \n",
      "\n",
      "Yeah, the group segmented is her like mostly like to two segments are grouped. f4c5c03c2e924de9847e0f2a65095d8c \n",
      "\n",
      "If it is less than XnumberX just there is no fallback mechanism or anything. e966b3da536b49a38ef6f6a8ff986a70 \n",
      "\n",
      "This is doing is just what happened and get it for you did not see that the mostly less than XnumberX seconds with them. 0428e901c7654286a5d593a86228c607 \n",
      "\n",
      "Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like XnumberX seconds is a hard limit. 0428e901c7654286a5d593a86228c607 \n",
      "\n",
      "If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now. 390016daaf6e4634a4be7868593dd57d \n",
      "\n",
      "Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right? 4102ada43e0844a696cde7a5a1c6b45c \n",
      "\n",
      "Now instead of distance score, we would just send an acknowledgement that we have analyzed it. 062c62fb2baf44b199c6056b64c3265f \n",
      "\n",
      "Some default like XnumberX or something like the score so that will not pick that values. 14dd6a5daeea4ec3bf59eb567300dcec \n",
      "\n",
      "Come back to school we call this analyzer and staging we just created as a subject in the current table as it is and they hate us and the actual NLP readers empty. af44ede593da494f8a2eb21ebcd7970f \n",
      "\n",
      "Let is say XnumberX is minus XnumberX are some negative value meaning that they are not even anything correctly. af44ede593da494f8a2eb21ebcd7970f \n",
      "\n",
      "Knowing that a pending State I use some value actually, which is actually floatXnumberX value, right? 253223dc3e7b4eb5b268a5c5ed141922 \n",
      "\n",
      "Do some huge number actually add some Randomness and final value basically that waking up. ca8a45efd9a4482abc5e007681cf75f0 \n",
      "\n",
      "I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error. 131db9a5cba54cedac7d976b77e41b8e \n",
      "\n",
      "Yes at the end of the curve you getting all the segments and you are doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment is to which they belong right? 131db9a5cba54cedac7d976b77e41b8e \n",
      "\n",
      "Yeah, like so you have some XnumberX groups if you have done right do we? 90b04c9a271844e8b2dc332a24c11def \n",
      "\n",
      "Yeah, so we we we are just limiting it XnumberX to be in line with with this but we can does not mean anything. 8586fa3289cb47a9bdc872e277da29bb \n",
      "\n",
      "--------------\n",
      "But the name Remains the Same or itself should be different, right? e759d5051b224ca8ab10e1e625e07a03 \n",
      "\n",
      "Yeah, because we will be using interchangeable if we want to use that courting ritual. 154dab9127204d0fa2f0ad3aa00b246c \n",
      "\n",
      "Lentils and we are creating new ones service which would replace the current room service. b1f79bd4e2f24571a5fc13cd9d924dc7 \n",
      "\n",
      "Currently, but we will have to update some default values or some. 64c9d785e5e54899a58c02a1dc09656a \n",
      "\n",
      "I am assuming this is not the same as the current one. 212e7cd858544b99935d437b5635a753 \n",
      "\n",
      "But as we can we will have to create a temporary structure in that format then. 67428c44bf8b4abbbab289b875915fcf \n",
      "\n",
      "Be may need to reject some items that do not that overlap with the manual markers. 850319c7aab04f49a38fdd9dda7420a2 \n",
      "\n",
      "We need to First other words coming back and then decide how this will be. 2f00ada973054f28b67c4669d9be9e23 \n",
      "\n",
      "Maybe not immediately, but that is if you go to production that might be needed. 2f00ada973054f28b67c4669d9be9e23 \n",
      "\n",
      "So we will have to have like a pipeline for that like in each section that we publish. ae7dc522e8ff44bda4cbd9aef5811b1a \n",
      "\n",
      "Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open. 9648c443a927463daeb63edf81915bb7 \n",
      "\n",
      "So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody. 9648c443a927463daeb63edf81915bb7 \n",
      "\n",
      "Were not going to intersperse the topics with the manual markers that have been created or not. 5c526d59a4ce4528abc88397f77dd539 \n",
      "\n",
      "So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production. 5c526d59a4ce4528abc88397f77dd539 \n",
      "\n",
      "So even for now just so that we can observe what is coming out from the grouping and what we expect in the keywords. 5c526d59a4ce4528abc88397f77dd539 \n",
      "\n",
      "--------------\n",
      "First one is also Lambda or it is a service rate the current service on this end. 7a46bff8ef27494ab87bd13b363feae6 \n",
      "\n",
      "So you would make a pair called the landlord be same for both APA Falls, except the page the input changes. 684d1db8043f4c738409345102d7a044 \n",
      "\n",
      "But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one. 765f426547244837a63c95746c5c45be \n",
      "\n",
      "So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary. 765f426547244837a63c95746c5c45be \n",
      "\n",
      "So maybe then we need to be able to configure which one to liquid at least inject which analyzer to choose at least you can start off with staging and select one analyzer in production. 404c97b0053e426ab34deafa7d73dd36 \n",
      "\n",
      "Is it the separate language requirement of the same Lambda to promote the to to little methods is the same language. e81a512fc8ca4befa53b22f9535fa5d1 \n",
      "\n",
      "So in this one so but is it up can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective. bd3dc1b663b147a886fe0b9ef9d10b2a \n",
      "\n",
      "Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve. bd3dc1b663b147a886fe0b9ef9d10b2a \n",
      "\n",
      "So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready? e697609e7e8b4de19a556a6e49471518 \n",
      "\n",
      "It is clear, but you can put it in the other you have another issue right in the APA GitHub itself. e3cfd0caac88481592b8c2623cdfdd8a \n",
      "\n",
      "--------------\n",
      "We will be using those where we were using only the older version like to get the score the only top XnumberX in kind of thing, right but in this new one, we do not need anything because we do not have any data, right? ef05c0a0bc254eb0927a5b41f10e0572 \n",
      "\n",
      "There is something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code 2f1896133539433fa78f4e836897f526 \n",
      "\n",
      "For example, let us say when I call this new servers on let us do this. 2f1896133539433fa78f4e836897f526 \n",
      "\n",
      "Okay Android if nothing is written in their objective some preprocessing error. 2f1896133539433fa78f4e836897f526 \n",
      "\n",
      "We Implement in your analyzer right B it information and return. 2f1896133539433fa78f4e836897f526 \n",
      "\n",
      "But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there. dc9670f4070549c58777cd5762154777 \n",
      "\n",
      "Analyze menu, and then we also have midsegment analyzed and we pass analysis object left with it. cc7f9fa72d6d4325869e86e28286b2cc \n",
      "\n",
      "Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth. 8e4abf19839e41c1ad14ec83b08da03c \n",
      "\n",
      "So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted. 8e4abf19839e41c1ad14ec83b08da03c \n",
      "\n",
      "Like if you want to change the input and asking whether it can be used for anything. 9b7f46eb8209407486527fa3ad097480 \n",
      "\n",
      "Not necessarily think we can just call the second part separately, too. 41866e610c7748418a1d2c08817de9b2 \n",
      "\n",
      "But five and then if you see if we have a better way of making it have adaptive we will we will only take care of that. f8499b9df4e645ada9ac0e38aa7e9771 \n",
      "\n",
      "--------------\n",
      "The next sentence is a text when a field called text and a hiding with the sentence belong funny. a3cc958237dc46b4bd80e6ac6a7dd499 \n",
      "\n",
      "That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here. a3cc958237dc46b4bd80e6ac6a7dd499 \n",
      "\n",
      "Okay, so and it will also add a new field called feel call or text in each object. 52bdaab6df324ca0bccf8ce34c35db12 \n",
      "\n",
      "It would definitely be using the anything else great, except the Alta text. 280eccf326464766a80e1aca7ee18c3e \n",
      "\n",
      "--------------\n",
      "Okay, then for now just keep it as the same Lambda but have distinct, you know code structure so that they are not necessarily. c0b238a5290746138978a1ad41cdca19 \n",
      "\n",
      "--------------\n",
      "Gil Gil just call everything a segment on a laser it is the same service so I think so. 440d804fb9fe4331ad4fe9a30db7d03a \n",
      "\n",
      "--------------\n",
      "I think I am trying to connect some iOS but it is fairly. 321dbac48fa440cfa7a0e801bf6d64b1 \n",
      "\n",
      "<---------------->\n",
      "order difference: 1\n",
      "Relevant sentence:  Subject of peace and humanely tell that we should have expected.    =====    At least one chapter coming out right like I mean if I am wrong.\n",
      "Not Relevant sentence:  At least one chapter coming out right like I mean if I am wrong.    !=    I would say I would like you somewhere to find this is a qualitative group and which is not.\n",
      "order difference: 3\n",
      "order difference: 0\n",
      "Relevant sentence:  I would say I would like you somewhere to find this is a qualitative group and which is not.    =====    Are you talking about topics as the markers or The Pimps idea?\n",
      "Not Relevant sentence:  Are you talking about topics as the markers or The Pimps idea?    !=    Is it only for triggering summary or is it about doing anything?\n",
      "order difference: 32\n",
      "Not Relevant sentence:  Is it only for triggering summary or is it about doing anything?    !=    Just so that we are on the same page because this is a replacement chapter.\n",
      "order difference: 33\n",
      "order difference: 1\n",
      "Relevant sentence:  Just so that we are on the same page because this is a replacement chapter.    =====    But it would be it would have more depth than the chapters.\n",
      "Not Relevant sentence:  But it would be it would have more depth than the chapters.    !=    I know but does that help because we want to give them topics in the connotation.\n",
      "order difference: 2\n",
      "order difference: 1\n",
      "Relevant sentence:  I know but does that help because we want to give them topics in the connotation.    =====    Now the new summary it is there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create.\n",
      "order difference: 1\n",
      "Relevant sentence:  Now the new summary it is there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create.    =====    So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion.\n",
      "order difference: 0\n",
      "Relevant sentence:  So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion.    =====    You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.\n",
      "order difference: 1\n",
      "Relevant sentence:  You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights.    =====    If I had to push back to slack with two sections one is topics and one of the actions.\n",
      "order difference: 0\n",
      "Relevant sentence:  If I had to push back to slack with two sections one is topics and one of the actions.    =====    Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.\n",
      "Not Relevant sentence:  Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that.    !=    Let is assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics.\n",
      "order difference: 2\n",
      "order difference: 0\n",
      "Relevant sentence:  Let is assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics.    =====    They are like either is relevant or something, but it is that is what so if that is it on high level of difference between chapters.\n",
      "order difference: 0\n",
      "Relevant sentence:  They are like either is relevant or something, but it is that is what so if that is it on high level of difference between chapters.    =====    If you had limit on five you want to cover the whole years is at least as a big thing.\n",
      "order difference: 1\n",
      "Relevant sentence:  If you had limit on five you want to cover the whole years is at least as a big thing.    =====    So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important.\n",
      "Not Relevant sentence:  So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important.    !=    Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.\n",
      "order difference: 6\n",
      "order difference: 0\n",
      "Relevant sentence:  Improving service array basically if you are giving a segments, yeah, you can see that there are some between this time range.    =====    We found something for you as a topic and within that time range itself be graded on someone read a manual marker.\n",
      "Not Relevant sentence:  We found something for you as a topic and within that time range itself be graded on someone read a manual marker.    !=    But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.\n",
      "order difference: 2\n",
      "Not Relevant sentence:  But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye.    !=    But generally the idea was if you had sections of topics actions and decisions and we just did a great job on discovering them and someone had given some signals we take that and use that instead of words automatically.\n",
      "order difference: 3\n",
      "Not Relevant sentence:  But generally the idea was if you had sections of topics actions and decisions and we just did a great job on discovering them and someone had given some signals we take that and use that instead of words automatically.    !=    Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.\n",
      "order difference: 6\n",
      "order difference: 0\n",
      "Relevant sentence:  Let is stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions.    =====    Then comes actions are we do need to do anything with post call for actions?\n",
      "Not Relevant sentence:  Then comes actions are we do need to do anything with post call for actions?    !=    Both call you can you can just you can just show whatever whatever that Action Service returns.\n",
      "order difference: 11\n",
      "Not Relevant sentence:  Both call you can you can just you can just show whatever whatever that Action Service returns.    !=    That is what are you doing on you doing it at life essentially?\n",
      "order difference: 2\n",
      "Not Relevant sentence:  Actually, there is some more work here with it because they are actually returning some data and the original one the second one.    !=    It depends if we know what segment ideas we should probably update the key phrases like video right now because we use it.\n",
      "order difference: 6\n",
      "order difference: 1\n",
      "Relevant sentence:  It depends if we know what segment ideas we should probably update the key phrases like video right now because we use it.    =====    Is there at that field will have to update once we get it?\n",
      "Not Relevant sentence:  Is there at that field will have to update once we get it?    !=    Under the we like we need to purchase those sentences for one segment.\n",
      "order difference: 2\n",
      "Not Relevant sentence:  Under the we like we need to purchase those sentences for one segment.    !=    All it does is like it analyzes the segment each segment separately stores if each other Vector area so setting\n",
      "order difference: 9\n",
      "Not Relevant sentence:  All it does is like it analyzes the segment each segment separately stores if each other Vector area so setting    !=    Yeah, that would be grouped as a single segment only we want again spread that.\n",
      "order difference: 14\n",
      "order difference: 1\n",
      "Relevant sentence:  Yeah, that would be grouped as a single segment only we want again spread that.    =====    They are giving the or text as three three sentences separated by full stops.\n",
      "order difference: 1\n",
      "Relevant sentence:  They are giving the or text as three three sentences separated by full stops.    =====    It is like key is a segment segment and value is ASL.\n",
      "order difference: 1\n",
      "Relevant sentence:  It is like key is a segment segment and value is ASL.    =====    We will not contain all the sentences from the original segment, but only the Filter Works.\n",
      "order difference: 0\n",
      "Relevant sentence:  We will not contain all the sentences from the original segment, but only the Filter Works.    =====    Actually, he is saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text.\n",
      "Not Relevant sentence:  Actually, he is saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text.    !=    One more field in the same segment object itself is it?\n",
      "order difference: 2\n",
      "Not Relevant sentence:  One more field in the same segment object itself is it?    !=    So included you have group XnumberX and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative.\n",
      "order difference: 4\n",
      "order difference: 1\n",
      "Relevant sentence:  So included you have group XnumberX and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative.    =====    For each group then do we extract the key phrases for all the segments in a group?\n",
      "order difference: 1\n",
      "Relevant sentence:  For each group then do we extract the key phrases for all the segments in a group?    =====    What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service.\n",
      "order difference: 0\n",
      "Relevant sentence:  What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service.    =====    And you want us to make basically they were in groups.\n",
      "order difference: 0\n",
      "Relevant sentence:  And you want us to make basically they were in groups.    =====    Yes generation field called Dont extract do not populate the graph.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yes generation field called Dont extract do not populate the graph.    =====    We make any concurrent calls to get the key phases for each group.\n",
      "order difference: 1\n",
      "Relevant sentence:  We make any concurrent calls to get the key phases for each group.    =====    So once that is done, let us assume we got all the for each group.\n",
      "Not Relevant sentence:  Yeah so that you do not have to hard limit based on time true.    !=    No, no, it is ends that can is it a reusable they give you?\n",
      "order difference: 41\n",
      "order difference: 1\n",
      "Relevant sentence:  No, no, it is ends that can is it a reusable they give you?    =====    Everybody do not use exact as tomorrow the same thing can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Relevant sentence:  Everybody do not use exact as tomorrow the same thing can be used.    !=    I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space.\n",
      "order difference: 32\n",
      "order difference: 1\n",
      "Relevant sentence:  I say so even even now that still remain so what are we return you will show everything or if you do not want it to be clever put an upper limit put a upper limit to better manage the space.    =====    But essentially the idea is the same thing, right if we could use the highlighter topics.\n",
      "Not Relevant sentence:  But essentially the idea is the same thing, right if we could use the highlighter topics.    !=    Yeah, but when we say we found topic we give them a list of subtopics and everything, right?\n",
      "order difference: 5\n",
      "Not Relevant sentence:  Yeah, but when we say we found topic we give them a list of subtopics and everything, right?    !=    We do not have anything to do with the only thing somebody.\n",
      "order difference: 11\n",
      "order difference: 1\n",
      "Relevant sentence:  We do not have anything to do with the only thing somebody.    =====    So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part.    =====    Ideally table of contents can only be found in the book is complete.\n",
      "order difference: 0\n",
      "Relevant sentence:  Ideally table of contents can only be found in the book is complete.    =====    So let us separate that and I like that idea from this video.\n",
      "order difference: 1\n",
      "Relevant sentence:  So let us separate that and I like that idea from this video.    =====    So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it will not let us see what happens, right?    =====    Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics.\n",
      "order difference: 0\n",
      "Relevant sentence:  Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics.    =====    Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay.\n",
      "order difference: 0\n",
      "Relevant sentence:  Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it is okay.    =====    Then what is does is like for every discussion just give the highlights.\n",
      "order difference: 0\n",
      "Relevant sentence:  Then what is does is like for every discussion just give the highlights.    =====    So if you if you want to know Or even nine third chapters as well.\n",
      "order difference: 0\n",
      "Relevant sentence:  So if you if you want to know Or even nine third chapters as well.    =====    Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters.\n",
      "order difference: 1\n",
      "Relevant sentence:  Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters.    =====    Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.\n",
      "order difference: 0\n",
      "Relevant sentence:  Well come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you are doing right now you are trying to To distinguish the essential topics in a Convent in a complete conversation.    =====    If you to make real time, it would still more or less work in the way you currently intended.\n",
      "order difference: 0\n",
      "Relevant sentence:  If you to make real time, it would still more or less work in the way you currently intended.    =====    No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.\n",
      "order difference: 0\n",
      "Relevant sentence:  No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they are two different age is one is just by minute highlights fiveminute keywords essential keywords within a specific time period they do not all of it.    =====    But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong.\n",
      "order difference: 0\n",
      "Relevant sentence:  But with some caveats here and there but it is not necessarily going to be completed the same as every five minute keywords that we do right wrong.    =====    They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?\n",
      "order difference: 0\n",
      "Relevant sentence:  They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation?    =====    Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know.\n",
      "Not Relevant sentence:  Well figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let us not, you know.    !=    Yeah, I have a placeholder need to work on it for now.\n",
      "order difference: 11\n",
      "order difference: 0\n",
      "Relevant sentence:  So so I had looked at that tart that flowchart Witcher XnumberX had sent rate on the earlier.    =====    I wanted to discuss like what are the request response those things basically?\n",
      "Not Relevant sentence:  I wanted to discuss like what are the request response those things basically?    !=    But the API signature and everything would change a peer response will remain a little bit different which could be same response would be different.\n",
      "order difference: 5\n",
      "order difference: 1\n",
      "Relevant sentence:  But the API signature and everything would change a peer response will remain a little bit different which could be same response would be different.    =====    What is the request is nothing right only the instance ID unit meeting insensitive or whatever.\n",
      "order difference: 1\n",
      "Relevant sentence:  What is the request is nothing right only the instance ID unit meeting insensitive or whatever.    =====    Is it like girl you same way same way you have to send for the new service.\n",
      "order difference: 1\n",
      "Relevant sentence:  Is it like girl you same way same way you have to send for the new service.    =====    You sent a request with the same request you present for new service.\n",
      "order difference: 0\n",
      "Relevant sentence:  You sent a request with the same request you present for new service.    =====    And just dump everything on Tinder like the current chapters like four chapters chapter summary.\n",
      "Not Relevant sentence:  And just dump everything on Tinder like the current chapters like four chapters chapter summary.    !=    So this anything current sub to service its you have the response which you get would be the same as this new service.\n",
      "order difference: 43\n",
      "Not Relevant sentence:  So this anything current sub to service its you have the response which you get would be the same as this new service.    !=    What if you want every sent back to us in what we push back in slab in staging?\n",
      "order difference: 43\n",
      "Not Relevant sentence:  What if you want every sent back to us in what we push back in slab in staging?    !=    Deployment package ready, but ask the shun to change the because you have to change the way except response rate coming included on the response of is working on that once it is there L Death.\n",
      "order difference: 8\n",
      "order difference: 0\n",
      "Relevant sentence:  Deployment package ready, but ask the shun to change the because you have to change the way except response rate coming included on the response of is working on that once it is there L Death.    =====    That is yeah, but we try to call fate action items with groups.\n",
      "Not Relevant sentence:  You said earlier this maybe change all the text to something more.    !=    No then we have to be real should not hard limit on Facebook.\n",
      "order difference: 14\n",
      "Not Relevant sentence:  No then we have to be real should not hard limit on Facebook.    !=    Okay, so then do not do not show it in the slack, but you still have to propagate that to the graphs and every other turn same class that uses this.\n",
      "order difference: 11\n",
      "order difference: 1\n",
      "Relevant sentence:  Okay, so then do not do not show it in the slack, but you still have to propagate that to the graphs and every other turn same class that uses this.    =====    Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later.    =====    Okay, let us do overlap macon is do we remove this or do we keep this or what makes sense?\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay, let us do overlap macon is do we remove this or do we keep this or what makes sense?    =====    That is so yeah, you do not have to do in the pool right now.\n",
      "Not Relevant sentence:  That is so yeah, you do not have to do in the pool right now.    !=    let people know that these are or we can just push both but it is up to we will.\n",
      "order difference: 15\n",
      "order difference: 1\n",
      "Relevant sentence:  let people know that these are or we can just push both but it is up to we will.    =====    So you know that everyone knows the difference we can always Google.\n",
      "order difference: 1\n",
      "Relevant sentence:  So you know that everyone knows the difference we can always Google.    =====    And then we really wanted confident of this is working as expected.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then we really wanted confident of this is working as expected.    =====    within the time Ridge so okay, please find anything is okay for actions now just only top\n",
      "Not Relevant sentence:  within the time Ridge so okay, please find anything is okay for actions now just only top    !=    So you will okay it gets populated using the light cord itself.\n",
      "order difference: 2\n",
      "Not Relevant sentence:  So just so that we are all on the same page.    !=    It is just parameters and then we have to like the feature extraction would be like a single step instead of only that is all.\n",
      "order difference: 29\n",
      "Not Relevant sentence:  It is just parameters and then we have to like the feature extraction would be like a single step instead of only that is all.    !=    It is this right the rapper service or on both of them.\n",
      "order difference: 2\n",
      "order difference: 0\n",
      "Relevant sentence:  It is this right the rapper service or on both of them.    =====    It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now.\n",
      "order difference: 1\n",
      "Relevant sentence:  It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now.    =====    Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.\n",
      "order difference: 0\n",
      "Relevant sentence:  Let is assume that I am hitting the a Lambda function with all the segments and I am getting a group set set of groupings with each object.    =====    Okay, so then we will come to deployment separately less assuming.\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay, so then we will come to deployment separately less assuming.    =====    Yes, Each of which would contain the segment ID as a field and the text and the sentence.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yes, Each of which would contain the segment ID as a field and the text and the sentence.    =====    Let is say in group XnumberX it is an array of Group XnumberX is an array of objects embolism, right?\n",
      "Not Relevant sentence:  Let is say in group XnumberX it is an array of Group XnumberX is an array of objects embolism, right?    !=    I am not really in a one single group for you can have duplicate segments, right?\n",
      "order difference: 2\n",
      "Not Relevant sentence:  I am not really in a one single group for you can have duplicate segments, right?    !=    Number of groups we would actually have like very high number of groups we would again use the rankings to take on it outside.\n",
      "order difference: 18\n",
      "order difference: 1\n",
      "Relevant sentence:  That so I just sharing the screen of one of the meeting happened just now.    =====    it says so these are the input segmented is which have got we are able to see right, it is less than XnumberX secibds.\n",
      "order difference: 1\n",
      "Relevant sentence:  it says so these are the input segmented is which have got we are able to see right, it is less than XnumberX secibds.    =====    And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.\n",
      "order difference: 0\n",
      "Relevant sentence:  And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than XnumberX seconds.    =====    Yeah, the group segmented is her like mostly like to two segments are grouped.\n",
      "Not Relevant sentence:  Yeah, the group segmented is her like mostly like to two segments are grouped.    !=    If it is less than XnumberX just there is no fallback mechanism or anything.\n",
      "order difference: 3\n",
      "order difference: 1\n",
      "Relevant sentence:  If it is less than XnumberX just there is no fallback mechanism or anything.    =====    This is doing is just what happened and get it for you did not see that the mostly less than XnumberX seconds with them.\n",
      "order difference: 0\n",
      "Relevant sentence:  This is doing is just what happened and get it for you did not see that the mostly less than XnumberX seconds with them.    =====    Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like XnumberX seconds is a hard limit.\n",
      "Not Relevant sentence:  Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like XnumberX seconds is a hard limit.    !=    If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now.\n",
      "order difference: 3\n",
      "Not Relevant sentence:  If it is XnumberX seconds, if you want to remove the condition make it make it less than threshold for now.    !=    Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?\n",
      "order difference: 2\n",
      "order difference: 1\n",
      "Relevant sentence:  Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right?    =====    Now instead of distance score, we would just send an acknowledgement that we have analyzed it.\n",
      "Not Relevant sentence:  Now instead of distance score, we would just send an acknowledgement that we have analyzed it.    !=    Some default like XnumberX or something like the score so that will not pick that values.\n",
      "order difference: 15\n",
      "Not Relevant sentence:  Some default like XnumberX or something like the score so that will not pick that values.    !=    Come back to school we call this analyzer and staging we just created as a subject in the current table as it is and they hate us and the actual NLP readers empty.\n",
      "order difference: 8\n",
      "order difference: 0\n",
      "Relevant sentence:  Come back to school we call this analyzer and staging we just created as a subject in the current table as it is and they hate us and the actual NLP readers empty.    =====    Let is say XnumberX is minus XnumberX are some negative value meaning that they are not even anything correctly.\n",
      "order difference: 1\n",
      "Relevant sentence:  Let is say XnumberX is minus XnumberX are some negative value meaning that they are not even anything correctly.    =====    Knowing that a pending State I use some value actually, which is actually floatXnumberX value, right?\n",
      "order difference: 1\n",
      "Relevant sentence:  Knowing that a pending State I use some value actually, which is actually floatXnumberX value, right?    =====    Do some huge number actually add some Randomness and final value basically that waking up.\n",
      "Not Relevant sentence:  Do some huge number actually add some Randomness and final value basically that waking up.    !=    I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.\n",
      "order difference: 10\n",
      "order difference: 0\n",
      "Relevant sentence:  I am saying one is doing feature extraction one is we during the call are doing protects preprocessing on each segment and doing feature extraction and returning okay of error.    =====    Yes at the end of the curve you getting all the segments and you are doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment is to which they belong right?\n",
      "Not Relevant sentence:  Yes at the end of the curve you getting all the segments and you are doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment is to which they belong right?    !=    Yeah, like so you have some XnumberX groups if you have done right do we?\n",
      "order difference: 23\n",
      "Not Relevant sentence:  Yeah, like so you have some XnumberX groups if you have done right do we?    !=    Yeah, so we we we are just limiting it XnumberX to be in line with with this but we can does not mean anything.\n",
      "order difference: 14\n",
      "order difference: 1\n",
      "Relevant sentence:  But the name Remains the Same or itself should be different, right?    =====    Yeah, because we will be using interchangeable if we want to use that courting ritual.\n",
      "Not Relevant sentence:  Yeah, because we will be using interchangeable if we want to use that courting ritual.    !=    Lentils and we are creating new ones service which would replace the current room service.\n",
      "order difference: 6\n",
      "Not Relevant sentence:  Lentils and we are creating new ones service which would replace the current room service.    !=    Currently, but we will have to update some default values or some.\n",
      "order difference: 6\n",
      "Not Relevant sentence:  Currently, but we will have to update some default values or some.    !=    I am assuming this is not the same as the current one.\n",
      "order difference: 15\n",
      "Not Relevant sentence:  I am assuming this is not the same as the current one.    !=    But as we can we will have to create a temporary structure in that format then.\n",
      "order difference: 22\n",
      "Not Relevant sentence:  But as we can we will have to create a temporary structure in that format then.    !=    Be may need to reject some items that do not that overlap with the manual markers.\n",
      "order difference: 22\n",
      "order difference: 1\n",
      "Relevant sentence:  Be may need to reject some items that do not that overlap with the manual markers.    =====    We need to First other words coming back and then decide how this will be.\n",
      "order difference: 0\n",
      "Relevant sentence:  We need to First other words coming back and then decide how this will be.    =====    Maybe not immediately, but that is if you go to production that might be needed.\n",
      "Not Relevant sentence:  Maybe not immediately, but that is if you go to production that might be needed.    !=    So we will have to have like a pipeline for that like in each section that we publish.\n",
      "order difference: 7\n",
      "Not Relevant sentence:  So we will have to have like a pipeline for that like in each section that we publish.    !=    Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.\n",
      "order difference: 10\n",
      "order difference: 0\n",
      "Relevant sentence:  Cause this update this one say topics and maybe put this comment at the other one some a service because that is what method is following and Link both of them this issue that open.    =====    So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody.\n",
      "Not Relevant sentence:  So initially, what we will do in staging we will not be markers in the new summary the way we push things somebody.    !=    Were not going to intersperse the topics with the manual markers that have been created or not.\n",
      "order difference: 2\n",
      "order difference: 0\n",
      "Relevant sentence:  Were not going to intersperse the topics with the manual markers that have been created or not.    =====    So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production.\n",
      "order difference: 0\n",
      "Relevant sentence:  So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production.    =====    So even for now just so that we can observe what is coming out from the grouping and what we expect in the keywords.\n",
      "Not Relevant sentence:  First one is also Lambda or it is a service rate the current service on this end.    !=    So you would make a pair called the landlord be same for both APA Falls, except the page the input changes.\n",
      "order difference: 2\n",
      "Not Relevant sentence:  So you would make a pair called the landlord be same for both APA Falls, except the page the input changes.    !=    But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.\n",
      "order difference: 2\n",
      "order difference: 0\n",
      "Relevant sentence:  But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one.    =====    So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.\n",
      "order difference: 1\n",
      "Relevant sentence:  So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary.    =====    So maybe then we need to be able to configure which one to liquid at least inject which analyzer to choose at least you can start off with staging and select one analyzer in production.\n",
      "Not Relevant sentence:  So maybe then we need to be able to configure which one to liquid at least inject which analyzer to choose at least you can start off with staging and select one analyzer in production.    !=    Is it the separate language requirement of the same Lambda to promote the to to little methods is the same language.\n",
      "order difference: 20\n",
      "order difference: 1\n",
      "Relevant sentence:  Is it the separate language requirement of the same Lambda to promote the to to little methods is the same language.    =====    So in this one so but is it up can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective.\n",
      "order difference: 0\n",
      "Relevant sentence:  So in this one so but is it up can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective.    =====    Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.\n",
      "Not Relevant sentence:  Community let us assume it is the same deployment because what you are doing is you are accepting features and you are just using those features and breaking the sentence article with somebody right to deserve.    !=    So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready?\n",
      "order difference: 50\n",
      "order difference: 1\n",
      "Relevant sentence:  So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready?    =====    It is clear, but you can put it in the other you have another issue right in the APA GitHub itself.\n",
      "order difference: 1\n",
      "Relevant sentence:  We will be using those where we were using only the older version like to get the score the only top XnumberX in kind of thing, right but in this new one, we do not need anything because we do not have any data, right?    =====    There is something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code\n",
      "order difference: 0\n",
      "Relevant sentence:  There is something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code    =====    For example, let us say when I call this new servers on let us do this.\n",
      "order difference: 0\n",
      "Relevant sentence:  For example, let us say when I call this new servers on let us do this.    =====    Okay Android if nothing is written in their objective some preprocessing error.\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay Android if nothing is written in their objective some preprocessing error.    =====    We Implement in your analyzer right B it information and return.\n",
      "order difference: 1\n",
      "Relevant sentence:  We Implement in your analyzer right B it information and return.    =====    But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there.\n",
      "Not Relevant sentence:  But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there.    !=    Analyze menu, and then we also have midsegment analyzed and we pass analysis object left with it.\n",
      "order difference: 8\n",
      "Not Relevant sentence:  Analyze menu, and then we also have midsegment analyzed and we pass analysis object left with it.    !=    Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.\n",
      "order difference: 2\n",
      "order difference: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant sentence:  Whatd you do is XnumberX gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth.    =====    So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted.\n",
      "Not Relevant sentence:  So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted.    !=    Like if you want to change the input and asking whether it can be used for anything.\n",
      "order difference: 6\n",
      "Not Relevant sentence:  Like if you want to change the input and asking whether it can be used for anything.    !=    Not necessarily think we can just call the second part separately, too.\n",
      "order difference: 2\n",
      "Not Relevant sentence:  Not necessarily think we can just call the second part separately, too.    !=    But five and then if you see if we have a better way of making it have adaptive we will we will only take care of that.\n",
      "order difference: 23\n",
      "order difference: 0\n",
      "Relevant sentence:  The next sentence is a text when a field called text and a hiding with the sentence belong funny.    =====    That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here.\n",
      "Not Relevant sentence:  That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here.    !=    Okay, so and it will also add a new field called feel call or text in each object.\n",
      "order difference: 22\n",
      "Not Relevant sentence:  Okay, so and it will also add a new field called feel call or text in each object.    !=    It would definitely be using the anything else great, except the Alta text.\n",
      "order difference: 9\n",
      "[(0, 0), (1, 0), (2, 0), (3, 0), (6, 0), (7, 0), (13, 0), (4, 1), (5, 1), (8, 1), (9, 2), (10, 2), (19, 2), (20, 2), (25, 2), (34, 2), (11, 3), (17, 3), (18, 3), (26, 3), (12, 4), (14, 5), (15, 5), (30, 5), (31, 5), (32, 5), (16, 6), (21, 7), (22, 7), (23, 7), (24, 7), (33, 7), (27, 8), (28, 8), (29, 8), (35, 9)]\n",
      "[[['28 minutes and then there are there are enough. Subject of peace and humanely tell that we should have expected. '], '2019-10-24T09:37:55Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '12ee4b3dc175408abddadb34bb622606'], [[\"At least one chapter coming out right like I mean if I'm wrong. \"], '2019-10-24T09:38:18Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e9096016c7994ee7adac1f309c635781']] \n",
      "\n",
      "\n",
      "[[[\"Just so that we're on the same page because this is a replacement chapter. This will be Topic in his essentially. \"], '2019-10-24T09:59:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7e0ed18332e74a0091c7d3c4300a1f60'], [['But it would be it would have more depth than the chapters. '], '2019-10-24T09:59:37Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'c77a0e26e4d3468e91c08a02c897890d']] \n",
      "\n",
      "\n",
      "[[['I know but does that help because we want to give them topics in the connotation. What are the topics?'], '2019-10-24T09:59:57Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '1cf24541a3514a2f86d05f74f62fe6e3'], [[\"Okay, that's no difference. Now the new summary it's there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create. That's the that's what we discussed earlier also. \"], '2019-10-24T10:00:08Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cec9d9832cd24135a14e1b7a936f2b7e'], [[\"No, not not that big a dick. So what happens is like it's similar to Chapters. You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights. So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion. \"], '2019-10-24T10:00:46Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ef9b701a62ea481485ad23db01cbd776'], [['Let me put it this way. If I had to push back to slack with two sections one is topics and one of the actions. Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that. '], '2019-10-24T10:01:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e51c3385ccc6405193808ec2711dc293']] \n",
      "\n",
      "\n",
      "[[[\"If you had limit on five you want to cover the whole years is at least as a big thing. Let's assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics. They are like either is relevant or something, but it's that's what so if that is it on high level of difference between chapters. \"], '2019-10-24T10:01:50Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '65d3a52e005f469d8cba97bcafa2739c'], [[\"It's the same so good. So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important. Is that whether it is five or six or seven? \"], '2019-10-24T10:02:28Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'beff02d81e604638939892b1b784d4b2']] \n",
      "\n",
      "\n",
      "[[['But generally the idea was if you had sections of topics actions and decisions and we just did a great job on discovering them and someone had given some signals we take that and use that instead of words automatically. '], '2019-10-24T10:06:00Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8ec61fc25ef44f1e810b0f17d1422470']] \n",
      "\n",
      "\n",
      "[[[\"Let's stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions. There is also acceptable anymore if you have this. Then comes actions are we do need to do anything with post call for actions?\"], '2019-10-24T10:08:21Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bd04b29039e14e0aba93598cde210dc5']] \n",
      "\n",
      "\n",
      "[[[\"And we have to have something else. We don't have anything to do with the only thing somebody. \"], '2019-10-24T10:08:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '83fc6652dad543538c9a66dd245120a0'], [[\"Ideally table of contents can only be found in the book is complete. Yeah, right. So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part. You don't necessarily have to correlate to a topic. So let's separate that and I like that idea from this video. Maybe not caught not listen call them chapters. \"], '2019-10-24T10:08:46Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '347d89717f7b46ebbc9effada658a928'], [[\"Security my whole idea was like been in future. Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics. Then what is does is like for every discussion just give the highlights. But your again separating it into two groups right now. They're not kill groups. Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters. Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it's okay. So if you if you want to know Or even nine third chapters as well. You can be seen before member this becomes different. But that your engine anything right now, right? So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it won't let us see what happens, right? \"], '2019-10-24T10:09:10Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '5ce3830ac74449cfa0594d9e7e922315'], [[\"No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they're two different age is one is just by minute highlights five-minute keywords essential keywords within a specific time period they don't all of it. So it's like recurring every five minutes. We'll come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you're doing right now you're trying to To distinguish the essential topics in a Convent in a complete conversation. If you to make real time, it would still more or less work in the way you currently intended. But with some caveats here and there but it's not necessarily going to be completed the same as every five minute keywords that we do right wrong. So we had to make it real time. We'll figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let's not, you know. They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation? \"], '2019-10-24T10:10:29Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3e73ba7a1b0543fc97519322f7eb9eb4']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Improving service array basically if you're giving a segments, yeah, you can see that there are some between this time range. We found something for you as a topic and within that time range itself be graded on someone read a manual marker. Hmm. It should prefer that to this one. \"], '2019-10-24T10:04:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'cd7717a085d0444f8fe3ee598fe81417']] \n",
      "\n",
      "\n",
      "[[['But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye. Okay, you just by looking at them even slap. '], '2019-10-24T10:04:53Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '84da28210d524bbcb0de12b3c068026b']] \n",
      "\n",
      "\n",
      "[[['It depends if we know what segment ideas we should probably update the key phrases like video right now because we use it. '], '2019-10-24T09:46:49Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '183b0c4fcb2546aa8479160a6dd8f86c'], [[\"So we'll update that keywords or something. Is there at that field will have to update once we get it? \"], '2019-10-24T09:46:58Z', '84fbaa66a2474ea29ae053f3a2e519d6', '0983ef203b5248559376addb96cc125d']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['So if one segment splits, it has multiple sentences. Yeah, that would be grouped as a single segment only we want again spread that. '], '2019-10-24T09:54:40Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '67a84321aff94e3591e883b26c947dcb'], [['They are giving the or text as three three sentences separated by full stops. Yes. Okay, so that means everything. '], '2019-10-24T09:55:10Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'f55867392efa46819fcbc409edebf99e'], [[\"Valium which all right. It's like key is a segment segment and value is ASL. Just a string. \"], '2019-10-24T09:55:21Z', '84fbaa66a2474ea29ae053f3a2e519d6', '0aa9643d8be34aa98b3059e705200447'], [[\"Actually, he's saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text. We will not contain all the sentences from the original segment, but only the Filter Works. \"], '2019-10-24T09:55:27Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '08cb5accf2cf4fe4819da499718e6a8a']] \n",
      "\n",
      "\n",
      "[[['Exactly. So included you have group 0 and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative. '], '2019-10-24T09:57:22Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c1f966917c2449fab372b88f6fb93d23'], [['Okay, so once that is done. For each group then do we extract the key phrases for all the segments in a group? '], '2019-10-24T09:57:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9c911229fa124080bed9320da700aed3'], [[\"What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service. Yes generation field called Don't extract don't populate the graph. He will go give us a key phrases for that. And you want us to make basically they were in groups. We make any concurrent calls to get the key phases for each group. \"], '2019-10-24T09:57:51Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'aef4d82f30dd4eff9a653c12f091d669'], [[\"So once that is done, let's assume we got all the for each group. We get key places. What do we do do we? Need to filter or reduce any counter. We just take medication. \"], '2019-10-24T09:58:25Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '86f39c46e153416ca86e69002db48097']] \n",
      "\n",
      "\n",
      "[[[\"It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now. It's this right the rapper service or on both of them. \"], '2019-10-24T09:52:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '755ac6aa613f45d5be5566a5fe1d784d'], [[\"Okay, so then we'll come to deployment separately less assuming. Let's assume that I'm hitting the a Lambda function with all the segments and I'm getting a group set set of groupings with each object. Let's say in group 1 it's an array of Group 1 is an array of objects embolism, right? Yes, Each of which would contain the segment ID as a field and the text and the sentence. To which another field called sentence? \"], '2019-10-24T09:52:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8c4930798f1e4460a3483d12067e10a6']] \n",
      "\n",
      "\n",
      "[[['That so I just sharing the screen of one of the meeting happened just now. It happened on engineering Channel. Yeah. '], '2019-10-24T09:36:48Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'c8ee1afb64f74ec380c133f570084b0b'], [['If you see the screen, right, I have one log. it says so these are the input segmented is which have got we are able to see right, it is less than 120 secibds.'], '2019-10-24T09:37:08Z', '84fbaa66a2474ea29ae053f3a2e519d6', '3be57485efb14ff8be6d23ecd62dabd2'], [[\"Yeah, the group segmented is her like mostly like to two segments are grouped. And for all of the groups, I am adding a log saying that no chapter marker for due to a shorter duration of two segments are less than 120 seconds. Yeah, that's the reason. \"], '2019-10-24T09:37:30Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'f4c5c03c2e924de9847e0f2a65095d8c']] \n",
      "\n",
      "\n",
      "[[[\"I'm saying one is doing feature extraction one is we during the call are doing protects pre-processing on each segment and doing feature extraction and returning okay of error. Yes at the end of the curve you getting all the segments and you're doing some more stuff and trying to get break them down into individual sentences and give us grouping based on those segments sentences and to the segment's to which they belong right? \"], '2019-10-24T09:51:40Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '131db9a5cba54cedac7d976b77e41b8e']] \n",
      "\n",
      "\n",
      "[[[\"So whenever I am in a segment analyzed we just use it to detect some very positive process somebody at this point once all the parrot is extracted. All segments have been transcribed. The Randy is over recording available. We will trigger somebody header like with the new strategy. Yeah, and it's one. What'd you do is 3/4 gather all the segments in The Firm sort them any ascending order if it is not already and call the canoe Lambeth. that they using for grouping the \"], '2019-10-24T09:49:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '8e4abf19839e41c1ad14ec83b08da03c']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['No, no, it is ends that can is it a reusable they give you? '], '2019-10-24T09:52:17Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bd1ba775b4ef449da97e6f5920b3650a'], [[\"Everybody don't use exact as tomorrow the same thing can be used. \"], '2019-10-24T09:52:22Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'd8c052b48ca244068d4b118a427a4289']] \n",
      "\n",
      "\n",
      "[[[\"Okay, so then don't don't show it in the slack, but you still have to propagate that to the graphs and every other turn same class that uses this. \"], '2019-10-24T10:05:12Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'b13bb3e8ad7248d59dc4dd16fa81699a'], [[\"That's so yeah, you don't have to do in the pool right now. Yeah, everybody will just push further they give us right now and staging to see if it is good enough right and later. We can side of correlate. Okay, let's do overlap macon's do we remove this or do we keep this or what makes sense? \"], '2019-10-24T10:05:37Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '7658b0fa8ea14eb8acc62f015032bbeb']] \n",
      "\n",
      "\n",
      "[[[\"let people know that these are or we can just push both but it's up to we will. \"], '2019-10-24T10:12:59Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a160895632904c3c99206511ef0efe3b'], [['Good to be prepared. So you know that everyone knows the difference we can always Google. '], '2019-10-24T10:13:06Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '7dbae367c4d04dae8584d290b7c82077'], [['And then we really wanted confident of this is working as expected. We can merge and remove any choppers that go inside. within the time Ridge so okay, please find anything is okay for actions now just only top '], '2019-10-24T10:13:12Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '3dc868cd1f184517ace6449becb87e08']] \n",
      "\n",
      "\n",
      "[[[\"Okay, okay, he won't be expecting any scores. But the name Remains the Same or itself should be different, right? \"], '2019-10-24T09:41:25Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e759d5051b224ca8ab10e1e625e07a03'], [['Yeah, because we will be using interchangeable if we want to use that courting ritual. '], '2019-10-24T09:41:38Z', '84fbaa66a2474ea29ae053f3a2e519d6', '154dab9127204d0fa2f0ad3aa00b246c']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"We thought we will stick to five for now and then do that but that's not really that doesn't stop anything. I say so even even now that still remain so what are we return you will show everything or if you don't want it to be clever put an upper limit put a upper limit to better manage the space. \"], '2019-10-24T10:02:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e09a73ccea7b4e7d94c2f3992743cded'], [[\"Stayed out and seeding will only enable strategy for space. So let's put a full limit me on this. But essentially the idea is the same thing, right if we could use the highlighter topics. Nobody comes. \"], '2019-10-24T10:03:15Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'af09fd64cfbc4b3dae3f8f2b054316c1']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Let's discuss on the community thing, right? So so I had looked at that tart that flowchart Witcher 3 had sent rate on the earlier. The design-wise it's fine. But with respect to the API a signature ways. I wanted to discuss like what are the request response those things basically? \"], '2019-10-24T09:40:42Z', '84fbaa66a2474ea29ae053f3a2e519d6', '531ca88fd1014c94953402ceff5efdb4']] \n",
      "\n",
      "\n",
      "[[['But the API signature and everything would change a peer response will remain a little bit different which could be same response would be different. Okay? '], '2019-10-24T09:41:53Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '3981d9750b194120acfb825466a97ea1'], [['With respect to the first one the second the API. What is the request is nothing right only the instance ID unit meeting insensitive or whatever. '], '2019-10-24T09:42:05Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'b3d10173ca17432e8e5ae3c1071fe323'], [['Group Services Under Equus right now. Is it like girl you same way same way you have to send for the new service. '], '2019-10-24T09:42:35Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'd1112b3c90094ffea1878a898ceb17b8'], [['And just dump everything on Tinder like the current chapters like four chapters chapter summary. You sent a request with the same request you present for new service. '], '2019-10-24T09:42:45Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'ab22180c9af64f12974a806f574e0cb2']] \n",
      "\n",
      "\n",
      "[[['So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary. These are the some regeneration process. But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one. '], '2019-10-24T09:44:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '765f426547244837a63c95746c5c45be'], [['So maybe then we need to be able to configure which one to liquid at least inject which analyzer to choose at least you can start off with staging and select one analyzer in production. You can use Channel mind itself. '], '2019-10-24T09:44:42Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '404c97b0053e426ab34deafa7d73dd36']] \n",
      "\n",
      "\n",
      "[[['Different different rate. Is it the separate language requirement of the same Lambda to promote the to to little methods is the same language. '], '2019-10-24T09:50:29Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e81a512fc8ca4befa53b22f9535fa5d1'], [[\"Community let's assume it's the same deployment because what you're doing is you're accepting features and you're just using those features and breaking the sentence article with somebody right to deserve. This is what your goal is. So in this one so but is it up' can this what are you doing right now can be taken it to use for anything else that it requires it to be a separate Lambda like it is in the group in perspective. \"], '2019-10-24T09:51:06Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'bd3dc1b663b147a886fe0b9ef9d10b2a']] \n",
      "\n",
      "\n",
      "[[['Yeah, okay. Thanks Martin. So you see you so in this one what spending is discussing of the just solidifying the spec what the what each Lambda would return us ready? So that method can start working on it. Right? You mean the response structure? Yeah. '], '2019-10-24T10:06:45Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'e697609e7e8b4de19a556a6e49471518'], [[\"It's clear, but you can put it in the other you have another issue right in the APA GitHub itself. You create another show post with them. I think the other one. \"], '2019-10-24T10:07:12Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'e3cfd0caac88481592b8c2623cdfdd8a']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Okay, so that's fine. That's yeah, but we try to call fate action items with groups. Definitely once we establish dress. Yeah other thing I asked Richard. I mean I have I have them. Deployment package ready, but ask the shun to change the because you have to change the way except response rate coming included on the response of is working on that once it's there L Death. \"], '2019-10-24T10:14:09Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', 'bf11d1b5c35e4d6c8f946f66c85d8538']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"No, at least in my code. I haven't written like that. If it is less than 120 just there's no fallback mechanism or anything. \"], '2019-10-24T09:38:23Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'e966b3da536b49a38ef6f6a8ff986a70'], [[\"This is doing is just what happened and get it for you didn't see that the mostly less than 120 seconds with them. So they have filters. Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like 120 seconds is a hard limit. \"], '2019-10-24T09:38:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '0428e901c7654286a5d593a86228c607']] \n",
      "\n",
      "\n",
      "[[[\"Yes, you can it's make the product magnetic sensor consists for the names of my service itself. If it's 10 seconds, if you want to remove the condition make it make it less than threshold for now. We'll until we finalize something. \"], '2019-10-24T09:39:38Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '390016daaf6e4634a4be7868593dd57d']] \n",
      "\n",
      "\n",
      "[[['It would be the same like whatever you give for scorer service, right? Okay, so we switch it up and we give like you give each segment as an input and then you receive a distance go, right? '], '2019-10-24T09:41:04Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '4102ada43e0844a696cde7a5a1c6b45c'], [['Now instead of distance score, we would just send an acknowledgement that we have analyzed it. '], '2019-10-24T09:41:19Z', 'b1e8787a9a1f4859ac11cbb6a8124fd9', '062c62fb2baf44b199c6056b64c3265f']] \n",
      "\n",
      "\n",
      "[[[\"Come back to school we call this analyzer and staging we just created as a subject in the current table as it is and they hate us and the actual NLP readers empty. Let's say 4 is minus 1 are some negative value meaning that they're not even anything correctly. We had already doing for visits. \"], '2019-10-24T09:48:03Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'af44ede593da494f8a2eb21ebcd7970f'], [['Knowing that a pending State I use some value actually, which is actually float64 value, right? '], '2019-10-24T09:48:29Z', '84fbaa66a2474ea29ae053f3a2e519d6', '253223dc3e7b4eb5b268a5c5ed141922'], [['Do some huge number actually add some Randomness and final value basically that waking up. '], '2019-10-24T09:48:37Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'ca8a45efd9a4482abc5e007681cf75f0']] \n",
      "\n",
      "\n",
      "[[[\"We will be using those where we were using only the older version like to get the score the only top 10 in kind of thing, right but in this new one, we don't need anything because we don't have any data, right? \"], '2019-10-24T09:45:34Z', '84fbaa66a2474ea29ae053f3a2e519d6', 'ef05c0a0bc254eb0927a5b41f10e0572'], [[\"For example, let's say when I call this new servers on let's do this. We Implement in your analyzer right B it information and return. Okay object or datum status. Okay Android if nothing is written in their objective some pre-processing error. There's something really yeah if they return okay, we need to not relate to it analysis analysis object right at least and say if you look at the way current code \"], '2019-10-24T09:45:49Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f1896133539433fa78f4e836897f526'], [['But that analysis object is essentially just a dummy object with no just an analysis ID transcript ID and maybe the recording some other metadata but the actual data of analysis is pretty epic is there. '], '2019-10-24T09:46:21Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'dc9670f4070549c58777cd5762154777']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Be may need to reject some items that don't that overlap with the manual markers. \"], '2019-10-24T10:03:53Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '850319c7aab04f49a38fdd9dda7420a2'], [[\"Maybe not immediately, but that's if you go to production that might be needed. We need to First other words coming back and then decide how this will be. But just you have to keep that in mind. \"], '2019-10-24T10:04:05Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '2f00ada973054f28b67c4669d9be9e23']] \n",
      "\n",
      "\n",
      "[[[\"Cause this update this one say topics and maybe put this comment at the other one some a service because that's what method is following and Link both of them this issue that open. So initially, what we'll do in staging we will not be markers in the new summary the way we push things somebody. \"], '2019-10-24T10:11:56Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '9648c443a927463daeb63edf81915bb7']] \n",
      "\n",
      "\n",
      "[[[\"So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production. We're going to use it. Whatever you use right now. Hmm that very comfortable that this is working as intended. We can include that make sense. So even for now just so that we can observe what's coming out from the grouping and what we expect in the keywords. We're not going to intersperse the topics with the manual markers that have been created or not. \"], '2019-10-24T10:12:27Z', '62b6ae1d7f834b0bb2055f7c72bc3368', '5c526d59a4ce4528abc88397f77dd539']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['DWS. Yeah, here is the same thing. That Shane was also asking me to making sentences down that I interned under sentences for each unique object the beginning here. The next sentence is a text when a field called text and a hiding with the sentence belong funny. '], '2019-10-24T09:47:14Z', '62b6ae1d7f834b0bb2055f7c72bc3368', 'a3cc958237dc46b4bd80e6ac6a7dd499']] \n",
      "\n",
      "\n",
      "9\n",
      "Before Merging 36\n",
      "[(37, 38), (24, 55), (34, 15), (15, 17), (3, 4), (4, 5), (6, 7), (9, 22), (51, 52)]\n",
      "\n",
      "\n",
      "No, at least in my code. I haven't written like that. If it is less than 120 just there's no fallback mechanism or anything. \n",
      "This is doing is just what happened and get it for you didn't see that the mostly less than 120 seconds with them. So they have filters. Oh, yeah, we can remove the catheter and I will filter that try say in some sort of like 120 seconds is a hard limit. \n",
      "\n",
      "\n",
      "Yes, you can it's make the product magnetic sensor consists for the names of my service itself. If it's 10 seconds, if you want to remove the condition make it make it less than threshold for now. We'll until we finalize something. \n",
      "\n",
      "\n",
      "But the API signature and everything would change a peer response will remain a little bit different which could be same response would be different. Okay? \n",
      "With respect to the first one the second the API. What is the request is nothing right only the instance ID unit meeting insensitive or whatever. \n",
      "Group Services Under Equus right now. Is it like girl you same way same way you have to send for the new service. \n",
      "And just dump everything on Tinder like the current chapters like four chapters chapter summary. You sent a request with the same request you present for new service. \n",
      "\n",
      "\n",
      "So right now what happens is at the end of the call when we decide to say that hairball is ended in a ready to push the summary. These are the some regeneration process. But before that in during the call, we need to be able to send all the segments that were created to a different Lambda right instead of the current one. \n",
      "So maybe then we need to be able to configure which one to liquid at least inject which analyzer to choose at least you can start off with staging and select one analyzer in production. You can use Channel mind itself. \n",
      "\n",
      "\n",
      "It would be like a completely separate So currently we have this core is always right and grouping sequence of us right now. It's this right the rapper service or on both of them. \n",
      "Okay, so then we'll come to deployment separately less assuming. Let's assume that I'm hitting the a Lambda function with all the segments and I'm getting a group set set of groupings with each object. Let's say in group 1 it's an array of Group 1 is an array of objects embolism, right? Yes, Each of which would contain the segment ID as a field and the text and the sentence. To which another field called sentence? \n",
      "\n",
      "\n",
      "So if one segment splits, it has multiple sentences. Yeah, that would be grouped as a single segment only we want again spread that. \n",
      "They are giving the or text as three three sentences separated by full stops. Yes. Okay, so that means everything. \n",
      "Valium which all right. It's like key is a segment segment and value is ASL. Just a string. \n",
      "Actually, he's saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text. We will not contain all the sentences from the original segment, but only the Filter Works. \n",
      "\n",
      "\n",
      "So if one segment splits, it has multiple sentences. Yeah, that would be grouped as a single segment only we want again spread that. \n",
      "They are giving the or text as three three sentences separated by full stops. Yes. Okay, so that means everything. \n",
      "Valium which all right. It's like key is a segment segment and value is ASL. Just a string. \n",
      "Actually, he's saying that will send this will return the same object like you turn for each group will have a list of segment objects and the form and the structure is same as what you send us requests hole with an additional field called Alta text. We will not contain all the sentences from the original segment, but only the Filter Works. \n",
      "\n",
      "\n",
      "Exactly. So included you have group 0 and that you have a list of segments Bennet Ahmed will have segment ID and the rest of the properties and also one more property called alternative. \n",
      "Okay, so once that is done. For each group then do we extract the key phrases for all the segments in a group? \n",
      "What all the architects in the so how do you want us to send the so basically will it be take all the segments of for each group send it in one shot to keep his Senate has one request to keep your service. Yes generation field called Don't extract don't populate the graph. He will go give us a key phrases for that. And you want us to make basically they were in groups. We make any concurrent calls to get the key phases for each group. \n",
      "So once that is done, let's assume we got all the for each group. We get key places. What do we do do we? Need to filter or reduce any counter. We just take medication. \n",
      "\n",
      "\n",
      "Just so that we're on the same page because this is a replacement chapter. This will be Topic in his essentially. \n",
      "But it would be it would have more depth than the chapters. \n",
      "\n",
      "\n",
      "I know but does that help because we want to give them topics in the connotation. What are the topics?\n",
      "Okay, that's no difference. Now the new summary it's there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create. That's the that's what we discussed earlier also. \n",
      "No, not not that big a dick. So what happens is like it's similar to Chapters. You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights. So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion. \n",
      "Let me put it this way. If I had to push back to slack with two sections one is topics and one of the actions. Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that. \n",
      "\n",
      "\n",
      "I know but does that help because we want to give them topics in the connotation. What are the topics?\n",
      "Okay, that's no difference. Now the new summary it's there that highlights right highlights means what are the different distinct set of items being discussed in the past and they will be merging with the manual markers that we create. That's the that's what we discussed earlier also. \n",
      "No, not not that big a dick. So what happens is like it's similar to Chapters. You try to find like the number of distinct chapters happening in a discussion and then for each chapter, so you go and find the highlights. So the bulbs are highlights the chapters are the whole trying to cover the whole uniqueness of the discussion. \n",
      "Let me put it this way. If I had to push back to slack with two sections one is topics and one of the actions. Topics were interspersed with manual markers and we would remove any overlapping chapters within that range that you would protect yourself perfectly fit in with that. \n",
      "\n",
      "\n",
      "If you had limit on five you want to cover the whole years is at least as a big thing. Let's assume that there is a threshold in the characterization anything about that would flow as a topics below that would not do not go as topics. They are like either is relevant or something, but it's that's what so if that is it on high level of difference between chapters. \n",
      "It's the same so good. So we have only somebody if the action it is, the said you have the summary of the discussion you show them all the topics that we think are important. Is that whether it is five or six or seven? \n",
      "\n",
      "\n",
      "Improving service array basically if you're giving a segments, yeah, you can see that there are some between this time range. We found something for you as a topic and within that time range itself be graded on someone read a manual marker. Hmm. It should prefer that to this one. \n",
      "\n",
      "\n",
      "But still if you give them overlapping watch links for the same portion of the call, is it helpful because manual Motors are more descriptive at least makes more sense to the human eye. Okay, you just by looking at them even slap. \n",
      "\n",
      "\n",
      "Let's stick the topics which are and me go back and makes you want to have a separate chapter is topics assumptions. There is also acceptable anymore if you have this. Then comes actions are we do need to do anything with post call for actions?\n",
      "\n",
      "\n",
      "And we have to have something else. We don't have anything to do with the only thing somebody. \n",
      "Ideally table of contents can only be found in the book is complete. Yeah, right. So what do I give as part of periodic chapters that every five segments is just a set of keywords the deducted for those primary part. You don't necessarily have to correlate to a topic. So let's separate that and I like that idea from this video. Maybe not caught not listen call them chapters. \n",
      "Security my whole idea was like been in future. Maybe if you want to also use group segments as chapters like in like so then you will be chopped what it I did it as a surprise to cover the whole range of discussions like separated segregate all the different different topics. Then what is does is like for every discussion just give the highlights. But your again separating it into two groups right now. They're not kill groups. Yeah, if you say highlights from the paint and what happens to the rest of the documents that is covered in chapters. Like the chapter gives you the whole idea like the separation in different different topics and the problems just give you highlights what is important for each topic, but when you put the consumer in the same place, maybe it's okay. So if you if you want to know Or even nine third chapters as well. You can be seen before member this becomes different. But that your engine anything right now, right? So even if we let us assume the vision the summary the baby thought when everything in slack not even doing anything, so no, it won't let us see what happens, right? \n",
      "No, there is no we yeah, I mean the whole even if you were to replace whatever we have right now for now assume they're two different age is one is just by minute highlights five-minute keywords essential keywords within a specific time period they don't all of it. So it's like recurring every five minutes. We'll come up with something how we represent that information we can change it, but for now keep that as a feature separate from what you're doing right now you're trying to To distinguish the essential topics in a Convent in a complete conversation. If you to make real time, it would still more or less work in the way you currently intended. But with some caveats here and there but it's not necessarily going to be completed the same as every five minute keywords that we do right wrong. So we had to make it real time. We'll figure out how to represent that information and deprecated the way we do it is show information timeline right now, but let's not, you know. They compare both so go to the periodic keywords is a periodic givers what you see in the timeline and what are you doing our topics you essentially extracting topics in the conversation? \n",
      "\n",
      "\n",
      "Cause this update this one say topics and maybe put this comment at the other one some a service because that's what method is following and Link both of them this issue that open. So initially, what we'll do in staging we will not be markers in the new summary the way we push things somebody. \n",
      "\n",
      "\n",
      "So this strategy whatever we working on right now, the grouping strategies warning only going to apply and staging and production. We're going to use it. Whatever you use right now. Hmm that very comfortable that this is working as intended. We can include that make sense. So even for now just so that we can observe what's coming out from the grouping and what we expect in the keywords. We're not going to intersperse the topics with the manual markers that have been created or not. \n",
      "After Merging 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16': [], '7': [], '0': [(4178, 4), (1420, 4), (2404, 4), (5688, 4), (4882, 4), (2054, 4), (1879, 3), (3657, 3), (6496, 2), (623, 2), (2267, 2), (5249, 2), (1012, 2), (1440, 2), (1694, 2)], '12': [], '17': [(4627, 6), (511, 3), (1923, 3)], '20': [], '1': [(1818, 2)], '24': [(2333, 4), (358, 3), (5249, 2), (3282, 2), (852, 2), (5564, 2), (3001, 2), (1083, 2), (5501, 2), (1420, 2), (5096, 2), (1775, 2)], '9': [], '26': [], '18': [(2613, 3), (5249, 2), (3216, 2)], '25': [(2613, 2), (5941, 2)], '22': [(4865, 3), (2404, 3), (2613, 2), (3175, 2), (4594, 2), (2850, 2), (239, 2), (6235, 2), (1026, 2), (4055, 2), (5824, 2)], '19': [(5059, 2), (5299, 2)], '10': [], '2': [(2613, 3), (5030, 2), (3773, 2), (5132, 2), (5655, 2), (4719, 2), (852, 2), (4941, 2)], '3': [(960, 6), (2613, 6), (3987, 6), (313, 6), (529, 6), (4395, 5), (70, 4), (4038, 3), (2435, 3), (5592, 3), (3655, 2), (241, 2), (709, 2), (131, 2)], '11': [(1420, 2), (70, 2), (3157, 2), (2054, 2), (886, 2), (3867, 2), (1342, 2), (66, 2)], '21': [], '4': [(511, 3), (313, 3), (4921, 3), (2613, 3), (4194, 3), (2435, 3), (1203, 2), (4038, 2), (631, 2), (529, 2)], '14': [], '8': [], '23': [(1775, 2)], '5': [(4459, 4), (3675, 3), (1297, 3), (1775, 3), (103, 2), (201, 2), (139, 2), (2097, 2), (763, 2), (239, 2), (2613, 2)], '6': [(313, 2), (1203, 2), (2613, 2), (70, 2), (2435, 2), (529, 2), (4038, 2), (131, 2), (241, 2), (1401, 2)], '15': [], '13': [(449, 2), (440, 2), (1051, 2), (2489, 2)]}\n",
      "writing the gc and lc update.\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "ORG\n",
      "Counter({'ORG': 1, 'O': 0, 'MISC': 0, 'PER': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "MISC\n",
      "Counter({'MISC': 1, 'O': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "MISC\n",
      "Counter({'MISC': 1, 'O': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "PER\n",
      "Counter({'PER': 1, 'O': 0, 'MISC': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "ORG\n",
      "Counter({'ORG': 1, 'O': 0, 'MISC': 0, 'PER': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "LOC\n",
      "Counter({'LOC': 1, 'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "MISC\n",
      "Counter({'MISC': 1, 'O': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "O\n",
      "Counter({'O': 1, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "PER\n",
      "Counter({'PER': 1, 'O': 0, 'MISC': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "ORG\n",
      "Counter({'ORG': 1, 'O': 0, 'MISC': 0, 'PER': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "ORG\n",
      "Counter({'ORG': 1, 'O': 0, 'MISC': 0, 'PER': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "PER\n",
      "Counter({'PER': 1, 'O': 0, 'MISC': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "ORG\n",
      "Counter({'ORG': 1, 'O': 0, 'MISC': 0, 'PER': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "PER\n",
      "Counter({'PER': 1, 'O': 0, 'MISC': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "PER\n",
      "Counter({'PER': 1, 'O': 0, 'MISC': 0, 'ORG': 0, 'LOC': 0})\n",
      "Counter({'O': 0, 'MISC': 0, 'PER': 0, 'ORG': 0, 'LOC': 0})\n",
      "ORG\n",
      "Counter({'ORG': 1, 'O': 0, 'MISC': 0, 'PER': 0, 'LOC': 0})\n",
      "updating community artifacts\n",
      "<ETHER>-Jason\n",
      "<ETHER>-Ramona Richard\n",
      "<ETHER>-Mind Mind\n",
      "<ETHER>-Mla Sink\n",
      "<ETHER>-Engineering Channel\n",
      "<ETHER>-Secibds\n",
      "<ETHER>-Apa Github\n"
     ]
    }
   ],
   "source": [
    "# test it on a meeting\n",
    "entity_sent_dict = []\n",
    "#test_set = ['sync_eng_2020_01_03.txt', 'sync_eng_2020_01_08.txt']\n",
    "test_set = os.listdir(\"../recency_dataset/ai/\")\n",
    "artifacts_dir = \"/home/ray__/ssd/minds/\" + domain + \"/recency_cw/\"\n",
    "\n",
    "for file in test_set:\n",
    "    with open(\"../recency_dataset/ai/\"+file,'rb') as f:\n",
    "        request = json.load(f)\n",
    "        if isinstance(request, str):\n",
    "            request = json.loads(request)\n",
    "\n",
    "    group, group_ent_map_rank_lc, group_ent_map_rank_gc, gc, lc, group_ent_map_filtered, group_ent = computing_groups(request, artifacts_dir)\n",
    "    filtered_group = get_filtered_groups(group)\n",
    "    ent_sent_dict, entity_dict = update_mind_artifacts(group, artifacts_dir)\n",
    "    entity_sent_dict.append(ent_sent_dict)\n",
    "    #entity_sent_dict.append(update_mind_artifacts(filtered_group, artifacts_dir))\n",
    "    com_map, gc, lc = recency_util_post.get_entity_artifacts(artifacts_dir)\n",
    "    fv_new, fv = recency_util_post.get_common_entities(com_map, entity_dict)\n",
    "    if fv!={}:\n",
    "        #fv_new = dict([('<ETHER>-'+ent, entity_dict['<ETHER>-'+ent]) for ent in ent_sent_dict.keys() if ent not in fv and '<ETHER>-'+ent in entity_dict.keys()])\n",
    "        new_ent_placement = recency_util_post.get_most_similar_entities(fv_new, fv)\n",
    "        agreed_communities = recency_util_post.get_agreable_communities(new_ent_placement, com_map)\n",
    "        com_map, gc, lc = recency_util_post.update_communitiy_artifacts(agreed_communities, com_map, gc, lc)\n",
    "    recency_util_post.dump_community_artifacts(com_map, gc, lc, entity_dict, artifacts_dir)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T08:51:31.449577Z",
     "start_time": "2020-03-05T08:51:31.339296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupid:   11   ['Data', 'School', 'AI', 'High', 'Turing', 'Program', 'TTS', '<ETHER>-Data', 'Mario', 'TTS', 'Turing', 'School', 'AI', 'Data', '<ETHER>-Data', 'High', 'Program', 'Mario'] \n",
      "\n",
      "\n",
      "A major thing which I wanted a clean program that I don't see any major which one. Because of linguistic similarities and and the shorter sentence by ask because when somebody gives really high school because we are relying completely on passing similarity. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   33   ['Key', 'Value', 'In', 'Key', 'Value', 'In'] \n",
      "\n",
      "\n",
      "The way I'm playing currently with key face levels imperative.  I'm not sure hot where to plug that in or whether it would be helpful. But based on my like cutest situated esterday key phrase in value of the variable. Okay, so I think we can make use of them. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   6   ['Boolean', 'XOR', 'Name', 'Key', 'Register', 'Qlik', 'Classifier', 'C', 'R', 'System', 'XOR', 'C', 'Classifier', 'Boolean', 'Linear', 'System', 'Confusion Matrix', 'Linear Regression', 'Qlik', 'RMSE', '<ETHER>-English', 'English', 'Computers', 'Name', 'Boolean', '<ETHER>-Kubernetes', 'XOR', 'System', 'Alexa', 'C'] \n",
      "\n",
      "\n",
      "Yeah, we should be if it's if it if the the the compass is consistent we should get it it did it again depends on what we are trying to compare right so we can compare every keep this to every other key face.  Depends. Yeah, so even if even within the context so I mean if you compare to people this, is that okay, is that okay? Even if the composition is nicely simple version are you okay for the for the whole system in the whole process took two to base your decision on a comparison that's not really reliable like like you get a similarity score, but what if you compare two cases are not related and then this similar is not Really interpretable this one question. Just think of it. I mean maybe when you start when you start testing or if You observe something like this just I will be just just because everything Okay and morning session can they were also discussing the word this is what the document so as you pointed out of a spirit like when I say I look I've been staring at that for 10-15 minutes you pointed out that means that I mean I'm not able to infer anything and not so isn't that isn't that problem in general not with the approach but with the hole? whole notion of summaries that we are thinking \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   17   [] \n",
      "\n",
      "\n",
      "But that is by actually wanted to move from segment level to something which is more understandable called a stalker alert somebody but if that's not working then we have to think of something else to make it work. you know the idea of I think I think \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   21   [] \n",
      "\n",
      "\n",
      "CB if we are trying if yes, if we as adults are starting to understand what what those people's mean knowing the context of the meeting isn't that bad should be should we think of should we should be restored we are trying to solve. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   12   ['Key', 'Frame', 'Key', 'Frame', 'Key', 'Frame'] \n",
      "\n",
      "\n",
      "This is this is more and more to think as we go if you have any thoughts on Lexus and for suggesting that if we can filter out. If you insert showing the key phrase is right, if we have a way to get the the truly reflecting sentences of the meeting. We should we should be able to show only the sentences instead of the the key phrase or alternatively take the key phrases and frame whole summary that that these key phrases are trying to address. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   29   [] \n",
      "\n",
      "\n",
      "But in most of our time get transcript is really bad when we just need to help accessing only he and used and I think it's okay. But if it's General then but what if what if we what if you don't? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   30   ['Ground'] \n",
      "\n",
      "\n",
      "Because that's all the things that are in our control is giving others are fixed or ideal. Right? So if we start thinking about it, then we are deviating like like how we move from testing on Google instead of bleep ground. Same thing here. We will if we if we give good results on E, Nu s what if that's enough \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   13   ['English', 'Bigrams', 'Word', 'Grove', 'Name', 'Names', 'Context', 'BoW', '<ETHER>-X', 'YC', 'New York Times', 'CTO', 'Machine', 'Holmes', 'Life', 'Humanity', 'AI', 'CA', 'YC', 'America'] \n",
      "\n",
      "\n",
      "And one more to that even if it's not sentences, I think for a single group or even single with them we can still show like two or three phases position that word reef. He faces are the ones which could explain the whole context. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   31   ['NLTK', 'Translation', 'Language', 'Entity', 'Key', 'NLP', 'Natural Language Processing', 'RNNs', 'Mind', 'Cluster', 'Mind', 'Translation', 'GANs', 'Language', 'RNNs', 'NLP', 'Generative', 'Natural Language Processing', 'Key', 'API', 'Language', 'Entity', 'Translation', 'NLP', 'Natural Language Processing', 'NLTK', 'JANs', 'Mind', 'API', 'RNNs', 'Translation', 'Mind', 'Language', 'NLP', 'GANs', 'RNNs', 'Natural Language Processing', 'NLTK', 'Entity', 'API'] \n",
      "\n",
      "\n",
      "Let me sew a that a that a sentence all the key phrases self-contained give them that are good enough. I mean actually essentially a problem remains a but we are just trying to take more control of water goes into the summer.  We do that we come to that later. But let's let's take let's will keep thinking about it as we as we work on everything else that we currently working on. So essentially between you and archean. Can you can you can you work together on on on the key phrases identities and then connect entities for the sake of my key phrases entities and then and then the sentence embeddings whatever or the sake of summarization and try and start trying to connect these these things so that we are barely working on the mind bringing in the my notion also in form of entity gloves.  I'm just trying to say that I'm just putting this on cold water. We have fun cooking signals unless it's a bugger. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   22   [] \n",
      "\n",
      "\n",
      "Yeah, let's click. Let's let's freeze on the let us assume that this is the best possible grouping that we have and then we're away with the other thing and then let it slip reflect in the group is our filter of the loops. Yeah, but you get what if what if these are the best groups that we could do and then we hold on to it and then we improve everything that surrounds me. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   16   ['String', '<ETHER>-Internet', 'Entity', 'Key', 'Good', 'Internet', 'Board', 'Trust', 'ML', 'Statistics', '<ETHER>-Internet', 'String', 'Entity', 'Key', 'Trust', 'Board', 'ML', 'Internet', 'Good', 'AI', 'String', 'Entity', 'Key', 'Trust', 'Good', 'Board', 'ML', '<ETHER>-Internet', 'AI', 'Internet', 'Internet', 'Board', 'AI', 'Good', 'Trust', 'Entity', 'ML', 'Statistics', 'String', 'Machine Learning', 'Entity', 'String', 'Good', 'ML', 'Statistics', 'Trust', 'Key', 'AI', 'Machine Learning', 'Internet'] \n",
      "\n",
      "\n",
      "Mexico so I think maybe we should look at the entities and key phrases together instead of trying to separate them because they in the in the in the in the body called segments we get them together. So maybe we should be should also try to map them instead of instead of looking at them separately. So if I if I may if I fail to get started I would look at it this way see if you have Entities, we have the known entities for which we have represented things, right? And then we have also see I've also observe the victims you can test it as you do so a known entity if it is detected as an entity. I can safely use its representation. But if it's a known entity if I detected through the string match then then the representations are inconsistent.  And eventually marrying them to Pieces because entities are not that common. How do we associate? Maybe is it is it a good idea to think that we always try to associate key phrases with the known or unknown entities somehow? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   34   ['Graph', 'Key', 'Time', 'Long', 'Backgammon'] \n",
      "\n",
      "\n",
      "Be be did that long time ago right like two weeks ago with this playing with key face is getting he faced many, please out of the sink meetings and then either do substring match of string match with the key phases present in the MVD graph. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   32   ['<ETHER>-II', '<ETHER>-Context', 'Hmm', '<ETHER>-GP', 'Map', 'BBC', 'French', 'Mario Kart', 'English', 'API', 'Map', 'API', 'App', '<ETHER>-Context', 'Android', 'OS', 'NetworkX', 'Google Maps', 'Graph', 'Longitude', '<ETHER>-L', '<ETHER>-GP', 'X', 'Blue', 'Dot', 'Map', 'Sklearn', 'Euclidean', 'Classification', '<ETHER>-Context', 'BI', 'Data', 'News', 'Google Analytics', 'Wikipedia', 'Quora', 'KPIs', 'Names', 'ML', 'Language', 'Map', 'Dot', 'NetworkX', 'Domain', 'Python', 'Sklearn', 'Graph', 'Github', 'Longitude', 'Groupby', 'NLU', 'Language', 'Matrix', 'Action', 'Problem', 'DL', 'Age', 'PP', 'Wikipedia', 'Markov', 'David', 'Action', 'Real World', 'English', 'French', '<ETHER>-Context', 'Language', 'Hmm', 'Alexa', 'Searle'] \n",
      "\n",
      "\n",
      "Tired and even I said neighboring and it is what it is is like if you have some segments which talks about something like a context with Docker or something, but there is no proper entities percent and therefore is trying to say what this is actually talking about. So we take this and we know we are putting an idol station that entities are more relay ability faces. Now we can pick she faces the try to find wherever it is present in the graph and now Even if it's present, then we actually wanted to see all its connections. Like what are the more like Mayberry?  Okay, so if that's the case I do you think it's it's ideal if you start with the soft with the actual domain data instead of ether data again, this is this kind of denoising current problem. We don't want to start with the with the potentially noisy candidates like like a sink calls instead. We'll start on the domain domain data and then we'll just some copper in u.s. Spot. Cast and then see if you are able to establish these things. And we obviously we are assuming that we will only start with the known entities kind of problems and then we'll take it to the unknown ones or make the fall back so that if you don't have so can we can we can we start with that? Let's not let's not look at the let's not look at improving our sing calls until we until we conclude on this Idol problems occur.  I could have you like have you any feeling that it is a bit noisy the graph. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   0   ['Post', 'Data', 'Domain', 'Graph', 'Engineering', 'Edge', 'Key', 'Ether', 'Entity', 'Graph', 'Post', 'Data', 'Edge', 'Key', 'Domain', 'Ether', 'Entity', 'Engineering', 'Post', 'Graph', 'Data', 'Domain', 'Edge', 'Ether', 'Engineering', 'Key', 'Entity', 'Post', 'Ether', 'Key', 'Domain', 'Data', 'Engineering', 'Graph', 'Entity', 'Edge'] \n",
      "\n",
      "\n",
      "Then started made it nicer because I end up in the if you are taking if you talk about a secret, right? I didn't remove it. I didn't remove any entities that are even occurring only ones. I can I can safely remove them without any doubt from that domain data not from The Ether engineering because that get reinforced.  Is it possible to be aggressive while taking the entities and faces? Yeah, that's up to you. That's up to you to you. So think of it as a source and then you take whatever you want because everything is captured in the node and Edge properties of some of the data except while you're populating the entity graph.  Okay. Why should I why should why should we miss the best information of the source itself directly when I can always isolate.  I didn't I actually didn't Focus much because I know they're they're way more noise here. Yes, if you oh, even if they are, even if they're noisy in the graph, so what what bothers you how should what do you think should be the post processing step that we took a wash it? What do you think should be the condition to include or not include the key phrase in the \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   14   ['Key', 'Time'] \n",
      "\n",
      "\n",
      "If there is any of that and then also, I'll go back and see if what patterns are used for the key phrases if that's if that's sounding a little of the track since I did it last time then I will change. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   1   ['Graph', 'Entity', 'Domain', 'Model', 'Super', 'Path', 'MNIST', 'Engineering', 'Bokeh', 'Geoffrey Hinton', 'Model', 'Domain', 'MNIST', 'Graph', 'Bokeh', 'Super', 'Engineering', 'Entity', 'Path', 'Decision Tree', 'Software', 'Super', 'Graph', 'Engineering', 'Entity', 'Domain', 'Geoffrey Hinton', 'Bokeh', 'Google Brain Team', 'Path', 'Software', 'Super', 'Bokeh', 'Model', 'Graph', 'Domain', 'Entity', 'MNIST', 'Google Brain Team', 'Engineering', 'Software', 'Engineering', 'Bokeh', 'Graph', 'Domain', 'MNIST', 'Super', 'Google Brain Team', 'Model', 'Entity', 'Super', 'Model', 'Software', 'Graph', 'Engineering', 'Domain', 'MNIST', 'Geoffrey Hinton', 'Decision Tree', 'Bokeh', 'MNIST', 'Model', 'Bokeh', 'Graph', 'Domain', 'Super', 'Engineering', 'Software', 'Decision Tree', 'Path'] \n",
      "\n",
      "\n",
      "Not even the verb base because that will blow up the grass. Yeah, but we need to be nice if that's there's no doubt about it for now. What I'll do is I'll Focus only on the entity's yes, and then and then see how I can score and denies it as you as you work on the I think you and Arjun can align and then finalize on the model that you guys want to use for no super soft engineering and then and then we'll think of the second domain participate will not will not talk about either till we have this fixed.  So if it is software engineering even the even the entity graph is there so the one that's not either we're in the same path. So and I think your then if its offerings netting you are using this use the same model that you're pointing is today. Yeah said Rosie.  I don't see four plus one on the software engineering. Yeah, it's okay if it's working out and then they're no they're not keep it on that right? No second thought Sturgeon Bay.  got it, but but this is a different data set. So which means you're not do not build up its okay fine for now. I think that's fine. But it's I think we already discussed about this. Right and we will always have like two or three snapshots for the same model. And this was done before this discussion. I can guess why?  Yeah, maybe is worth what to leave? I don't think you need to do any in to put any effort to train the modified. So just leave them all trading over the weekend. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   7   ['Good', 'Good'] \n",
      "\n",
      "\n",
      "that's a good idea take we no one is waiting for the  So so we we are clear on this set. So let's I think maybe we can we can we came If anyone among us updated Among Us is on this and then we'll see how how we proceed on this and it is pesky phrases plus some ways, okay. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   23   [] \n",
      "\n",
      "\n",
      "Up early should be also look into merging the somebody's coming. Yeah, I think this eventually will go there right? So yeah I missed.  for in that session quantity of so we have seen places where the summer is the group should have been merged which we don't have control of but \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   35   ['ML', 'Ml', 'ML', 'Ml'] \n",
      "\n",
      "\n",
      "It's almost like the whole topic split into two very can say that this talks about something different and this talks about something different. You can actually see a very clearly in the ml walk through which you get. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   24   ['Community', 'Algorithm'] \n",
      "\n",
      "\n",
      "You can still group if you want but my question was whether we want to do.  Yeah, we have to we have to have okay whether we want to do is situational but we would definitely need a way to group them or group should be in our control not enhance of a very greedy algorithm like Community detection. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   18   ['GeoPandas', 'Name', 'Ggplot2', 'JSON', 'Dictionaries', 'Excel', 'Sine', 'IMDb', 'Register', 'SPARQL', '<ETHER>-English', 'Shell', 'XOR', 'Wekinator', 'SPARQL', 'Name', 'English', 'R', 'Alexa', 'JSON', 'GeoPandas', 'Kaggle', 'Ggplot2', 'Scala', 'Excel', 'Register', 'Data Lake', 'Repo', 'Sine', 'Python'] \n",
      "\n",
      "\n",
      "I'm not sure but but we can debate on number of segments that you want to show right so now okay, let's simplify. Sorry.  Because separate out the quality with the experience then maybe we are a little off track so we should be afraid to look at them together, right?  Just because that is of them is good. There is no guarantee that it is. It is good on the use as a simple item if it makes sense, but I'm just thinking it turn on those lines simple. I'm just looking at the MLA sink where with few exceptions. I mean, there's aggregation fine. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   2   [] \n",
      "\n",
      "\n",
      "For one thing. I wanted to point this like I don't because I that the for the animal calls the community in itself isn't good. I'm not sure why whether it's something that the model or the way we speak.  If you have seen that if you have observed most of these conversations that we have either in sync calls. Are not very exhaustive. They're clearly separable. Whereas in this specific conversation. I don't know maybe the closest thing would be comparing this to the platform was thinks that sing that you have seen. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   27   ['ML', 'Medium', 'Model', 'Ml', 'Camera', 'Medium', 'ML', 'Camera', 'Ml', 'Model'] \n",
      "\n",
      "\n",
      "Even Platformers Inquisition that but I think we can drink one ml model and see how it performs.  I see medium particle reaches scope camera medium article focused intervention. Yeah. Okay plus if I want to see where the \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   8   ['Nathan'] \n",
      "\n",
      "\n",
      "Amazing the same calls. There are cases where at least I am being dumb here. And then I'm seeing only the people who are group. It just grew me one E & vamsi and three shank me Nathan Ramsey. Maybe that makes sense.  If I just go ahead go where that I'm not sure if that's still okay with us or not. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   25   ['Case', 'HR', 'Key', 'Entity', 'Mind', 'HR', 'Entity', 'Mind', 'Key', 'Case'] \n",
      "\n",
      "\n",
      "Yeah, that's good. I mean on the same lines. We thought we should also be able to affect keep the group's fixed like as they are today and then we try to if we have more control if you have more control of its case keyframes and everything we should be able to be should have a mechanism that is definitely needed. Whether we use it or not is a different thing. We should have a mechanism to a the group or split maybe split is fine. Like is like likely talking if Is a segment where there are see a CD and HR and if there's an essay mind if entity graph says HR entities and and key phrases are unrelated. We can actually take take them away that means even even then your group looks homogeneous. It's not mix. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   28   ['Graph'] \n",
      "\n",
      "\n",
      "Probably if you're talking about doing it via the communities then I'm not sure. Maybe it'll be good or bad.  Yep, one more than on communities, but not on the same graph. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   15   ['EDA', 'First', 'AlphaGo', 'EDA', 'First', 'AlphaGo', 'EDA', 'First', 'AlphaGo'] \n",
      "\n",
      "\n",
      "Ten twenty first time we just go based on sentences. So I really want to try this probe is hierarchy can just spread the topics, you know sentences it would be groups So based on group similarity would try to merge  I really could just be each group would have all the sentences and then I would take all the most influence sentence the among them and then while comparing groups similarity, I would take the inference is composition.  Well, then that's essentially taking one candidate from each group one candidate sentence from each group and then comparing.  How does that work? If you if you have any rough numbers if I have like 30 sentences like okay, if I have in my first step if I have 20 groups, what would that Translate to? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   3   [] \n",
      "\n",
      "\n",
      "That's not possible because whenever there is some because they care about them. Okay, at least even one needs to be connected together. Yeah.  Going to say is if there's only one or two connections, that's as good as having not taken a position right as good as that one.  It won't do another connection like it would be FC. Elsie the not Center  Terror example that you think can demonstrate what you're trying to do whatever you think is the closest distance  Fine whenever if you think that's that's something that we can control we can you can look at it. Just just share some two or three testers in that. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   26   ['Filter', 'Filter', 'Filter'] \n",
      "\n",
      "\n",
      "So what I was saying was like for example, if you take the ml seeing right there are like conversation with split into like two or three groups. So if you assume that there is no like in a problem with the model or something. The community does well when it comes to splitting into topics and subtopics. Maybe the second filter should instead of again grouping them or come doing community on them. Like a group much them based on some other metrics or something. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   9   [] \n",
      "\n",
      "\n",
      "We are trying to improve this idea. So instead of this jumping at the end and trying to fix it. We can start from first and see where it leads us. And then if it is needed again, we can try to fix them. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   36   ['KPIs', 'ISO', 'Jane', 'Database', 'Ie', 'Harvard Business Review', 'History', 'Names', 'Google', 'American'] \n",
      "\n",
      "\n",
      "Rarity is not that we are not right into the technical quality hair, but from the use cases, we need to find a way to infuse the mines in the whole summary process and try to clean them up a bit, right? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   10   ['Sam Altman', 'Engineering', 'Moon', 'AGI', 'Providence', 'Smith', 'Earth', 'ASI', 'AI', 'Lee', 'C++', 'GitHub Repo', 'Python', 'Git', 'Linux', 'App', 'Src', 'Markov', 'MobileNets', 'Matrix'] \n",
      "\n",
      "\n",
      "It is a realistic few High School right mouthing of final goals. If it's anyway implementable we can just put it fast or else we will just proceed with whatever we think of Anthony's key places on using it after that. You can come back to this. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   19   ['Word', '<ETHER>-Dog', 'NER', 'Count', 'Dog', 'URL', 'Softmax', 'Ukraine', 'Fantasy', 'F1', 'URL', 'ImageDataGenerator', 'Bird', 'F1', 'KPIs', 'Python', 'Ukraine', 'NER', 'Neural Network', 'Postal Code'] \n",
      "\n",
      "\n",
      "The even even which are noisy we can actually filter them out by looking at the how how many words are there in that subject or subjects word count. We can filter them out with bird cam rather than checking the correct account. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   4   ['Great', 'English', '<ETHER>-English', 'Love', '<ETHER>-M', 'X', 'Side', 'Haskell', 'NLTK', 'Bing Lexicon', 'Popper', 'Classical Mechanics', 'Darwin', 'AGI', 'Science', 'Galileo', 'Medicine', 'Hanson', 'Hollywood', 'Artificial Intelligence', 'NLTK', 'Great', 'English', 'NLP', 'FP', 'Natural Language Toolkit', 'Side', '<ETHER>-English', 'Love', 'F1', 'Great', 'Model 2', 'Love', 'X', 'R', 'X-axis', 'Twitter', 'FPR', '<ETHER>-U.S', 'F1', 'Model 2', 'F1', 'FP', 'FPR', 'ROC', 'AUC', 'TPR', 'ROC-AUC', 'ROC Curve', 'ProPublica', 'English', '<ETHER>-English', 'Great', 'NLTK', 'NLP', 'Love', 'Natural Language Toolkit', 'En', 'Side', 'Haskell', '<ETHER>-English', '<ETHER>-M', 'Great', 'Love', '<ETHER>-Amazon', 'English', 'Hollywood', 'Artificial Intelligence', 'AI', '<ETHER>-U.S'] \n",
      "\n",
      "\n",
      "Then I have seen that we are missing a as an even if we want to filter it out. We should make it make it less greater than for actually a greater than 3 so that we can include because there are a lot of  Yesterday night if you think that's cool, if you think the positive coverage is good for 3/4 is just a number because I thought any useful noun would be at least four letter for letter thing. Is that simple a there's no scientific reasoning for that. It's only business.  Also on the other side NLT case very bad at the non detection so it can it can give you a wide range of nouns useless nouns like by and everything. Okay. Do one thing simple why should we even debate on which which number is correct? Just just make it if you want to get rid of it. Just get rid of it and show the cause false positives and true positives if you want to increase or reduce it to do the same thing and do the show The False politician true positives.  And secondly is that even if false positives are coming up? I guess we can filter it out using other.  If you if you have if you can restrict the number of grammar rules to say one or two for that, that's absolutely fine. But if you're going to keep adding that maybe that's not fine.  Yeah, just just a little bit just say that I'm back. What? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   20   [] \n",
      "\n",
      "\n",
      "Study session is there maybe you would have shared it. But do you have you have a issue where you outline how you're doing the recommendation budget thing, right? Yeah. Any repo can you just bring it to me? I just want to check that. I am not I'll push. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:   5   ['List', 'Query', 'Word', 'Key', 'Next', 'Entity', 'D', 'MRI'] \n",
      "\n",
      "\n",
      "Basically flow right now is job. So you have you have so from D graphite query for all the user key phrases from last ten meetings.  Reading has in not by date, but it's like sorted by degraaf's minute. So we some for every user we get like list of key phrases, right? So these formed a reference key phrase against which we do comparison whenever we get a segment or something.  So now all of these key phrases are vectorized but we don't but I'm not doing the word by word similar to comparison but instead bring approximate similarity. So basically placing So say if you take our timeline chapters, so this will be the input key phrases. They will be compared against the reference key phrase of all the users and okay, and we get approximate similarity of users closeness to this particular intersection.  And then you pick those five users key phrases and now you do proper cosine similar.  So they're not that so out of sorry. I look at the four top fi users out of 19 red. So out of the stop for usually 3 of them are correct and two of them are random.  Yeah, so it is definitely noisy. So I have to like Dina is them and use a like maybe run rerun The Entity extractor on all the segments that is like the next step.  So if the first part works at least the first out of top five users at least three or four of them come correctly most of the time then proceed to the next. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for groupid, ent_list in group_ent.items():\n",
    "    print (\"Groupid:  \", groupid, \" \", [e for e,s in ent_list], \"\\n\\n\")\n",
    "    print (\" \".join([seg[\"originalText\"] for seg in group[groupid]]))\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T08:52:42.968064Z",
     "start_time": "2020-03-05T08:52:42.874959Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "GroupRank:  1  GroupId:   32 \n",
      "\n",
      "\n",
      "Tired and even I said neighboring and it is what it is is like if you have some segments which talks about something like a context with Docker or something, but there is no proper entities percent and therefore is trying to say what this is actually talking about. So we take this and we know we are putting an idol station that entities are more relay ability faces. Now we can pick she faces the try to find wherever it is present in the graph and now Even if it's present, then we actually wanted to see all its connections. Like what are the more like Mayberry? \n",
      "\n",
      "Okay, so if that's the case I do you think it's it's ideal if you start with the soft with the actual domain data instead of ether data again, this is this kind of denoising current problem. We don't want to start with the with the potentially noisy candidates like like a sink calls instead. We'll start on the domain domain data and then we'll just some copper in u.s. Spot. Cast and then see if you are able to establish these things. And we obviously we are assuming that we will only start with the known entities kind of problems and then we'll take it to the unknown ones or make the fall back so that if you don't have so can we can we can we start with that? Let's not let's not look at the let's not look at improving our sing calls until we until we conclude on this Idol problems occur. \n",
      "\n",
      "I could have you like have you any feeling that it is a bit noisy the graph. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GroupRank:  2  GroupId:   16 \n",
      "\n",
      "\n",
      "Mexico so I think maybe we should look at the entities and key phrases together instead of trying to separate them because they in the in the in the in the body called segments we get them together. So maybe we should be should also try to map them instead of instead of looking at them separately. So if I if I may if I fail to get started I would look at it this way see if you have Entities, we have the known entities for which we have represented things, right? And then we have also see I've also observe the victims you can test it as you do so a known entity if it is detected as an entity. I can safely use its representation. But if it's a known entity if I detected through the string match then then the representations are inconsistent. \n",
      "\n",
      "And eventually marrying them to Pieces because entities are not that common. How do we associate? Maybe is it is it a good idea to think that we always try to associate key phrases with the known or unknown entities somehow? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GroupRank:  3  GroupId:   4 \n",
      "\n",
      "\n",
      "Then I have seen that we are missing a as an even if we want to filter it out. We should make it make it less greater than for actually a greater than 3 so that we can include because there are a lot of \n",
      "\n",
      "Yesterday night if you think that's cool, if you think the positive coverage is good for 3/4 is just a number because I thought any useful noun would be at least four letter for letter thing. Is that simple a there's no scientific reasoning for that. It's only business. \n",
      "\n",
      "Also on the other side NLT case very bad at the non detection so it can it can give you a wide range of nouns useless nouns like by and everything. Okay. Do one thing simple why should we even debate on which which number is correct? Just just make it if you want to get rid of it. Just get rid of it and show the cause false positives and true positives if you want to increase or reduce it to do the same thing and do the show The False politician true positives. \n",
      "\n",
      "And secondly is that even if false positives are coming up? I guess we can filter it out using other. \n",
      "\n",
      "If you if you have if you can restrict the number of grammar rules to say one or two for that, that's absolutely fine. But if you're going to keep adding that maybe that's not fine. \n",
      "\n",
      "Yeah, just just a little bit just say that I'm back. What? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GroupRank:  4  GroupId:   18 \n",
      "\n",
      "\n",
      "I'm not sure but but we can debate on number of segments that you want to show right so now okay, let's simplify. Sorry. \n",
      "\n",
      "Because separate out the quality with the experience then maybe we are a little off track so we should be afraid to look at them together, right? \n",
      "\n",
      "Just because that is of them is good. There is no guarantee that it is. It is good on the use as a simple item if it makes sense, but I'm just thinking it turn on those lines simple. I'm just looking at the MLA sink where with few exceptions. I mean, there's aggregation fine. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GroupRank:  5  GroupId:   33 \n",
      "\n",
      "\n",
      "The way I'm playing currently with key face levels imperative. \n",
      "\n",
      "I'm not sure hot where to plug that in or whether it would be helpful. But based on my like cutest situated esterday key phrase in value of the variable. Okay, so I think we can make use of them. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (groupid, groupobj) in enumerate(list(filtered_group.items())[:5]):\n",
    "#     print (\"\\n\\nGroupRank: \", index+1, \" GroupId:  \", groupid , \"  Agreed on Communities: \" ,list(map(lambda kv:kv[0], group_ent_map_filtered[groupid])), \"\\n\\n\")\n",
    "    print (\"\\n\\nGroupRank: \", index+1, \" GroupId:  \", groupid , \"\\n\\n\")\n",
    "    seg_list = [seg[\"originalText\"] for seg in groupobj]\n",
    "    print (*seg_list, sep=\"\\n\\n\")\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T09:16:10.135562Z",
     "start_time": "2020-03-02T09:16:10.050515Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "GroupRank:  1  GroupId:   7 \n",
      "\n",
      "\n",
      "It's on the website. Like what do we do? Like we have a for example, the the theory we have is that when there are more than there are some n number of simultaneous page views. We are seeing those errors. Question is what level of traffic can be sustained rate right now, right? So the fatal error that we would see in PHP are no more once it increase the memory allocation on Locker to about to the max of what the cv5 machine provides which is 2.5 GB is Preservation and Max allocations to confine minimum resolution is 1 GB. So that's pretty much solving that class not found exception and Communication. So the next thing I did was I ran if you click on current usage tests bench tests with a sustained time period five minutes. So thousand requests per minute consistent energy coming in five minute period Sarkozy results success ratio, there was 17% 17 percent success. So between 500 finer tools fine arteries, but no fatal levels just that. System was not able to handle the load. So one thing we should see is if we can if it's possible. So this is redundancy may or may not help I mean, but that's in a very expensive given the machine size and how much traffic will be giving for that if it's possible to separate the static content like the static initial website like the careers or the main lips their page from Um the woocommerce part then and deploy that independent link that is one way to see that is true. She got the water playing tennis and I don't do any work on the website. \n",
      "\n",
      "Because there's so many other things in the product we have to do and I want to spend like another week or two and the website is right. So I want to get it to a reasonable stability where at least 10 to 15 simultaneous web used page views and work and everything will work. Okay. All right. So in that case, let's see what how we are doing with the current memory size and then we even still running into issues will go to college. So I so I graduated a gradual test. So I started with with 60 then 120 120 also requests per minute that means \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GroupRank:  2  GroupId:   13 \n",
      "\n",
      "\n",
      "Right, let him do this test just to show that we don't go back and visit transcript once and for all we know there is solid, right? Okay. \n",
      "\n",
      "The pause and play back cache partition, but this is remaining the ready to cast thing so using the socket and yeah till we get the event recording a sudden showing The View. \n",
      "\n",
      "Well, so that Franklin kit can test and Report any box and I have some PR comments to it. This will take those comments. It is the way and then I can also do this. This will be a small change the refresh the channel list and if you don't hang up, so right away. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GroupRank:  3  GroupId:   2 \n",
      "\n",
      "\n",
      "Yeah on the back key words from last week. We have a we have this entity and key press graph the afar at least specifically detailed engineering channel. So with that shank is going to put that into the FIFA service and then see how how it is performing with respect to filtration. I just tested it offline. So it has predominantly removed. One time occurring or bad transcripts that happens within a single meeting. But but one in rare occasions, what's happening is there are cases where you work consistently spelled incorrectly across matings. So in that case what happens is they come as a they come as a usual usable knows that we cannot filter with the current approach yet. But this has happened this is this is rare, but this is one flaw that I've seen with the Also has been we'll we'll figure out how to address those problems. But with the current graph we should be able to remove most of the sorry. I'm getting remove most of the bad transcripts that happens once or twice occasionally. \n",
      "\n",
      "Yeah, that would be good for me to understand is if you are having any benchmarks for this, right, so let's say that I have been calls that have happened for which we have keywords. Yeah, just with your offline work. If you can kind of share what how it looks after the you know filtration are useful so that we see for how well looks like you are. Yeah. \n",
      "\n",
      "So what I'll do is I'll then I'll take a few recent calls and try to filter out of line and then see what what was there earlier and then what is it? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GroupRank:  4  GroupId:   9 \n",
      "\n",
      "\n",
      "And on the before we go on to the recommended Watchers on the on the custom minds and aggressive communities. We I think we have last week day before we had mentioned about having this bad transcriptions in the model, right? So so Arjun had signed a new model with the GitHub calls, which is currently testing. So if it aligns with our current Community approach, we should also be should be able to proceed further with the custom mines also in the same way without any modifications to the way we currently do the domain mines. So that's still in that still in testing Arjun can update on the test once he has \n",
      "\n",
      "Okay. So by the way laughing, I will tell you funny things last night in my dream. I had a dream where one of the summary keywords us. Just hi. Go back to sleep after that. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GroupRank:  5  GroupId:   10 \n",
      "\n",
      "\n",
      "Also, I am thanking her tested like the router changes and a performance changes in simulator on once like we are the okay with the cast changes. I will merge those changes to this crunched and then I can raise a pier and regarding the cast pinning view. I am doing that so Because as like Karthik suggested will not rebase and will merge from Ab c-- Upstream. So I'll also update like the latest code from jitsi the first layer effects like a couple of pots and yeah, I'll create a PR for that today. Like I'll generate the SDK which it seizes the after the changes I will raise up there and then maybe we can test after giving a bit. \n",
      "\n",
      "Okay, what you can do deep is first try to get the pinning changes done. Yeah, right. Yeah with the existing build, right so that caused a proceedings and then you can work on other words. \n",
      "\n",
      "Button controls that we were working on or these done or still. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (groupid, groupobj) in enumerate(list(filtered_group.items())[:5]):\n",
    "#     print (\"\\n\\nGroupRank: \", index+1, \" GroupId:  \", groupid , \"  Agreed on Communities: \" ,list(map(lambda kv:kv[0], group_ent_map_filtered[groupid])), \"\\n\\n\")\n",
    "    print (\"\\n\\nGroupRank: \", index+1, \" GroupId:  \", groupid , \"\\n\\n\")\n",
    "    seg_list = [seg[\"originalText\"] for seg in groupobj]\n",
    "    print (*seg_list, sep=\"\\n\\n\")\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:26:30.258042Z",
     "start_time": "2020-02-27T12:26:30.197021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Application Programming Interface',\n",
       " 'Api Connect',\n",
       " 'Api Manager',\n",
       " 'Webservices',\n",
       " 'Http Apis',\n",
       " 'Representational State Transfer',\n",
       " 'Rest Architecture',\n",
       " 'Hateoas',\n",
       " 'Rest Apis',\n",
       " 'Rest Level 3',\n",
       " 'Web Apis',\n",
       " 'Http Protocol',\n",
       " 'Rest']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[1509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T08:53:07.487230Z",
     "start_time": "2020-03-05T08:53:05.278982Z"
    }
   },
   "outputs": [],
   "source": [
    "lc_copy = pickle.load(open(\"/home/ray__/ssd/minds/ai/recency_cw/lc.pkl\",\"rb\"))\n",
    "gc_copy = pickle.load(open(\"/home/ray__/ssd/minds/ai/recency_cw/gc.pkl\",\"rb\"))\n",
    "com_map_updated = pickle.load(open(\"/home/ray__/ssd/minds/ai/recency_cw/com_map.pkl\",\"rb\"))\n",
    "entity_updated = pickle.load(open(\"/home/ray__/ssd/minds/ai/recency_cw/entity.pkl\",\"rb\"))\n",
    "kp_entity_graph_updated = pickle.load(open(\"/home/ray__/ssd/minds/ai/recency_cw/kp_entity_graph.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T08:53:08.489120Z",
     "start_time": "2020-03-05T08:53:08.391892Z"
    }
   },
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for ent, com in com_map_updated.items():\n",
    "    if com in clusters.keys():\n",
    "        clusters[com].append(ent)\n",
    "    else:\n",
    "        clusters[com] = [ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T08:53:09.278180Z",
     "start_time": "2020-03-05T08:53:09.212735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2613, [2, 17, 29, 42, 17]),\n",
       " (999, [0, 6, 0, 5, 13]),\n",
       " (4242, [6, 0, 0, 0, 17]),\n",
       " (3655, [0, 0, 0, 4, 19]),\n",
       " (960, [12, 4, 0, 6, 0])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lc_copy.items(), key=lambda kv:sum(kv[1]), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T08:53:53.114666Z",
     "start_time": "2020-03-05T08:53:53.050418Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T08:32:54.810558Z",
     "start_time": "2020-02-23T08:32:54.742407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28, [91, 118, 80, 95, 84]),\n",
       " (11, [92, 18, 15, 24, 16]),\n",
       " (49, [56, 12, 13, 14, 18]),\n",
       " (33, [15, 14, 26, 24, 29]),\n",
       " (21, [21, 16, 3, 16, 25])]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lc_copy.items(), key=lambda kv: sum(kv[1]), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T09:55:11.582634Z",
     "start_time": "2020-02-25T09:55:11.511074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'<ETHER>-Ether Engineering' in entity_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T05:39:57.574741Z",
     "start_time": "2020-02-23T05:39:57.513176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{14: [17],\n",
       " 7: [16],\n",
       " 33: [34],\n",
       " 28: [89],\n",
       " 15: [4],\n",
       " 1: [19],\n",
       " 49: [19],\n",
       " 21: [19],\n",
       " 17: [3],\n",
       " 57: [13],\n",
       " 30: [2],\n",
       " 186: [2],\n",
       " 48: [11],\n",
       " 11: [57],\n",
       " 628: [2],\n",
       " 689: [2],\n",
       " 357: [4],\n",
       " 468: [2],\n",
       " 214: [2],\n",
       " 1201: [3],\n",
       " 510: [2],\n",
       " 602: [2],\n",
       " 3: [8],\n",
       " 527: [2],\n",
       " 768: [2]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T19:12:21.976206Z",
     "start_time": "2020-02-22T19:12:21.881919Z"
    }
   },
   "outputs": [],
   "source": [
    "added_entities = [ list(sent_dict.keys()) for sent_dict in entity_sent_dict]\n",
    "added_entities = [i for j in added_entities for i in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T14:27:20.500178Z",
     "start_time": "2020-02-25T14:27:12.201716Z"
    }
   },
   "outputs": [],
   "source": [
    "kp_entity_graph_cl = pickle.load(open(\"/home/ray__/ssd/minds/se/recency/kp_entity_graph.pkl\",\"rb\"))\n",
    "kp_entity_graph_df = pickle.load(open(\"/home/ray__/ssd/minds/se/recency_df_unpoluted/kp_entity_graph.pkl\",\"rb\"))\n",
    "com_map_updated = pickle.load(open(\"/home/ray__/ssd/minds/se/recency/com_map.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T14:44:22.891143Z",
     "start_time": "2020-02-25T14:44:21.756595Z"
    }
   },
   "outputs": [],
   "source": [
    "enriched_nodes = []\n",
    "for node in kp_entity_graph_cl.nodes():\n",
    "    \n",
    "    #if node in kp_entity_graph_df.nodes() and kp_entity_graph_cl.nodes[node] != kp_entity_graph_df.nodes[node] and kp_entity_graph_df.nodes[node]['node_type']=='entity':\n",
    "    if node not in kp_entity_graph_df.nodes() and kp_entity_graph_cl.nodes[node]['node_type']=='entity':\n",
    "        \n",
    "        enriched_nodes.append(\"<ETHER>-\"+node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T14:46:40.336509Z",
     "start_time": "2020-02-25T14:46:39.249487Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "G = nx.Graph()\n",
    "node_list = enriched_nodes\n",
    "for index1, nodea in enumerate(node_list):\n",
    "    for index2, nodeb in enumerate(node_list):\n",
    "        if index2 >= index1:\n",
    "            c_score = 1 - cosine(entity_dict[nodea], entity_dict[nodeb])\n",
    "            #if c_score>= outlier_score:\n",
    "            G.add_edge(nodea, nodeb, weight = c_score)\n",
    "    closest_connection_n = sorted(dict(G[nodea]).items(), key=lambda kv:kv[1][\"weight\"], reverse=True)\n",
    "    weights_n = list(map(lambda kv: (kv[1][\"weight\"]).tolist(), closest_connection_n))\n",
    "    q3 = np.percentile(weights_n, 75)\n",
    "    iqr = np.subtract(*np.percentile(weights_n, [75, 25]))\n",
    "    #outlier_score = q3 + (1.5 * iqr)\n",
    "    outlier_score = q3 + (1.5 * iqr)\n",
    "    for nodeb, param in dict(G[nodea]).items():\n",
    "        if param['weight']>=q3:\n",
    "            pass\n",
    "        else:\n",
    "            G.remove_edge(nodea, nodeb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T14:47:10.750210Z",
     "start_time": "2020-02-25T14:47:10.375898Z"
    }
   },
   "outputs": [],
   "source": [
    "from community import best_partition\n",
    "\n",
    "comm = best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T14:47:56.346313Z",
     "start_time": "2020-02-25T14:47:56.273250Z"
    }
   },
   "outputs": [],
   "source": [
    "clusters_cm = {}\n",
    "for ent, com in comm.items():\n",
    "    if com in clusters_cm.keys():\n",
    "        clusters_cm[com].append(ent)\n",
    "    else:\n",
    "        clusters_cm[com] = [ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T14:48:04.033277Z",
     "start_time": "2020-02-25T14:48:03.828238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['<ETHER>-Makonnen Karthik',\n",
       "  '<ETHER>-Lifeline',\n",
       "  '<ETHER>-Troy Times',\n",
       "  '<ETHER>-Karthik',\n",
       "  '<ETHER>-Janus',\n",
       "  '<ETHER>-Iframe',\n",
       "  '<ETHER>-AI',\n",
       "  '<ETHER>-Costas',\n",
       "  '<ETHER>-Dialogue Blog',\n",
       "  '<ETHER>-Going Away',\n",
       "  '<ETHER>-Trenton',\n",
       "  '<ETHER>-Decade',\n",
       "  '<ETHER>-Institute'],\n",
       " 1: ['<ETHER>-Bunnies',\n",
       "  '<ETHER>-Channel List',\n",
       "  '<ETHER>-Guys',\n",
       "  '<ETHER>-Frenchy',\n",
       "  '<ETHER>-Cardigan',\n",
       "  '<ETHER>-Tropicals',\n",
       "  '<ETHER>-Janice',\n",
       "  '<ETHER>-Broncos',\n",
       "  '<ETHER>-Society',\n",
       "  '<ETHER>-Mansion',\n",
       "  '<ETHER>-Dekada',\n",
       "  '<ETHER>-Aztecs',\n",
       "  '<ETHER>-New Link',\n",
       "  '<ETHER>-Alexis',\n",
       "  '<ETHER>-Php Summer Olympic',\n",
       "  '<ETHER>-Father Karthik',\n",
       "  '<ETHER>-Kings',\n",
       "  '<ETHER>-Chao Garden De Labarre the Della Della Person',\n",
       "  '<ETHER>-Latest',\n",
       "  '<ETHER>-Us Michelle',\n",
       "  '<ETHER>-Never Went Away',\n",
       "  '<ETHER>-Cho',\n",
       "  '<ETHER>-Fft',\n",
       "  '<ETHER>-Zeke',\n",
       "  '<ETHER>-Paschal',\n",
       "  '<ETHER>-Olivia',\n",
       "  '<ETHER>-Camera Dot',\n",
       "  '<ETHER>-Web Desktop',\n",
       "  '<ETHER>-Navigation'],\n",
       " 2: ['<ETHER>-Ether Engineering',\n",
       "  '<ETHER>-Psi',\n",
       "  '<ETHER>-Franklin',\n",
       "  '<ETHER>-Rod',\n",
       "  '<ETHER>-Graph Esther',\n",
       "  '<ETHER>-Sages',\n",
       "  '<ETHER>-Gothic',\n",
       "  '<ETHER>-General Eric',\n",
       "  '<ETHER>-Slack Graph Slack',\n",
       "  '<ETHER>-Entity Graph',\n",
       "  '<ETHER>-Sufi',\n",
       "  '<ETHER>-Sookie',\n",
       "  '<ETHER>-Channel China',\n",
       "  '<ETHER>-Coptic',\n",
       "  '<ETHER>-Beyonce',\n",
       "  '<ETHER>-Caldwells',\n",
       "  '<ETHER>-Yo',\n",
       "  '<ETHER>-Dancing',\n",
       "  '<ETHER>-Ab C--',\n",
       "  '<ETHER>-Karthika',\n",
       "  '<ETHER>-Franklyn',\n",
       "  '<ETHER>-Fifa',\n",
       "  '<ETHER>-Ciso',\n",
       "  '<ETHER>-Multiple',\n",
       "  '<ETHER>-Squall',\n",
       "  '<ETHER>-Guam',\n",
       "  '<ETHER>-Retinol',\n",
       "  '<ETHER>-Jitsi Lip Jitsi',\n",
       "  '<ETHER>-De Puerto',\n",
       "  '<ETHER>-Iphone 6 Plus',\n",
       "  '<ETHER>-Ffvp'],\n",
       " 3: ['<ETHER>-Vdp',\n",
       "  '<ETHER>-Leo',\n",
       "  '<ETHER>-Bill Franklin',\n",
       "  '<ETHER>-Franklin Kit',\n",
       "  '<ETHER>-World War Two'],\n",
       " 4: ['<ETHER>-Shopkins',\n",
       "  '<ETHER>-Dario',\n",
       "  '<ETHER>-Janus Video Bridge',\n",
       "  '<ETHER>-Z1',\n",
       "  '<ETHER>-Cullen',\n",
       "  '<ETHER>-Filtration',\n",
       "  '<ETHER>-Arjun',\n",
       "  '<ETHER>-Trisha',\n",
       "  '<ETHER>-Semi',\n",
       "  '<ETHER>-Nazi',\n",
       "  '<ETHER>-Shank',\n",
       "  '<ETHER>-Fifa Service'],\n",
       " 5: ['<ETHER>-Correct',\n",
       "  '<ETHER>-Backfilling Tusk',\n",
       "  '<ETHER>-Locker',\n",
       "  '<ETHER>-Cv5',\n",
       "  '<ETHER>-Sarkozy',\n",
       "  '<ETHER>-Careers',\n",
       "  '<ETHER>-Suzhou',\n",
       "  '<ETHER>-Calendar Api',\n",
       "  '<ETHER>-Vegan',\n",
       "  '<ETHER>-Darren',\n",
       "  '<ETHER>-Auerbach Bombards',\n",
       "  '<ETHER>-Google Aps',\n",
       "  '<ETHER>-Yen',\n",
       "  '<ETHER>-Ether Mines',\n",
       "  '<ETHER>-Spo Rt',\n",
       "  '<ETHER>-May Day',\n",
       "  '<ETHER>-Bike 82',\n",
       "  '<ETHER>-Esper',\n",
       "  '<ETHER>-Llama']}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T19:16:12.796186Z",
     "start_time": "2020-02-22T19:16:11.708650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n",
      "Iframe\n",
      "AI 7\n",
      "Aztecs 7\n",
      "Nazi 7\n",
      "Franklin 7\n",
      "Coptic 7\n",
      "Dekada 7\n",
      "Karthik 7\n",
      "Backfilling Tusk 7\n",
      "Caldwells 7\n",
      "Filtration 7\n",
      "Arjun 7\n",
      "Trisha 7\n",
      "Semi 7\n",
      "Ether Engineering 7\n",
      "Bill Franklin 7\n",
      "New Link 7\n",
      "Beyonce\n",
      "Slack Graph Slack 7\n",
      "Entity Graph 7\n",
      "Janus 7\n",
      "Sufi 7\n",
      "Sookie 7\n",
      "Channel China 7\n",
      "Dario 7\n",
      "Karthik 7\n",
      "Janus Video Bridge 7\n",
      "Janice 7\n",
      "Correct 7\n",
      "Rod 7\n",
      "Graph Esther 7\n",
      "Sages 7\n",
      "Broncos 7\n",
      "Franklin 7\n",
      "Society\n",
      "Z1 7\n",
      "Leo 7\n",
      "Gothic\n",
      "General Eric 7\n",
      "Cullen 7\n",
      "Yen\n",
      "Ether Mines 7\n",
      "Costas 7\n",
      "Dialogue Blog 7\n",
      "Going Away 7\n",
      "Us Michelle 7\n",
      "Never Went Away 7\n",
      "Cho 7\n",
      "Trenton 7\n",
      "Calendar Api 7\n",
      "Vegan 7\n",
      "Darren 7\n",
      "Auerbach Bombards 7\n",
      "Google Aps 7\n",
      "Kings 7\n",
      "Chao Garden De Labarre the Della Della Person 7\n",
      "Latest\n",
      "C Corp 7\n",
      "Fifa 7\n",
      "Suzhou 7\n",
      "World War Two 7\n",
      "Web Desktop 7\n",
      "Jitsi Lip Jitsi 7\n",
      "De Puerto 7\n",
      "Iphone 6 Plus 7\n",
      "Iframe\n",
      "Ffvp 7\n",
      "Janus 7\n",
      "Navigation\n",
      "Guam 7\n",
      "Retinol 7\n",
      "Emily\n",
      "Olivia 7\n",
      "Franklin 7\n",
      "Squall 7\n",
      "Decade 7\n",
      "Institute 7\n",
      "Ciso\n",
      "May Day 7\n",
      "Bike 82 7\n",
      "Esper\n",
      "Trenton 7\n",
      "Llama\n",
      "Camera Dot 7\n",
      "Spo Rt 7\n",
      "Multiple 7\n",
      "Fft\n",
      "Zeke 7\n",
      "Paschal 7\n",
      "Makonnen Karthik 7\n",
      "Lifeline 7\n",
      "Troy Times 7\n",
      "Cardigan 7\n",
      "Tropicals 7\n",
      "Channel List 7\n",
      "Ether Engineering 7\n",
      "Psi 7\n",
      "Franklin 7\n",
      "Shopkins 7\n",
      "Guys\n",
      "Frenchy 7\n",
      "Vdp 7\n",
      "Bunnies 7\n",
      "Arjun 7\n",
      "Yo\n",
      "Dancing 7\n",
      "Shank 7\n",
      "Franklin Kit 7\n",
      "Alexis 7\n",
      "Php Summer Olympic 7\n",
      "Fifa Service 7\n",
      "Father Karthik 7\n",
      "Locker 7\n",
      "Cv5 7\n",
      "Sarkozy 7\n",
      "Careers\n",
      "Karthik 7\n",
      "Ab C-- 7\n",
      "Franklin 7\n",
      "Karthika 7\n",
      "Franklyn 7\n"
     ]
    }
   ],
   "source": [
    "nodes_list = list(kp_entity_graph_df.nodes())\n",
    "new_entity_list = []\n",
    "print (len(added_entities))\n",
    "for ent in added_entities:\n",
    "    if ent not in nodes_list:\n",
    "        if '<ETHER>-'+ent in com_map_updated.keys():\n",
    "            print (ent, com_map_updated['<ETHER>-'+ent])\n",
    "            new_entity_list.append(ent)\n",
    "            pass\n",
    "        else:\n",
    "            print (ent)\n",
    "            pass\n",
    "        \n",
    "        #print (ent, end=\", \")\n",
    "        if ent not in kp_entity_graph_cl.nodes():\n",
    "            print (\"<False>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T19:05:56.033010Z",
     "start_time": "2020-02-22T19:05:55.891613Z"
    }
   },
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for ent, com in com_map_updated.items():\n",
    "    if com in clusters.keys():\n",
    "        clusters[com].append(ent)\n",
    "    else:\n",
    "        clusters[com] = [ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T19:06:05.246867Z",
     "start_time": "2020-02-22T19:06:05.163216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First',\n",
       " '3',\n",
       " 'Machine',\n",
       " 'Amazon Linux Ami',\n",
       " 'Application',\n",
       " 'Cpu',\n",
       " 'Services',\n",
       " '1',\n",
       " 'Version 1',\n",
       " '50',\n",
       " '000',\n",
       " '300',\n",
       " 'Nvidia',\n",
       " 'Gpus',\n",
       " '000+',\n",
       " 'Sla',\n",
       " '20',\n",
       " 'T2',\n",
       " 'Micro Instance',\n",
       " 'Disk',\n",
       " 'Service',\n",
       " 'Pms',\n",
       " 'Gpu',\n",
       " 'Gcps',\n",
       " 'A4',\n",
       " 'Iot',\n",
       " 'Kpis',\n",
       " 'Simple',\n",
       " 'Us East',\n",
       " 'Virginia',\n",
       " 'Us-east-1',\n",
       " 'Transcoding',\n",
       " '9',\n",
       " '500',\n",
       " 'Benchmark',\n",
       " 'P1',\n",
       " 'P2',\n",
       " 'P3',\n",
       " '100',\n",
       " 'Xfs',\n",
       " 'Sydney',\n",
       " 'B',\n",
       " 'Pvms',\n",
       " 'Pvm',\n",
       " 'N1-standard-1',\n",
       " 'P90',\n",
       " 'P99',\n",
       " 'Spot',\n",
       " 'Usd',\n",
       " 'Wikipedia',\n",
       " 'Mongoose',\n",
       " '2xlarge',\n",
       " '250',\n",
       " 'Language',\n",
       " 'Us-west-2',\n",
       " 'Ebs',\n",
       " 'Store',\n",
       " 'Internet of Things',\n",
       " '5',\n",
       " 'Hello World',\n",
       " '0',\n",
       " '4',\n",
       " 'Target',\n",
       " 'Pin',\n",
       " 'Example',\n",
       " 'Com',\n",
       " 'One',\n",
       " '6',\n",
       " '7',\n",
       " '10',\n",
       " 'Control',\n",
       " 'Ghz',\n",
       " 'Applications',\n",
       " 'Slas',\n",
       " 'Ab',\n",
       " 'Ads',\n",
       " 'Aperture',\n",
       " 'Pinner',\n",
       " 'Pinners',\n",
       " 'Pinterest',\n",
       " '25',\n",
       " 'Monad',\n",
       " 'Code-based',\n",
       " 'Language-specific',\n",
       " 'System',\n",
       " '15',\n",
       " 'Ssd',\n",
       " 'C5d',\n",
       " '4xlarge',\n",
       " 'Iops',\n",
       " 'Hello',\n",
       " 'Ram',\n",
       " 'Stack',\n",
       " 'Pinterests',\n",
       " 'Lightstep',\n",
       " 'Engine',\n",
       " '13',\n",
       " 'Cuda',\n",
       " 'Cudnn',\n",
       " 'Wikipedias',\n",
       " 'Non-local',\n",
       " 'Segfault',\n",
       " 'Ztf',\n",
       " '600',\n",
       " '200',\n",
       " 'Middle',\n",
       " 'M4',\n",
       " 'Large',\n",
       " 'R4',\n",
       " 'Xlarge',\n",
       " 'Validation',\n",
       " 'Modern',\n",
       " '11',\n",
       " 'Eu-west-1',\n",
       " 'M5',\n",
       " 'Jiras',\n",
       " 'Non-gpu',\n",
       " 'Gpu-powered',\n",
       " 'T3',\n",
       " 'Spot Instance',\n",
       " 'Nvidia Device',\n",
       " 'World',\n",
       " 'Cross',\n",
       " 'Bs',\n",
       " 'Noisy Neighbor',\n",
       " '2.0',\n",
       " 'Rcu',\n",
       " 'Tesla K80 Gpu',\n",
       " 'Nvidia Gpu',\n",
       " 'Nvidia Gpus',\n",
       " 'I5',\n",
       " 'Vcpus',\n",
       " 'Fs-extra',\n",
       " 'Fs',\n",
       " '2.1',\n",
       " 'Hdd',\n",
       " 'Dsls',\n",
       " 'Small',\n",
       " 'Ssds',\n",
       " 'Gb',\n",
       " 'Enum',\n",
       " 'Dsl',\n",
       " 'Kpi',\n",
       " 'Embedded',\n",
       " '1.0',\n",
       " 'Rps',\n",
       " 'Pagespeed Insights',\n",
       " '6.X',\n",
       " 'Newer',\n",
       " 'Sram',\n",
       " 'Nes',\n",
       " 'Psram',\n",
       " 'Apache Jmeter',\n",
       " '400',\n",
       " 'Rss',\n",
       " 'Latency-based',\n",
       " 'Eu-central-1',\n",
       " '1m',\n",
       " 'Slos',\n",
       " 'Slo',\n",
       " 'Binlog',\n",
       " 'Eu-west-3',\n",
       " 'Vcpu',\n",
       " 'Jmh',\n",
       " 'Explain',\n",
       " 'C4',\n",
       " '000 Rps',\n",
       " 'Llap',\n",
       " '30',\n",
       " 'Jmeter',\n",
       " 'Version 3',\n",
       " 'Apache Bench',\n",
       " 'Memory',\n",
       " 'Ptal',\n",
       " '60',\n",
       " 'Io1',\n",
       " 'Nvme',\n",
       " 'A5',\n",
       " 'Bh',\n",
       " 'Sri',\n",
       " 'Operand',\n",
       " '501',\n",
       " 'Tmpfs',\n",
       " 'Cpus',\n",
       " 'Vpss',\n",
       " 'Oom',\n",
       " 'Oom-killer',\n",
       " 'Cfs',\n",
       " 'Standard',\n",
       " '150',\n",
       " 'Apache Benchmark',\n",
       " 'Lightbend',\n",
       " 'Sks',\n",
       " '99',\n",
       " '45',\n",
       " 'Sup',\n",
       " 'Acus',\n",
       " 'Timess',\n",
       " 'Amazon Linux',\n",
       " 'Nps',\n",
       " '4ghz',\n",
       " 'P1v2 Sku',\n",
       " 'Churn',\n",
       " 'Mcores',\n",
       " 'P50',\n",
       " 'Lightgbm',\n",
       " 'Csps',\n",
       " 'Psps',\n",
       " 'Jsq',\n",
       " 'Integrated Development Environment',\n",
       " 'Research_ave_boost',\n",
       " 'Filter Api',\n",
       " 'Search Api',\n",
       " 'Benevolentai',\n",
       " 'Instead',\n",
       " '40',\n",
       " 'Slis',\n",
       " 'Raid0',\n",
       " 'Wcu',\n",
       " 'Hpc',\n",
       " 'Domain Specific Language',\n",
       " 'Zswap',\n",
       " 'D2',\n",
       " 'Iot-enabled',\n",
       " 'Aws-ec2',\n",
       " 'Ec2-slave',\n",
       " 'Transcode',\n",
       " 'Djvm',\n",
       " 'Gp2',\n",
       " 'Domain-specific Language',\n",
       " 'Fc',\n",
       " 'Super Bowl',\n",
       " 'Heaphero',\n",
       " 'Gb-seconds',\n",
       " 'Benchmarkdotnet',\n",
       " 'I3',\n",
       " 'I3s',\n",
       " 'Jsperf',\n",
       " 'Instance-1',\n",
       " '120',\n",
       " 'Ios-factor',\n",
       " 'Yo',\n",
       " '<ETHER>-AI',\n",
       " '<ETHER>-Aztecs',\n",
       " '<ETHER>-Nazi',\n",
       " '<ETHER>-Dekada',\n",
       " '<ETHER>-Filtration',\n",
       " '<ETHER>-Arjun',\n",
       " '<ETHER>-Trisha',\n",
       " '<ETHER>-Semi',\n",
       " '<ETHER>-Ether Engineering',\n",
       " '<ETHER>-Bill Franklin',\n",
       " '<ETHER>-Franklin',\n",
       " '<ETHER>-Coptic',\n",
       " '<ETHER>-Karthik',\n",
       " '<ETHER>-Backfilling Tusk',\n",
       " '<ETHER>-Caldwells',\n",
       " '<ETHER>-New Link',\n",
       " '<ETHER>-Slack Graph Slack',\n",
       " '<ETHER>-Entity Graph',\n",
       " '<ETHER>-Janus',\n",
       " '<ETHER>-Sufi',\n",
       " '<ETHER>-Sookie',\n",
       " '<ETHER>-Channel China',\n",
       " '<ETHER>-Jitsi',\n",
       " '<ETHER>-Dario',\n",
       " '<ETHER>-Janus Video Bridge',\n",
       " '<ETHER>-Janice',\n",
       " '<ETHER>-Correct',\n",
       " '<ETHER>-Rod',\n",
       " '<ETHER>-Graph Esther',\n",
       " '<ETHER>-Sages',\n",
       " '<ETHER>-Broncos',\n",
       " '<ETHER>-Z1',\n",
       " '<ETHER>-Leo',\n",
       " '<ETHER>-General Eric',\n",
       " '<ETHER>-Cullen',\n",
       " '<ETHER>-Castile',\n",
       " '<ETHER>-Adaptive Mind Speech Three',\n",
       " '<ETHER>-Lee',\n",
       " '<ETHER>-Anisha',\n",
       " '<ETHER>-Aether',\n",
       " '<ETHER>-Communica',\n",
       " '<ETHER>-Commission',\n",
       " '<ETHER>-Carolyn Pizzas',\n",
       " '<ETHER>-Esther',\n",
       " '<ETHER>-Cut Tree',\n",
       " '<ETHER>-Chew Gum',\n",
       " '<ETHER>-Wankers Free',\n",
       " '<ETHER>-Suba',\n",
       " '<ETHER>-Makah',\n",
       " '<ETHER>-Magnolia',\n",
       " '<ETHER>-Cosmo',\n",
       " '<ETHER>-Lonnie',\n",
       " '<ETHER>-Ethercast',\n",
       " '<ETHER>-Domain Key Phrase',\n",
       " '<ETHER>-Gypsy',\n",
       " '<ETHER>-Pierre',\n",
       " '<ETHER>-Quarter Join',\n",
       " '<ETHER>-Recorder Recording',\n",
       " '<ETHER>-Molly',\n",
       " '<ETHER>-Ether Mines',\n",
       " '<ETHER>-Costas',\n",
       " '<ETHER>-Dialogue Blog',\n",
       " '<ETHER>-Going Away',\n",
       " '<ETHER>-Us Michelle',\n",
       " '<ETHER>-Never Went Away',\n",
       " '<ETHER>-Cho',\n",
       " '<ETHER>-Trenton',\n",
       " '<ETHER>-Calendar Api',\n",
       " '<ETHER>-Vegan',\n",
       " '<ETHER>-Darren',\n",
       " '<ETHER>-Auerbach Bombards',\n",
       " '<ETHER>-Google Aps',\n",
       " '<ETHER>-Kings',\n",
       " '<ETHER>-Chao Garden De Labarre the Della Della Person',\n",
       " '<ETHER>-C Corp',\n",
       " '<ETHER>-Fifa',\n",
       " '<ETHER>-Suzhou',\n",
       " '<ETHER>-World War Two',\n",
       " '<ETHER>-Web Desktop',\n",
       " '<ETHER>-Jitsi Lip Jitsi',\n",
       " '<ETHER>-De Puerto',\n",
       " '<ETHER>-Iphone 6 Plus',\n",
       " '<ETHER>-Ffvp',\n",
       " '<ETHER>-Kate',\n",
       " '<ETHER>-Guam',\n",
       " '<ETHER>-Retinol',\n",
       " '<ETHER>-Olivia',\n",
       " '<ETHER>-Squall',\n",
       " '<ETHER>-Decade',\n",
       " '<ETHER>-Institute',\n",
       " '<ETHER>-May Day',\n",
       " '<ETHER>-Bike 82',\n",
       " '<ETHER>-Camera Dot',\n",
       " '<ETHER>-Spo Rt',\n",
       " '<ETHER>-Multiple',\n",
       " '<ETHER>-Zeke',\n",
       " '<ETHER>-Paschal',\n",
       " '<ETHER>-Makonnen Karthik',\n",
       " '<ETHER>-Lifeline',\n",
       " '<ETHER>-Troy Times',\n",
       " '<ETHER>-Cardigan',\n",
       " '<ETHER>-Tropicals',\n",
       " '<ETHER>-Channel List',\n",
       " '<ETHER>-Psi',\n",
       " '<ETHER>-Shopkins',\n",
       " '<ETHER>-Frenchy',\n",
       " '<ETHER>-Vdp',\n",
       " '<ETHER>-Bunnies',\n",
       " '<ETHER>-Dancing',\n",
       " '<ETHER>-Shank',\n",
       " '<ETHER>-Franklin Kit',\n",
       " '<ETHER>-Alexis',\n",
       " '<ETHER>-Php Summer Olympic',\n",
       " '<ETHER>-Fifa Service',\n",
       " '<ETHER>-Father Karthik',\n",
       " '<ETHER>-Locker',\n",
       " '<ETHER>-Cv5',\n",
       " '<ETHER>-Sarkozy',\n",
       " '<ETHER>-Ab C--',\n",
       " '<ETHER>-Karthika',\n",
       " '<ETHER>-Franklyn']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T15:01:43.111456Z",
     "start_time": "2020-02-22T15:01:42.335853Z"
    }
   },
   "outputs": [],
   "source": [
    "e_fv = pickle.load(open(\"/home/ray__/ssd/minds/se/recency/entity.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T15:39:29.466341Z",
     "start_time": "2020-02-22T15:39:19.604060Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "t_sim = []\n",
    "t_sim = [(e, 1-cosine(e_fv[e], e_fv[\"<ETHER>-Ether Engineering\"])) for e in e_fv.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T15:39:29.597323Z",
     "start_time": "2020-02-22T15:39:29.468806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N', 0.7033717632293701),\n",
       " ('3', 0.6879128813743591),\n",
       " ('1', 0.6854665875434875),\n",
       " ('Usd', 0.6810983419418335),\n",
       " ('E', 0.670531153678894),\n",
       " ('Self', 0.6653602719306946),\n",
       " ('Naples', 0.6644787788391113),\n",
       " ('P', 0.6593735814094543),\n",
       " ('Control + C', 0.657631516456604),\n",
       " ('Ps', 0.6469427943229675)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(t_sim, key=lambda kv:kv[1], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T15:40:17.482325Z",
     "start_time": "2020-02-22T15:40:17.421191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_map_updated['Ps']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
