{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:41:31.792854Z",
     "start_time": "2020-02-24T09:41:31.758637Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-26T09:03:32.370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ray__/ssd/pos_tag/code/\") # Custom pos tag location.\n",
    "sys.path.append(\"/home/ray__/ssd/\") # ner util code\n",
    "sys.path.append(\"/home/ray__/ssd/hinton/community_detection/group_segments/helper_functions/\")\n",
    "import recency_util_post\n",
    "\n",
    "from bert_ner_utils_graph import BERT_NER\n",
    "from distilbert_pos_tagger import DistilBertPosTagger\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "pos_tagger = DistilBertPosTagger(\"/home/ray__/ssd/pos_tag/model/Distilbert/\",\"cpu\")\n",
    "ner_model = BERT_NER('/home/ray__/ssd/bert-ner/',labels = [\"O\", \"MISC\", \"MISC\",  \"PER\", \"PER\", \"ORG\", \"ORG\", \"LOC\", \"LOC\"],device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:42:10.990606Z",
     "start_time": "2020-02-24T09:41:43.753410Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ray__/ssd/BERT/\")\n",
    "sys.path.append(\"/home/ray__/CS/org/etherlabs/ai-engine/pkg/\")\n",
    "from gpt_feat_utils import GPT_Inference\n",
    "\n",
    "gpt_model = GPT_Inference(\"/home/ray__/ssd/BERT/models/customer_service/epoch3/\", device=\"cuda\")\n",
    "#gpt_model = GPT_Inference(\"/home/ray__/ssd/BERT/models/ether_v2/ether_googleJan13_groupsplit_withstop_4+w_gt3s_lr3e-5/\",device=\"cuda\")\n",
    "# gpt_model = GPT_Inference(\"/home/ray__/ssd/BERT/models/product/\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:49:44.839356Z",
     "start_time": "2020-02-24T09:49:07.168898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  01DAAQY88QZB19JQZ5PRJFR76Y  for feature extraction\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 122, \"module\": \"scorer\", \"batches count\": 2, \"number of sentences\": 396, \"ts\": \"2020-02-24T09:49:18.476869Z\", \"msg\": \"computing in batches\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 125, \"module\": \"scorer\", \"iteration count:\": 0, \"ts\": \"2020-02-24T09:49:18.484931Z\", \"msg\": \"getting feature vector\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 133, \"module\": \"scorer\", \"iteration count\": 0, \"ts\": \"2020-02-24T09:49:23.892805Z\", \"msg\": \"Request Sent\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 125, \"module\": \"scorer\", \"iteration count:\": 1, \"ts\": \"2020-02-24T09:49:23.897699Z\", \"msg\": \"getting feature vector\"}\n",
      "{\"level\": \"info\", \"filename\": \"scorer.py\", \"lineno\": 133, \"module\": \"scorer\", \"iteration count\": 1, \"ts\": \"2020-02-24T09:49:25.610317Z\", \"msg\": \"Request Sent\"}\n",
      "('What we have done is we have had to hack the data hunger of the more of the neural network language models.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('What we have done is we have had to hack the data hunger of the more of the neural network language models.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('What we have done is we have had to hack the data hunger of the more of the neural network language models.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('The model is the actual neural network model and the mind is is the graph data structure that organizes the information.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('I because we get the data in a very small increments for the machine learning model.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('I I think I think we can on the validation component.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('I because we get the data in a very small increments for the machine learning model.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('I because we get the data in a very small increments for the machine learning model.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('I because we get the data in a very small increments for the machine learning model.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('I because we get the data in a very small increments for the machine learning model.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So so that is where the channel mind comes into play when we say mine.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it is a static component.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('I I think I think we can on the validation component.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it is a static component.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it is a static component.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('And then in the meantime, we do not want to lose the information that we have.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('I I think I think we can on the validation component.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('And then in the meantime, we do not want to lose the information that we have.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('And then in the meantime, we do not want to lose the information that we have.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('And then in the meantime, we do not want to lose the information that we have.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('Once we once we have the language model, that is fine tune.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('I I think I think we can on the validation component.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So so that is where the channel mind comes into play when we say mine.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('Action that is coming, you know to The Ether AI engine if you are it.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So that is kind of the engineering that we did for the channel Minds got it.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated.', '2019-10-31T13:29:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'd2c0d63048af47c0808ed53e761c9f7b')\n",
      "('So that is kind of the engineering that we did for the channel Minds got it.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('I I think I think we can on the validation component.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So that is kind of the engineering that we did for the channel Minds got it.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So that is kind of the engineering that we did for the channel Minds got it.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So that is kind of the engineering that we did for the channel Minds got it.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So that is kind of the engineering that we did for the channel Minds got it.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('Once we once we have the language model, that is fine tune.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So that is kind of the engineering that we did for the channel Minds got it.', '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e') ('So so that is where the channel mind comes into play when we say mine.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated.', '2019-10-31T13:29:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'd2c0d63048af47c0808ed53e761c9f7b') ('I I think I think we can on the validation component.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated.', '2019-10-31T13:29:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'd2c0d63048af47c0808ed53e761c9f7b') ('So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated.', '2019-10-31T13:29:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'd2c0d63048af47c0808ed53e761c9f7b') ('So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated.', '2019-10-31T13:29:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'd2c0d63048af47c0808ed53e761c9f7b') ('So let me get just started my mind Generations on the top.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d')\n",
      "('How is that attach to the with a slack Channel and then how it how the channel Minds selfgenerated right?', '2019-10-31T13:29:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'd2c0d63048af47c0808ed53e761c9f7b') ('I I think I think we can on the validation component.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('How is that attach to the with a slack Channel and then how it how the channel Minds selfgenerated right?', '2019-10-31T13:29:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'd2c0d63048af47c0808ed53e761c9f7b') ('So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562')\n",
      "('What we do is actually there are there is a twostage validation one is one is the language model that we that we have two other people which is well, which is actually finetune various tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562') ('So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is wellversed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d')\n",
      "('When I say a task it is it is like asking asking the language model to predict whether whether a sentence is at whether a sentence whether two sentences are continuous.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562') ('So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d')\n",
      "('Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562') ('So so this this just shows how how the chat the domain Minds, you know shapeshifts into the channel and by learning all the information that it gets from the conversations.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d')\n",
      "('Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562') ('So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is wellversed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d')\n",
      "('So so we have we have fairly statistical validation approaches to validate this auxiliary tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562') ('So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d')\n",
      "('So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.', '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562') ('So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d')\n",
      "('So so this this just shows how how the chat the domain Minds, you know shapeshifts into the channel and by learning all the information that it gets from the conversations.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So so this this just shows how how the chat the domain Minds, you know shapeshifts into the channel and by learning all the information that it gets from the conversations.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So let me get just started my mind Generations on the top.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('So so this is this is fairly simple, you know, simple.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So we we we use open data to to you know, generate generate a fix.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('Were in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So we we we use open data to to you know, generate generate a fix.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is wellversed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('Were in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is wellversed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('It is a simple example would be a bug a bug in nature may be different from the bug in a software engineering model.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('This is likelihood that with the talk about a double s Lambda also, it means that they seem to be talking about a similar as similar aspect for that certain Tim.', '2019-10-31T13:32:03Z', '3f01f2032f584b178fafde6b437058ae', 'e1e4c629ba3549f09e95805e87b19902')\n",
      "('It is a simple example would be a bug a bug in nature may be different from the bug in a software engineering model.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('So so this is this is fairly simple, you know, simple.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('It is a simple example would be a bug a bug in nature may be different from the bug in a software engineering model.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So from once we have this domain language model right as we were talking about the domain minder.', '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d') ('So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('Something like, you know, if I am part of a channel that is a very direct relationship which does not require a lot of intelligence which is get it right out of the station.', '2019-10-31T13:43:50Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0378db3c78e4aae90c1b891b5ccafaf') ('And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Whereas when I say, hey, you know Karthik follow up on this production issue, you know the idea that Karthik is the person who I am assigning this action to is something that is not so intuitive and needs to be gleaned right by first applying NLP in these types of rules then later on also being getting represented in the laugh', '2019-10-31T13:43:50Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0378db3c78e4aae90c1b891b5ccafaf') ('So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Whereas when I say, hey, you know Karthik follow up on this production issue, you know the idea that Karthik is the person who I am assigning this action to is something that is not so intuitive and needs to be gleaned right by first applying NLP in these types of rules then later on also being getting represented in the laugh', '2019-10-31T13:43:50Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0378db3c78e4aae90c1b891b5ccafaf') ('So how in fact we can even take consensus just because Karthik is talking we need not say that he could be an expert.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.', '2019-10-31T13:47:29Z', '3f01f2032f584b178fafde6b437058ae', 'd664f7f953984352a85c1b8b06a309b8') ('So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38')\n",
      "('Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.', '2019-10-31T13:47:29Z', '3f01f2032f584b178fafde6b437058ae', 'd664f7f953984352a85c1b8b06a309b8') ('It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38')\n",
      "('Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.', '2019-10-31T13:47:29Z', '3f01f2032f584b178fafde6b437058ae', 'd664f7f953984352a85c1b8b06a309b8') ('They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.', '2019-10-31T13:47:29Z', '3f01f2032f584b178fafde6b437058ae', 'd664f7f953984352a85c1b8b06a309b8') ('All the users will have their own representation that not just captures what who they are.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('Yes, I eat a graph is more of a traditional representation of God.', '2019-10-31T13:47:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ca7d7bdff13246d89898f335ec0ab4ac') ('All the users will have their own representation that not just captures what who they are.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('Yes, it is teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them.', '2019-10-31T13:47:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ca7d7bdff13246d89898f335ec0ab4ac') ('They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('Yes, it is teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them.', '2019-10-31T13:47:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ca7d7bdff13246d89898f335ec0ab4ac') ('All the users will have their own representation that not just captures what who they are.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('Okay and then I guess once you have these types of graphs.', '2019-10-31T13:47:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ca7d7bdff13246d89898f335ec0ab4ac') ('So we we just organize the topics key phrases captured as the notes on that.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('Okay and then I guess once you have these types of graphs.', '2019-10-31T13:47:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ca7d7bdff13246d89898f335ec0ab4ac') ('So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('Okay and then I guess once you have these types of graphs.', '2019-10-31T13:47:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ca7d7bdff13246d89898f335ec0ab4ac') ('All the users will have their own representation that not just captures what who they are.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('Just think of integrating these insights into you know, a ticket management tool like jira, right?', '2019-10-31T13:50:01Z', '3f01f2032f584b178fafde6b437058ae', '42c18ef5d2f543f98e10b9c46d7e1d3a') ('That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.', '2019-10-31T13:50:23Z', '3f01f2032f584b178fafde6b437058ae', 'abceb463b6d442dd88e9607b7c09c7b9')\n",
      "('Just think of integrating these insights into you know, a ticket management tool like jira, right?', '2019-10-31T13:50:01Z', '3f01f2032f584b178fafde6b437058ae', '42c18ef5d2f543f98e10b9c46d7e1d3a') ('So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('Just think of integrating these insights into you know, a ticket management tool like jira, right?', '2019-10-31T13:50:01Z', '3f01f2032f584b178fafde6b437058ae', '42c18ef5d2f543f98e10b9c46d7e1d3a') ('All the users will have their own representation that not just captures what who they are.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this.', '2019-10-31T13:50:01Z', '3f01f2032f584b178fafde6b437058ae', '42c18ef5d2f543f98e10b9c46d7e1d3a') ('That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.', '2019-10-31T13:50:23Z', '3f01f2032f584b178fafde6b437058ae', 'abceb463b6d442dd88e9607b7c09c7b9')\n",
      "('So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this.', '2019-10-31T13:50:01Z', '3f01f2032f584b178fafde6b437058ae', '42c18ef5d2f543f98e10b9c46d7e1d3a') ('So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this.', '2019-10-31T13:50:01Z', '3f01f2032f584b178fafde6b437058ae', '42c18ef5d2f543f98e10b9c46d7e1d3a') ('All the users will have their own representation that not just captures what who they are.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.', '2019-10-31T13:50:23Z', '3f01f2032f584b178fafde6b437058ae', 'abceb463b6d442dd88e9607b7c09c7b9') ('So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.', '2019-10-31T13:50:23Z', '3f01f2032f584b178fafde6b437058ae', 'abceb463b6d442dd88e9607b7c09c7b9') ('If you do not talk about anything else if direct enables us to form the you know, form the form this noninductive relationships like talked about a certain topic or action item assigned to so now let us take forward and then use This graph that is actually being formed after all the conversations.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.', '2019-10-31T13:50:23Z', '3f01f2032f584b178fafde6b437058ae', 'abceb463b6d442dd88e9607b7c09c7b9') ('And then what we what we do is we just put it through a graph neural networks kind or the different graph algorithms.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.', '2019-10-31T13:50:23Z', '3f01f2032f584b178fafde6b437058ae', 'abceb463b6d442dd88e9607b7c09c7b9') ('All the users will have their own representation that not just captures what who they are.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.', '2019-10-31T13:50:23Z', '3f01f2032f584b178fafde6b437058ae', 'abceb463b6d442dd88e9607b7c09c7b9') ('But but what they come as a combination represents, so once they have this as a mathematical object, like like a like a embedding what we can do is we can do lot of you know algorithms on because we are free to do all the math around it and then we can you can get for the similar users to kartik from the context of you know, the topics that that he discusses or from the context of the action items.', '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2')\n",
      "('That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph.', '2019-10-31T13:32:03Z', '3f01f2032f584b178fafde6b437058ae', 'e1e4c629ba3549f09e95805e87b19902') ('That is on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph.', '2019-10-31T13:32:03Z', '3f01f2032f584b178fafde6b437058ae', 'e1e4c629ba3549f09e95805e87b19902') ('Were in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph.', '2019-10-31T13:32:03Z', '3f01f2032f584b178fafde6b437058ae', 'e1e4c629ba3549f09e95805e87b19902') ('We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So that means if someone is talking about deployment aunt and then if in a certain channel is if they always associate deployment with let us say AWS Lambda.', '2019-10-31T13:32:03Z', '3f01f2032f584b178fafde6b437058ae', 'e1e4c629ba3549f09e95805e87b19902') ('So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So this relationship is learned that when there is an aid of a deployment.', '2019-10-31T13:32:03Z', '3f01f2032f584b178fafde6b437058ae', 'e1e4c629ba3549f09e95805e87b19902') ('So so this is this is fairly simple, you know, simple.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So this relationship is learned that when there is an aid of a deployment.', '2019-10-31T13:32:03Z', '3f01f2032f584b178fafde6b437058ae', 'e1e4c629ba3549f09e95805e87b19902') ('So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('So this is kind of relationship that this combination of language model undermined men captures.', '2019-10-31T13:32:03Z', '3f01f2032f584b178fafde6b437058ae', 'e1e4c629ba3549f09e95805e87b19902') ('So so this is this is fairly simple, you know, simple.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('Okay as we mentioned so domain Channel mine is fairly Dynamic.', '2019-10-31T13:35:01Z', '3f01f2032f584b178fafde6b437058ae', '676708b576584e38acaa6d634427fa8c') ('That is on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('Okay as we mentioned so domain Channel mine is fairly Dynamic.', '2019-10-31T13:35:01Z', '3f01f2032f584b178fafde6b437058ae', '676708b576584e38acaa6d634427fa8c') ('Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6')\n",
      "('Okay as we mentioned so domain Channel mine is fairly Dynamic.', '2019-10-31T13:35:01Z', '3f01f2032f584b178fafde6b437058ae', '676708b576584e38acaa6d634427fa8c') ('It is just in the context of a team, right like essentially Channel equals a team.', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82')\n",
      "('Okay as we mentioned so domain Channel mine is fairly Dynamic.', '2019-10-31T13:35:01Z', '3f01f2032f584b178fafde6b437058ae', '676708b576584e38acaa6d634427fa8c') ('All right, so there is there is here is a kind of an example.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('So let us move on and maybe just give a quick example not going to spend a whole lot of time on this but just to give a representation of here is a real world example.', '2019-10-31T13:52:41Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '97f2b973beea4fad9394feb35dde9990') ('So these types of relationships get pulled out very easily from the knowledge.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b')\n",
      "('Let me see if I can actually pull up the graph itself.', '2019-10-31T13:52:41Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '97f2b973beea4fad9394feb35dde9990') ('Yeah, so so it actually brings it to one more notion.', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('Let me see if I can actually pull up the graph itself.', '2019-10-31T13:52:41Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '97f2b973beea4fad9394feb35dde9990') ('We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('Let me see if I can actually pull up the graph itself.', '2019-10-31T13:52:41Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '97f2b973beea4fad9394feb35dde9990') ('So one is we are able to we took essentially one of the workspaces and map the interactions into a into a graph here and let us say we want to find out who the goo.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b')\n",
      "('Let me see if I can actually pull up the graph itself.', '2019-10-31T13:52:41Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '97f2b973beea4fad9394feb35dde9990') ('That is just a quick example at a sample of what we do.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b')\n",
      "('Let me stop the content here and show the real graph.', '2019-10-31T13:52:41Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '97f2b973beea4fad9394feb35dde9990') ('Yeah, so so it actually brings it to one more notion.', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('Let me stop the content here and show the real graph.', '2019-10-31T13:52:41Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '97f2b973beea4fad9394feb35dde9990') ('I do not know if you are able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b')\n",
      "('Let me stop the content here and show the real graph.', '2019-10-31T13:52:41Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '97f2b973beea4fad9394feb35dde9990') ('That is just a quick example at a sample of what we do.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b')\n",
      "('So every time every time there is a new conversation that comes in the comes in the eater.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6') ('It is just in the context of a team, right like essentially Channel equals a team.', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82')\n",
      "('So every time every time there is a new conversation that comes in the comes in the eater.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6') ('Let is say on either some other channel at home or some other let us say Google Hangouts for example, right if there is a concept of a Group in Google Hangout and that prisons attain the same level of attachment of mines and ending can also happen there.', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82')\n",
      "('Calls there would be there would be scored or they would be compared against this domain mind till we have the transformation to the channel Minds.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6') ('It is just in the context of a team, right like essentially Channel equals a team.', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82')\n",
      "('So so this is this is fairly simple, you know, simple.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6') ('It is just in the context of a team, right like essentially Channel equals a team.', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82')\n",
      "('Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind.', '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6') ('It is just in the context of a team, right like essentially Channel equals a team.', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82')\n",
      "('It is just in the context of a team, right like essentially Channel equals a team.', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82') ('Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb')\n",
      "('It is just in the context of a team, right like essentially Channel equals a team.', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82') ('All right, so there is there is here is a kind of an example.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n",
      "('So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right?', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82') ('Alright, so that is actually a good segue to actually before we do that.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n",
      "('So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right?', '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82') ('All right, so there is there is here is a kind of an example.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n",
      "('Okay, so when could I thought it will be good for us to do a little bit have a dis little bit of a discussion on just the I stack with ether.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41')\n",
      "('Okay, so when could I thought it will be good for us to do a little bit have a dis little bit of a discussion on just the I stack with ether.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right?', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('So I am assuming that a lot of the folks who are seeing.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('On the background and we will touch upon those as well.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('So I am assuming that a lot of the folks who are seeing.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('This will be gone through that that call and got up.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('This will be gone through that that call and got up.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('On the background and we will touch upon those as well.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('This will be gone through that that call and got up.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('All right, but just to reiterate if you look at ethers a I stack there are a few things that that we want to kind of highlight, right?', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('So that is a very interesting aspect of ethers a sec as well and last but not the least.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('Let is say there is a team that is working on software engineering or databases or Our devops in general, right?', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('Let is say you are in a meeting and you are and the team is having a discussion and in an hour is call you are talking about a bunch of different topics.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41')\n",
      "('Let is say there is a team that is working on software engineering or databases or Our devops in general, right?', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('So there is a static idea that they are working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('So there is a static idea that they are working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('On the background and we will touch upon those as well.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('Is that a production issue that is being addressed right now it is that a particular type of database are talking about or you know, a particular aspect of their software engineering stack that they are talking about.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('Being and you are having a discussion, maybe it is a group meeting and you are talking about five different topics in the call or you are talking about, you know, you are doing a two people are talking about one particular subject.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41')\n",
      "('So the first time Idea is idea about Channel or team Minds.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('On the background and we will touch upon those as well.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide.', '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c') ('So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('All right, so there is there is here is a kind of an example.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n",
      "('So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right?', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b')\n",
      "('So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right?', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('Alright, so that is actually a good segue to actually before we do that.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n",
      "('So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b')\n",
      "('So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b')\n",
      "('And then when you pass it through when you have that meeting in the context of a software engineering mind, the discussion summarizes The Ether summarizes the discussion pulls out topics related to software for example things about database continuously ICD kubernetes Etc.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b')\n",
      "('You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right?', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('All right, so it is a great segue into you know, so when we talked about Channel Minds you brought up this notion of the dynamic portion.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b')\n",
      "('You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right?', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that is a very unique way of representing the intelligence of the Insight that is happening in the context of teams and and the organization in a graph format and using this in a variety of different ways.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b')\n",
      "('So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that is associated with it.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('Maybe you can just walk us through this a little bit.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b')\n",
      "('So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that is associated with it.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('All right, so there is there is here is a kind of an example.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n",
      "('So again, let me go back switch to my presentation here.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('Maybe you can just walk us through this a little bit.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b')\n",
      "('So again, let me go back switch to my presentation here.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('Alright, so that is actually a good segue to actually before we do that.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n",
      "('So again, let me go back switch to my presentation here.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('All right, so there is there is here is a kind of an example.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n",
      "('So again, let me go back switch to my presentation here.', '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb') ('Let me actually take this down and show it in a real slack conversation.', '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5')\n",
      "('it is fair play shows how how the channel man is able to differentiate based on the Mind attached to it during the', '2019-10-31T13:38:49Z', '3f01f2032f584b178fafde6b437058ae', '3e7f63d9f4b446a18a0b25758e6020ca') ('So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b')\n",
      "('Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right?', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('And so the way we built ether was to have a lot of flexibility in being able to associate any speechtotext engine to with our for our purposes.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider?', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('So one quick way of kind of talking about the the graph would be that it is a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right?', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right?', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('So one quick way of kind of talking about the the graph would be that it is a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right?', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('I think the the next one is this idea of you know, how once a call is over.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('I think the the next one is this idea of you know, how once a call is over.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('Let is say you are in a meeting and you are and the team is having a discussion and in an hour is call you are talking about a bunch of different topics.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('Should talk about next is the keyphrase extraction, which is sometimes it is hard to blame the entire discussion.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('Let is say you are in a meeting and you are and the team is having a discussion and in an hour is call you are talking about a bunch of different topics.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('And so how do you extract what is Meaningful and what is not so that is another aspect of how either ether zai gets applied to just the meetings their interactions, right?', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('The next is the idea of topic detection using communities, which is a you know, when you there is a there is a meeting that is happening.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('Should talk about next is the keyphrase extraction, which is sometimes it is hard to blame the entire discussion.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('The next is the idea of topic detection using communities, which is a you know, when you there is a there is a meeting that is happening.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right?', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('Being and you are having a discussion, maybe it is a group meeting and you are talking about five different topics in the call or you are talking about, you know, you are doing a two people are talking about one particular subject.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('Should talk about next is the keyphrase extraction, which is sometimes it is hard to blame the entire discussion.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('Being and you are having a discussion, maybe it is a group meeting and you are talking about five different topics in the call or you are talking about, you know, you are doing a two people are talking about one particular subject.', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right?', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right?', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right?', '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41') ('So before we get started a lot of times question comes up when we talk about ether how we do our speechtotext, right?', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77')\n",
      "('That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that is a very unique way of representing the intelligence of the Insight that is happening in the context of teams and and the organization in a graph format and using this in a variety of different ways.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b') ('It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc')\n",
      "('That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that is a very unique way of representing the intelligence of the Insight that is happening in the context of teams and and the organization in a graph format and using this in a variety of different ways.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b') ('So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc')\n",
      "('That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that is a very unique way of representing the intelligence of the Insight that is happening in the context of teams and and the organization in a graph format and using this in a variety of different ways.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b') ('I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad')\n",
      "('So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b') ('I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad')\n",
      "('So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is.', '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b') ('T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Should talk about next is the keyphrase extraction, which is sometimes it is hard to blame the entire discussion.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Maybe you can just give us a quick overview of what channel Minds is.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('When we go to market with our partners, they actually like to use their own speechtotext technology for integrating.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Maybe you can just give us a quick overview of what channel Minds is.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Maybe you can just give us a quick overview of what channel Minds is.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Maybe you can just give us a quick overview of what channel Minds is.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So that is a very interesting aspect of ethers a sec as well and last but not the least.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('When we go to market with our partners, they actually like to use their own speechtotext technology for integrating.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('So that is a very interesting aspect of ethers a sec as well and last but not the least.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('So that is a very interesting aspect of ethers a sec as well and last but not the least.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So, of course, there is also a couple of other things that we are working on.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('So, of course, there is also a couple of other things that we are working on.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('So that is the other kind of unique aspect about how we have built it inside our architecture.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So, of course, there is also a couple of other things that we are working on.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So, of course, there is also a couple of other things that we are working on.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('On the background and we will touch upon those as well.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('On the background and we will touch upon those as well.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('On the background and we will touch upon those as well.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('On the background and we will touch upon those as well.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Maybe you can just give us a quick overview of what channel Minds is.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('On the background and we will touch upon those as well.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('Maybe you can just give us a quick overview of what channel Minds is.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So before we get started a lot of times question comes up when we talk about ether how we do our speechtotext, right?', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So before we get started a lot of times question comes up when we talk about ether how we do our speechtotext, right?', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('We just to kind of lay this out is we do not', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('We just to kind of lay this out is we do not', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible So we', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448')\n",
      "('We just to kind of lay this out is we do not', '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('When we go to market with our partners, they actually like to use their own speechtotext technology for integrating.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('Maybe you can just give us a quick overview of what channel Minds is.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('And so the way we built ether was to have a lot of flexibility in being able to associate any speechtotext engine to with our for our purposes.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('So that is the other kind of unique aspect about how we have built it inside our architecture.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('And so the way we built ether was to have a lot of flexibility in being able to associate any speechtotext engine to with our for our purposes.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So the way we do this is, you know showcases app, which is ether meet.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('We integrate with the close partner called Deep Graham to provide.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('So that is the other kind of unique aspect about how we have built it inside our architecture.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('We integrate with the close partner called Deep Graham to provide.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('Maybe you can just give us a quick overview of what channel Minds is.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality.', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider?', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('So that is the other kind of unique aspect about how we have built it inside our architecture.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider?', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider?', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('So on and so forth, so it is very very flexible.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible So we', '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448') ('I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.', '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c')\n",
      "('I think before before we get started with its II think I think I will just give you a heads up on a thin configuration by it.', '2019-10-31T13:18:46Z', '3f01f2032f584b178fafde6b437058ae', '48da3759d2eb45f49c1ba344eec381ce') ('So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0')\n",
      "('I think before before we get started with its II think I think I will just give you a heads up on a thin configuration by it.', '2019-10-31T13:18:46Z', '3f01f2032f584b178fafde6b437058ae', '48da3759d2eb45f49c1ba344eec381ce') ('So having said that I think I think that should be good enough with the team and then maybe it is good time to get here.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0')\n",
      "('Maybe you know, I sorry for not doing this, but maybe you can just give a quick introduction about yourself.', '2019-10-31T13:18:55Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '642438db75064a729d29f91ac8463dcb') ('So having said that I think I think that should be good enough with the team and then maybe it is good time to get here.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0')\n",
      "('And also maybe give a little bit of background about Ari, I think sure.', '2019-10-31T13:18:55Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '642438db75064a729d29f91ac8463dcb') ('So it is a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0')\n",
      "('And also maybe give a little bit of background about Ari, I think sure.', '2019-10-31T13:18:55Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '642438db75064a729d29f91ac8463dcb') ('I also also like the Imaging and then the video processing and on the text, I mean the speechtotext and and and the whole whole spectrum of the AI ecosystem.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0')\n",
      "('And also maybe give a little bit of background about Ari, I think sure.', '2019-10-31T13:18:55Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '642438db75064a729d29f91ac8463dcb') ('So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0')\n",
      "('So you can kind of get a feel for it as we go on but wine to get started and let us dive in and talk a little bit about Channel Minds.', '2019-10-31T13:20:31Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'e79cf121424c4717afd9092c89923582') ('So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0')\n",
      "('So you can kind of get a feel for it as we go on but wine to get started and let us dive in and talk a little bit about Channel Minds.', '2019-10-31T13:20:31Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'e79cf121424c4717afd9092c89923582') ('So which means I mean, Coming to the language model aspect of it.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('Check just like so eat a graph serves multiple purposes one one being as we talked about it.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('So in that help engine, it is like a it is like a pre fabricating the data such so that it can go into the graph structure.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Check just like so eat a graph serves multiple purposes one one being as we talked about it.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Check just like so eat a graph serves multiple purposes one one being as we talked about it.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('So in that help engine, it is like a it is like a pre fabricating the data such so that it can go into the graph structure.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('So we are in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad')\n",
      "('T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad')\n",
      "('So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data.', '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc') ('So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Yeah, I guess it really we are operating in the text domain.', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad') ('So we are in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Yeah, I guess it really we are operating in the text domain.', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad') ('So presentation so that we can be can you know use it for all sorts of computations.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Yeah, I guess it really we are operating in the text domain.', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad') ('So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('So if it is a speech data we converted to text first if there is Vision data, let us say the slides that need to be processed.', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad') ('So we are in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('So if it is a speech data we converted to text first if there is Vision data, let us say the slides that need to be processed.', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad') ('So presentation so that we can be can you know use it for all sorts of computations.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('So if it is a speech data we converted to text first if there is Vision data, let us say the slides that need to be processed.', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad') ('So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad') ('So presentation so that we can be can you know use it for all sorts of computations.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad') ('So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as', '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad') ('And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself is not are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or nonobvious inside sort of the god Apollo.', '2019-10-31T13:43:27Z', '3f01f2032f584b178fafde6b437058ae', '0028af3fa1cd42fb916efc5ea85f9abe') ('So in that help engine, it is like a it is like a pre fabricating the data such so that it can go into the graph structure.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself is not are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or nonobvious inside sort of the god Apollo.', '2019-10-31T13:43:27Z', '3f01f2032f584b178fafde6b437058ae', '0028af3fa1cd42fb916efc5ea85f9abe') ('And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.', '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d')\n",
      "('Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself is not are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or nonobvious inside sort of the god Apollo.', '2019-10-31T13:43:27Z', '3f01f2032f584b178fafde6b437058ae', '0028af3fa1cd42fb916efc5ea85f9abe') ('So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38')\n",
      "('Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it is too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the', '2019-10-31T13:54:33Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '95a41af139e448c19878b2703b380e0f') ('This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it is too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the', '2019-10-31T13:54:33Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '95a41af139e448c19878b2703b380e0f') ('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it is too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the', '2019-10-31T13:54:33Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '95a41af139e448c19878b2703b380e0f') ('So we just we just so Channel Minds just drops it or even the associated key phrases.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('So I guess it is a very good very quick kind of a real world example of this extracted from real call, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('So moving on I guess the next very I guess very important thing one way.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018')\n",
      "('So I guess it is a very good very quick kind of a real world example of this extracted from real call, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So I guess it is a very good very quick kind of a real world example of this extracted from real call, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So I guess it is a very good very quick kind of a real world example of this extracted from real call, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So I guess it is a very good very quick kind of a real world example of this extracted from real call, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('I will come to the training part A little later, but we just passed it through that are.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('We just passed the context through this algorithm finetuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that is currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right?', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right?', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018')\n",
      "('for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('And then coming to come into the training part of it.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('I will come to the training part A little later, but we just passed it through that are.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so', '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b') ('So and then we score the in the scoring process is what the training aspect is.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So moving on I guess the next very I guess very important thing one way.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So moving on I guess the next very I guess very important thing one way.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('I will come to the training part A little later, but we just passed it through that are.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So moving on I guess the next very I guess very important thing one way.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So moving on I guess the next very I guess very important thing one way.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('We just we just passed this, you know, all the segments.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('One of the things that I always like to say is ether is the world is best meeting somebody engine right there.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that is currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right?', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('Up tents of or hundreds of calls and then we manually curate what are the most important moments given the converse given the meeting given that this meeting is part of a certain Channel.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('How do you Pull out what is important and what is not so maybe you can just quickly run through.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('How do you Pull out what is important and what is not so maybe you can just quickly run through.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c')\n",
      "('How do you Pull out what is important and what is not so maybe you can just quickly run through.', '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018') ('So without without much Concepts so once so, that is how we validate.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('I mean, I think we all had the solution as well.', '2019-10-31T14:07:57Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b411b227696341bba3ef7cc36371c806') ('Right thus often times, you know, people are talking like, you know, in a team of say five six people one a call teams tend to get into discussions, you know, we are going back and forth particular subject and then you move on to some other subject in some other topic and so on right where so how do we kind of use this?', '2019-10-31T14:08:31Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '15c91e41708949e6b6661aa7213b5f70')\n",
      "('Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case.', '2019-10-31T14:07:57Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b411b227696341bba3ef7cc36371c806') ('How do we pull these chapters out of pull these topics out and and show them?', '2019-10-31T14:08:31Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '15c91e41708949e6b6661aa7213b5f70')\n",
      "('Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case.', '2019-10-31T14:07:57Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b411b227696341bba3ef7cc36371c806') ('So the the whole intent of this app does not topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about.', '2019-10-31T14:09:02Z', '3f01f2032f584b178fafde6b437058ae', 'bfb6232992d24ca7af89c09a807be6f6')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Then and I leave The A Team we are we are a team of XnumberX.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('Ml Engineers who are who primarily work on machine learning deployments and also building the stateoftheart machine learning models.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('Ml Engineers who are who primarily work on machine learning deployments and also building the stateoftheart machine learning models.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('Ml Engineers who are who primarily work on machine learning deployments and also building the stateoftheart machine learning models.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('Ml Engineers who are who primarily work on machine learning deployments and also building the stateoftheart machine learning models.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('I mean the feature extractor for the whole process wherein we train we train the neural net.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('So it is a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('I mean as a team they worked on very broader set of are use cases ranging.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('So we stopped with such which talks about each domain when talks about certain certain.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('I also also like the Imaging and then the video processing and on the text, I mean the speechtotext and and and the whole whole spectrum of the AI ecosystem.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('It is just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('I also also like the Imaging and then the video processing and on the text, I mean the speechtotext and and and the whole whole spectrum of the AI ecosystem.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a preloaded, you know library of domain mines be call.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('It is just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('So having said that I think I think that should be good enough with the team and then maybe it is good time to get here.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('So I will just walk you through I will give you a tip.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('So having said that I think I think that should be good enough with the team and then maybe it is good time to get here.', '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0') ('I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5')\n",
      "('Right the fact that when a user is interacting with our tool.', '2019-10-31T14:15:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'dbc27c69e0cb400792109ef93ffa4b9a') ('I mean, I mean relatively so sure so that is what the topic is.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8')\n",
      "('Right the fact that when a user is interacting with our tool.', '2019-10-31T14:15:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'dbc27c69e0cb400792109ef93ffa4b9a') ('So just to just to be just to be aligned with the with the flow.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('Right the fact that when a user is interacting with our tool.', '2019-10-31T14:15:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'dbc27c69e0cb400792109ef93ffa4b9a') ('This is one says even the whole subject is about about software.', '2019-10-31T14:15:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0586a3fbdb6e4276ae19b4f04f5e3311')\n",
      "('Right the fact that when a user is interacting with our tool.', '2019-10-31T14:15:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'dbc27c69e0cb400792109ef93ffa4b9a') ('So so it just it is just able to put them together aggressive.', '2019-10-31T14:16:29Z', '3f01f2032f584b178fafde6b437058ae', 'fb2a244ad7bf446f9b97a082430c6a27')\n",
      "('Yep at the manual tasks that they do very naturally helps reinforce our a models.', '2019-10-31T14:15:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'dbc27c69e0cb400792109ef93ffa4b9a') ('So just to just to be just to be aligned with the with the flow.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('Yep at the manual tasks that they do very naturally helps reinforce our a models.', '2019-10-31T14:15:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'dbc27c69e0cb400792109ef93ffa4b9a') ('And then how we trial how we trial is as I said, it is more of it.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('Yep at the manual tasks that they do very naturally helps reinforce our a models.', '2019-10-31T14:15:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'dbc27c69e0cb400792109ef93ffa4b9a') ('Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('Yep at the manual tasks that they do very naturally helps reinforce our a models.', '2019-10-31T14:15:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'dbc27c69e0cb400792109ef93ffa4b9a') ('So so it just it is just able to put them together aggressive.', '2019-10-31T14:16:29Z', '3f01f2032f584b178fafde6b437058ae', 'fb2a244ad7bf446f9b97a082430c6a27')\n",
      "('So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('Youll recall or wherein we do not want to miss anything that has an accent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So maybe you can quickly run through how we pull out action items.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('Youll recall or wherein we do not want to miss anything that has an accent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('So maybe you can quickly run through how we pull out action items.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('So maybe you can quickly run through how we pull out action items.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('So maybe you can quickly run through how we pull out action items.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So maybe you can quickly run through how we pull out action items.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So maybe you can quickly run through how we pull out action items.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('What are the action items that are that it that they either bought things as an action items and then and then and then gives gives away.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So maybe you can quickly run through how we pull out action items.', '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('Okay, cool, so I guess here is a taking a quick example, so here are three different segments, right?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So that is why we find you this classifier to have a highest possible.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('Okay, cool, so I guess here is a taking a quick example, so here are three different segments, right?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('Okay, cool, so I guess here is a taking a quick example, so here are three different segments, right?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So I am just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we have done some amount of proof of Concepts and investigation into it and we plan to do more on this.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved.', '2019-10-31T14:24:42Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a939ecf68bc24d3895eef49731912d5c')\n",
      "('Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('What we do is we just we just pass the center.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So obviously and and I will just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('You are very nuanced and these types of actions are actually pulled out automatically from the conversations.', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('You are very nuanced and these types of actions are actually pulled out automatically from the conversations.', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('You are very nuanced and these types of actions are actually pulled out automatically from the conversations.', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('We are also able to extract who it is assigned to write based on who is present in the call.', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('Youll recall or wherein we do not want to miss anything that has an accent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('We are also able to extract who it is assigned to write based on who is present in the call.', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('We are also able to extract who it is assigned to write based on who is present in the call.', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('We are also able to extract who it is assigned to write based on who is present in the call.', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('We are also able to extract who it is assigned to write based on who is present in the call.', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('And you know who is speaking and who is the recipient and so on?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28')\n",
      "('And you know who is speaking and who is the recipient and so on?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('And you know who is speaking and who is the recipient and so on?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('So obviously and and I will just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('And you know who is speaking and who is the recipient and so on?', '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7') ('We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved.', '2019-10-31T14:24:42Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a939ecf68bc24d3895eef49731912d5c') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved.', '2019-10-31T14:24:42Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a939ecf68bc24d3895eef49731912d5c') ('So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved.', '2019-10-31T14:24:42Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a939ecf68bc24d3895eef49731912d5c') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So I think with the headset that you gave about the channel Minds I meant that that is like a thousand feet free of what channel mine does.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So which means I mean, Coming to the language model aspect of it.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('So I think with the headset that you gave about the channel Minds I meant that that is like a thousand feet free of what channel mine does.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('So I think with the headset that you gave about the channel Minds I meant that that is like a thousand feet free of what channel mine does.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('It is just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('It is just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So I will just walk you through I will give you a tip.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So which means I mean, Coming to the language model aspect of it.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('So I will just walk you through I will give you a tip.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('Once we once we have the language model, that is fine tune.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So I will just walk you through I will give you a tip.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So so that is where the channel mind comes into play when we say mine.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So which means I mean, Coming to the language model aspect of it.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So when when a user is invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('The model is the actual neural network model and the mind is is the graph data structure that organizes the information.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('The model is the actual neural network model and the mind is is the graph data structure that organizes the information.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('I mean the feature extractor for the whole process wherein we train we train the neural net.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('That means we keep on adding the the new domains to our domain Library.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('I mean the feature extractor for the whole process wherein we train we train the neural net.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So which means I mean, Coming to the language model aspect of it.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('I mean the feature extractor for the whole process wherein we train we train the neural net.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('I mean the feature extractor for the whole process wherein we train we train the neural net.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('I mean the feature extractor for the whole process wherein we train we train the neural net.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a preloaded, you know library of domain mines be call.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('That means we keep on adding the the new domains to our domain Library.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a preloaded, you know library of domain mines be call.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a preloaded, you know library of domain mines be call.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('So we stopped with such which talks about each domain when talks about certain certain.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('That means we keep on adding the the new domains to our domain Library.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('So we stopped with such which talks about each domain when talks about certain certain.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd')\n",
      "('So we stopped with such which talks about each domain when talks about certain certain.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So we stopped with such which talks about each domain when talks about certain certain.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('So so that is where the channel mind comes into play when we say mine.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('It is a wonder my mind is software engineering the other one could be markers.', '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5') ('We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there is an unknown speaker.', '2019-10-31T14:27:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a710f5a0577544f5b83550f11a02fa2f') ('Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there is an unknown speaker.', '2019-10-31T14:27:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a710f5a0577544f5b83550f11a02fa2f') ('So obviously and and I will just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there is an unknown speaker.', '2019-10-31T14:27:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a710f5a0577544f5b83550f11a02fa2f') ('We are continually creating a library of our signature using standard MFC sea bass techniques and creating patterns and storing them for every speaker that we know and then as we detect changes in those patterns, we we kind of apply that to speaker dilation and then if the signature actually matches someone in our database', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('Maybe someone can manually tag it and so on using our user interface, right?', '2019-10-31T14:27:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a710f5a0577544f5b83550f11a02fa2f') ('Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('Maybe someone can manually tag it and so on using our user interface, right?', '2019-10-31T14:27:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a710f5a0577544f5b83550f11a02fa2f') ('So we are working on a technique where we can detect that the slide is being presented and then automatically pull out information from that using Standard computer vision techniques and then once the vision was a slight information is converted to text a lot of the same information can be used in terms of applying what is relevant and what is not and what is the topic and what is a keyword and so on so forth, right?', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('So we do not need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also', '2019-10-31T14:27:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a710f5a0577544f5b83550f11a02fa2f') ('Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('So we do not need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also', '2019-10-31T14:27:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a710f5a0577544f5b83550f11a02fa2f') ('So I am just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we have done some amount of proof of Concepts and investigation into it and we plan to do more on this.', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('Hopefully this gives you a pretty good idea to the viewer about the different things types of things that we use in either for AI and I guess in a different discussion, I guess maybe we can go into how actually a lot of this is operationalized inside our deployments, but that is a discussion for another day.', '2019-10-31T14:27:25Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b623465fc8024dee92d363bfd236281f') ('So we are working on a technique where we can detect that the slide is being presented and then automatically pull out information from that using Standard computer vision techniques and then once the vision was a slight information is converted to text a lot of the same information can be used in terms of applying what is relevant and what is not and what is the topic and what is a keyword and so on so forth, right?', '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416')\n",
      "('That means we keep on adding the the new domains to our domain Library.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('Once we once we have the language model, that is fine tune.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('That means we keep on adding the the new domains to our domain Library.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So when when a user is invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So when when a user is invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('So so that is where the channel mind comes into play when we say mine.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So when when a user is invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('So which means I mean, Coming to the language model aspect of it.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('So which means I mean, Coming to the language model aspect of it.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('So so that is where the channel mind comes into play when we say mine.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you are doing earlier, right?', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you are doing earlier, right?', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('The model is the actual neural network model and the mind is is the graph data structure that organizes the information.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you are doing earlier, right?', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('So so that is where the channel mind comes into play when we say mine.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('Let is say the if the engineering teams talks about production.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('Let is say the if the engineering teams talks about production.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('Once we once we have the language model, that is fine tune.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15')\n",
      "('Let is say the if the engineering teams talks about production.', '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.', '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15') ('Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.', '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6')\n",
      "('So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38') ('So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38') ('So that is how the evaluation of you know, relationships happened within the that is one of the example that I just gave program give you an idea of how computation graph works.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38') ('So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we are going to talk about a little so so so and also other top XO from the from the from the computation graph perspective.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('So having said that I will just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38') ('So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('So having said that I will just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38') ('So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we are going to talk about a little so so so and also other top XO from the from the from the computation graph perspective.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('So we are in the in the computation graph as we as mentioned earlier.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38') ('So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we are going to talk about a little so so so and also other top XO from the from the from the computation graph perspective.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38') ('What bought the nodes could be along with the the factual notes like the users and favorite pics.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks.', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38') ('They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n",
      "('So say for example, if I have to give you one example of how the how the body is nonintuitive relations could be is you know, let us say let us say let us say Karthik talked about kubernetes in one of the in couple of calls', '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38') ('So that is how the evaluation of you know, relationships happened within the that is one of the example that I just gave program give you an idea of how computation graph works.', '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What are the use cases that we always talk about is, you know a lot of times when you have a meeting, let us say you and I are having this call and then we produce a summary it will be always good to know who should you know, what people who are would actually likely to watch this, right?', '2019-10-31T13:50:45Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2e6829cebf67481d95955e3afdf08c5b') ('We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('Yeah, and so kind of generating this idea of who are the recommended Watchers.', '2019-10-31T13:50:45Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2e6829cebf67481d95955e3afdf08c5b') ('Yeah, so so it actually brings it to one more notion.', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('Youre a discussion right are more importantly, you know, as we see in ecommerce lot of times right you buy this product you also You know you get this common thing that saves users who bought this are also interested in these other types of products, right?', '2019-10-31T13:50:45Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2e6829cebf67481d95955e3afdf08c5b') ('Yeah, so so it actually brings it to one more notion.', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('So those types of things can be applied to Enterprise intelligence as well because a lot of times T teams keep discussing the same subjects again and again, right so it is very common that in a team for example in an engineering team a particular type of databases that you know is being considered for their architecture, you know, the engineer leaves the company goes away voila six months later.', '2019-10-31T13:50:45Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2e6829cebf67481d95955e3afdf08c5b') ('Yeah, so so it actually brings it to one more notion.', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('A new person comes and then he comes and talks about the same subject right ether can very easily extract the idea that this discussion has happened before and actually say hey now that you are discussing this subject.', '2019-10-31T13:50:45Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2e6829cebf67481d95955e3afdf08c5b') ('We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('You may also want to follow up on this other topic right?', '2019-10-31T13:50:45Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2e6829cebf67481d95955e3afdf08c5b') ('Yeah, so so it actually brings it to one more notion.', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('You may also want to follow up on this other topic right?', '2019-10-31T13:50:45Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2e6829cebf67481d95955e3afdf08c5b') ('We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('Are you watch this other discussion that happened a few months ago and that makes teams just work a lot efficiently and save a lot of time in going back and forth, right?', '2019-10-31T13:50:45Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2e6829cebf67481d95955e3afdf08c5b') ('We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6')\n",
      "('We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?', '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6') ('That is just a quick example at a sample of what we do.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b')\n",
      "('I do not know if you are able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('So let me just put it in my queuing for the scoring in the next steps.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('I do not know if you are able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('So one is we are able to we took essentially one of the workspaces and map the interactions into a into a graph here and let us say we want to find out who the goo.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('So one is we are able to we took essentially one of the workspaces and map the interactions into a into a graph here and let us say we want to find out who the goo.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('So one is we are able to we took essentially one of the workspaces and map the interactions into a into a graph here and let us say we want to find out who the goo.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('So those types of relationships can be gleaned very easily from the knowledge graph, right like so for example in this particular case when we run this query about who is who is a personal talked about Google these three people who come up myself Cullen and Karthik right where we talk a lot about Google.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('So these types of relationships get pulled out very easily from the knowledge.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('So so what we do is it is a two step process.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('That is just a quick example at a sample of what we do.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('That is just a quick example at a sample of what we do.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('So so what we do is it is a two step process.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('That is just a quick example at a sample of what we do.', '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b') ('We do not have any context of what is important and what is not important.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf')\n",
      "('This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('But what we do is when we say topic identification or be identified the potential important moments in the call.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('But what we do is when we say topic identification or be identified the potential important moments in the call.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('But what we do is when we say topic identification or be identified the potential important moments in the call.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So we just we just so Channel Minds just drops it or even the associated key phrases.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('But what we do is when we say topic identification or be identified the potential important moments in the call.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('But what we do is when we say topic identification or be identified the potential important moments in the call.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('But what we do is when we say topic identification or be identified the potential important moments in the call.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So we just we just so Channel Minds just drops it or even the associated key phrases.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So so what we do is it is a two step process.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So so what we do is it is a two step process.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('And then coming to come into the training part of it.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So we just we just so Channel Minds just drops it or even the associated key phrases.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('We do not have any context of what is important and what is not important.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('We do not have any context of what is important and what is not important.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('We do not have any context of what is important and what is not important.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('All we know is this this this diagram or the three words combination sounds as if it is an important people.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('All we know is this this this diagram or the three words combination sounds as if it is an important people.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So let me just put it in my queuing for the scoring in the next steps.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('So let me just put it in my queuing for the scoring in the next steps.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So let me just put it in my queuing for the scoring in the next steps.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So one of these data sets that we use for our general benchmarking is this SST wherein it captures all the sentence similarity task action.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618')\n",
      "('So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of', '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('Whole context of the either the topic of the important movement.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('Text and then we correlate that with the context associated with the channel Minds at the end of this this whole process this multi step three step process.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('Whole context of the either the topic of the important movement.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('We just passed the context through this algorithm finetuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('And then coming to come into the training part of it.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('Need to be captured as a as an important environmental issues as an important topic of the people.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So we just we just so Channel Minds just drops it or even the associated key phrases.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So we just we just so Channel Minds just drops it or even the associated key phrases.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So we just we just so Channel Minds just drops it or even the associated key phrases.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64')\n",
      "('So we just we just so Channel Minds just drops it or even the associated key phrases.', '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618') ('What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64') ('When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64') ('When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64') ('What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('And then coming to come into the training part of it.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64') ('When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64') ('We just passed the context through this algorithm finetuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64') ('When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64') ('What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.', '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64') ('What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.', '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d')\n",
      "('Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('We come up from the initial filtration of their performance and then we pass all those candidate models.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('So without without much Concepts so once so, that is how we validate.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('We should also, you know, improve our improve or adapt to the validation data that we create.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('I will come to the training part A little later, but we just passed it through that are.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('I will come to the training part A little later, but we just passed it through that are.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('We come up from the initial filtration of their performance and then we pass all those candidate models.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('What is the score for a certain segment when you say segment?', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('So without without much Concepts so once so, that is how we validate.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('What is the score for a certain segment when you say segment?', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('What is the score for a certain segment when you say segment?', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('We just we just passed this, you know, all the segments.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('What is the score for a certain segment when you say segment?', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('I mean we need not worry about the what do you call the quantifiable T of the score because you know, it is all relative.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('What is the score for a certain segment when you say segment?', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('So each segment will have relative score on of course passes through certain minimal threshold.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('It is like a Texan which is actually fairly selfcontained either either.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that is currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right?', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that is currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right?', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So and then we score the in the scoring process is what the training aspect is.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So and then we score the in the scoring process is what the training aspect is.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('We come up from the initial filtration of their performance and then we pass all those candidate models.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So and then we score the in the scoring process is what the training aspect is.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('So without without much Concepts so once so, that is how we validate.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So and then we score the in the scoring process is what the training aspect is.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So and then we score the in the scoring process is what the training aspect is.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('So this scoring box and then what what comes out is again.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So and then we score the in the scoring process is what the training aspect is.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('So each segment will have relative score on of course passes through certain minimal threshold.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('We come up from the initial filtration of their performance and then we pass all those candidate models.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('Through this validation data on this we keep updating this validation data so that we can we can safely say that if it passes the validation set because it has not seen those validation satyr during training if it passes the validation set we can fairly say that we can deploy that into the, you know, Ever Changing dynamics of the team.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('So without without much Concepts so once so, that is how we validate.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('We should also, you know, improve our improve or adapt to the validation data that we create.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('I mean we need not worry about the what do you call the quantifiable T of the score because you know, it is all relative.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So what we do is when we do this the similarity task, you know finetuning of the language model.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So what we do is when we do this the similarity task, you know finetuning of the language model.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('So without without much Concepts so once so, that is how we validate.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So what we do is when we do this the similarity task, you know finetuning of the language model.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('What we do is we have we we continuously create a list of summaries.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('We come up from the initial filtration of their performance and then we pass all those candidate models.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('What we do is we have we we continuously create a list of summaries.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('So without without much Concepts so once so, that is how we validate.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('What we do is we have we we continuously create a list of summaries.', '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c') ('We just we just passed this, you know, all the segments.', '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d')\n",
      "('So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graphbased for this.', '2019-10-31T14:10:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0fd2a6dbbea446c88b98dd6cd79958e7') ('But otherwise if in another call we talked about Lambda base deployments for a whole lot of XnumberX minutes.', '2019-10-31T14:09:02Z', '3f01f2032f584b178fafde6b437058ae', 'bfb6232992d24ca7af89c09a807be6f6')\n",
      "('So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graphbased for this.', '2019-10-31T14:10:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0fd2a6dbbea446c88b98dd6cd79958e7') ('Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407')\n",
      "('So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graphbased for this.', '2019-10-31T14:10:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0fd2a6dbbea446c88b98dd6cd79958e7') ('So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407')\n",
      "('So the the whole intent of this app does not topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about.', '2019-10-31T14:09:02Z', '3f01f2032f584b178fafde6b437058ae', 'bfb6232992d24ca7af89c09a807be6f6') ('So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they are moving back and forth.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407')\n",
      "('So the the whole intent of this app does not topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about.', '2019-10-31T14:09:02Z', '3f01f2032f584b178fafde6b437058ae', 'bfb6232992d24ca7af89c09a807be6f6') ('So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407')\n",
      "('Let is say what we do is when you are as you have shown in the example at wearing one Call we are run through all the multiple channels of then we got different sub arrays.', '2019-10-31T14:09:02Z', '3f01f2032f584b178fafde6b437058ae', 'bfb6232992d24ca7af89c09a807be6f6') ('So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407')\n",
      "('We talked about Recruitment and also the product strategy what it does is most likely could put Lambda and deployment the same topic because you know, they have been discussed together.', '2019-10-31T14:09:02Z', '3f01f2032f584b178fafde6b437058ae', 'bfb6232992d24ca7af89c09a807be6f6') ('It just would be found between them but no, it should be formed between Docker or the recruitment because even though they are talked in the same conversation or even inverse cos they are actually talked right one after the other because', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407')\n",
      "('So it is like a fairly flexible topic slicing algorithm that we that we have in place a topic extraction.', '2019-10-31T14:09:02Z', '3f01f2032f584b178fafde6b437058ae', 'bfb6232992d24ca7af89c09a807be6f6') ('Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407')\n",
      "('So again the action item as a whole is not just a model here sigh that is what I wanted to highlight here.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So again the action item as a whole is not just a model here sigh that is what I wanted to highlight here.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So this This fairly has nothing to do with the with the language model that we discussed earlier.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I am okay to have a lot of noise in the carrot patch.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I am okay to have a lot of noise in the carrot patch.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('That is why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I am okay to have a lot of noise in the carrot patch.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('Sorry, but I do not want to miss even a single action item.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('Sorry, but I do not want to miss even a single action item.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So that is why we find you this classifier to have a highest possible.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So that is why we find you this classifier to have a highest possible.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So that is why we find you this classifier to have a highest possible.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('Youll recall or wherein we do not want to miss anything that has an accent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('Youll recall or wherein we do not want to miss anything that has an accent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('Youll recall or wherein we do not want to miss anything that has an accent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('Youll recall or wherein we do not want to miss anything that has an accent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('There is if they have seen a lot of exotic references like that.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('Mmm, but we are okay to have lot of that means if I capture XnumberX out of XnumberX candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('I am okay to have only four of them being the real action items, but I do not want to miss even one of the action items one of those pork perfect.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So so so we have trained a language model to finetune such that we can be we have adopted that language model to be a binary classifier.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So so so we have trained a language model to finetune such that we can be we have adopted that language model to be a binary classifier.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So so so we have trained a language model to finetune such that we can be we have adopted that language model to be a binary classifier.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So this This fairly has nothing to do with the with the language model that we discussed earlier.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So so so we have trained a language model to finetune such that we can be we have adopted that language model to be a binary classifier.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('What we do is we just we just pass the center.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('Should I just like I think when we say action items, let us let me put one point before we talk about it.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('But as a total it has actually it has identified only XnumberX, even though the noise is list.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('That is why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('What we do is we just we just pass the center.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0')\n",
      "('We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.', '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they are moving back and forth.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they are moving back and forth.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they are moving back and forth.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So what we do is we just organized the meeting into the graph that that is fairly simple because you know, you have lot of this text segments and then we we have eat them as the node.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So what we do is we just organized the meeting into the graph that that is fairly simple because you know, you have lot of this text segments and then we we have eat them as the node.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('And then we have a graph a graph with with all these conversations as a notes.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('It just would be found between them but no, it should be formed between Docker or the recruitment because even though they are talked in the same conversation or even inverse cos they are actually talked right one after the other because', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8')\n",
      "('It just would be found between them but no, it should be formed between Docker or the recruitment because even though they are talked in the same conversation or even inverse cos they are actually talked right one after the other because', '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407') ('What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('What we do is we just we just pass the center.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('So how do we do that is we have actually collected lot of training data for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('What we do is we just we just pass the center.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So that means as soon as we get this speech segments from specific sequence from the call, right?', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('Should I just like I think when we say action items, let us let me put one point before we talk about it.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('Should I just like I think when we say action items, let us let me put one point before we talk about it.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('Say for example, if there is an action item detected by the candidate, but I did not find any grammatically relevant subject in them.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('Should I just like I think when we say action items, let us let me put one point before we talk about it.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('Say for example, if there is an action item detected by the candidate, but I did not find any grammatically relevant subject in them.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('That is why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect.', '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0') ('So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('So just to just to be just to be aligned with the with the flow.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('A nation of community algorithm parameters and the language model performance.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('And then how we trial how we trial is as I said, it is more of it.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('Actually, there was strong association between within XnumberX people where in most of the people are connected with most of the others.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('It comes from the language model finetuning which has nothing to do with the communities.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('I mean, I mean relatively so sure so that is what the topic is.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('And then how we trial how we trial is as I said, it is more of it.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('I mean, I mean relatively so sure so that is what the topic is.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.', '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8') ('What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.', '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc')\n",
      "('Got it tigers have wanted to show a quick example of how this works.', '2019-10-31T14:15:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0586a3fbdb6e4276ae19b4f04f5e3311') ('So they end up as a topics or to the as we go granular.', '2019-10-31T14:16:29Z', '3f01f2032f584b178fafde6b437058ae', 'fb2a244ad7bf446f9b97a082430c6a27')\n",
      "('Things like that and then they went back Arjun venkat and three shots now talked about databases.', '2019-10-31T14:15:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0586a3fbdb6e4276ae19b4f04f5e3311') ('I hear it did not actually slice the whole databases databases singled out because it just reaches talked about database and run something related to deployment together.', '2019-10-31T14:16:29Z', '3f01f2032f584b178fafde6b437058ae', 'fb2a244ad7bf446f9b97a082430c6a27')\n",
      "('Things like that and then they went back Arjun venkat and three shots now talked about databases.', '2019-10-31T14:15:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0586a3fbdb6e4276ae19b4f04f5e3311') ('That means if we talk only about databases on the deployment, it would have done the other way like click diplomatic conversations and then they database so that is the level of flexible.', '2019-10-31T14:16:29Z', '3f01f2032f584b178fafde6b437058ae', 'fb2a244ad7bf446f9b97a082430c6a27')\n",
      "('I guess, you know different topics are different groups of topics and the people involved in those conversations are pulled out a very elegant way I think is very cool.', '2019-10-31T14:15:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0586a3fbdb6e4276ae19b4f04f5e3311') ('So so it just it is just able to put them together aggressive.', '2019-10-31T14:16:29Z', '3f01f2032f584b178fafde6b437058ae', 'fb2a244ad7bf446f9b97a082430c6a27')\n",
      "('That means if we talk only about databases on the deployment, it would have done the other way like click diplomatic conversations and then they database so that is the level of flexible.', '2019-10-31T14:16:29Z', '3f01f2032f584b178fafde6b437058ae', 'fb2a244ad7bf446f9b97a082430c6a27') ('So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n",
      "('Granular Kappa can get you can go from the top level where in you have totally relevant unrelated topics discussed.', '2019-10-31T14:16:29Z', '3f01f2032f584b178fafde6b437058ae', 'fb2a244ad7bf446f9b97a082430c6a27') ('So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier.', '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 397, \"module\": \"grouper_segments\", \"outlier threshold is : \": 0.5197237730026245, \"ts\": \"2020-02-24T09:49:40.422668Z\", \"msg\": \"Outlier Score\"}\n",
      "{\"level\": \"info\", \"filename\": \"grouper_segments.py\", \"lineno\": 1041, \"module\": \"grouper_segments\", \"edges before prunning\": 3184, \"edges after prunning\": 3184, \"modularity\": 0.7191883095279836, \"ts\": \"2020-02-24T09:49:43.842280Z\", \"msg\": \"Meeting Graph results\"}\n",
      "cluster before alteration=========>\n",
      "What we have done is we have had to hack the data hunger of the more of the neural network language models.\n",
      "I because we get the data in a very small increments for the machine learning model.\n",
      "So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it is a static component.\n",
      "And then in the meantime, we do not want to lose the information that we have.\n",
      "So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.\n",
      "So that is kind of the engineering that we did for the channel Minds got it.\n",
      "So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.\n",
      "So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.\n",
      "So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.\n",
      "That means that that it can it can read all the information that it gives every every every minute or so, whereas somewhat relatively static is the channel language model which we update once we have enough information for a neural network to be fine, too.\n",
      "I mean the feature extractor for the whole process wherein we train we train the neural net.\n",
      "We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you are doing earlier, right?\n",
      "The model is the actual neural network model and the mind is is the graph data structure that organizes the information.\n",
      "I I think I think we can on the validation component.\n",
      "So so that is where the channel mind comes into play when we say mine.\n",
      "I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.\n",
      "Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.\n",
      "Once we once we have the language model, that is fine tune.\n",
      "What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data.\n",
      "I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.\n",
      "Action that is coming, you know to The Ether AI engine if you are it.\n",
      "So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated.\n",
      "How is that attach to the with a slack Channel and then how it how the channel Minds selfgenerated right?\n",
      "What we do is actually there are there is a twostage validation one is one is the language model that we that we have two other people which is well, which is actually finetune various tasks.\n",
      "When I say a task it is it is like asking asking the language model to predict whether whether a sentence is at whether a sentence whether two sentences are continuous.\n",
      "Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations.\n",
      "So so we have we have fairly statistical validation approaches to validate this auxiliary tasks.\n",
      "Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.\n",
      "So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.\n",
      "So I will just walk you through I will give you a tip.\n",
      "So which means I mean, Coming to the language model aspect of it.\n",
      "Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a preloaded, you know library of domain mines be call.\n",
      "That means we keep on adding the the new domains to our domain Library.\n",
      "So when when a user is invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel.\n",
      "We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.\n",
      "These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether.\n",
      "I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.\n",
      "So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans.\n",
      "Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion.\n",
      "I think before before we get started with its II think I think I will just give you a heads up on a thin configuration by it.\n",
      "So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know.\n",
      "So having said that I think I think that should be good enough with the team and then maybe it is good time to get here.\n",
      "Maybe you know, I sorry for not doing this, but maybe you can just give a quick introduction about yourself.\n",
      "And also maybe give a little bit of background about Ari, I think sure.\n",
      "So it is a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor.\n",
      "I also also like the Imaging and then the video processing and on the text, I mean the speechtotext and and and the whole whole spectrum of the AI ecosystem.\n",
      "So I think with the headset that you gave about the channel Minds I meant that that is like a thousand feet free of what channel mine does.\n",
      "Then and I leave The A Team we are we are a team of XnumberX.\n",
      "Ml Engineers who are who primarily work on machine learning deployments and also building the stateoftheart machine learning models.\n",
      "I mean as a team they worked on very broader set of are use cases ranging.\n",
      "Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe.\n",
      "So we stopped with such which talks about each domain when talks about certain certain.\n",
      "It is just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period.\n",
      "It is a wonder my mind is software engineering the other one could be markers.\n",
      "Let is say the if the engineering teams talks about production.\n",
      "I guess one way to talk about that would be there is a static component.\n",
      "cluster before alteration=========>\n",
      "So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation.\n",
      "So let me get just started my mind Generations on the top.\n",
      "So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is wellversed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model.\n",
      "So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering.\n",
      "So so this this just shows how how the chat the domain Minds, you know shapeshifts into the channel and by learning all the information that it gets from the conversations.\n",
      "So a quick heads up on this on this slide because this puts everything I can with my cousin in one single view.\n",
      "So we we we use open data to to you know, generate generate a fix.\n",
      "A library of domain Minds as as we mentioned some of the samples here some this is ever growing we keep on adding so to this list.\n",
      "It is a simple example would be a bug a bug in nature may be different from the bug in a software engineering model.\n",
      "So this domain mind gets it domain language for who gets attached to the to the channel when the user says invites you to the channel.\n",
      "So from once we have this domain language model right as we were talking about the domain minder.\n",
      "Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind.\n",
      "We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds.\n",
      "So so this is this is fairly simple, you know, simple.\n",
      "Were in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier.\n",
      "This is likelihood that with the talk about a double s Lambda also, it means that they seem to be talking about a similar as similar aspect for that certain Tim.\n",
      "So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team.\n",
      "That is on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel.\n",
      "It is just in the context of a team, right like essentially Channel equals a team.\n",
      "That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph.\n",
      "So that means if someone is talking about deployment aunt and then if in a certain channel is if they always associate deployment with let us say AWS Lambda.\n",
      "So this relationship is learned that when there is an aid of a deployment.\n",
      "So this is kind of relationship that this combination of language model undermined men captures.\n",
      "Okay as we mentioned so domain Channel mine is fairly Dynamic.\n",
      "So every time every time there is a new conversation that comes in the comes in the eater.\n",
      "Calls there would be there would be scored or they would be compared against this domain mind till we have the transformation to the channel Minds.\n",
      "So that is this is where you know, you have the real learning component of Egypt\n",
      "cluster before alteration=========>\n",
      "So we are in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature.\n",
      "And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.\n",
      "I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as\n",
      "So in that help engine, it is like a it is like a pre fabricating the data such so that it can go into the graph structure.\n",
      "So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.\n",
      "Check just like so eat a graph serves multiple purposes one one being as we talked about it.\n",
      "So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior.\n",
      "You know, Knowledge Graph like the factual graph on The Ether graph.\n",
      "I will talk about the difference just just in a minute, but but so what we are trying to say here is along with the actual factual information like who spoke what or or what are the you know who attended the meeting so these Services enable The Ether\n",
      "It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.\n",
      "So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data.\n",
      "T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction.\n",
      "A source would just go as is to the general feeling.\n",
      "Yeah, I guess it really we are operating in the text domain.\n",
      "So if it is a speech data we converted to text first if there is Vision data, let us say the slides that need to be processed.\n",
      "So presentation so that we can be can you know use it for all sorts of computations.\n",
      "Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself is not are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or nonobvious inside sort of the god Apollo.\n",
      "So we again use the associated domain language model of the custom custom Channel language model for for feature is Amal the text that picket and then and then we also bring in the notion of Miles here.\n",
      "In terms of its relevance relevance and other aspects caps in other aspects.\n",
      "cluster before alteration=========>\n",
      "And then what we what we do is we just put it through a graph neural networks kind or the different graph algorithms.\n",
      "So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we are going to talk about a little so so so and also other top XO from the from the from the computation graph perspective.\n",
      "So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations.\n",
      "It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks.\n",
      "All the users will have their own representation that not just captures what who they are.\n",
      "Something like, you know, if I am part of a channel that is a very direct relationship which does not require a lot of intelligence which is get it right out of the station.\n",
      "Whereas when I say, hey, you know Karthik follow up on this production issue, you know the idea that Karthik is the person who I am assigning this action to is something that is not so intuitive and needs to be gleaned right by first applying NLP in these types of rules then later on also being getting represented in the laugh\n",
      "So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik.\n",
      "So so so what it does is it also forms a relation between Karthik as anode which is the user and then the kubernetes as a topic and then says you know here Initially then as as as as more and more conversations around kubernetes are happening.\n",
      "So how in fact we can even take consensus just because Karthik is talking we need not say that he could be an expert.\n",
      "But if I orthotic that means every time Karthik talks about kubernetes if you are a watch it so which which makes in which makes him kind of we approve his Dont open it is and that we captured that inside to and then reinforce that that relationship as a Karthik is an expert in kubernetes.\n",
      "You know, I would rather than that we use like the node embeddings what I mean by no damn wedding is when there is Karthik so we do not just we do not just see Karthik as you know a person so we also input all the information that he that actually this ether captures about about that.\n",
      "But but what they come as a combination represents, so once they have this as a mathematical object, like like a like a embedding what we can do is we can do lot of you know algorithms on because we are free to do all the math around it and then we can you can get for the similar users to kartik from the context of you know, the topics that that he discusses or from the context of the action items.\n",
      "Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.\n",
      "So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get.\n",
      "So that is how the evaluation of you know, relationships happened within the that is one of the example that I just gave program give you an idea of how computation graph works.\n",
      "They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting.\n",
      "Yes, I eat a graph is more of a traditional representation of God.\n",
      "Yes, it is teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them.\n",
      "Okay and then I guess once you have these types of graphs.\n",
      "That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.\n",
      "So we we just organize the topics key phrases captured as the notes on that.\n",
      "Just think of integrating these insights into you know, a ticket management tool like jira, right?\n",
      "So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this.\n",
      "If you do not talk about anything else if direct enables us to form the you know, form the form this noninductive relationships like talked about a certain topic or action item assigned to so now let us take forward and then use This graph that is actually being formed after all the conversations.\n",
      "So having said that I will just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component.\n",
      "And then what comes out is actually a lot more, you know a lot more insights that will enable us to do like very nonintuitive recommendations.\n",
      "So as you said the example that you gave write a card they can you follow the on this can come as part of the conversation in the free text, you know free language.\n",
      "So we are in the in the computation graph as we as mentioned earlier.\n",
      "So say for example, if I have to give you one example of how the how the body is nonintuitive relations could be is you know, let us say let us say let us say Karthik talked about kubernetes in one of the in couple of calls\n",
      "What bought the nodes could be along with the the factual notes like the users and favorite pics.\n",
      "So as I talked about that Karthik being expert in a in kubernetes, right so that can be formed from the from some of this.\n",
      "The talked about can get interest into is a is an expert in tuber natives even say that is very cool.\n",
      "That means all the relationships about the topics whom he follows or whom who I mean, what are the topics that he usually discusses and then we just call that whole component and then we encode everything into into the cottage.\n",
      "cluster before alteration=========>\n",
      "What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.\n",
      "We do not have any context of what is important and what is not important.\n",
      "So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.\n",
      "So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.\n",
      "So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are.\n",
      "When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.\n",
      "Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows.\n",
      "So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.\n",
      "So let me just put it in my queuing for the scoring in the next steps.\n",
      "So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it.\n",
      "It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.\n",
      "All we know is this this this diagram or the three words combination sounds as if it is an important people.\n",
      "We just passed the context through this algorithm finetuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know.\n",
      "So so what we do is it is a two step process.\n",
      "Text and then we correlate that with the context associated with the channel Minds at the end of this this whole process this multi step three step process.\n",
      "So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.\n",
      "Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.\n",
      "So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point.\n",
      "So we just we just so Channel Minds just drops it or even the associated key phrases.\n",
      "Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it is too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the\n",
      "This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.\n",
      "So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.\n",
      "So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right?\n",
      "for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so\n",
      "What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.\n",
      "And then coming to come into the training part of it.\n",
      "So when you have see how it comes is when you have let us say the conversation about machine learning or or any software engineering related.\n",
      "This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.\n",
      "So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.\n",
      "But what we do is when we say topic identification or be identified the potential important moments in the call.\n",
      "So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of\n",
      "So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms.\n",
      "So one of these data sets that we use for our general benchmarking is this SST wherein it captures all the sentence similarity task action.\n",
      "Whole context of the either the topic of the important movement.\n",
      "Need to be captured as a as an important environmental issues as an important topic of the people.\n",
      "We do is we take we take each candidate key face on the contacts associated with it.\n",
      "cluster before alteration=========>\n",
      "Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there.\n",
      "Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.\n",
      "What it does is it will be able to defeat evil to slice machine learning related components into one one topic and Lambda base if there is a fair segregation it will be able To slice them.\n",
      "That is the whole point of the channel when so so so the inference that I said, it just scores against channel channel Pine and then and then what comes out is the bunch of segments that that post that mostly covers the whole conversation at the same time sticking to what the channel is related to ensure of a deviating from that.\n",
      "I mean, I mean relatively so sure so that is what the topic is.\n",
      "It just would be found between them but no, it should be formed between Docker or the recruitment because even though they are talked in the same conversation or even inverse cos they are actually talked right one after the other because\n",
      "But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated.\n",
      "So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends.\n",
      "What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community.\n",
      "So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they are moving back and forth.\n",
      "So so what this some topic extraction does is it will be very very, you know Broad in its topic identification also, so so let us say a certain Paul covered software engineering in which we talked about Lambda and Learning deployment and then in the same pot.\n",
      "Yep at the manual tasks that they do very naturally helps reinforce our a models.\n",
      "And then we have a graph a graph with with all these conversations as a notes.\n",
      "Let is say on either some other channel at home or some other let us say Google Hangouts for example, right if there is a concept of a Group in Google Hangout and that prisons attain the same level of attachment of mines and ending can also happen there.\n",
      "We talked about Recruitment and also the product strategy what it does is most likely could put Lambda and deployment the same topic because you know, they have been discussed together.\n",
      "But otherwise if in another call we talked about Lambda base deployments for a whole lot of XnumberX minutes.\n",
      "So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out.\n",
      "So what it does is if there are if there is a broader, you know, the broader categories of topics that are being discussed in certain calls.\n",
      "So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.\n",
      "It comes from the language model finetuning which has nothing to do with the communities.\n",
      "A nation of community algorithm parameters and the language model performance.\n",
      "Right thus often times, you know, people are talking like, you know, in a team of say five six people one a call teams tend to get into discussions, you know, we are going back and forth particular subject and then you move on to some other subject in some other topic and so on right where so how do we kind of use this?\n",
      "So the the whole intent of this app does not topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about.\n",
      "And then how we trial how we trial is as I said, it is more of it.\n",
      "So what we do is we just organized the meeting into the graph that that is fairly simple because you know, you have lot of this text segments and then we we have eat them as the node.\n",
      "What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.\n",
      "I mean, I think we all had the solution as well.\n",
      "Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case.\n",
      "How do we pull these chapters out of pull these topics out and and show them?\n",
      "Right the fact that when a user is interacting with our tool.\n",
      "So just to just to be just to be aligned with the with the flow.\n",
      "So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graphbased for this.\n",
      "But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model.\n",
      "So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.\n",
      "It is just a stock affection adult done done in a very flexible way.\n",
      "Let is say what we do is when you are as you have shown in the example at wearing one Call we are run through all the multiple channels of then we got different sub arrays.\n",
      "So it is like a fairly flexible topic slicing algorithm that we that we have in place a topic extraction.\n",
      "Actually, there was strong association between within XnumberX people where in most of the people are connected with most of the others.\n",
      "So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting.\n",
      "cluster before alteration=========>\n",
      "So on and so forth, so it is very very flexible.\n",
      "I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.\n",
      "So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.\n",
      "Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.\n",
      "We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide.\n",
      "On the background and we will touch upon those as well.\n",
      "Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.\n",
      "So that is a very interesting aspect of ethers a sec as well and last but not the least.\n",
      "Okay, so when could I thought it will be good for us to do a little bit have a dis little bit of a discussion on just the I stack with ether.\n",
      "But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right?\n",
      "And so the way we built ether was to have a lot of flexibility in being able to associate any speechtotext engine to with our for our purposes.\n",
      "So I am assuming that a lot of the folks who are seeing.\n",
      "This will be gone through that that call and got up.\n",
      "All right, but just to reiterate if you look at ethers a I stack there are a few things that that we want to kind of highlight, right?\n",
      "The first is its concept of Channel or team mines where whereby we are representing the team context both the static aspects of it.\n",
      "Let is say there is a team that is working on software engineering or databases or Our devops in general, right?\n",
      "So there is a static idea that they are working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently.\n",
      "Is that a production issue that is being addressed right now it is that a particular type of database are talking about or you know, a particular aspect of their software engineering stack that they are talking about.\n",
      "So the first time Idea is idea about Channel or team Minds.\n",
      "How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information.\n",
      "And so how do you extract what is Meaningful and what is not so that is another aspect of how either ether zai gets applied to just the meetings their interactions, right?\n",
      "We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right?\n",
      "So before we get started a lot of times question comes up when we talk about ether how we do our speechtotext, right?\n",
      "So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.\n",
      "I think the the next one is this idea of you know, how once a call is over.\n",
      "First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.\n",
      "So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss.\n",
      "So, of course, there is also a couple of other things that we are working on.\n",
      "So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider?\n",
      "Let is say you are in a meeting and you are and the team is having a discussion and in an hour is call you are talking about a bunch of different topics.\n",
      "Being and you are having a discussion, maybe it is a group meeting and you are talking about five different topics in the call or you are talking about, you know, you are doing a two people are talking about one particular subject.\n",
      "So let us talk about Channel Minds right little deeper into Channel Minds.\n",
      "So one quick way of kind of talking about the the graph would be that it is a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right?\n",
      "The next is the idea of topic detection using communities, which is a you know, when you there is a there is a meeting that is happening.\n",
      "Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.\n",
      "Should talk about next is the keyphrase extraction, which is sometimes it is hard to blame the entire discussion.\n",
      "Maybe you can just give us a quick overview of what channel Minds is.\n",
      "So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them.\n",
      "We just to kind of lay this out is we do not\n",
      "When we go to market with our partners, they actually like to use their own speechtotext technology for integrating.\n",
      "We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality.\n",
      "We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.\n",
      "Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well.\n",
      "So that is the other kind of unique aspect about how we have built it inside our architecture.\n",
      "And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible So we\n",
      "So the way we do this is, you know showcases app, which is ether meet.\n",
      "We integrate with the close partner called Deep Graham to provide.\n",
      "cluster before alteration=========>\n",
      "And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.\n",
      "We should also, you know, improve our improve or adapt to the validation data that we create.\n",
      "It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.\n",
      "So without without much Concepts so once so, that is how we validate.\n",
      "So moving on I guess the next very I guess very important thing one way.\n",
      "I will come to the training part A little later, but we just passed it through that are.\n",
      "What we do is we have we we continuously create a list of summaries.\n",
      "One of the things that I always like to say is ether is the world is best meeting somebody engine right there.\n",
      "We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.\n",
      "How do you Pull out what is important and what is not so maybe you can just quickly run through.\n",
      "So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.\n",
      "Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time.\n",
      "So I guess it is a very good very quick kind of a real world example of this extracted from real call, right?\n",
      "It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that is currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right?\n",
      "So and then we score the in the scoring process is what the training aspect is.\n",
      "We just we just passed this, you know, all the segments.\n",
      "Up tents of or hundreds of calls and then we manually curate what are the most important moments given the converse given the meeting given that this meeting is part of a certain Channel.\n",
      "It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context.\n",
      "We generate like lot of candidate Al Gore models that will come out for that.\n",
      "We come up from the initial filtration of their performance and then we pass all those candidate models.\n",
      "So this this kind of a semiautomatic autonomous approach because we just do not want to automate it we can we can definitely automate but but the whole point Of the channel Minds to ever evolve at the same time.\n",
      "And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward.\n",
      "What is the score for a certain segment when you say segment?\n",
      "It is like a Texan which is actually fairly selfcontained either either.\n",
      "So what we do is when we do this the similarity task, you know finetuning of the language model.\n",
      "I mean we need not worry about the what do you call the quantifiable T of the score because you know, it is all relative.\n",
      "So each segment will have relative score on of course passes through certain minimal threshold.\n",
      "So this scoring box and then what what comes out is again.\n",
      "Through this validation data on this we keep updating this validation data so that we can we can safely say that if it passes the validation set because it has not seen those validation satyr during training if it passes the validation set we can fairly say that we can deploy that into the, you know, Ever Changing dynamics of the team.\n",
      "So it is a semiauto autonomous approach that we adopt the pews for the validation.\n",
      "cluster before alteration=========>\n",
      "We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.\n",
      "And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.\n",
      "Okay, cool, so I guess here is a taking a quick example, so here are three different segments, right?\n",
      "So so so we have trained a language model to finetune such that we can be we have adopted that language model to be a binary classifier.\n",
      "So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier.\n",
      "They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved.\n",
      "You are very nuanced and these types of actions are actually pulled out automatically from the conversations.\n",
      "So this This fairly has nothing to do with the with the language model that we discussed earlier.\n",
      "So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.\n",
      "So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture.\n",
      "We are also able to extract who it is assigned to write based on who is present in the call.\n",
      "So that means as soon as we get this speech segments from specific sequence from the call, right?\n",
      "So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on.\n",
      "What we do is we just we just pass the center.\n",
      "Youll recall or wherein we do not want to miss anything that has an accent.\n",
      "So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items.\n",
      "So maybe you can quickly run through how we pull out action items.\n",
      "Mmm, but we are okay to have lot of that means if I capture XnumberX out of XnumberX candidate action items.\n",
      "Okay, I guess so it kind of going into the details right the other I guess very important aspect is how we pull out meeting Primitives, I guess.\n",
      "So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right.\n",
      "So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.\n",
      "Should I just like I think when we say action items, let us let me put one point before we talk about it.\n",
      "But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not.\n",
      "So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.\n",
      "So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services.\n",
      "What are the action items that are that it that they either bought things as an action items and then and then and then gives gives away.\n",
      "Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?\n",
      "And you know who is speaking and who is the recipient and so on?\n",
      "So that is why we find you this classifier to have a highest possible.\n",
      "So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.\n",
      "And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item.\n",
      "Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent.\n",
      "If you are spending the five ten in the first five minutes talking about the latest IPL score Kidd game as that happen, you are able to easily filter those unimportant moments out and get right into the important moments, which is what are the rest of the team can\n",
      "There is if they have seen a lot of exotic references like that.\n",
      "So again the action item as a whole is not just a model here sigh that is what I wanted to highlight here.\n",
      "This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I am okay to have a lot of noise in the carrot patch.\n",
      "Sorry, but I do not want to miss even a single action item.\n",
      "I am okay to have only four of them being the real action items, but I do not want to miss even one of the action items one of those pork perfect.\n",
      "So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items.\n",
      "But as a total it has actually it has identified only XnumberX, even though the noise is list.\n",
      "That is why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect.\n",
      "Say for example, if there is an action item detected by the candidate, but I did not find any grammatically relevant subject in them.\n",
      "So how do we do that is we have actually collected lot of training data for this.\n",
      "So actually we are talking about action items that are being in the freeflow conversation like what we are doing right now.\n",
      "cluster before alteration=========>\n",
      "Hopefully this gives you a pretty good idea to the viewer about the different things types of things that we use in either for AI and I guess in a different discussion, I guess maybe we can go into how actually a lot of this is operationalized inside our deployments, but that is a discussion for another day.\n",
      "Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels.\n",
      "All right, so there is there is here is a kind of an example.\n",
      "That is just a quick example at a sample of what we do.\n",
      "So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that is associated with it.\n",
      "So let us move on and maybe just give a quick example not going to spend a whole lot of time on this but just to give a representation of here is a real world example.\n",
      "So again, let me go back switch to my presentation here.\n",
      "So those types of relationships can be gleaned very easily from the knowledge graph, right like so for example in this particular case when we run this query about who is who is a personal talked about Google these three people who come up myself Cullen and Karthik right where we talk a lot about Google.\n",
      "So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is.\n",
      "I do not know if you are able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things.\n",
      "So these types of relationships get pulled out very easily from the knowledge.\n",
      "Let me see if I can actually pull up the graph itself.\n",
      "Let me stop the content here and show the real graph.\n",
      "Yeah, so so it actually brings it to one more notion.\n",
      "We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?\n",
      "So one is we are able to we took essentially one of the workspaces and map the interactions into a into a graph here and let us say we want to find out who the goo.\n",
      "Alright, so that is actually a good segue to actually before we do that.\n",
      "So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right?\n",
      "So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right?\n",
      "That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that is a very unique way of representing the intelligence of the Insight that is happening in the context of teams and and the organization in a graph format and using this in a variety of different ways.\n",
      "Maybe you can just walk us through this a little bit.\n",
      "What are the use cases that we always talk about is, you know a lot of times when you have a meeting, let us say you and I are having this call and then we produce a summary it will be always good to know who should you know, what people who are would actually likely to watch this, right?\n",
      "So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics.\n",
      "And then when you pass it through when you have that meeting in the context of a software engineering mind, the discussion summarizes The Ether summarizes the discussion pulls out topics related to software for example things about database continuously ICD kubernetes Etc.\n",
      "Our infrastructure that Kafka whereas when you talk about when you run the same meeting through the marketing channel, you know, it pulls out things about, you know, digital marketing.\n",
      "You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right?\n",
      "So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like.\n",
      "All right, so it is a great segue into you know, so when we talked about Channel Minds you brought up this notion of the dynamic portion.\n",
      "So those types of things can be applied to Enterprise intelligence as well because a lot of times T teams keep discussing the same subjects again and again, right so it is very common that in a team for example in an engineering team a particular type of databases that you know is being considered for their architecture, you know, the engineer leaves the company goes away voila six months later.\n",
      "Let me actually take this down and show it in a real slack conversation.\n",
      "it is fair play shows how how the channel man is able to differentiate based on the Mind attached to it during the\n",
      "Will experts are in a workspace in this can be very simple as a who is the person who is interested in a particular technology.\n",
      "So you can kind of get a feel for it as we go on but wine to get started and let us dive in and talk a little bit about Channel Minds.\n",
      "You may also want to follow up on this other topic right?\n",
      "A new person comes and then he comes and talks about the same subject right ether can very easily extract the idea that this discussion has happened before and actually say hey now that you are discussing this subject.\n",
      "So I think that that kind of concludes this discussion right thanks to incur that we have covered a lot of things.\n",
      "I wanted to kind of call out Channel minds and action.\n",
      "Yeah, and so kind of generating this idea of who are the recommended Watchers.\n",
      "Youre a discussion right are more importantly, you know, as we see in ecommerce lot of times right you buy this product you also You know you get this common thing that saves users who bought this are also interested in these other types of products, right?\n",
      "Are you watch this other discussion that happened a few months ago and that makes teams just work a lot efficiently and save a lot of time in going back and forth, right?\n",
      "cluster before alteration=========>\n",
      "So so it just it is just able to put them together aggressive.\n",
      "So here is a call that happened and where there is a bunch of discussion that that happened between a group of people and we are able to very nicely kind of pull out the fact that the shunt and Arjun talked about deployment and configuration devops related subjects and then the Russians and blanket in then moved on and talked about some database subjects like Seattle and Cloud SQL exactly exactly.\n",
      "I hear it did not actually slice the whole databases databases singled out because it just reaches talked about database and run something related to deployment together.\n",
      "That means if we talk only about databases on the deployment, it would have done the other way like click diplomatic conversations and then they database so that is the level of flexible.\n",
      "I guess, you know different topics are different groups of topics and the people involved in those conversations are pulled out a very elegant way I think is very cool.\n",
      "This is one says even the whole subject is about about software.\n",
      "So they end up as a topics or to the as we go granular.\n",
      "Whole lot of huge HR conversation within in software engineering team so it could it could so it could still give out some important moments.\n",
      "But even if there is a slight mention of software engineering its prices for it higher than than the rest but it gives you a very good summary of what is happening.\n",
      "Yep, so it is kind of a very folks summer day would say so so it just it just cuts out the noise very aggressive price to stick to what what the team needs actually.\n",
      "Got it tigers have wanted to show a quick example of how this works.\n",
      "Things like that and then they went back Arjun venkat and three shots now talked about databases.\n",
      "Granular Kappa can get you can go from the top level where in you have totally relevant unrelated topics discussed.\n",
      "cluster before alteration=========>\n",
      "So I am just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we have done some amount of proof of Concepts and investigation into it and we plan to do more on this.\n",
      "Maybe someone can manually tag it and so on using our user interface, right?\n",
      "Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on.\n",
      "So we are working on a technique where we can detect that the slide is being presented and then automatically pull out information from that using Standard computer vision techniques and then once the vision was a slight information is converted to text a lot of the same information can be used in terms of applying what is relevant and what is not and what is the topic and what is a keyword and so on so forth, right?\n",
      "Let is say a bunch of people are crowded around the conference call content speakerphone or whatever, right?\n",
      "So obviously and and I will just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that.\n",
      "We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there is an unknown speaker.\n",
      "We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right.\n",
      "So we do not need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also\n",
      "We are continually creating a library of our signature using standard MFC sea bass techniques and creating patterns and storing them for every speaker that we know and then as we detect changes in those patterns, we we kind of apply that to speaker dilation and then if the signature actually matches someone in our database\n",
      "In the coming weeks and months is that in a shed setting?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "What we have done is we have had to hack the data hunger of the more of the neural network language models.\n",
      "I because we get the data in a very small increments for the machine learning model.\n",
      "So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it is a static component.\n",
      "And then in the meantime, we do not want to lose the information that we have.\n",
      "So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.\n",
      "So that is kind of the engineering that we did for the channel Minds got it.\n",
      "So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.\n",
      "So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.\n",
      "So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.\n",
      "I mean the feature extractor for the whole process wherein we train we train the neural net.\n",
      "We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you are doing earlier, right?\n",
      "The model is the actual neural network model and the mind is is the graph data structure that organizes the information.\n",
      "I I think I think we can on the validation component.\n",
      "So so that is where the channel mind comes into play when we say mine.\n",
      "I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.\n",
      "Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.\n",
      "Once we once we have the language model, that is fine tune.\n",
      "What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data.\n",
      "I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.\n",
      "Action that is coming, you know to The Ether AI engine if you are it.\n",
      "So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated.\n",
      "How is that attach to the with a slack Channel and then how it how the channel Minds selfgenerated right?\n",
      "What we do is actually there are there is a twostage validation one is one is the language model that we that we have two other people which is well, which is actually finetune various tasks.\n",
      "When I say a task it is it is like asking asking the language model to predict whether whether a sentence is at whether a sentence whether two sentences are continuous.\n",
      "Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations.\n",
      "So so we have we have fairly statistical validation approaches to validate this auxiliary tasks.\n",
      "Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.\n",
      "So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.\n",
      "So I will just walk you through I will give you a tip.\n",
      "So which means I mean, Coming to the language model aspect of it.\n",
      "Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a preloaded, you know library of domain mines be call.\n",
      "That means we keep on adding the the new domains to our domain Library.\n",
      "So when when a user is invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel.\n",
      "We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.\n",
      "These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether.\n",
      "I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.\n",
      "So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans.\n",
      "Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion.\n",
      "I think before before we get started with its II think I think I will just give you a heads up on a thin configuration by it.\n",
      "So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know.\n",
      "So having said that I think I think that should be good enough with the team and then maybe it is good time to get here.\n",
      "Maybe you know, I sorry for not doing this, but maybe you can just give a quick introduction about yourself.\n",
      "And also maybe give a little bit of background about Ari, I think sure.\n",
      "So it is a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor.\n",
      "I also also like the Imaging and then the video processing and on the text, I mean the speechtotext and and and the whole whole spectrum of the AI ecosystem.\n",
      "So I think with the headset that you gave about the channel Minds I meant that that is like a thousand feet free of what channel mine does.\n",
      "Then and I leave The A Team we are we are a team of XnumberX.\n",
      "Ml Engineers who are who primarily work on machine learning deployments and also building the stateoftheart machine learning models.\n",
      "I mean as a team they worked on very broader set of are use cases ranging.\n",
      "Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe.\n",
      "So we stopped with such which talks about each domain when talks about certain certain.\n",
      "It is just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period.\n",
      "It is a wonder my mind is software engineering the other one could be markers.\n",
      "Let is say the if the engineering teams talks about production.\n",
      "I guess one way to talk about that would be there is a static component.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation.\n",
      "So let me get just started my mind Generations on the top.\n",
      "So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is wellversed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model.\n",
      "So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering.\n",
      "So so this this just shows how how the chat the domain Minds, you know shapeshifts into the channel and by learning all the information that it gets from the conversations.\n",
      "So a quick heads up on this on this slide because this puts everything I can with my cousin in one single view.\n",
      "So we we we use open data to to you know, generate generate a fix.\n",
      "A library of domain Minds as as we mentioned some of the samples here some this is ever growing we keep on adding so to this list.\n",
      "It is a simple example would be a bug a bug in nature may be different from the bug in a software engineering model.\n",
      "So this domain mind gets it domain language for who gets attached to the to the channel when the user says invites you to the channel.\n",
      "So from once we have this domain language model right as we were talking about the domain minder.\n",
      "Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind.\n",
      "We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds.\n",
      "So so this is this is fairly simple, you know, simple.\n",
      "Were in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier.\n",
      "This is likelihood that with the talk about a double s Lambda also, it means that they seem to be talking about a similar as similar aspect for that certain Tim.\n",
      "So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team.\n",
      "That is on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel.\n",
      "That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph.\n",
      "So that means if someone is talking about deployment aunt and then if in a certain channel is if they always associate deployment with let us say AWS Lambda.\n",
      "So this relationship is learned that when there is an aid of a deployment.\n",
      "So this is kind of relationship that this combination of language model undermined men captures.\n",
      "Okay as we mentioned so domain Channel mine is fairly Dynamic.\n",
      "So every time every time there is a new conversation that comes in the comes in the eater.\n",
      "Calls there would be there would be scored or they would be compared against this domain mind till we have the transformation to the channel Minds.\n",
      "So that is this is where you know, you have the real learning component of Egypt\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So we are in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature.\n",
      "And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.\n",
      "I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as\n",
      "So in that help engine, it is like a it is like a pre fabricating the data such so that it can go into the graph structure.\n",
      "So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.\n",
      "Check just like so eat a graph serves multiple purposes one one being as we talked about it.\n",
      "So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior.\n",
      "You know, Knowledge Graph like the factual graph on The Ether graph.\n",
      "I will talk about the difference just just in a minute, but but so what we are trying to say here is along with the actual factual information like who spoke what or or what are the you know who attended the meeting so these Services enable The Ether\n",
      "It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.\n",
      "So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data.\n",
      "T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction.\n",
      "A source would just go as is to the general feeling.\n",
      "Yeah, I guess it really we are operating in the text domain.\n",
      "So if it is a speech data we converted to text first if there is Vision data, let us say the slides that need to be processed.\n",
      "So presentation so that we can be can you know use it for all sorts of computations.\n",
      "Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself is not are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or nonobvious inside sort of the god Apollo.\n",
      "So we again use the associated domain language model of the custom custom Channel language model for for feature is Amal the text that picket and then and then we also bring in the notion of Miles here.\n",
      "In terms of its relevance relevance and other aspects caps in other aspects.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "And then what we what we do is we just put it through a graph neural networks kind or the different graph algorithms.\n",
      "So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we are going to talk about a little so so so and also other top XO from the from the from the computation graph perspective.\n",
      "So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations.\n",
      "It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks.\n",
      "All the users will have their own representation that not just captures what who they are.\n",
      "Something like, you know, if I am part of a channel that is a very direct relationship which does not require a lot of intelligence which is get it right out of the station.\n",
      "Whereas when I say, hey, you know Karthik follow up on this production issue, you know the idea that Karthik is the person who I am assigning this action to is something that is not so intuitive and needs to be gleaned right by first applying NLP in these types of rules then later on also being getting represented in the laugh\n",
      "So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik.\n",
      "So so so what it does is it also forms a relation between Karthik as anode which is the user and then the kubernetes as a topic and then says you know here Initially then as as as as more and more conversations around kubernetes are happening.\n",
      "So how in fact we can even take consensus just because Karthik is talking we need not say that he could be an expert.\n",
      "But if I orthotic that means every time Karthik talks about kubernetes if you are a watch it so which which makes in which makes him kind of we approve his Dont open it is and that we captured that inside to and then reinforce that that relationship as a Karthik is an expert in kubernetes.\n",
      "You know, I would rather than that we use like the node embeddings what I mean by no damn wedding is when there is Karthik so we do not just we do not just see Karthik as you know a person so we also input all the information that he that actually this ether captures about about that.\n",
      "But but what they come as a combination represents, so once they have this as a mathematical object, like like a like a embedding what we can do is we can do lot of you know algorithms on because we are free to do all the math around it and then we can you can get for the similar users to kartik from the context of you know, the topics that that he discusses or from the context of the action items.\n",
      "Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.\n",
      "So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get.\n",
      "So that is how the evaluation of you know, relationships happened within the that is one of the example that I just gave program give you an idea of how computation graph works.\n",
      "They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting.\n",
      "Yes, I eat a graph is more of a traditional representation of God.\n",
      "Yes, it is teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them.\n",
      "Okay and then I guess once you have these types of graphs.\n",
      "That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.\n",
      "So we we just organize the topics key phrases captured as the notes on that.\n",
      "Just think of integrating these insights into you know, a ticket management tool like jira, right?\n",
      "So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this.\n",
      "If you do not talk about anything else if direct enables us to form the you know, form the form this noninductive relationships like talked about a certain topic or action item assigned to so now let us take forward and then use This graph that is actually being formed after all the conversations.\n",
      "So having said that I will just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component.\n",
      "And then what comes out is actually a lot more, you know a lot more insights that will enable us to do like very nonintuitive recommendations.\n",
      "So as you said the example that you gave write a card they can you follow the on this can come as part of the conversation in the free text, you know free language.\n",
      "So we are in the in the computation graph as we as mentioned earlier.\n",
      "So say for example, if I have to give you one example of how the how the body is nonintuitive relations could be is you know, let us say let us say let us say Karthik talked about kubernetes in one of the in couple of calls\n",
      "What bought the nodes could be along with the the factual notes like the users and favorite pics.\n",
      "So as I talked about that Karthik being expert in a in kubernetes, right so that can be formed from the from some of this.\n",
      "The talked about can get interest into is a is an expert in tuber natives even say that is very cool.\n",
      "That means all the relationships about the topics whom he follows or whom who I mean, what are the topics that he usually discusses and then we just call that whole component and then we encode everything into into the cottage.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.\n",
      "We do not have any context of what is important and what is not important.\n",
      "So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.\n",
      "So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.\n",
      "So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are.\n",
      "When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.\n",
      "Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows.\n",
      "So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.\n",
      "So let me just put it in my queuing for the scoring in the next steps.\n",
      "So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it.\n",
      "It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.\n",
      "All we know is this this this diagram or the three words combination sounds as if it is an important people.\n",
      "We just passed the context through this algorithm finetuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know.\n",
      "So so what we do is it is a two step process.\n",
      "Text and then we correlate that with the context associated with the channel Minds at the end of this this whole process this multi step three step process.\n",
      "So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.\n",
      "Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.\n",
      "So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point.\n",
      "So we just we just so Channel Minds just drops it or even the associated key phrases.\n",
      "Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it is too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the\n",
      "This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.\n",
      "So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.\n",
      "So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right?\n",
      "for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so\n",
      "What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.\n",
      "And then coming to come into the training part of it.\n",
      "So when you have see how it comes is when you have let us say the conversation about machine learning or or any software engineering related.\n",
      "This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.\n",
      "So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.\n",
      "But what we do is when we say topic identification or be identified the potential important moments in the call.\n",
      "So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of\n",
      "So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms.\n",
      "So one of these data sets that we use for our general benchmarking is this SST wherein it captures all the sentence similarity task action.\n",
      "Whole context of the either the topic of the important movement.\n",
      "Need to be captured as a as an important environmental issues as an important topic of the people.\n",
      "We do is we take we take each candidate key face on the contacts associated with it.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there.\n",
      "Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.\n",
      "What it does is it will be able to defeat evil to slice machine learning related components into one one topic and Lambda base if there is a fair segregation it will be able To slice them.\n",
      "That is the whole point of the channel when so so so the inference that I said, it just scores against channel channel Pine and then and then what comes out is the bunch of segments that that post that mostly covers the whole conversation at the same time sticking to what the channel is related to ensure of a deviating from that.\n",
      "I mean, I mean relatively so sure so that is what the topic is.\n",
      "It just would be found between them but no, it should be formed between Docker or the recruitment because even though they are talked in the same conversation or even inverse cos they are actually talked right one after the other because\n",
      "But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated.\n",
      "So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends.\n",
      "What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community.\n",
      "So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they are moving back and forth.\n",
      "So so what this some topic extraction does is it will be very very, you know Broad in its topic identification also, so so let us say a certain Paul covered software engineering in which we talked about Lambda and Learning deployment and then in the same pot.\n",
      "Yep at the manual tasks that they do very naturally helps reinforce our a models.\n",
      "And then we have a graph a graph with with all these conversations as a notes.\n",
      "We talked about Recruitment and also the product strategy what it does is most likely could put Lambda and deployment the same topic because you know, they have been discussed together.\n",
      "But otherwise if in another call we talked about Lambda base deployments for a whole lot of XnumberX minutes.\n",
      "So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out.\n",
      "So what it does is if there are if there is a broader, you know, the broader categories of topics that are being discussed in certain calls.\n",
      "So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.\n",
      "It comes from the language model finetuning which has nothing to do with the communities.\n",
      "A nation of community algorithm parameters and the language model performance.\n",
      "Right thus often times, you know, people are talking like, you know, in a team of say five six people one a call teams tend to get into discussions, you know, we are going back and forth particular subject and then you move on to some other subject in some other topic and so on right where so how do we kind of use this?\n",
      "So the the whole intent of this app does not topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about.\n",
      "And then how we trial how we trial is as I said, it is more of it.\n",
      "So what we do is we just organized the meeting into the graph that that is fairly simple because you know, you have lot of this text segments and then we we have eat them as the node.\n",
      "What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.\n",
      "I mean, I think we all had the solution as well.\n",
      "Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case.\n",
      "How do we pull these chapters out of pull these topics out and and show them?\n",
      "Right the fact that when a user is interacting with our tool.\n",
      "So just to just to be just to be aligned with the with the flow.\n",
      "So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graphbased for this.\n",
      "But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model.\n",
      "So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.\n",
      "It is just a stock affection adult done done in a very flexible way.\n",
      "Let is say what we do is when you are as you have shown in the example at wearing one Call we are run through all the multiple channels of then we got different sub arrays.\n",
      "So it is like a fairly flexible topic slicing algorithm that we that we have in place a topic extraction.\n",
      "Actually, there was strong association between within XnumberX people where in most of the people are connected with most of the others.\n",
      "So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So on and so forth, so it is very very flexible.\n",
      "I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.\n",
      "So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.\n",
      "Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.\n",
      "We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide.\n",
      "On the background and we will touch upon those as well.\n",
      "Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.\n",
      "So that is a very interesting aspect of ethers a sec as well and last but not the least.\n",
      "Okay, so when could I thought it will be good for us to do a little bit have a dis little bit of a discussion on just the I stack with ether.\n",
      "But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right?\n",
      "And so the way we built ether was to have a lot of flexibility in being able to associate any speechtotext engine to with our for our purposes.\n",
      "So I am assuming that a lot of the folks who are seeing.\n",
      "This will be gone through that that call and got up.\n",
      "All right, but just to reiterate if you look at ethers a I stack there are a few things that that we want to kind of highlight, right?\n",
      "The first is its concept of Channel or team mines where whereby we are representing the team context both the static aspects of it.\n",
      "Let is say there is a team that is working on software engineering or databases or Our devops in general, right?\n",
      "So there is a static idea that they are working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently.\n",
      "Is that a production issue that is being addressed right now it is that a particular type of database are talking about or you know, a particular aspect of their software engineering stack that they are talking about.\n",
      "So the first time Idea is idea about Channel or team Minds.\n",
      "How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information.\n",
      "And so how do you extract what is Meaningful and what is not so that is another aspect of how either ether zai gets applied to just the meetings their interactions, right?\n",
      "We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right?\n",
      "So before we get started a lot of times question comes up when we talk about ether how we do our speechtotext, right?\n",
      "So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.\n",
      "I think the the next one is this idea of you know, how once a call is over.\n",
      "First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.\n",
      "So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss.\n",
      "So, of course, there is also a couple of other things that we are working on.\n",
      "So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider?\n",
      "Let is say you are in a meeting and you are and the team is having a discussion and in an hour is call you are talking about a bunch of different topics.\n",
      "Being and you are having a discussion, maybe it is a group meeting and you are talking about five different topics in the call or you are talking about, you know, you are doing a two people are talking about one particular subject.\n",
      "So let us talk about Channel Minds right little deeper into Channel Minds.\n",
      "So one quick way of kind of talking about the the graph would be that it is a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right?\n",
      "The next is the idea of topic detection using communities, which is a you know, when you there is a there is a meeting that is happening.\n",
      "Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.\n",
      "Should talk about next is the keyphrase extraction, which is sometimes it is hard to blame the entire discussion.\n",
      "Maybe you can just give us a quick overview of what channel Minds is.\n",
      "So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them.\n",
      "We just to kind of lay this out is we do not\n",
      "When we go to market with our partners, they actually like to use their own speechtotext technology for integrating.\n",
      "We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality.\n",
      "We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.\n",
      "Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well.\n",
      "So that is the other kind of unique aspect about how we have built it inside our architecture.\n",
      "And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible So we\n",
      "So the way we do this is, you know showcases app, which is ether meet.\n",
      "We integrate with the close partner called Deep Graham to provide.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.\n",
      "We should also, you know, improve our improve or adapt to the validation data that we create.\n",
      "It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.\n",
      "So without without much Concepts so once so, that is how we validate.\n",
      "So moving on I guess the next very I guess very important thing one way.\n",
      "I will come to the training part A little later, but we just passed it through that are.\n",
      "What we do is we have we we continuously create a list of summaries.\n",
      "One of the things that I always like to say is ether is the world is best meeting somebody engine right there.\n",
      "We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.\n",
      "How do you Pull out what is important and what is not so maybe you can just quickly run through.\n",
      "So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.\n",
      "Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time.\n",
      "It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that is currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right?\n",
      "So and then we score the in the scoring process is what the training aspect is.\n",
      "We just we just passed this, you know, all the segments.\n",
      "Up tents of or hundreds of calls and then we manually curate what are the most important moments given the converse given the meeting given that this meeting is part of a certain Channel.\n",
      "It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context.\n",
      "We generate like lot of candidate Al Gore models that will come out for that.\n",
      "We come up from the initial filtration of their performance and then we pass all those candidate models.\n",
      "So this this kind of a semiautomatic autonomous approach because we just do not want to automate it we can we can definitely automate but but the whole point Of the channel Minds to ever evolve at the same time.\n",
      "And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward.\n",
      "What is the score for a certain segment when you say segment?\n",
      "It is like a Texan which is actually fairly selfcontained either either.\n",
      "So what we do is when we do this the similarity task, you know finetuning of the language model.\n",
      "I mean we need not worry about the what do you call the quantifiable T of the score because you know, it is all relative.\n",
      "So each segment will have relative score on of course passes through certain minimal threshold.\n",
      "So this scoring box and then what what comes out is again.\n",
      "Through this validation data on this we keep updating this validation data so that we can we can safely say that if it passes the validation set because it has not seen those validation satyr during training if it passes the validation set we can fairly say that we can deploy that into the, you know, Ever Changing dynamics of the team.\n",
      "So it is a semiauto autonomous approach that we adopt the pews for the validation.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.\n",
      "And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.\n",
      "Okay, cool, so I guess here is a taking a quick example, so here are three different segments, right?\n",
      "So so so we have trained a language model to finetune such that we can be we have adopted that language model to be a binary classifier.\n",
      "So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier.\n",
      "They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved.\n",
      "You are very nuanced and these types of actions are actually pulled out automatically from the conversations.\n",
      "So this This fairly has nothing to do with the with the language model that we discussed earlier.\n",
      "So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.\n",
      "So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture.\n",
      "We are also able to extract who it is assigned to write based on who is present in the call.\n",
      "So that means as soon as we get this speech segments from specific sequence from the call, right?\n",
      "So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on.\n",
      "What we do is we just we just pass the center.\n",
      "Youll recall or wherein we do not want to miss anything that has an accent.\n",
      "So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items.\n",
      "So maybe you can quickly run through how we pull out action items.\n",
      "Mmm, but we are okay to have lot of that means if I capture XnumberX out of XnumberX candidate action items.\n",
      "Okay, I guess so it kind of going into the details right the other I guess very important aspect is how we pull out meeting Primitives, I guess.\n",
      "So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right.\n",
      "So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.\n",
      "Should I just like I think when we say action items, let us let me put one point before we talk about it.\n",
      "But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not.\n",
      "So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.\n",
      "So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services.\n",
      "What are the action items that are that it that they either bought things as an action items and then and then and then gives gives away.\n",
      "Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?\n",
      "And you know who is speaking and who is the recipient and so on?\n",
      "So that is why we find you this classifier to have a highest possible.\n",
      "So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.\n",
      "And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item.\n",
      "Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent.\n",
      "If you are spending the five ten in the first five minutes talking about the latest IPL score Kidd game as that happen, you are able to easily filter those unimportant moments out and get right into the important moments, which is what are the rest of the team can\n",
      "There is if they have seen a lot of exotic references like that.\n",
      "So again the action item as a whole is not just a model here sigh that is what I wanted to highlight here.\n",
      "This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I am okay to have a lot of noise in the carrot patch.\n",
      "Sorry, but I do not want to miss even a single action item.\n",
      "I am okay to have only four of them being the real action items, but I do not want to miss even one of the action items one of those pork perfect.\n",
      "So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items.\n",
      "But as a total it has actually it has identified only XnumberX, even though the noise is list.\n",
      "That is why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect.\n",
      "Say for example, if there is an action item detected by the candidate, but I did not find any grammatically relevant subject in them.\n",
      "So how do we do that is we have actually collected lot of training data for this.\n",
      "So actually we are talking about action items that are being in the freeflow conversation like what we are doing right now.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "Hopefully this gives you a pretty good idea to the viewer about the different things types of things that we use in either for AI and I guess in a different discussion, I guess maybe we can go into how actually a lot of this is operationalized inside our deployments, but that is a discussion for another day.\n",
      "Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels.\n",
      "All right, so there is there is here is a kind of an example.\n",
      "That is just a quick example at a sample of what we do.\n",
      "So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that is associated with it.\n",
      "So let us move on and maybe just give a quick example not going to spend a whole lot of time on this but just to give a representation of here is a real world example.\n",
      "So again, let me go back switch to my presentation here.\n",
      "So those types of relationships can be gleaned very easily from the knowledge graph, right like so for example in this particular case when we run this query about who is who is a personal talked about Google these three people who come up myself Cullen and Karthik right where we talk a lot about Google.\n",
      "So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is.\n",
      "I do not know if you are able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things.\n",
      "So these types of relationships get pulled out very easily from the knowledge.\n",
      "Let me see if I can actually pull up the graph itself.\n",
      "Let me stop the content here and show the real graph.\n",
      "Yeah, so so it actually brings it to one more notion.\n",
      "We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?\n",
      "So one is we are able to we took essentially one of the workspaces and map the interactions into a into a graph here and let us say we want to find out who the goo.\n",
      "Alright, so that is actually a good segue to actually before we do that.\n",
      "So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right?\n",
      "So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right?\n",
      "That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that is a very unique way of representing the intelligence of the Insight that is happening in the context of teams and and the organization in a graph format and using this in a variety of different ways.\n",
      "Maybe you can just walk us through this a little bit.\n",
      "What are the use cases that we always talk about is, you know a lot of times when you have a meeting, let us say you and I are having this call and then we produce a summary it will be always good to know who should you know, what people who are would actually likely to watch this, right?\n",
      "So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics.\n",
      "And then when you pass it through when you have that meeting in the context of a software engineering mind, the discussion summarizes The Ether summarizes the discussion pulls out topics related to software for example things about database continuously ICD kubernetes Etc.\n",
      "Our infrastructure that Kafka whereas when you talk about when you run the same meeting through the marketing channel, you know, it pulls out things about, you know, digital marketing.\n",
      "You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right?\n",
      "So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like.\n",
      "All right, so it is a great segue into you know, so when we talked about Channel Minds you brought up this notion of the dynamic portion.\n",
      "So those types of things can be applied to Enterprise intelligence as well because a lot of times T teams keep discussing the same subjects again and again, right so it is very common that in a team for example in an engineering team a particular type of databases that you know is being considered for their architecture, you know, the engineer leaves the company goes away voila six months later.\n",
      "Let me actually take this down and show it in a real slack conversation.\n",
      "it is fair play shows how how the channel man is able to differentiate based on the Mind attached to it during the\n",
      "Will experts are in a workspace in this can be very simple as a who is the person who is interested in a particular technology.\n",
      "So you can kind of get a feel for it as we go on but wine to get started and let us dive in and talk a little bit about Channel Minds.\n",
      "You may also want to follow up on this other topic right?\n",
      "A new person comes and then he comes and talks about the same subject right ether can very easily extract the idea that this discussion has happened before and actually say hey now that you are discussing this subject.\n",
      "So I think that that kind of concludes this discussion right thanks to incur that we have covered a lot of things.\n",
      "I wanted to kind of call out Channel minds and action.\n",
      "Yeah, and so kind of generating this idea of who are the recommended Watchers.\n",
      "Youre a discussion right are more importantly, you know, as we see in ecommerce lot of times right you buy this product you also You know you get this common thing that saves users who bought this are also interested in these other types of products, right?\n",
      "Are you watch this other discussion that happened a few months ago and that makes teams just work a lot efficiently and save a lot of time in going back and forth, right?\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So so it just it is just able to put them together aggressive.\n",
      "So here is a call that happened and where there is a bunch of discussion that that happened between a group of people and we are able to very nicely kind of pull out the fact that the shunt and Arjun talked about deployment and configuration devops related subjects and then the Russians and blanket in then moved on and talked about some database subjects like Seattle and Cloud SQL exactly exactly.\n",
      "I hear it did not actually slice the whole databases databases singled out because it just reaches talked about database and run something related to deployment together.\n",
      "That means if we talk only about databases on the deployment, it would have done the other way like click diplomatic conversations and then they database so that is the level of flexible.\n",
      "I guess, you know different topics are different groups of topics and the people involved in those conversations are pulled out a very elegant way I think is very cool.\n",
      "This is one says even the whole subject is about about software.\n",
      "So they end up as a topics or to the as we go granular.\n",
      "Whole lot of huge HR conversation within in software engineering team so it could it could so it could still give out some important moments.\n",
      "But even if there is a slight mention of software engineering its prices for it higher than than the rest but it gives you a very good summary of what is happening.\n",
      "Yep, so it is kind of a very folks summer day would say so so it just it just cuts out the noise very aggressive price to stick to what what the team needs actually.\n",
      "Got it tigers have wanted to show a quick example of how this works.\n",
      "Things like that and then they went back Arjun venkat and three shots now talked about databases.\n",
      "Granular Kappa can get you can go from the top level where in you have totally relevant unrelated topics discussed.\n",
      "\n",
      "After removing overlapping groups\n",
      "cluster =========>\n",
      "\n",
      "So I am just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we have done some amount of proof of Concepts and investigation into it and we plan to do more on this.\n",
      "Maybe someone can manually tag it and so on using our user interface, right?\n",
      "Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on.\n",
      "So we are working on a technique where we can detect that the slide is being presented and then automatically pull out information from that using Standard computer vision techniques and then once the vision was a slight information is converted to text a lot of the same information can be used in terms of applying what is relevant and what is not and what is the topic and what is a keyword and so on so forth, right?\n",
      "Let is say a bunch of people are crowded around the conference call content speakerphone or whatever, right?\n",
      "So obviously and and I will just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that.\n",
      "We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there is an unknown speaker.\n",
      "We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right.\n",
      "So we do not need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also\n",
      "We are continually creating a library of our signature using standard MFC sea bass techniques and creating patterns and storing them for every speaker that we know and then as we detect changes in those patterns, we we kind of apply that to speaker dilation and then if the signature actually matches someone in our database\n",
      "In the coming weeks and months is that in a shed setting?\n",
      "\n",
      "\n",
      "Checking Timerange --------------\n",
      "--------------\n",
      "I think before before we get started with its II think I think I will just give you a heads up on a thin configuration by it. 48da3759d2eb45f49c1ba344eec381ce \n",
      "\n",
      "Maybe you know, I sorry for not doing this, but maybe you can just give a quick introduction about yourself. 642438db75064a729d29f91ac8463dcb \n",
      "\n",
      "And also maybe give a little bit of background about Ari, I think sure. 642438db75064a729d29f91ac8463dcb \n",
      "\n",
      "So it is a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor. aaaa272fedd34dc482ce4005349d1bb0 \n",
      "\n",
      "Then and I leave The A Team we are we are a team of XnumberX. aaaa272fedd34dc482ce4005349d1bb0 \n",
      "\n",
      "I mean as a team they worked on very broader set of are use cases ranging. aaaa272fedd34dc482ce4005349d1bb0 \n",
      "\n",
      "So having said that I think I think that should be good enough with the team and then maybe it is good time to get here. aaaa272fedd34dc482ce4005349d1bb0 \n",
      "\n",
      "So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know. aaaa272fedd34dc482ce4005349d1bb0 \n",
      "\n",
      "Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe. aaaa272fedd34dc482ce4005349d1bb0 \n",
      "\n",
      "Ml Engineers who are who primarily work on machine learning deployments and also building the stateoftheart machine learning models. aaaa272fedd34dc482ce4005349d1bb0 \n",
      "\n",
      "I also also like the Imaging and then the video processing and on the text, I mean the speechtotext and and and the whole whole spectrum of the AI ecosystem. aaaa272fedd34dc482ce4005349d1bb0 \n",
      "\n",
      "Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "So I will just walk you through I will give you a tip. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a preloaded, you know library of domain mines be call. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "So I think with the headset that you gave about the channel Minds I meant that that is like a thousand feet free of what channel mine does. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "So we stopped with such which talks about each domain when talks about certain certain. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "It is just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "It is a wonder my mind is software engineering the other one could be markers. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "I mean the feature extractor for the whole process wherein we train we train the neural net. acf261aee5bf4ea6adfcb987687da4d5 \n",
      "\n",
      "That means we keep on adding the the new domains to our domain Library. eac06a96244c481ab1e2e4445eddd5bd \n",
      "\n",
      "So which means I mean, Coming to the language model aspect of it. eac06a96244c481ab1e2e4445eddd5bd \n",
      "\n",
      "We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you are doing earlier, right? eac06a96244c481ab1e2e4445eddd5bd \n",
      "\n",
      "Let is say the if the engineering teams talks about production. eac06a96244c481ab1e2e4445eddd5bd \n",
      "\n",
      "Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about. eac06a96244c481ab1e2e4445eddd5bd \n",
      "\n",
      "So when when a user is invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel. eac06a96244c481ab1e2e4445eddd5bd \n",
      "\n",
      "I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked. eac06a96244c481ab1e2e4445eddd5bd \n",
      "\n",
      "We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet. 07aa7bee0c1d4d5b8fb24bb453411b15 \n",
      "\n",
      "Action that is coming, you know to The Ether AI engine if you are it. 07aa7bee0c1d4d5b8fb24bb453411b15 \n",
      "\n",
      "So so that is where the channel mind comes into play when we say mine. 07aa7bee0c1d4d5b8fb24bb453411b15 \n",
      "\n",
      "I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that. 07aa7bee0c1d4d5b8fb24bb453411b15 \n",
      "\n",
      "So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that. 07aa7bee0c1d4d5b8fb24bb453411b15 \n",
      "\n",
      "Once we once we have the language model, that is fine tune. 07aa7bee0c1d4d5b8fb24bb453411b15 \n",
      "\n",
      "What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data. 07aa7bee0c1d4d5b8fb24bb453411b15 \n",
      "\n",
      "The model is the actual neural network model and the mind is is the graph data structure that organizes the information. 07aa7bee0c1d4d5b8fb24bb453411b15 \n",
      "\n",
      "I guess one way to talk about that would be there is a static component. 0004d9a74fe448f5af8ab09915ca2eb6 \n",
      "\n",
      "Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on. 0004d9a74fe448f5af8ab09915ca2eb6 \n",
      "\n",
      "So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it is a static component. 6a0a928643ab4788aa51b94b2ea8952e \n",
      "\n",
      "So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently. 6a0a928643ab4788aa51b94b2ea8952e \n",
      "\n",
      "And then in the meantime, we do not want to lose the information that we have. 6a0a928643ab4788aa51b94b2ea8952e \n",
      "\n",
      "I because we get the data in a very small increments for the machine learning model. 6a0a928643ab4788aa51b94b2ea8952e \n",
      "\n",
      "So that is kind of the engineering that we did for the channel Minds got it. 6a0a928643ab4788aa51b94b2ea8952e \n",
      "\n",
      "What we have done is we have had to hack the data hunger of the more of the neural network language models. 6a0a928643ab4788aa51b94b2ea8952e \n",
      "\n",
      "So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are. e55cb15e24f34c1090a70d0c8bc8f562 \n",
      "\n",
      "When I say a task it is it is like asking asking the language model to predict whether whether a sentence is at whether a sentence whether two sentences are continuous. e55cb15e24f34c1090a70d0c8bc8f562 \n",
      "\n",
      "So so we have we have fairly statistical validation approaches to validate this auxiliary tasks. e55cb15e24f34c1090a70d0c8bc8f562 \n",
      "\n",
      "What we do is actually there are there is a twostage validation one is one is the language model that we that we have two other people which is well, which is actually finetune various tasks. e55cb15e24f34c1090a70d0c8bc8f562 \n",
      "\n",
      "I I think I think we can on the validation component. e55cb15e24f34c1090a70d0c8bc8f562 \n",
      "\n",
      "Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations. e55cb15e24f34c1090a70d0c8bc8f562 \n",
      "\n",
      "So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks. e55cb15e24f34c1090a70d0c8bc8f562 \n",
      "\n",
      "So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation. e55cb15e24f34c1090a70d0c8bc8f562 \n",
      "\n",
      "So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated. d2c0d63048af47c0808ed53e761c9f7b \n",
      "\n",
      "How is that attach to the with a slack Channel and then how it how the channel Minds selfgenerated right? d2c0d63048af47c0808ed53e761c9f7b \n",
      "\n",
      "--------------\n",
      "So this domain mind gets it domain language for who gets attached to the to the channel when the user says invites you to the channel. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "So from once we have this domain language model right as we were talking about the domain minder. 79d8bd4f528d42128311b753ac48139d \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a simple example would be a bug a bug in nature may be different from the bug in a software engineering model. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "So we we we use open data to to you know, generate generate a fix. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "So let me get just started my mind Generations on the top. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is wellversed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "So a quick heads up on this on this slide because this puts everything I can with my cousin in one single view. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "So so this this just shows how how the chat the domain Minds, you know shapeshifts into the channel and by learning all the information that it gets from the conversations. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "A library of domain Minds as as we mentioned some of the samples here some this is ever growing we keep on adding so to this list. 79d8bd4f528d42128311b753ac48139d \n",
      "\n",
      "So that means if someone is talking about deployment aunt and then if in a certain channel is if they always associate deployment with let us say AWS Lambda. e1e4c629ba3549f09e95805e87b19902 \n",
      "\n",
      "So this is kind of relationship that this combination of language model undermined men captures. e1e4c629ba3549f09e95805e87b19902 \n",
      "\n",
      "That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph. e1e4c629ba3549f09e95805e87b19902 \n",
      "\n",
      "This is likelihood that with the talk about a double s Lambda also, it means that they seem to be talking about a similar as similar aspect for that certain Tim. e1e4c629ba3549f09e95805e87b19902 \n",
      "\n",
      "So this relationship is learned that when there is an aid of a deployment. e1e4c629ba3549f09e95805e87b19902 \n",
      "\n",
      "Were in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier. f091fdbca2c645d5876c2c90d46e73f6 \n",
      "\n",
      "Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind. f091fdbca2c645d5876c2c90d46e73f6 \n",
      "\n",
      "That is on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel. f091fdbca2c645d5876c2c90d46e73f6 \n",
      "\n",
      "So so this is this is fairly simple, you know, simple. f091fdbca2c645d5876c2c90d46e73f6 \n",
      "\n",
      "Calls there would be there would be scored or they would be compared against this domain mind till we have the transformation to the channel Minds. f091fdbca2c645d5876c2c90d46e73f6 \n",
      "\n",
      "So that is this is where you know, you have the real learning component of Egypt f091fdbca2c645d5876c2c90d46e73f6 \n",
      "\n",
      "So every time every time there is a new conversation that comes in the comes in the eater. f091fdbca2c645d5876c2c90d46e73f6 \n",
      "\n",
      "We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds. f091fdbca2c645d5876c2c90d46e73f6 \n",
      "\n",
      "So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team. f091fdbca2c645d5876c2c90d46e73f6 \n",
      "\n",
      "Okay as we mentioned so domain Channel mine is fairly Dynamic. 676708b576584e38acaa6d634427fa8c \n",
      "\n",
      "--------------\n",
      "Check just like so eat a graph serves multiple purposes one one being as we talked about it. 547cd6b3d9a64d828e6c3eb3417149bc \n",
      "\n",
      "T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction. 547cd6b3d9a64d828e6c3eb3417149bc \n",
      "\n",
      "It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability. 547cd6b3d9a64d828e6c3eb3417149bc \n",
      "\n",
      "So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data. 547cd6b3d9a64d828e6c3eb3417149bc \n",
      "\n",
      "A source would just go as is to the general feeling. 547cd6b3d9a64d828e6c3eb3417149bc \n",
      "\n",
      "Yeah, I guess it really we are operating in the text domain. 4e970b30bd224610abf23d1fe9121aad \n",
      "\n",
      "I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as 4e970b30bd224610abf23d1fe9121aad \n",
      "\n",
      "So if it is a speech data we converted to text first if there is Vision data, let us say the slides that need to be processed. 4e970b30bd224610abf23d1fe9121aad \n",
      "\n",
      "So in that help engine, it is like a it is like a pre fabricating the data such so that it can go into the graph structure. ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior. ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "So we again use the associated domain language model of the custom custom Channel language model for for feature is Amal the text that picket and then and then we also bring in the notion of Miles here. ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "I will talk about the difference just just in a minute, but but so what we are trying to say here is along with the actual factual information like who spoke what or or what are the you know who attended the meeting so these Services enable The Ether ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "In terms of its relevance relevance and other aspects caps in other aspects. ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have. ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "You know, Knowledge Graph like the factual graph on The Ether graph. ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "So presentation so that we can be can you know use it for all sorts of computations. ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "So we are in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature. ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim. ba1e58eebf634454876be91308dd126d \n",
      "\n",
      "Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself is not are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or nonobvious inside sort of the god Apollo. 0028af3fa1cd42fb916efc5ea85f9abe \n",
      "\n",
      "--------------\n",
      "Whereas when I say, hey, you know Karthik follow up on this production issue, you know the idea that Karthik is the person who I am assigning this action to is something that is not so intuitive and needs to be gleaned right by first applying NLP in these types of rules then later on also being getting represented in the laugh c0378db3c78e4aae90c1b891b5ccafaf \n",
      "\n",
      "Something like, you know, if I am part of a channel that is a very direct relationship which does not require a lot of intelligence which is get it right out of the station. c0378db3c78e4aae90c1b891b5ccafaf \n",
      "\n",
      "So we are in the in the computation graph as we as mentioned earlier. 9bc06ede99df459890697edb5ca18a38 \n",
      "\n",
      "So say for example, if I have to give you one example of how the how the body is nonintuitive relations could be is you know, let us say let us say let us say Karthik talked about kubernetes in one of the in couple of calls 9bc06ede99df459890697edb5ca18a38 \n",
      "\n",
      "It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks. 9bc06ede99df459890697edb5ca18a38 \n",
      "\n",
      "So having said that I will just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component. 9bc06ede99df459890697edb5ca18a38 \n",
      "\n",
      "So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get. 9bc06ede99df459890697edb5ca18a38 \n",
      "\n",
      "So as you said the example that you gave write a card they can you follow the on this can come as part of the conversation in the free text, you know free language. 9bc06ede99df459890697edb5ca18a38 \n",
      "\n",
      "So that is how the evaluation of you know, relationships happened within the that is one of the example that I just gave program give you an idea of how computation graph works. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "But if I orthotic that means every time Karthik talks about kubernetes if you are a watch it so which which makes in which makes him kind of we approve his Dont open it is and that we captured that inside to and then reinforce that that relationship as a Karthik is an expert in kubernetes. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "So so so what it does is it also forms a relation between Karthik as anode which is the user and then the kubernetes as a topic and then says you know here Initially then as as as as more and more conversations around kubernetes are happening. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "So we we just organize the topics key phrases captured as the notes on that. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "So how in fact we can even take consensus just because Karthik is talking we need not say that he could be an expert. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "The talked about can get interest into is a is an expert in tuber natives even say that is very cool. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we are going to talk about a little so so so and also other top XO from the from the from the computation graph perspective. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "What bought the nodes could be along with the the factual notes like the users and favorite pics. f144cefb8c3240909750cb9940444be9 \n",
      "\n",
      "Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation. d664f7f953984352a85c1b8b06a309b8 \n",
      "\n",
      "Okay and then I guess once you have these types of graphs. ca7d7bdff13246d89898f335ec0ab4ac \n",
      "\n",
      "Yes, I eat a graph is more of a traditional representation of God. ca7d7bdff13246d89898f335ec0ab4ac \n",
      "\n",
      "Yes, it is teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them. ca7d7bdff13246d89898f335ec0ab4ac \n",
      "\n",
      "So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations. 2c322826f6084509a38f3ea7be1705f2 \n",
      "\n",
      "But but what they come as a combination represents, so once they have this as a mathematical object, like like a like a embedding what we can do is we can do lot of you know algorithms on because we are free to do all the math around it and then we can you can get for the similar users to kartik from the context of you know, the topics that that he discusses or from the context of the action items. 2c322826f6084509a38f3ea7be1705f2 \n",
      "\n",
      "That means all the relationships about the topics whom he follows or whom who I mean, what are the topics that he usually discusses and then we just call that whole component and then we encode everything into into the cottage. 2c322826f6084509a38f3ea7be1705f2 \n",
      "\n",
      "All the users will have their own representation that not just captures what who they are. 2c322826f6084509a38f3ea7be1705f2 \n",
      "\n",
      "And then what comes out is actually a lot more, you know a lot more insights that will enable us to do like very nonintuitive recommendations. 2c322826f6084509a38f3ea7be1705f2 \n",
      "\n",
      "So as I talked about that Karthik being expert in a in kubernetes, right so that can be formed from the from some of this. 2c322826f6084509a38f3ea7be1705f2 \n",
      "\n",
      "You know, I would rather than that we use like the node embeddings what I mean by no damn wedding is when there is Karthik so we do not just we do not just see Karthik as you know a person so we also input all the information that he that actually this ether captures about about that. 2c322826f6084509a38f3ea7be1705f2 \n",
      "\n",
      "If you do not talk about anything else if direct enables us to form the you know, form the form this noninductive relationships like talked about a certain topic or action item assigned to so now let us take forward and then use This graph that is actually being formed after all the conversations. 2c322826f6084509a38f3ea7be1705f2 \n",
      "\n",
      "And then what we what we do is we just put it through a graph neural networks kind or the different graph algorithms. 2c322826f6084509a38f3ea7be1705f2 \n",
      "\n",
      "Just think of integrating these insights into you know, a ticket management tool like jira, right? 42c18ef5d2f543f98e10b9c46d7e1d3a \n",
      "\n",
      "So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this. 42c18ef5d2f543f98e10b9c46d7e1d3a \n",
      "\n",
      "That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it. abceb463b6d442dd88e9607b7c09c7b9 \n",
      "\n",
      "--------------\n",
      "Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it is too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the 95a41af139e448c19878b2703b380e0f \n",
      "\n",
      "So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "So let me just put it in my queuing for the scoring in the next steps. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "So so what we do is it is a two step process. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "But what we do is when we say topic identification or be identified the potential important moments in the call. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "So so that brings us to how we do that keyphrase extraction from the from the technical standpoint. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "We do not have any context of what is important and what is not important. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "All we know is this this this diagram or the three words combination sounds as if it is an important people. fefe76dee147480e853c0df3db683dbf \n",
      "\n",
      "So we just we just so Channel Minds just drops it or even the associated key phrases. b85dddabb62f4cc6896abc7ebdde9618 \n",
      "\n",
      "So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it. b85dddabb62f4cc6896abc7ebdde9618 \n",
      "\n",
      "Need to be captured as a as an important environmental issues as an important topic of the people. b85dddabb62f4cc6896abc7ebdde9618 \n",
      "\n",
      "Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues. b85dddabb62f4cc6896abc7ebdde9618 \n",
      "\n",
      "Whole context of the either the topic of the important movement. b85dddabb62f4cc6896abc7ebdde9618 \n",
      "\n",
      "It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need. b85dddabb62f4cc6896abc7ebdde9618 \n",
      "\n",
      "So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating. b85dddabb62f4cc6896abc7ebdde9618 \n",
      "\n",
      "So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "So when you have see how it comes is when you have let us say the conversation about machine learning or or any software engineering related. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "And then coming to come into the training part of it. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "So one of these data sets that we use for our general benchmarking is this SST wherein it captures all the sentence similarity task action. b11cd18c8a1e4b2cbd3ea53775db9f64 \n",
      "\n",
      "Text and then we correlate that with the context associated with the channel Minds at the end of this this whole process this multi step three step process. f4773b1607784818b1f9ec84d60f497d \n",
      "\n",
      "What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment. f4773b1607784818b1f9ec84d60f497d \n",
      "\n",
      "We just passed the context through this algorithm finetuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know. f4773b1607784818b1f9ec84d60f497d \n",
      "\n",
      "We do is we take we take each candidate key face on the contacts associated with it. f4773b1607784818b1f9ec84d60f497d \n",
      "\n",
      "When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there. f4773b1607784818b1f9ec84d60f497d \n",
      "\n",
      "So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right? 2a6e41e2ddda495d82a94089f247211b \n",
      "\n",
      "for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so 2a6e41e2ddda495d82a94089f247211b \n",
      "\n",
      "--------------\n",
      "That is the whole point of the channel when so so so the inference that I said, it just scores against channel channel Pine and then and then what comes out is the bunch of segments that that post that mostly covers the whole conversation at the same time sticking to what the channel is related to ensure of a deviating from that. ccaf53d160fa453e9e591b4920256a16 \n",
      "\n",
      "Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case. b411b227696341bba3ef7cc36371c806 \n",
      "\n",
      "I mean, I think we all had the solution as well. b411b227696341bba3ef7cc36371c806 \n",
      "\n",
      "How do we pull these chapters out of pull these topics out and and show them? 15c91e41708949e6b6661aa7213b5f70 \n",
      "\n",
      "Right thus often times, you know, people are talking like, you know, in a team of say five six people one a call teams tend to get into discussions, you know, we are going back and forth particular subject and then you move on to some other subject in some other topic and so on right where so how do we kind of use this? 15c91e41708949e6b6661aa7213b5f70 \n",
      "\n",
      "It is just a stock affection adult done done in a very flexible way. bfb6232992d24ca7af89c09a807be6f6 \n",
      "\n",
      "So so what this some topic extraction does is it will be very very, you know Broad in its topic identification also, so so let us say a certain Paul covered software engineering in which we talked about Lambda and Learning deployment and then in the same pot. bfb6232992d24ca7af89c09a807be6f6 \n",
      "\n",
      "Let is say what we do is when you are as you have shown in the example at wearing one Call we are run through all the multiple channels of then we got different sub arrays. bfb6232992d24ca7af89c09a807be6f6 \n",
      "\n",
      "We talked about Recruitment and also the product strategy what it does is most likely could put Lambda and deployment the same topic because you know, they have been discussed together. bfb6232992d24ca7af89c09a807be6f6 \n",
      "\n",
      "What it does is it will be able to defeat evil to slice machine learning related components into one one topic and Lambda base if there is a fair segregation it will be able To slice them. bfb6232992d24ca7af89c09a807be6f6 \n",
      "\n",
      "So it is like a fairly flexible topic slicing algorithm that we that we have in place a topic extraction. bfb6232992d24ca7af89c09a807be6f6 \n",
      "\n",
      "But otherwise if in another call we talked about Lambda base deployments for a whole lot of XnumberX minutes. bfb6232992d24ca7af89c09a807be6f6 \n",
      "\n",
      "So the the whole intent of this app does not topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about. bfb6232992d24ca7af89c09a807be6f6 \n",
      "\n",
      "So what it does is if there are if there is a broader, you know, the broader categories of topics that are being discussed in certain calls. bfb6232992d24ca7af89c09a807be6f6 \n",
      "\n",
      "So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graphbased for this. 0fd2a6dbbea446c88b98dd6cd79958e7 \n",
      "\n",
      "And then we have a graph a graph with with all these conversations as a notes. ef4868f848594956b91214db33188407 \n",
      "\n",
      "It just would be found between them but no, it should be formed between Docker or the recruitment because even though they are talked in the same conversation or even inverse cos they are actually talked right one after the other because ef4868f848594956b91214db33188407 \n",
      "\n",
      "So what we do is we just organized the meeting into the graph that that is fairly simple because you know, you have lot of this text segments and then we we have eat them as the node. ef4868f848594956b91214db33188407 \n",
      "\n",
      "So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed. ef4868f848594956b91214db33188407 \n",
      "\n",
      "So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they are moving back and forth. ef4868f848594956b91214db33188407 \n",
      "\n",
      "Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there. ef4868f848594956b91214db33188407 \n",
      "\n",
      "So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends. c8c884f333ad49ce8447248a4a41dfc8 \n",
      "\n",
      "I mean, I mean relatively so sure so that is what the topic is. c8c884f333ad49ce8447248a4a41dfc8 \n",
      "\n",
      "So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics. c8c884f333ad49ce8447248a4a41dfc8 \n",
      "\n",
      "So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting. c8c884f333ad49ce8447248a4a41dfc8 \n",
      "\n",
      "So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out. c8c884f333ad49ce8447248a4a41dfc8 \n",
      "\n",
      "Actually, there was strong association between within XnumberX people where in most of the people are connected with most of the others. c8c884f333ad49ce8447248a4a41dfc8 \n",
      "\n",
      "What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community. 7e78f8c1912640d5a7874ed1673c3bdc \n",
      "\n",
      "It comes from the language model finetuning which has nothing to do with the communities. 7e78f8c1912640d5a7874ed1673c3bdc \n",
      "\n",
      "And then how we trial how we trial is as I said, it is more of it. 7e78f8c1912640d5a7874ed1673c3bdc \n",
      "\n",
      "So just to just to be just to be aligned with the with the flow. 7e78f8c1912640d5a7874ed1673c3bdc \n",
      "\n",
      "Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here. 7e78f8c1912640d5a7874ed1673c3bdc \n",
      "\n",
      "A nation of community algorithm parameters and the language model performance. 7e78f8c1912640d5a7874ed1673c3bdc \n",
      "\n",
      "What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth. 7e78f8c1912640d5a7874ed1673c3bdc \n",
      "\n",
      "But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model. 7e78f8c1912640d5a7874ed1673c3bdc \n",
      "\n",
      "But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated. 7e78f8c1912640d5a7874ed1673c3bdc \n",
      "\n",
      "Right the fact that when a user is interacting with our tool. dbc27c69e0cb400792109ef93ffa4b9a \n",
      "\n",
      "Yep at the manual tasks that they do very naturally helps reinforce our a models. dbc27c69e0cb400792109ef93ffa4b9a \n",
      "\n",
      "--------------\n",
      "Okay, so when could I thought it will be good for us to do a little bit have a dis little bit of a discussion on just the I stack with ether. c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "The first is its concept of Channel or team mines where whereby we are representing the team context both the static aspects of it. c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "Let is say there is a team that is working on software engineering or databases or Our devops in general, right? c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "So there is a static idea that they are working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently. c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "All right, but just to reiterate if you look at ethers a I stack there are a few things that that we want to kind of highlight, right? c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "This will be gone through that that call and got up. c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "Is that a production issue that is being addressed right now it is that a particular type of database are talking about or you know, a particular aspect of their software engineering stack that they are talking about. c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "So I am assuming that a lot of the folks who are seeing. c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide. c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "So the first time Idea is idea about Channel or team Minds. c0811e5112d64a2283f7245cad8a2f9c \n",
      "\n",
      "And so how do you extract what is Meaningful and what is not so that is another aspect of how either ether zai gets applied to just the meetings their interactions, right? b60bd6a19af74c8babd823c334cabe41 \n",
      "\n",
      "But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right? b60bd6a19af74c8babd823c334cabe41 \n",
      "\n",
      "Being and you are having a discussion, maybe it is a group meeting and you are talking about five different topics in the call or you are talking about, you know, you are doing a two people are talking about one particular subject. b60bd6a19af74c8babd823c334cabe41 \n",
      "\n",
      "Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them. b60bd6a19af74c8babd823c334cabe41 \n",
      "\n",
      "Let is say you are in a meeting and you are and the team is having a discussion and in an hour is call you are talking about a bunch of different topics. b60bd6a19af74c8babd823c334cabe41 \n",
      "\n",
      "So one quick way of kind of talking about the the graph would be that it is a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right? b60bd6a19af74c8babd823c334cabe41 \n",
      "\n",
      "How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information. b60bd6a19af74c8babd823c334cabe41 \n",
      "\n",
      "The next is the idea of topic detection using communities, which is a you know, when you there is a there is a meeting that is happening. b60bd6a19af74c8babd823c334cabe41 \n",
      "\n",
      "I think the the next one is this idea of you know, how once a call is over. b60bd6a19af74c8babd823c334cabe41 \n",
      "\n",
      "Should talk about next is the keyphrase extraction, which is sometimes it is hard to blame the entire discussion. b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "So, of course, there is also a couple of other things that we are working on. b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "So before we get started a lot of times question comes up when we talk about ether how we do our speechtotext, right? b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth. b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right? b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "We just to kind of lay this out is we do not b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "On the background and we will touch upon those as well. b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them. b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out. b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss. b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "So that is a very interesting aspect of ethers a sec as well and last but not the least. b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects. b052f73988884a48894804b2d1113e77 \n",
      "\n",
      "So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider? cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time. cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "And so the way we built ether was to have a lot of flexibility in being able to associate any speechtotext engine to with our for our purposes. cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times. cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible So we cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well. cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "So the way we do this is, you know showcases app, which is ether meet. cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality. cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "We integrate with the close partner called Deep Graham to provide. cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "When we go to market with our partners, they actually like to use their own speechtotext technology for integrating. cc053b7c0140422da427a2de89414448 \n",
      "\n",
      "So let us talk about Channel Minds right little deeper into Channel Minds. a7d5164db7a84332b5973d95477f6c2c \n",
      "\n",
      "Maybe you can just give us a quick overview of what channel Minds is. a7d5164db7a84332b5973d95477f6c2c \n",
      "\n",
      "We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes. a7d5164db7a84332b5973d95477f6c2c \n",
      "\n",
      "I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on. a7d5164db7a84332b5973d95477f6c2c \n",
      "\n",
      "So that is the other kind of unique aspect about how we have built it inside our architecture. a7d5164db7a84332b5973d95477f6c2c \n",
      "\n",
      "So on and so forth, so it is very very flexible. a7d5164db7a84332b5973d95477f6c2c \n",
      "\n",
      "--------------\n",
      "One of the things that I always like to say is ether is the world is best meeting somebody engine right there. 958c5e5250b846b1b1e79045b696a018 \n",
      "\n",
      "So moving on I guess the next very I guess very important thing one way. 958c5e5250b846b1b1e79045b696a018 \n",
      "\n",
      "How do you Pull out what is important and what is not so maybe you can just quickly run through. 958c5e5250b846b1b1e79045b696a018 \n",
      "\n",
      "So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half. 958c5e5250b846b1b1e79045b696a018 \n",
      "\n",
      "What is the score for a certain segment when you say segment? 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "I will come to the training part A little later, but we just passed it through that are. 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about. 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that is currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right? 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "What we do is we have we we continuously create a list of summaries. 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time. 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time. 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "It is like a Texan which is actually fairly selfcontained either either. 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "So what we do is when we do this the similarity task, you know finetuning of the language model. 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "So and then we score the in the scoring process is what the training aspect is. 45f9dc69f29441e8b517565893255f0c \n",
      "\n",
      "And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "Through this validation data on this we keep updating this validation data so that we can we can safely say that if it passes the validation set because it has not seen those validation satyr during training if it passes the validation set we can fairly say that we can deploy that into the, you know, Ever Changing dynamics of the team. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "We generate like lot of candidate Al Gore models that will come out for that. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "We just we just passed this, you know, all the segments. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "So this this kind of a semiautomatic autonomous approach because we just do not want to automate it we can we can definitely automate but but the whole point Of the channel Minds to ever evolve at the same time. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "So each segment will have relative score on of course passes through certain minimal threshold. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "We should also, you know, improve our improve or adapt to the validation data that we create. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "So without without much Concepts so once so, that is how we validate. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "We come up from the initial filtration of their performance and then we pass all those candidate models. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "I mean we need not worry about the what do you call the quantifiable T of the score because you know, it is all relative. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "So this scoring box and then what what comes out is again. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "Up tents of or hundreds of calls and then we manually curate what are the most important moments given the converse given the meeting given that this meeting is part of a certain Channel. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "So it is a semiauto autonomous approach that we adopt the pews for the validation. 86d5c1d132554eaf8b26567de70faa9d \n",
      "\n",
      "--------------\n",
      "If you are spending the five ten in the first five minutes talking about the latest IPL score Kidd game as that happen, you are able to easily filter those unimportant moments out and get right into the important moments, which is what are the rest of the team can 85355cce55d6421999d8baa188a65d87 \n",
      "\n",
      "Okay, I guess so it kind of going into the details right the other I guess very important aspect is how we pull out meeting Primitives, I guess. 69109483e398424f96b987d904227cf1 \n",
      "\n",
      "So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right. 69109483e398424f96b987d904227cf1 \n",
      "\n",
      "So maybe you can quickly run through how we pull out action items. 69109483e398424f96b987d904227cf1 \n",
      "\n",
      "So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on. 69109483e398424f96b987d904227cf1 \n",
      "\n",
      "What are the action items that are that it that they either bought things as an action items and then and then and then gives gives away. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "So actually we are talking about action items that are being in the freeflow conversation like what we are doing right now. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "Should I just like I think when we say action items, let us let me put one point before we talk about it. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "There is if they have seen a lot of exotic references like that. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "So how do we do that is we have actually collected lot of training data for this. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "So this This fairly has nothing to do with the with the language model that we discussed earlier. e7071f03540e41928e524f6358fce509 \n",
      "\n",
      "But as a total it has actually it has identified only XnumberX, even though the noise is list. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "Mmm, but we are okay to have lot of that means if I capture XnumberX out of XnumberX candidate action items. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "So so so we have trained a language model to finetune such that we can be we have adopted that language model to be a binary classifier. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "So again the action item as a whole is not just a model here sigh that is what I wanted to highlight here. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "Youll recall or wherein we do not want to miss anything that has an accent. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I am okay to have a lot of noise in the carrot patch. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "Sorry, but I do not want to miss even a single action item. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "So that is why we find you this classifier to have a highest possible. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "I am okay to have only four of them being the real action items, but I do not want to miss even one of the action items one of those pork perfect. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items. 6052f095303e4390a3bef29c89cf8f28 \n",
      "\n",
      "What we do is we just we just pass the center. e44d0a245c4d403d8b2c46bb0b9bb9c0 \n",
      "\n",
      "So that means as soon as we get this speech segments from specific sequence from the call, right? e44d0a245c4d403d8b2c46bb0b9bb9c0 \n",
      "\n",
      "So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded. e44d0a245c4d403d8b2c46bb0b9bb9c0 \n",
      "\n",
      "And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item. e44d0a245c4d403d8b2c46bb0b9bb9c0 \n",
      "\n",
      "So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action. e44d0a245c4d403d8b2c46bb0b9bb9c0 \n",
      "\n",
      "So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step. e44d0a245c4d403d8b2c46bb0b9bb9c0 \n",
      "\n",
      "Say for example, if there is an action item detected by the candidate, but I did not find any grammatically relevant subject in them. e44d0a245c4d403d8b2c46bb0b9bb9c0 \n",
      "\n",
      "That is why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect. e44d0a245c4d403d8b2c46bb0b9bb9c0 \n",
      "\n",
      "We are also able to extract who it is assigned to write based on who is present in the call. ecf667ce7d2341bc9de3acb7140eeba7 \n",
      "\n",
      "Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right? ecf667ce7d2341bc9de3acb7140eeba7 \n",
      "\n",
      "And you know who is speaking and who is the recipient and so on? ecf667ce7d2341bc9de3acb7140eeba7 \n",
      "\n",
      "You are very nuanced and these types of actions are actually pulled out automatically from the conversations. ecf667ce7d2341bc9de3acb7140eeba7 \n",
      "\n",
      "Okay, cool, so I guess here is a taking a quick example, so here are three different segments, right? ecf667ce7d2341bc9de3acb7140eeba7 \n",
      "\n",
      "They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved. a939ecf68bc24d3895eef49731912d5c \n",
      "\n",
      "--------------\n",
      "So you can kind of get a feel for it as we go on but wine to get started and let us dive in and talk a little bit about Channel Minds. e79cf121424c4717afd9092c89923582 \n",
      "\n",
      "So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right? b5e0038d0a064f619167d6d0c34e6f82 \n",
      "\n",
      "All right, so there is there is here is a kind of an example. 3a204f1bbd3148a09474a475c92d3ae5 \n",
      "\n",
      "Let me actually take this down and show it in a real slack conversation. 3a204f1bbd3148a09474a475c92d3ae5 \n",
      "\n",
      "I wanted to kind of call out Channel minds and action. 3a204f1bbd3148a09474a475c92d3ae5 \n",
      "\n",
      "Alright, so that is actually a good segue to actually before we do that. 3a204f1bbd3148a09474a475c92d3ae5 \n",
      "\n",
      "You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right? 879767f019d74aabbba1b22bc86ff0cb \n",
      "\n",
      "So again, let me go back switch to my presentation here. 879767f019d74aabbba1b22bc86ff0cb \n",
      "\n",
      "So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that is associated with it. 879767f019d74aabbba1b22bc86ff0cb \n",
      "\n",
      "And then when you pass it through when you have that meeting in the context of a software engineering mind, the discussion summarizes The Ether summarizes the discussion pulls out topics related to software for example things about database continuously ICD kubernetes Etc. 879767f019d74aabbba1b22bc86ff0cb \n",
      "\n",
      "So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics. 879767f019d74aabbba1b22bc86ff0cb \n",
      "\n",
      "So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right? 879767f019d74aabbba1b22bc86ff0cb \n",
      "\n",
      "Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels. 879767f019d74aabbba1b22bc86ff0cb \n",
      "\n",
      "Our infrastructure that Kafka whereas when you talk about when you run the same meeting through the marketing channel, you know, it pulls out things about, you know, digital marketing. 879767f019d74aabbba1b22bc86ff0cb \n",
      "\n",
      "it is fair play shows how how the channel man is able to differentiate based on the Mind attached to it during the 3e7f63d9f4b446a18a0b25758e6020ca \n",
      "\n",
      "That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that is a very unique way of representing the intelligence of the Insight that is happening in the context of teams and and the organization in a graph format and using this in a variety of different ways. 49a9c7427412404abce4ff763aad210b \n",
      "\n",
      "So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like. 49a9c7427412404abce4ff763aad210b \n",
      "\n",
      "Maybe you can just walk us through this a little bit. 49a9c7427412404abce4ff763aad210b \n",
      "\n",
      "All right, so it is a great segue into you know, so when we talked about Channel Minds you brought up this notion of the dynamic portion. 49a9c7427412404abce4ff763aad210b \n",
      "\n",
      "So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is. 49a9c7427412404abce4ff763aad210b \n",
      "\n",
      "A new person comes and then he comes and talks about the same subject right ether can very easily extract the idea that this discussion has happened before and actually say hey now that you are discussing this subject. 2e6829cebf67481d95955e3afdf08c5b \n",
      "\n",
      "You may also want to follow up on this other topic right? 2e6829cebf67481d95955e3afdf08c5b \n",
      "\n",
      "Are you watch this other discussion that happened a few months ago and that makes teams just work a lot efficiently and save a lot of time in going back and forth, right? 2e6829cebf67481d95955e3afdf08c5b \n",
      "\n",
      "Yeah, and so kind of generating this idea of who are the recommended Watchers. 2e6829cebf67481d95955e3afdf08c5b \n",
      "\n",
      "So those types of things can be applied to Enterprise intelligence as well because a lot of times T teams keep discussing the same subjects again and again, right so it is very common that in a team for example in an engineering team a particular type of databases that you know is being considered for their architecture, you know, the engineer leaves the company goes away voila six months later. 2e6829cebf67481d95955e3afdf08c5b \n",
      "\n",
      "What are the use cases that we always talk about is, you know a lot of times when you have a meeting, let us say you and I are having this call and then we produce a summary it will be always good to know who should you know, what people who are would actually likely to watch this, right? 2e6829cebf67481d95955e3afdf08c5b \n",
      "\n",
      "Youre a discussion right are more importantly, you know, as we see in ecommerce lot of times right you buy this product you also You know you get this common thing that saves users who bought this are also interested in these other types of products, right? 2e6829cebf67481d95955e3afdf08c5b \n",
      "\n",
      "Yeah, so so it actually brings it to one more notion. d5a60e4f0a5a4ce48d929b81dd6260d6 \n",
      "\n",
      "We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right? d5a60e4f0a5a4ce48d929b81dd6260d6 \n",
      "\n",
      "So let us move on and maybe just give a quick example not going to spend a whole lot of time on this but just to give a representation of here is a real world example. 97f2b973beea4fad9394feb35dde9990 \n",
      "\n",
      "Let me see if I can actually pull up the graph itself. 97f2b973beea4fad9394feb35dde9990 \n",
      "\n",
      "Let me stop the content here and show the real graph. 97f2b973beea4fad9394feb35dde9990 \n",
      "\n",
      "So those types of relationships can be gleaned very easily from the knowledge graph, right like so for example in this particular case when we run this query about who is who is a personal talked about Google these three people who come up myself Cullen and Karthik right where we talk a lot about Google. 2413039a385f4b5e96464f3064d6142b \n",
      "\n",
      "So these types of relationships get pulled out very easily from the knowledge. 2413039a385f4b5e96464f3064d6142b \n",
      "\n",
      "So one is we are able to we took essentially one of the workspaces and map the interactions into a into a graph here and let us say we want to find out who the goo. 2413039a385f4b5e96464f3064d6142b \n",
      "\n",
      "Will experts are in a workspace in this can be very simple as a who is the person who is interested in a particular technology. 2413039a385f4b5e96464f3064d6142b \n",
      "\n",
      "That is just a quick example at a sample of what we do. 2413039a385f4b5e96464f3064d6142b \n",
      "\n",
      "I do not know if you are able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things. 2413039a385f4b5e96464f3064d6142b \n",
      "\n",
      "Hopefully this gives you a pretty good idea to the viewer about the different things types of things that we use in either for AI and I guess in a different discussion, I guess maybe we can go into how actually a lot of this is operationalized inside our deployments, but that is a discussion for another day. b623465fc8024dee92d363bfd236281f \n",
      "\n",
      "So I think that that kind of concludes this discussion right thanks to incur that we have covered a lot of things. b623465fc8024dee92d363bfd236281f \n",
      "\n",
      "--------------\n",
      "But even if there is a slight mention of software engineering its prices for it higher than than the rest but it gives you a very good summary of what is happening. e23d686b4b614aba8e082a32c44d539a \n",
      "\n",
      "Whole lot of huge HR conversation within in software engineering team so it could it could so it could still give out some important moments. e23d686b4b614aba8e082a32c44d539a \n",
      "\n",
      "Yep, so it is kind of a very folks summer day would say so so it just it just cuts out the noise very aggressive price to stick to what what the team needs actually. bfe619410c4e4688abeebeb959407df4 \n",
      "\n",
      "This is one says even the whole subject is about about software. 0586a3fbdb6e4276ae19b4f04f5e3311 \n",
      "\n",
      "I guess, you know different topics are different groups of topics and the people involved in those conversations are pulled out a very elegant way I think is very cool. 0586a3fbdb6e4276ae19b4f04f5e3311 \n",
      "\n",
      "Things like that and then they went back Arjun venkat and three shots now talked about databases. 0586a3fbdb6e4276ae19b4f04f5e3311 \n",
      "\n",
      "Got it tigers have wanted to show a quick example of how this works. 0586a3fbdb6e4276ae19b4f04f5e3311 \n",
      "\n",
      "So here is a call that happened and where there is a bunch of discussion that that happened between a group of people and we are able to very nicely kind of pull out the fact that the shunt and Arjun talked about deployment and configuration devops related subjects and then the Russians and blanket in then moved on and talked about some database subjects like Seattle and Cloud SQL exactly exactly. 0586a3fbdb6e4276ae19b4f04f5e3311 \n",
      "\n",
      "Granular Kappa can get you can go from the top level where in you have totally relevant unrelated topics discussed. fb2a244ad7bf446f9b97a082430c6a27 \n",
      "\n",
      "So they end up as a topics or to the as we go granular. fb2a244ad7bf446f9b97a082430c6a27 \n",
      "\n",
      "I hear it did not actually slice the whole databases databases singled out because it just reaches talked about database and run something related to deployment together. fb2a244ad7bf446f9b97a082430c6a27 \n",
      "\n",
      "So so it just it is just able to put them together aggressive. fb2a244ad7bf446f9b97a082430c6a27 \n",
      "\n",
      "That means if we talk only about databases on the deployment, it would have done the other way like click diplomatic conversations and then they database so that is the level of flexible. fb2a244ad7bf446f9b97a082430c6a27 \n",
      "\n",
      "--------------\n",
      "So we are working on a technique where we can detect that the slide is being presented and then automatically pull out information from that using Standard computer vision techniques and then once the vision was a slight information is converted to text a lot of the same information can be used in terms of applying what is relevant and what is not and what is the topic and what is a keyword and so on so forth, right? f853870e10f44514a6f048debee2a416 \n",
      "\n",
      "So obviously and and I will just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that. f853870e10f44514a6f048debee2a416 \n",
      "\n",
      "In the coming weeks and months is that in a shed setting? f853870e10f44514a6f048debee2a416 \n",
      "\n",
      "Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on. f853870e10f44514a6f048debee2a416 \n",
      "\n",
      "Let is say a bunch of people are crowded around the conference call content speakerphone or whatever, right? f853870e10f44514a6f048debee2a416 \n",
      "\n",
      "We are continually creating a library of our signature using standard MFC sea bass techniques and creating patterns and storing them for every speaker that we know and then as we detect changes in those patterns, we we kind of apply that to speaker dilation and then if the signature actually matches someone in our database f853870e10f44514a6f048debee2a416 \n",
      "\n",
      "So I am just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we have done some amount of proof of Concepts and investigation into it and we plan to do more on this. f853870e10f44514a6f048debee2a416 \n",
      "\n",
      "We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right. f853870e10f44514a6f048debee2a416 \n",
      "\n",
      "So we do not need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also a710f5a0577544f5b83550f11a02fa2f \n",
      "\n",
      "We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there is an unknown speaker. a710f5a0577544f5b83550f11a02fa2f \n",
      "\n",
      "Maybe someone can manually tag it and so on using our user interface, right? a710f5a0577544f5b83550f11a02fa2f \n",
      "\n",
      "<---------------->\n",
      "order difference: 1\n",
      "Relevant sentence:  I think before before we get started with its II think I think I will just give you a heads up on a thin configuration by it.    =====    Maybe you know, I sorry for not doing this, but maybe you can just give a quick introduction about yourself.\n",
      "order difference: 0\n",
      "Relevant sentence:  Maybe you know, I sorry for not doing this, but maybe you can just give a quick introduction about yourself.    =====    And also maybe give a little bit of background about Ari, I think sure.\n",
      "order difference: 1\n",
      "Relevant sentence:  And also maybe give a little bit of background about Ari, I think sure.    =====    So it is a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor.\n",
      "order difference: 0\n",
      "Relevant sentence:  So it is a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor.    =====    Then and I leave The A Team we are we are a team of XnumberX.\n",
      "order difference: 0\n",
      "Relevant sentence:  Then and I leave The A Team we are we are a team of XnumberX.    =====    I mean as a team they worked on very broader set of are use cases ranging.\n",
      "order difference: 0\n",
      "Relevant sentence:  I mean as a team they worked on very broader set of are use cases ranging.    =====    So having said that I think I think that should be good enough with the team and then maybe it is good time to get here.\n",
      "order difference: 0\n",
      "Relevant sentence:  So having said that I think I think that should be good enough with the team and then maybe it is good time to get here.    =====    So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the stateoftheart models in the Deep learning or any other machine learning space coming out then so that is where you see, you know.    =====    Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe.\n",
      "order difference: 0\n",
      "Relevant sentence:  Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe.    =====    Ml Engineers who are who primarily work on machine learning deployments and also building the stateoftheart machine learning models.\n",
      "order difference: 0\n",
      "Relevant sentence:  Ml Engineers who are who primarily work on machine learning deployments and also building the stateoftheart machine learning models.    =====    I also also like the Imaging and then the video processing and on the text, I mean the speechtotext and and and the whole whole spectrum of the AI ecosystem.\n",
      "Not Relevant sentence:  I also also like the Imaging and then the video processing and on the text, I mean the speechtotext and and and the whole whole spectrum of the AI ecosystem.    !=    Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion.\n",
      "order difference: 2\n",
      "order difference: 0\n",
      "Relevant sentence:  Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion.    =====    I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.\n",
      "order difference: 0\n",
      "Relevant sentence:  I will give you what goes behind the scenes for the for the channel Minds technically and then we will come to how it works across all the a downstream applications.    =====    So I will just walk you through I will give you a tip.\n",
      "order difference: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant sentence:  So I will just walk you through I will give you a tip.    =====    Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a preloaded, you know library of domain mines be call.\n",
      "order difference: 0\n",
      "Relevant sentence:  Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a preloaded, you know library of domain mines be call.    =====    So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans.\n",
      "order difference: 0\n",
      "Relevant sentence:  So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans.    =====    So I think with the headset that you gave about the channel Minds I meant that that is like a thousand feet free of what channel mine does.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I think with the headset that you gave about the channel Minds I meant that that is like a thousand feet free of what channel mine does.    =====    So we stopped with such which talks about each domain when talks about certain certain.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we stopped with such which talks about each domain when talks about certain certain.    =====    These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether.\n",
      "order difference: 0\n",
      "Relevant sentence:  These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether.    =====    It is just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period.\n",
      "order difference: 0\n",
      "Relevant sentence:  It is just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period.    =====    It is a wonder my mind is software engineering the other one could be markers.\n",
      "order difference: 0\n",
      "Relevant sentence:  It is a wonder my mind is software engineering the other one could be markers.    =====    I mean the feature extractor for the whole process wherein we train we train the neural net.\n",
      "order difference: 1\n",
      "Relevant sentence:  I mean the feature extractor for the whole process wherein we train we train the neural net.    =====    That means we keep on adding the the new domains to our domain Library.\n",
      "order difference: 0\n",
      "Relevant sentence:  That means we keep on adding the the new domains to our domain Library.    =====    So which means I mean, Coming to the language model aspect of it.\n",
      "order difference: 0\n",
      "Relevant sentence:  So which means I mean, Coming to the language model aspect of it.    =====    We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you are doing earlier, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you are doing earlier, right?    =====    Let is say the if the engineering teams talks about production.\n",
      "order difference: 0\n",
      "Relevant sentence:  Let is say the if the engineering teams talks about production.    =====    Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.\n",
      "order difference: 0\n",
      "Relevant sentence:  Coming to coming to finetune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about.    =====    So when when a user is invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel.\n",
      "order difference: 0\n",
      "Relevant sentence:  So when when a user is invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel.    =====    I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.\n",
      "order difference: 1\n",
      "Relevant sentence:  I am going to show some examples in the next slides, but but to give you what it means, let us say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked.    =====    We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.\n",
      "order difference: 0\n",
      "Relevant sentence:  We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet.    =====    Action that is coming, you know to The Ether AI engine if you are it.\n",
      "order difference: 0\n",
      "Relevant sentence:  Action that is coming, you know to The Ether AI engine if you are it.    =====    So so that is where the channel mind comes into play when we say mine.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so that is where the channel mind comes into play when we say mine.    =====    I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.\n",
      "order difference: 0\n",
      "Relevant sentence:  I will talk about the Mind generation in the next slide, but How do we finetune I will just continue on that.    =====    So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so along with fine tuning this language model wherein you know, software engineering language model would be finetuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that.    =====    Once we once we have the language model, that is fine tune.\n",
      "order difference: 0\n",
      "Relevant sentence:  Once we once we have the language model, that is fine tune.    =====    What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data.\n",
      "order difference: 0\n",
      "Relevant sentence:  What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data.    =====    The model is the actual neural network model and the mind is is the graph data structure that organizes the information.\n",
      "order difference: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant sentence:  The model is the actual neural network model and the mind is is the graph data structure that organizes the information.    =====    I guess one way to talk about that would be there is a static component.\n",
      "order difference: 0\n",
      "Relevant sentence:  I guess one way to talk about that would be there is a static component.    =====    Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.\n",
      "order difference: 1\n",
      "Relevant sentence:  Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on.    =====    So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it is a static component.\n",
      "order difference: 0\n",
      "Relevant sentence:  So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it is a static component.    =====    So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we are giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently.    =====    And then in the meantime, we do not want to lose the information that we have.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then in the meantime, we do not want to lose the information that we have.    =====    I because we get the data in a very small increments for the machine learning model.\n",
      "order difference: 0\n",
      "Relevant sentence:  I because we get the data in a very small increments for the machine learning model.    =====    So that is kind of the engineering that we did for the channel Minds got it.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that is kind of the engineering that we did for the channel Minds got it.    =====    What we have done is we have had to hack the data hunger of the more of the neural network language models.\n",
      "order difference: 1\n",
      "Relevant sentence:  What we have done is we have had to hack the data hunger of the more of the neural network language models.    =====    So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that way we just we just semiautomated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.    =====    When I say a task it is it is like asking asking the language model to predict whether whether a sentence is at whether a sentence whether two sentences are continuous.\n",
      "order difference: 0\n",
      "Relevant sentence:  When I say a task it is it is like asking asking the language model to predict whether whether a sentence is at whether a sentence whether two sentences are continuous.    =====    So so we have we have fairly statistical validation approaches to validate this auxiliary tasks.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so we have we have fairly statistical validation approaches to validate this auxiliary tasks.    =====    What we do is actually there are there is a twostage validation one is one is the language model that we that we have two other people which is well, which is actually finetune various tasks.\n",
      "order difference: 0\n",
      "Relevant sentence:  What we do is actually there are there is a twostage validation one is one is the language model that we that we have two other people which is well, which is actually finetune various tasks.    =====    I I think I think we can on the validation component.\n",
      "order difference: 0\n",
      "Relevant sentence:  I I think I think we can on the validation component.    =====    Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations.\n",
      "order difference: 0\n",
      "Relevant sentence:  Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations.    =====    So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks.    =====    So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.\n",
      "order difference: 1\n",
      "Relevant sentence:  So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation.    =====    So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I guess this is kind of a very it is a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated.    =====    How is that attach to the with a slack Channel and then how it how the channel Minds selfgenerated right?\n",
      "order difference: 0\n",
      "Relevant sentence:  So this domain mind gets it domain language for who gets attached to the to the channel when the user says invites you to the channel.    =====    So from once we have this domain language model right as we were talking about the domain minder.\n",
      "order difference: 0\n",
      "Relevant sentence:  So from once we have this domain language model right as we were talking about the domain minder.    =====    It is a simple example would be a bug a bug in nature may be different from the bug in a software engineering model.\n",
      "order difference: 0\n",
      "Relevant sentence:  It is a simple example would be a bug a bug in nature may be different from the bug in a software engineering model.    =====    So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering.    =====    So we we we use open data to to you know, generate generate a fix.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we we we use open data to to you know, generate generate a fix.    =====    So let me get just started my mind Generations on the top.\n",
      "order difference: 0\n",
      "Relevant sentence:  So let me get just started my mind Generations on the top.    =====    So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is wellversed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model.\n",
      "order difference: 0\n",
      "Relevant sentence:  So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is wellversed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model.    =====    So a quick heads up on this on this slide because this puts everything I can with my cousin in one single view.\n",
      "order difference: 0\n",
      "Relevant sentence:  So a quick heads up on this on this slide because this puts everything I can with my cousin in one single view.    =====    So so this this just shows how how the chat the domain Minds, you know shapeshifts into the channel and by learning all the information that it gets from the conversations.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so this this just shows how how the chat the domain Minds, you know shapeshifts into the channel and by learning all the information that it gets from the conversations.    =====    So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation.    =====    A library of domain Minds as as we mentioned some of the samples here some this is ever growing we keep on adding so to this list.\n",
      "order difference: 1\n",
      "Relevant sentence:  A library of domain Minds as as we mentioned some of the samples here some this is ever growing we keep on adding so to this list.    =====    So that means if someone is talking about deployment aunt and then if in a certain channel is if they always associate deployment with let us say AWS Lambda.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that means if someone is talking about deployment aunt and then if in a certain channel is if they always associate deployment with let us say AWS Lambda.    =====    So this is kind of relationship that this combination of language model undermined men captures.\n",
      "order difference: 0\n",
      "Relevant sentence:  So this is kind of relationship that this combination of language model undermined men captures.    =====    That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph.\n",
      "order difference: 0\n",
      "Relevant sentence:  That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph.    =====    This is likelihood that with the talk about a double s Lambda also, it means that they seem to be talking about a similar as similar aspect for that certain Tim.\n",
      "order difference: 0\n",
      "Relevant sentence:  This is likelihood that with the talk about a double s Lambda also, it means that they seem to be talking about a similar as similar aspect for that certain Tim.    =====    So this relationship is learned that when there is an aid of a deployment.\n",
      "order difference: 1\n",
      "Relevant sentence:  So this relationship is learned that when there is an aid of a deployment.    =====    Were in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier.\n",
      "order difference: 0\n",
      "Relevant sentence:  Were in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier.    =====    Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind.\n",
      "order difference: 0\n",
      "Relevant sentence:  Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind.    =====    That is on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel.\n",
      "order difference: 0\n",
      "Relevant sentence:  That is on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel.    =====    So so this is this is fairly simple, you know, simple.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so this is this is fairly simple, you know, simple.    =====    Calls there would be there would be scored or they would be compared against this domain mind till we have the transformation to the channel Minds.\n",
      "order difference: 0\n",
      "Relevant sentence:  Calls there would be there would be scored or they would be compared against this domain mind till we have the transformation to the channel Minds.    =====    So that is this is where you know, you have the real learning component of Egypt\n",
      "order difference: 0\n",
      "Relevant sentence:  So that is this is where you know, you have the real learning component of Egypt    =====    So every time every time there is a new conversation that comes in the comes in the eater.\n",
      "order difference: 0\n",
      "Relevant sentence:  So every time every time there is a new conversation that comes in the comes in the eater.    =====    We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds.\n",
      "order difference: 0\n",
      "Relevant sentence:  We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds.    =====    So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team.\n",
      "order difference: 1\n",
      "Relevant sentence:  So we are in along with the let us say software engineering it will also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team.    =====    Okay as we mentioned so domain Channel mine is fairly Dynamic.\n",
      "order difference: 0\n",
      "Relevant sentence:  Check just like so eat a graph serves multiple purposes one one being as we talked about it.    =====    T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction.\n",
      "order difference: 0\n",
      "Relevant sentence:  T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction.    =====    It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.\n",
      "order difference: 0\n",
      "Relevant sentence:  It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I will come but where I will start is, you know, it is about its ability.    =====    So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data.\n",
      "order difference: 0\n",
      "Relevant sentence:  So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data.    =====    A source would just go as is to the general feeling.\n",
      "order difference: 1\n",
      "Relevant sentence:  A source would just go as is to the general feeling.    =====    Yeah, I guess it really we are operating in the text domain.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, I guess it really we are operating in the text domain.    =====    I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as\n",
      "order difference: 0\n",
      "Relevant sentence:  I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let us say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as    =====    So if it is a speech data we converted to text first if there is Vision data, let us say the slides that need to be processed.\n",
      "order difference: 1\n",
      "Relevant sentence:  So if it is a speech data we converted to text first if there is Vision data, let us say the slides that need to be processed.    =====    So in that help engine, it is like a it is like a pre fabricating the data such so that it can go into the graph structure.\n",
      "order difference: 0\n",
      "Relevant sentence:  So in that help engine, it is like a it is like a pre fabricating the data such so that it can go into the graph structure.    =====    So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior.\n",
      "order difference: 0\n",
      "Relevant sentence:  So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior.    =====    So we again use the associated domain language model of the custom custom Channel language model for for feature is Amal the text that picket and then and then we also bring in the notion of Miles here.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we again use the associated domain language model of the custom custom Channel language model for for feature is Amal the text that picket and then and then we also bring in the notion of Miles here.    =====    I will talk about the difference just just in a minute, but but so what we are trying to say here is along with the actual factual information like who spoke what or or what are the you know who attended the meeting so these Services enable The Ether\n",
      "order difference: 0\n",
      "Relevant sentence:  I will talk about the difference just just in a minute, but but so what we are trying to say here is along with the actual factual information like who spoke what or or what are the you know who attended the meeting so these Services enable The Ether    =====    In terms of its relevance relevance and other aspects caps in other aspects.\n",
      "order difference: 0\n",
      "Relevant sentence:  In terms of its relevance relevance and other aspects caps in other aspects.    =====    So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have.    =====    You know, Knowledge Graph like the factual graph on The Ether graph.\n",
      "order difference: 0\n",
      "Relevant sentence:  You know, Knowledge Graph like the factual graph on The Ether graph.    =====    So presentation so that we can be can you know use it for all sorts of computations.\n",
      "order difference: 0\n",
      "Relevant sentence:  So presentation so that we can be can you know use it for all sorts of computations.    =====    So we are in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we are in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature.    =====    And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.\n",
      "order difference: 1\n",
      "Relevant sentence:  And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim.    =====    Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself is not are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or nonobvious inside sort of the god Apollo.\n",
      "order difference: 0\n",
      "Relevant sentence:  Whereas when I say, hey, you know Karthik follow up on this production issue, you know the idea that Karthik is the person who I am assigning this action to is something that is not so intuitive and needs to be gleaned right by first applying NLP in these types of rules then later on also being getting represented in the laugh    =====    Something like, you know, if I am part of a channel that is a very direct relationship which does not require a lot of intelligence which is get it right out of the station.\n",
      "order difference: 1\n",
      "Relevant sentence:  Something like, you know, if I am part of a channel that is a very direct relationship which does not require a lot of intelligence which is get it right out of the station.    =====    So we are in the in the computation graph as we as mentioned earlier.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we are in the in the computation graph as we as mentioned earlier.    =====    So say for example, if I have to give you one example of how the how the body is nonintuitive relations could be is you know, let us say let us say let us say Karthik talked about kubernetes in one of the in couple of calls\n",
      "order difference: 0\n",
      "Relevant sentence:  So say for example, if I have to give you one example of how the how the body is nonintuitive relations could be is you know, let us say let us say let us say Karthik talked about kubernetes in one of the in couple of calls    =====    It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks.\n",
      "order difference: 0\n",
      "Relevant sentence:  It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks.    =====    So having said that I will just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component.\n",
      "order difference: 0\n",
      "Relevant sentence:  So having said that I will just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component.    =====    So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get.    =====    So as you said the example that you gave write a card they can you follow the on this can come as part of the conversation in the free text, you know free language.\n",
      "order difference: 1\n",
      "Relevant sentence:  So as you said the example that you gave write a card they can you follow the on this can come as part of the conversation in the free text, you know free language.    =====    So that is how the evaluation of you know, relationships happened within the that is one of the example that I just gave program give you an idea of how computation graph works.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that is how the evaluation of you know, relationships happened within the that is one of the example that I just gave program give you an idea of how computation graph works.    =====    But if I orthotic that means every time Karthik talks about kubernetes if you are a watch it so which which makes in which makes him kind of we approve his Dont open it is and that we captured that inside to and then reinforce that that relationship as a Karthik is an expert in kubernetes.\n",
      "order difference: 0\n",
      "Relevant sentence:  But if I orthotic that means every time Karthik talks about kubernetes if you are a watch it so which which makes in which makes him kind of we approve his Dont open it is and that we captured that inside to and then reinforce that that relationship as a Karthik is an expert in kubernetes.    =====    So so so what it does is it also forms a relation between Karthik as anode which is the user and then the kubernetes as a topic and then says you know here Initially then as as as as more and more conversations around kubernetes are happening.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so so what it does is it also forms a relation between Karthik as anode which is the user and then the kubernetes as a topic and then says you know here Initially then as as as as more and more conversations around kubernetes are happening.    =====    So we we just organize the topics key phrases captured as the notes on that.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we we just organize the topics key phrases captured as the notes on that.    =====    So how in fact we can even take consensus just because Karthik is talking we need not say that he could be an expert.\n",
      "order difference: 0\n",
      "Relevant sentence:  So how in fact we can even take consensus just because Karthik is talking we need not say that he could be an expert.    =====    The talked about can get interest into is a is an expert in tuber natives even say that is very cool.\n",
      "order difference: 0\n",
      "Relevant sentence:  The talked about can get interest into is a is an expert in tuber natives even say that is very cool.    =====    So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we are going to talk about a little so so so and also other top XO from the from the from the computation graph perspective.\n",
      "order difference: 0\n",
      "Relevant sentence:  So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we are going to talk about a little so so so and also other top XO from the from the from the computation graph perspective.    =====    They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting.\n",
      "order difference: 0\n",
      "Relevant sentence:  They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting.    =====    So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik.    =====    What bought the nodes could be along with the the factual notes like the users and favorite pics.\n",
      "order difference: 1\n",
      "Relevant sentence:  What bought the nodes could be along with the the factual notes like the users and favorite pics.    =====    Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.\n",
      "order difference: 1\n",
      "Relevant sentence:  Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.    =====    Okay and then I guess once you have these types of graphs.\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay and then I guess once you have these types of graphs.    =====    Yes, I eat a graph is more of a traditional representation of God.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yes, I eat a graph is more of a traditional representation of God.    =====    Yes, it is teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them.\n",
      "order difference: 1\n",
      "Relevant sentence:  Yes, it is teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them.    =====    So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations.\n",
      "order difference: 0\n",
      "Relevant sentence:  So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations.    =====    But but what they come as a combination represents, so once they have this as a mathematical object, like like a like a embedding what we can do is we can do lot of you know algorithms on because we are free to do all the math around it and then we can you can get for the similar users to kartik from the context of you know, the topics that that he discusses or from the context of the action items.\n",
      "order difference: 0\n",
      "Relevant sentence:  But but what they come as a combination represents, so once they have this as a mathematical object, like like a like a embedding what we can do is we can do lot of you know algorithms on because we are free to do all the math around it and then we can you can get for the similar users to kartik from the context of you know, the topics that that he discusses or from the context of the action items.    =====    That means all the relationships about the topics whom he follows or whom who I mean, what are the topics that he usually discusses and then we just call that whole component and then we encode everything into into the cottage.\n",
      "order difference: 0\n",
      "Relevant sentence:  That means all the relationships about the topics whom he follows or whom who I mean, what are the topics that he usually discusses and then we just call that whole component and then we encode everything into into the cottage.    =====    All the users will have their own representation that not just captures what who they are.\n",
      "order difference: 0\n",
      "Relevant sentence:  All the users will have their own representation that not just captures what who they are.    =====    And then what comes out is actually a lot more, you know a lot more insights that will enable us to do like very nonintuitive recommendations.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then what comes out is actually a lot more, you know a lot more insights that will enable us to do like very nonintuitive recommendations.    =====    So as I talked about that Karthik being expert in a in kubernetes, right so that can be formed from the from some of this.\n",
      "order difference: 0\n",
      "Relevant sentence:  So as I talked about that Karthik being expert in a in kubernetes, right so that can be formed from the from some of this.    =====    You know, I would rather than that we use like the node embeddings what I mean by no damn wedding is when there is Karthik so we do not just we do not just see Karthik as you know a person so we also input all the information that he that actually this ether captures about about that.\n",
      "order difference: 0\n",
      "Relevant sentence:  You know, I would rather than that we use like the node embeddings what I mean by no damn wedding is when there is Karthik so we do not just we do not just see Karthik as you know a person so we also input all the information that he that actually this ether captures about about that.    =====    If you do not talk about anything else if direct enables us to form the you know, form the form this noninductive relationships like talked about a certain topic or action item assigned to so now let us take forward and then use This graph that is actually being formed after all the conversations.\n",
      "order difference: 0\n",
      "Relevant sentence:  If you do not talk about anything else if direct enables us to form the you know, form the form this noninductive relationships like talked about a certain topic or action item assigned to so now let us take forward and then use This graph that is actually being formed after all the conversations.    =====    And then what we what we do is we just put it through a graph neural networks kind or the different graph algorithms.\n",
      "order difference: 1\n",
      "Relevant sentence:  And then what we what we do is we just put it through a graph neural networks kind or the different graph algorithms.    =====    Just think of integrating these insights into you know, a ticket management tool like jira, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  Just think of integrating these insights into you know, a ticket management tool like jira, right?    =====    So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this.\n",
      "order difference: 1\n",
      "Relevant sentence:  So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this.    =====    That is kind of a that is what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it.\n",
      "order difference: 1\n",
      "Relevant sentence:  Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it is too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the    =====    So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of\n",
      "order difference: 0\n",
      "Relevant sentence:  So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of    =====    So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a byproduct as a as a representation of those topics of the the important moments in the conversation.    =====    So let me just put it in my queuing for the scoring in the next steps.\n",
      "order difference: 0\n",
      "Relevant sentence:  So let me just put it in my queuing for the scoring in the next steps.    =====    So so what we do is it is a two step process.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so what we do is it is a two step process.    =====    But what we do is when we say topic identification or be identified the potential important moments in the call.\n",
      "order difference: 0\n",
      "Relevant sentence:  But what we do is when we say topic identification or be identified the potential important moments in the call.    =====    This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.\n",
      "order difference: 0\n",
      "Relevant sentence:  This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket.    =====    So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so that brings us to how we do that keyphrase extraction from the from the technical standpoint.    =====    This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.\n",
      "order difference: 0\n",
      "Relevant sentence:  This is also I am in we can call this as a fairly, you know, secondary generic service because we do not use keyphrase extraction stand alone.    =====    We do not have any context of what is important and what is not important.\n",
      "order difference: 0\n",
      "Relevant sentence:  We do not have any context of what is important and what is not important.    =====    So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we are in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point.    =====    All we know is this this this diagram or the three words combination sounds as if it is an important people.\n",
      "order difference: 1\n",
      "Relevant sentence:  All we know is this this this diagram or the three words combination sounds as if it is an important people.    =====    So we just we just so Channel Minds just drops it or even the associated key phrases.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we just we just so Channel Minds just drops it or even the associated key phrases.    =====    So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it.    =====    Need to be captured as a as an important environmental issues as an important topic of the people.\n",
      "order difference: 0\n",
      "Relevant sentence:  Need to be captured as a as an important environmental issues as an important topic of the people.    =====    Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.\n",
      "order difference: 0\n",
      "Relevant sentence:  Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let us say in software engineering even though we talked at length about environment or environmental issues.    =====    Whole context of the either the topic of the important movement.\n",
      "order difference: 0\n",
      "Relevant sentence:  Whole context of the either the topic of the important movement.    =====    It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.\n",
      "order difference: 0\n",
      "Relevant sentence:  It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it does not really need.    =====    So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.\n",
      "order difference: 1\n",
      "Relevant sentence:  So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating.    =====    So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just finetune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.    =====    So when you have see how it comes is when you have let us say the conversation about machine learning or or any software engineering related.\n",
      "order difference: 0\n",
      "Relevant sentence:  So when you have see how it comes is when you have let us say the conversation about machine learning or or any software engineering related.    =====    And then coming to come into the training part of it.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then coming to come into the training part of it.    =====    What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.\n",
      "order difference: 0\n",
      "Relevant sentence:  What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem.    =====    So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are.\n",
      "order difference: 0\n",
      "Relevant sentence:  So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are.    =====    So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them.    =====    Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows.\n",
      "order difference: 0\n",
      "Relevant sentence:  Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows.    =====    So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.\n",
      "order difference: 0\n",
      "Relevant sentence:  So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we do not want to show them.    =====    So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms.    =====    So one of these data sets that we use for our general benchmarking is this SST wherein it captures all the sentence similarity task action.\n",
      "order difference: 1\n",
      "Relevant sentence:  So one of these data sets that we use for our general benchmarking is this SST wherein it captures all the sentence similarity task action.    =====    Text and then we correlate that with the context associated with the channel Minds at the end of this this whole process this multi step three step process.\n",
      "order difference: 0\n",
      "Relevant sentence:  Text and then we correlate that with the context associated with the channel Minds at the end of this this whole process this multi step three step process.    =====    What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.\n",
      "order difference: 0\n",
      "Relevant sentence:  What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment.    =====    We just passed the context through this algorithm finetuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know.\n",
      "order difference: 0\n",
      "Relevant sentence:  We just passed the context through this algorithm finetuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know.    =====    We do is we take we take each candidate key face on the contacts associated with it.\n",
      "order difference: 0\n",
      "Relevant sentence:  We do is we take we take each candidate key face on the contacts associated with it.    =====    When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.\n",
      "order difference: 1\n",
      "Relevant sentence:  When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there.    =====    So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right?    =====    for example pullout top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so\n",
      "Not Relevant sentence:  That is the whole point of the channel when so so so the inference that I said, it just scores against channel channel Pine and then and then what comes out is the bunch of segments that that post that mostly covers the whole conversation at the same time sticking to what the channel is related to ensure of a deviating from that.    !=    Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case.\n",
      "order difference: 3\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case.    =====    I mean, I think we all had the solution as well.\n",
      "order difference: 1\n",
      "Relevant sentence:  I mean, I think we all had the solution as well.    =====    How do we pull these chapters out of pull these topics out and and show them?\n",
      "order difference: 0\n",
      "Relevant sentence:  How do we pull these chapters out of pull these topics out and and show them?    =====    Right thus often times, you know, people are talking like, you know, in a team of say five six people one a call teams tend to get into discussions, you know, we are going back and forth particular subject and then you move on to some other subject in some other topic and so on right where so how do we kind of use this?\n",
      "order difference: 1\n",
      "Relevant sentence:  Right thus often times, you know, people are talking like, you know, in a team of say five six people one a call teams tend to get into discussions, you know, we are going back and forth particular subject and then you move on to some other subject in some other topic and so on right where so how do we kind of use this?    =====    It is just a stock affection adult done done in a very flexible way.\n",
      "order difference: 0\n",
      "Relevant sentence:  It is just a stock affection adult done done in a very flexible way.    =====    So so what this some topic extraction does is it will be very very, you know Broad in its topic identification also, so so let us say a certain Paul covered software engineering in which we talked about Lambda and Learning deployment and then in the same pot.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so what this some topic extraction does is it will be very very, you know Broad in its topic identification also, so so let us say a certain Paul covered software engineering in which we talked about Lambda and Learning deployment and then in the same pot.    =====    Let is say what we do is when you are as you have shown in the example at wearing one Call we are run through all the multiple channels of then we got different sub arrays.\n",
      "order difference: 0\n",
      "Relevant sentence:  Let is say what we do is when you are as you have shown in the example at wearing one Call we are run through all the multiple channels of then we got different sub arrays.    =====    We talked about Recruitment and also the product strategy what it does is most likely could put Lambda and deployment the same topic because you know, they have been discussed together.\n",
      "order difference: 0\n",
      "Relevant sentence:  We talked about Recruitment and also the product strategy what it does is most likely could put Lambda and deployment the same topic because you know, they have been discussed together.    =====    What it does is it will be able to defeat evil to slice machine learning related components into one one topic and Lambda base if there is a fair segregation it will be able To slice them.\n",
      "order difference: 0\n",
      "Relevant sentence:  What it does is it will be able to defeat evil to slice machine learning related components into one one topic and Lambda base if there is a fair segregation it will be able To slice them.    =====    So it is like a fairly flexible topic slicing algorithm that we that we have in place a topic extraction.\n",
      "order difference: 0\n",
      "Relevant sentence:  So it is like a fairly flexible topic slicing algorithm that we that we have in place a topic extraction.    =====    But otherwise if in another call we talked about Lambda base deployments for a whole lot of XnumberX minutes.\n",
      "order difference: 0\n",
      "Relevant sentence:  But otherwise if in another call we talked about Lambda base deployments for a whole lot of XnumberX minutes.    =====    So the the whole intent of this app does not topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about.\n",
      "order difference: 0\n",
      "Relevant sentence:  So the the whole intent of this app does not topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about.    =====    So what it does is if there are if there is a broader, you know, the broader categories of topics that are being discussed in certain calls.\n",
      "order difference: 1\n",
      "Relevant sentence:  So what it does is if there are if there is a broader, you know, the broader categories of topics that are being discussed in certain calls.    =====    So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graphbased for this.\n",
      "order difference: 1\n",
      "Relevant sentence:  So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graphbased for this.    =====    And then we have a graph a graph with with all these conversations as a notes.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then we have a graph a graph with with all these conversations as a notes.    =====    It just would be found between them but no, it should be formed between Docker or the recruitment because even though they are talked in the same conversation or even inverse cos they are actually talked right one after the other because\n",
      "order difference: 0\n",
      "Relevant sentence:  It just would be found between them but no, it should be formed between Docker or the recruitment because even though they are talked in the same conversation or even inverse cos they are actually talked right one after the other because    =====    So what we do is we just organized the meeting into the graph that that is fairly simple because you know, you have lot of this text segments and then we we have eat them as the node.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what we do is we just organized the meeting into the graph that that is fairly simple because you know, you have lot of this text segments and then we we have eat them as the node.    =====    So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed.    =====    So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they are moving back and forth.\n",
      "order difference: 0\n",
      "Relevant sentence:  So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they are moving back and forth.    =====    Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there.\n",
      "order difference: 1\n",
      "Relevant sentence:  Then what we do is to this is where the Elegance of graph algorithms  The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there.    =====    So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends.    =====    I mean, I mean relatively so sure so that is what the topic is.\n",
      "order difference: 0\n",
      "Relevant sentence:  I mean, I mean relatively so sure so that is what the topic is.    =====    So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.\n",
      "order difference: 0\n",
      "Relevant sentence:  So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.    =====    So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting.    =====    So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out.    =====    Actually, there was strong association between within XnumberX people where in most of the people are connected with most of the others.\n",
      "order difference: 1\n",
      "Relevant sentence:  Actually, there was strong association between within XnumberX people where in most of the people are connected with most of the others.    =====    What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community.\n",
      "order difference: 0\n",
      "Relevant sentence:  What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community.    =====    It comes from the language model finetuning which has nothing to do with the communities.\n",
      "order difference: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant sentence:  It comes from the language model finetuning which has nothing to do with the communities.    =====    And then how we trial how we trial is as I said, it is more of it.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then how we trial how we trial is as I said, it is more of it.    =====    So just to just to be just to be aligned with the with the flow.\n",
      "order difference: 0\n",
      "Relevant sentence:  So just to just to be just to be aligned with the with the flow.    =====    Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.\n",
      "order difference: 0\n",
      "Relevant sentence:  Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here.    =====    A nation of community algorithm parameters and the language model performance.\n",
      "order difference: 0\n",
      "Relevant sentence:  A nation of community algorithm parameters and the language model performance.    =====    What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.\n",
      "order difference: 0\n",
      "Relevant sentence:  What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth.    =====    But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model.\n",
      "order difference: 0\n",
      "Relevant sentence:  But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model.    =====    But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated.\n",
      "order difference: 1\n",
      "Relevant sentence:  But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated.    =====    Right the fact that when a user is interacting with our tool.\n",
      "order difference: 0\n",
      "Relevant sentence:  Right the fact that when a user is interacting with our tool.    =====    Yep at the manual tasks that they do very naturally helps reinforce our a models.\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay, so when could I thought it will be good for us to do a little bit have a dis little bit of a discussion on just the I stack with ether.    =====    The first is its concept of Channel or team mines where whereby we are representing the team context both the static aspects of it.\n",
      "order difference: 0\n",
      "Relevant sentence:  The first is its concept of Channel or team mines where whereby we are representing the team context both the static aspects of it.    =====    Let is say there is a team that is working on software engineering or databases or Our devops in general, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  Let is say there is a team that is working on software engineering or databases or Our devops in general, right?    =====    So there is a static idea that they are working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently.\n",
      "order difference: 0\n",
      "Relevant sentence:  So there is a static idea that they are working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently.    =====    All right, but just to reiterate if you look at ethers a I stack there are a few things that that we want to kind of highlight, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  All right, but just to reiterate if you look at ethers a I stack there are a few things that that we want to kind of highlight, right?    =====    This will be gone through that that call and got up.\n",
      "order difference: 0\n",
      "Relevant sentence:  This will be gone through that that call and got up.    =====    Is that a production issue that is being addressed right now it is that a particular type of database are talking about or you know, a particular aspect of their software engineering stack that they are talking about.\n",
      "order difference: 0\n",
      "Relevant sentence:  Is that a production issue that is being addressed right now it is that a particular type of database are talking about or you know, a particular aspect of their software engineering stack that they are talking about.    =====    So I am assuming that a lot of the folks who are seeing.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I am assuming that a lot of the folks who are seeing.    =====    We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide.\n",
      "order difference: 0\n",
      "Relevant sentence:  We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide.    =====    So the first time Idea is idea about Channel or team Minds.\n",
      "order difference: 1\n",
      "Relevant sentence:  So the first time Idea is idea about Channel or team Minds.    =====    And so how do you extract what is Meaningful and what is not so that is another aspect of how either ether zai gets applied to just the meetings their interactions, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  And so how do you extract what is Meaningful and what is not so that is another aspect of how either ether zai gets applied to just the meetings their interactions, right?    =====    But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right?    =====    Being and you are having a discussion, maybe it is a group meeting and you are talking about five different topics in the call or you are talking about, you know, you are doing a two people are talking about one particular subject.\n",
      "order difference: 0\n",
      "Relevant sentence:  Being and you are having a discussion, maybe it is a group meeting and you are talking about five different topics in the call or you are talking about, you know, you are doing a two people are talking about one particular subject.    =====    Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.\n",
      "order difference: 0\n",
      "Relevant sentence:  Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them.    =====    Let is say you are in a meeting and you are and the team is having a discussion and in an hour is call you are talking about a bunch of different topics.\n",
      "order difference: 0\n",
      "Relevant sentence:  Let is say you are in a meeting and you are and the team is having a discussion and in an hour is call you are talking about a bunch of different topics.    =====    So one quick way of kind of talking about the the graph would be that it is a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  So one quick way of kind of talking about the the graph would be that it is a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right?    =====    How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information.\n",
      "order difference: 0\n",
      "Relevant sentence:  How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information.    =====    The next is the idea of topic detection using communities, which is a you know, when you there is a there is a meeting that is happening.\n",
      "order difference: 0\n",
      "Relevant sentence:  The next is the idea of topic detection using communities, which is a you know, when you there is a there is a meeting that is happening.    =====    I think the the next one is this idea of you know, how once a call is over.\n",
      "order difference: 1\n",
      "Relevant sentence:  I think the the next one is this idea of you know, how once a call is over.    =====    Should talk about next is the keyphrase extraction, which is sometimes it is hard to blame the entire discussion.\n",
      "order difference: 0\n",
      "Relevant sentence:  Should talk about next is the keyphrase extraction, which is sometimes it is hard to blame the entire discussion.    =====    So, of course, there is also a couple of other things that we are working on.\n",
      "order difference: 0\n",
      "Relevant sentence:  So, of course, there is also a couple of other things that we are working on.    =====    So before we get started a lot of times question comes up when we talk about ether how we do our speechtotext, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  So before we get started a lot of times question comes up when we talk about ether how we do our speechtotext, right?    =====    Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.\n",
      "order difference: 0\n",
      "Relevant sentence:  Segments so that you can quickly in a snare ataglance come to know what is what is being discussed and so on and so forth.    =====    We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right?    =====    We just to kind of lay this out is we do not\n",
      "order difference: 0\n",
      "Relevant sentence:  We just to kind of lay this out is we do not    =====    On the background and we will touch upon those as well.\n",
      "order difference: 0\n",
      "Relevant sentence:  On the background and we will touch upon those as well.    =====    So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them.\n",
      "order difference: 0\n",
      "Relevant sentence:  So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them.    =====    First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.\n",
      "order difference: 0\n",
      "Relevant sentence:  First of all, the weight is very hard to read and understand so sometimes it is important to just be able to pull out.    =====    So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss.\n",
      "order difference: 0\n",
      "Relevant sentence:  So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss.    =====    So that is a very interesting aspect of ethers a sec as well and last but not the least.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that is a very interesting aspect of ethers a sec as well and last but not the least.    =====    So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.\n",
      "order difference: 1\n",
      "Relevant sentence:  So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects.    =====    So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider?\n",
      "order difference: 0\n",
      "Relevant sentence:  So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider?    =====    Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.\n",
      "order difference: 0\n",
      "Relevant sentence:  Build a speech to text technology ourselves because a lot of it one one reason for it is that it there is a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time.    =====    And so the way we built ether was to have a lot of flexibility in being able to associate any speechtotext engine to with our for our purposes.\n",
      "order difference: 0\n",
      "Relevant sentence:  And so the way we built ether was to have a lot of flexibility in being able to associate any speechtotext engine to with our for our purposes.    =====    So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we actually focus on we assume that that is actually a speechtotext engine that is in the background either with our with our partners lot of times.    =====    And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible So we\n",
      "order difference: 0\n",
      "Relevant sentence:  And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible So we    =====    Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well.\n",
      "order difference: 0\n",
      "Relevant sentence:  Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well.    =====    So the way we do this is, you know showcases app, which is ether meet.\n",
      "order difference: 0\n",
      "Relevant sentence:  So the way we do this is, you know showcases app, which is ether meet.    =====    We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality.\n",
      "order difference: 0\n",
      "Relevant sentence:  We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality.    =====    We integrate with the close partner called Deep Graham to provide.\n",
      "order difference: 0\n",
      "Relevant sentence:  We integrate with the close partner called Deep Graham to provide.    =====    When we go to market with our partners, they actually like to use their own speechtotext technology for integrating.\n",
      "order difference: 1\n",
      "Relevant sentence:  When we go to market with our partners, they actually like to use their own speechtotext technology for integrating.    =====    So let us talk about Channel Minds right little deeper into Channel Minds.\n",
      "order difference: 0\n",
      "Relevant sentence:  So let us talk about Channel Minds right little deeper into Channel Minds.    =====    Maybe you can just give us a quick overview of what channel Minds is.\n",
      "order difference: 0\n",
      "Relevant sentence:  Maybe you can just give us a quick overview of what channel Minds is.    =====    We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.\n",
      "order difference: 0\n",
      "Relevant sentence:  We have the ability to associate speechtotext Provider by workspace by and we have the ability to do it in two passes one passes.    =====    I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.\n",
      "order difference: 0\n",
      "Relevant sentence:  I mean, I guess we have already discussed what channel minds are but more about how we build it and how we use it and so on.    =====    So that is the other kind of unique aspect about how we have built it inside our architecture.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that is the other kind of unique aspect about how we have built it inside our architecture.    =====    So on and so forth, so it is very very flexible.\n",
      "order difference: 0\n",
      "Relevant sentence:  One of the things that I always like to say is ether is the world is best meeting somebody engine right there.    =====    So moving on I guess the next very I guess very important thing one way.\n",
      "order difference: 0\n",
      "Relevant sentence:  So moving on I guess the next very I guess very important thing one way.    =====    How do you Pull out what is important and what is not so maybe you can just quickly run through.\n",
      "order difference: 0\n",
      "Relevant sentence:  How do you Pull out what is important and what is not so maybe you can just quickly run through.    =====    So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.\n",
      "order difference: 1\n",
      "Relevant sentence:  So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half.    =====    What is the score for a certain segment when you say segment?\n",
      "order difference: 0\n",
      "Relevant sentence:  What is the score for a certain segment when you say segment?    =====    I will come to the training part A little later, but we just passed it through that are.\n",
      "order difference: 0\n",
      "Relevant sentence:  I will come to the training part A little later, but we just passed it through that are.    =====    We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.\n",
      "order difference: 0\n",
      "Relevant sentence:  We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about.    =====    It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that is currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that is currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right?    =====    What we do is we have we we continuously create a list of summaries.\n",
      "order difference: 0\n",
      "Relevant sentence:  What we do is we have we we continuously create a list of summaries.    =====    It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.\n",
      "order difference: 0\n",
      "Relevant sentence:  It is fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have finetuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time.    =====    Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time.\n",
      "order difference: 0\n",
      "Relevant sentence:  Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time.    =====    It is like a Texan which is actually fairly selfcontained either either.\n",
      "order difference: 0\n",
      "Relevant sentence:  It is like a Texan which is actually fairly selfcontained either either.    =====    So what we do is when we do this the similarity task, you know finetuning of the language model.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what we do is when we do this the similarity task, you know finetuning of the language model.    =====    So and then we score the in the scoring process is what the training aspect is.\n",
      "order difference: 1\n",
      "Relevant sentence:  So and then we score the in the scoring process is what the training aspect is.    =====    And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward.    =====    Through this validation data on this we keep updating this validation data so that we can we can safely say that if it passes the validation set because it has not seen those validation satyr during training if it passes the validation set we can fairly say that we can deploy that into the, you know, Ever Changing dynamics of the team.\n",
      "order difference: 0\n",
      "Relevant sentence:  Through this validation data on this we keep updating this validation data so that we can we can safely say that if it passes the validation set because it has not seen those validation satyr during training if it passes the validation set we can fairly say that we can deploy that into the, you know, Ever Changing dynamics of the team.    =====    We generate like lot of candidate Al Gore models that will come out for that.\n",
      "order difference: 0\n",
      "Relevant sentence:  We generate like lot of candidate Al Gore models that will come out for that.    =====    We just we just passed this, you know, all the segments.\n",
      "order difference: 0\n",
      "Relevant sentence:  We just we just passed this, you know, all the segments.    =====    So this this kind of a semiautomatic autonomous approach because we just do not want to automate it we can we can definitely automate but but the whole point Of the channel Minds to ever evolve at the same time.\n",
      "order difference: 0\n",
      "Relevant sentence:  So this this kind of a semiautomatic autonomous approach because we just do not want to automate it we can we can definitely automate but but the whole point Of the channel Minds to ever evolve at the same time.    =====    It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context.\n",
      "order difference: 0\n",
      "Relevant sentence:  It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context.    =====    So each segment will have relative score on of course passes through certain minimal threshold.\n",
      "order difference: 0\n",
      "Relevant sentence:  So each segment will have relative score on of course passes through certain minimal threshold.    =====    We should also, you know, improve our improve or adapt to the validation data that we create.\n",
      "order difference: 0\n",
      "Relevant sentence:  We should also, you know, improve our improve or adapt to the validation data that we create.    =====    So without without much Concepts so once so, that is how we validate.\n",
      "order difference: 0\n",
      "Relevant sentence:  So without without much Concepts so once so, that is how we validate.    =====    And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process.    =====    We come up from the initial filtration of their performance and then we pass all those candidate models.\n",
      "order difference: 0\n",
      "Relevant sentence:  We come up from the initial filtration of their performance and then we pass all those candidate models.    =====    I mean we need not worry about the what do you call the quantifiable T of the score because you know, it is all relative.\n",
      "order difference: 0\n",
      "Relevant sentence:  I mean we need not worry about the what do you call the quantifiable T of the score because you know, it is all relative.    =====    So this scoring box and then what what comes out is again.\n",
      "order difference: 0\n",
      "Relevant sentence:  So this scoring box and then what what comes out is again.    =====    Up tents of or hundreds of calls and then we manually curate what are the most important moments given the converse given the meeting given that this meeting is part of a certain Channel.\n",
      "order difference: 0\n",
      "Relevant sentence:  Up tents of or hundreds of calls and then we manually curate what are the most important moments given the converse given the meeting given that this meeting is part of a certain Channel.    =====    So it is a semiauto autonomous approach that we adopt the pews for the validation.\n",
      "Not Relevant sentence:  If you are spending the five ten in the first five minutes talking about the latest IPL score Kidd game as that happen, you are able to easily filter those unimportant moments out and get right into the important moments, which is what are the rest of the team can    !=    Okay, I guess so it kind of going into the details right the other I guess very important aspect is how we pull out meeting Primitives, I guess.\n",
      "order difference: 12\n",
      "order difference: 0\n",
      "Relevant sentence:  Okay, I guess so it kind of going into the details right the other I guess very important aspect is how we pull out meeting Primitives, I guess.    =====    So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right.\n",
      "order difference: 0\n",
      "Relevant sentence:  So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there is a project manager in the call was actually writing down the action item or something many times these Message right.    =====    So maybe you can quickly run through how we pull out action items.\n",
      "order difference: 0\n",
      "Relevant sentence:  So maybe you can quickly run through how we pull out action items.    =====    So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on.\n",
      "order difference: 1\n",
      "Relevant sentence:  So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on.    =====    What are the action items that are that it that they either bought things as an action items and then and then and then gives gives away.\n",
      "order difference: 0\n",
      "Relevant sentence:  What are the action items that are that it that they either bought things as an action items and then and then and then gives gives away.    =====    So actually we are talking about action items that are being in the freeflow conversation like what we are doing right now.\n",
      "order difference: 0\n",
      "Relevant sentence:  So actually we are talking about action items that are being in the freeflow conversation like what we are doing right now.    =====    But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not.\n",
      "order difference: 0\n",
      "Relevant sentence:  But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we finetune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not.    =====    Should I just like I think when we say action items, let us let me put one point before we talk about it.\n",
      "order difference: 0\n",
      "Relevant sentence:  Should I just like I think when we say action items, let us let me put one point before we talk about it.    =====    So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier.\n",
      "order difference: 0\n",
      "Relevant sentence:  So for this it is it is this this whole action item algorithm or the other approach is little different from what we have been discussing earlier.    =====    There is if they have seen a lot of exotic references like that.\n",
      "order difference: 0\n",
      "Relevant sentence:  There is if they have seen a lot of exotic references like that.    =====    So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services.\n",
      "order difference: 0\n",
      "Relevant sentence:  So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services.    =====    So how do we do that is we have actually collected lot of training data for this.\n",
      "order difference: 0\n",
      "Relevant sentence:  So how do we do that is we have actually collected lot of training data for this.    =====    So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture.\n",
      "order difference: 0\n",
      "Relevant sentence:  So what what what we do differently is we do not we do not need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture.    =====    So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.\n",
      "order difference: 0\n",
      "Relevant sentence:  So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.    =====    So this This fairly has nothing to do with the with the language model that we discussed earlier.\n",
      "order difference: 1\n",
      "Relevant sentence:  So this This fairly has nothing to do with the with the language model that we discussed earlier.    =====    But as a total it has actually it has identified only XnumberX, even though the noise is list.\n",
      "order difference: 0\n",
      "Relevant sentence:  But as a total it has actually it has identified only XnumberX, even though the noise is list.    =====    Mmm, but we are okay to have lot of that means if I capture XnumberX out of XnumberX candidate action items.\n",
      "order difference: 0\n",
      "Relevant sentence:  Mmm, but we are okay to have lot of that means if I capture XnumberX out of XnumberX candidate action items.    =====    So so so we have trained a language model to finetune such that we can be we have adopted that language model to be a binary classifier.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so so we have trained a language model to finetune such that we can be we have adopted that language model to be a binary classifier.    =====    And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then and then what we do is just I will talk I will talk briefly about the validation of this and then we will move on to the next steps in the pie pan.    =====    We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.\n",
      "order difference: 0\n",
      "Relevant sentence:  We do not consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we did not only candidate action items.    =====    So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items.\n",
      "order difference: 0\n",
      "Relevant sentence:  So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items.    =====    So again the action item as a whole is not just a model here sigh that is what I wanted to highlight here.\n",
      "order difference: 0\n",
      "Relevant sentence:  So again the action item as a whole is not just a model here sigh that is what I wanted to highlight here.    =====    Youll recall or wherein we do not want to miss anything that has an accent.\n",
      "order difference: 0\n",
      "Relevant sentence:  Youll recall or wherein we do not want to miss anything that has an accent.    =====    This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I am okay to have a lot of noise in the carrot patch.\n",
      "order difference: 0\n",
      "Relevant sentence:  This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I am okay to have a lot of noise in the carrot patch.    =====    Sorry, but I do not want to miss even a single action item.\n",
      "order difference: 0\n",
      "Relevant sentence:  Sorry, but I do not want to miss even a single action item.    =====    So that is why we find you this classifier to have a highest possible.\n",
      "order difference: 0\n",
      "Relevant sentence:  So that is why we find you this classifier to have a highest possible.    =====    I am okay to have only four of them being the real action items, but I do not want to miss even one of the action items one of those pork perfect.\n",
      "order difference: 0\n",
      "Relevant sentence:  I am okay to have only four of them being the real action items, but I do not want to miss even one of the action items one of those pork perfect.    =====    Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent.\n",
      "order difference: 0\n",
      "Relevant sentence:  Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent.    =====    So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items.\n",
      "order difference: 1\n",
      "Relevant sentence:  So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only XnumberX action items.    =====    What we do is we just we just pass the center.\n",
      "order difference: 0\n",
      "Relevant sentence:  What we do is we just we just pass the center.    =====    So that means as soon as we get this speech segments from specific sequence from the call, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  So that means as soon as we get this speech segments from specific sequence from the call, right?    =====    So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.\n",
      "order difference: 0\n",
      "Relevant sentence:  So this grammar rules and then the patterns that we have identified and anything that is not actually qualifying enough for from the pattern should be disregarded.    =====    And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item.    =====    So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.\n",
      "order difference: 0\n",
      "Relevant sentence:  So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.    =====    So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step.    =====    Say for example, if there is an action item detected by the candidate, but I did not find any grammatically relevant subject in them.\n",
      "order difference: 0\n",
      "Relevant sentence:  Say for example, if there is an action item detected by the candidate, but I did not find any grammatically relevant subject in them.    =====    That is why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect.\n",
      "order difference: 1\n",
      "Relevant sentence:  That is why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect.    =====    We are also able to extract who it is assigned to write based on who is present in the call.\n",
      "order difference: 0\n",
      "Relevant sentence:  We are also able to extract who it is assigned to write based on who is present in the call.    =====    Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle followup type of action items like Doom or regression tests before we deploy let us send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right?    =====    And you know who is speaking and who is the recipient and so on?\n",
      "order difference: 0\n",
      "Relevant sentence:  And you know who is speaking and who is the recipient and so on?    =====    You are very nuanced and these types of actions are actually pulled out automatically from the conversations.\n",
      "order difference: 0\n",
      "Relevant sentence:  You are very nuanced and these types of actions are actually pulled out automatically from the conversations.    =====    Okay, cool, so I guess here is a taking a quick example, so here are three different segments, right?\n",
      "order difference: 1\n",
      "Relevant sentence:  Okay, cool, so I guess here is a taking a quick example, so here are three different segments, right?    =====    They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved.\n",
      "Not Relevant sentence:  So you can kind of get a feel for it as we go on but wine to get started and let us dive in and talk a little bit about Channel Minds.    !=    So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right?\n",
      "order difference: 12\n",
      "order difference: 1\n",
      "Relevant sentence:  So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right?    =====    All right, so there is there is here is a kind of an example.\n",
      "order difference: 0\n",
      "Relevant sentence:  All right, so there is there is here is a kind of an example.    =====    Let me actually take this down and show it in a real slack conversation.\n",
      "order difference: 0\n",
      "Relevant sentence:  Let me actually take this down and show it in a real slack conversation.    =====    I wanted to kind of call out Channel minds and action.\n",
      "order difference: 0\n",
      "Relevant sentence:  I wanted to kind of call out Channel minds and action.    =====    Alright, so that is actually a good segue to actually before we do that.\n",
      "order difference: 1\n",
      "Relevant sentence:  Alright, so that is actually a good segue to actually before we do that.    =====    You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right?    =====    So again, let me go back switch to my presentation here.\n",
      "order difference: 0\n",
      "Relevant sentence:  So again, let me go back switch to my presentation here.    =====    So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that is associated with it.\n",
      "order difference: 0\n",
      "Relevant sentence:  So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that is associated with it.    =====    And then when you pass it through when you have that meeting in the context of a software engineering mind, the discussion summarizes The Ether summarizes the discussion pulls out topics related to software for example things about database continuously ICD kubernetes Etc.\n",
      "order difference: 0\n",
      "Relevant sentence:  And then when you pass it through when you have that meeting in the context of a software engineering mind, the discussion summarizes The Ether summarizes the discussion pulls out topics related to software for example things about database continuously ICD kubernetes Etc.    =====    So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics.\n",
      "order difference: 0\n",
      "Relevant sentence:  So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics.    =====    So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right?    =====    Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels.    =====    Our infrastructure that Kafka whereas when you talk about when you run the same meeting through the marketing channel, you know, it pulls out things about, you know, digital marketing.\n",
      "order difference: 1\n",
      "Relevant sentence:  Our infrastructure that Kafka whereas when you talk about when you run the same meeting through the marketing channel, you know, it pulls out things about, you know, digital marketing.    =====    it is fair play shows how how the channel man is able to differentiate based on the Mind attached to it during the\n",
      "order difference: 1\n",
      "Relevant sentence:  it is fair play shows how how the channel man is able to differentiate based on the Mind attached to it during the    =====    That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that is a very unique way of representing the intelligence of the Insight that is happening in the context of teams and and the organization in a graph format and using this in a variety of different ways.\n",
      "order difference: 0\n",
      "Relevant sentence:  That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that is a very unique way of representing the intelligence of the Insight that is happening in the context of teams and and the organization in a graph format and using this in a variety of different ways.    =====    So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like.\n",
      "order difference: 0\n",
      "Relevant sentence:  So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like.    =====    Maybe you can just walk us through this a little bit.\n",
      "order difference: 0\n",
      "Relevant sentence:  Maybe you can just walk us through this a little bit.    =====    All right, so it is a great segue into you know, so when we talked about Channel Minds you brought up this notion of the dynamic portion.\n",
      "order difference: 0\n",
      "Relevant sentence:  All right, so it is a great segue into you know, so when we talked about Channel Minds you brought up this notion of the dynamic portion.    =====    So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is.\n",
      "Not Relevant sentence:  So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is.    !=    A new person comes and then he comes and talks about the same subject right ether can very easily extract the idea that this discussion has happened before and actually say hey now that you are discussing this subject.\n",
      "order difference: 13\n",
      "order difference: 0\n",
      "Relevant sentence:  A new person comes and then he comes and talks about the same subject right ether can very easily extract the idea that this discussion has happened before and actually say hey now that you are discussing this subject.    =====    You may also want to follow up on this other topic right?\n",
      "order difference: 0\n",
      "Relevant sentence:  You may also want to follow up on this other topic right?    =====    Are you watch this other discussion that happened a few months ago and that makes teams just work a lot efficiently and save a lot of time in going back and forth, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  Are you watch this other discussion that happened a few months ago and that makes teams just work a lot efficiently and save a lot of time in going back and forth, right?    =====    Yeah, and so kind of generating this idea of who are the recommended Watchers.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, and so kind of generating this idea of who are the recommended Watchers.    =====    So those types of things can be applied to Enterprise intelligence as well because a lot of times T teams keep discussing the same subjects again and again, right so it is very common that in a team for example in an engineering team a particular type of databases that you know is being considered for their architecture, you know, the engineer leaves the company goes away voila six months later.\n",
      "order difference: 0\n",
      "Relevant sentence:  So those types of things can be applied to Enterprise intelligence as well because a lot of times T teams keep discussing the same subjects again and again, right so it is very common that in a team for example in an engineering team a particular type of databases that you know is being considered for their architecture, you know, the engineer leaves the company goes away voila six months later.    =====    What are the use cases that we always talk about is, you know a lot of times when you have a meeting, let us say you and I are having this call and then we produce a summary it will be always good to know who should you know, what people who are would actually likely to watch this, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  What are the use cases that we always talk about is, you know a lot of times when you have a meeting, let us say you and I are having this call and then we produce a summary it will be always good to know who should you know, what people who are would actually likely to watch this, right?    =====    Youre a discussion right are more importantly, you know, as we see in ecommerce lot of times right you buy this product you also You know you get this common thing that saves users who bought this are also interested in these other types of products, right?\n",
      "order difference: 1\n",
      "Relevant sentence:  Youre a discussion right are more importantly, you know, as we see in ecommerce lot of times right you buy this product you also You know you get this common thing that saves users who bought this are also interested in these other types of products, right?    =====    Yeah, so so it actually brings it to one more notion.\n",
      "order difference: 0\n",
      "Relevant sentence:  Yeah, so so it actually brings it to one more notion.    =====    We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?\n",
      "order difference: 1\n",
      "Relevant sentence:  We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right?    =====    So let us move on and maybe just give a quick example not going to spend a whole lot of time on this but just to give a representation of here is a real world example.\n",
      "order difference: 0\n",
      "Relevant sentence:  So let us move on and maybe just give a quick example not going to spend a whole lot of time on this but just to give a representation of here is a real world example.    =====    Let me see if I can actually pull up the graph itself.\n",
      "order difference: 0\n",
      "Relevant sentence:  Let me see if I can actually pull up the graph itself.    =====    Let me stop the content here and show the real graph.\n",
      "order difference: 1\n",
      "Relevant sentence:  Let me stop the content here and show the real graph.    =====    So those types of relationships can be gleaned very easily from the knowledge graph, right like so for example in this particular case when we run this query about who is who is a personal talked about Google these three people who come up myself Cullen and Karthik right where we talk a lot about Google.\n",
      "order difference: 0\n",
      "Relevant sentence:  So those types of relationships can be gleaned very easily from the knowledge graph, right like so for example in this particular case when we run this query about who is who is a personal talked about Google these three people who come up myself Cullen and Karthik right where we talk a lot about Google.    =====    So these types of relationships get pulled out very easily from the knowledge.\n",
      "order difference: 0\n",
      "Relevant sentence:  So these types of relationships get pulled out very easily from the knowledge.    =====    So one is we are able to we took essentially one of the workspaces and map the interactions into a into a graph here and let us say we want to find out who the goo.\n",
      "order difference: 0\n",
      "Relevant sentence:  So one is we are able to we took essentially one of the workspaces and map the interactions into a into a graph here and let us say we want to find out who the goo.    =====    Will experts are in a workspace in this can be very simple as a who is the person who is interested in a particular technology.\n",
      "order difference: 0\n",
      "Relevant sentence:  Will experts are in a workspace in this can be very simple as a who is the person who is interested in a particular technology.    =====    That is just a quick example at a sample of what we do.\n",
      "order difference: 0\n",
      "Relevant sentence:  That is just a quick example at a sample of what we do.    =====    I do not know if you are able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things.\n",
      "Not Relevant sentence:  I do not know if you are able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things.    !=    Hopefully this gives you a pretty good idea to the viewer about the different things types of things that we use in either for AI and I guess in a different discussion, I guess maybe we can go into how actually a lot of this is operationalized inside our deployments, but that is a discussion for another day.\n",
      "order difference: 32\n",
      "order difference: 0\n",
      "Relevant sentence:  Hopefully this gives you a pretty good idea to the viewer about the different things types of things that we use in either for AI and I guess in a different discussion, I guess maybe we can go into how actually a lot of this is operationalized inside our deployments, but that is a discussion for another day.    =====    So I think that that kind of concludes this discussion right thanks to incur that we have covered a lot of things.\n",
      "order difference: 0\n",
      "Relevant sentence:  But even if there is a slight mention of software engineering its prices for it higher than than the rest but it gives you a very good summary of what is happening.    =====    Whole lot of huge HR conversation within in software engineering team so it could it could so it could still give out some important moments.\n",
      "Not Relevant sentence:  Whole lot of huge HR conversation within in software engineering team so it could it could so it could still give out some important moments.    !=    Yep, so it is kind of a very folks summer day would say so so it just it just cuts out the noise very aggressive price to stick to what what the team needs actually.\n",
      "order difference: 3\n",
      "Not Relevant sentence:  Yep, so it is kind of a very folks summer day would say so so it just it just cuts out the noise very aggressive price to stick to what what the team needs actually.    !=    This is one says even the whole subject is about about software.\n",
      "order difference: 9\n",
      "order difference: 0\n",
      "Relevant sentence:  This is one says even the whole subject is about about software.    =====    I guess, you know different topics are different groups of topics and the people involved in those conversations are pulled out a very elegant way I think is very cool.\n",
      "order difference: 0\n",
      "Relevant sentence:  I guess, you know different topics are different groups of topics and the people involved in those conversations are pulled out a very elegant way I think is very cool.    =====    Things like that and then they went back Arjun venkat and three shots now talked about databases.\n",
      "order difference: 0\n",
      "Relevant sentence:  Things like that and then they went back Arjun venkat and three shots now talked about databases.    =====    Got it tigers have wanted to show a quick example of how this works.\n",
      "order difference: 0\n",
      "Relevant sentence:  Got it tigers have wanted to show a quick example of how this works.    =====    So here is a call that happened and where there is a bunch of discussion that that happened between a group of people and we are able to very nicely kind of pull out the fact that the shunt and Arjun talked about deployment and configuration devops related subjects and then the Russians and blanket in then moved on and talked about some database subjects like Seattle and Cloud SQL exactly exactly.\n",
      "order difference: 1\n",
      "Relevant sentence:  So here is a call that happened and where there is a bunch of discussion that that happened between a group of people and we are able to very nicely kind of pull out the fact that the shunt and Arjun talked about deployment and configuration devops related subjects and then the Russians and blanket in then moved on and talked about some database subjects like Seattle and Cloud SQL exactly exactly.    =====    Granular Kappa can get you can go from the top level where in you have totally relevant unrelated topics discussed.\n",
      "order difference: 0\n",
      "Relevant sentence:  Granular Kappa can get you can go from the top level where in you have totally relevant unrelated topics discussed.    =====    So they end up as a topics or to the as we go granular.\n",
      "order difference: 0\n",
      "Relevant sentence:  So they end up as a topics or to the as we go granular.    =====    I hear it did not actually slice the whole databases databases singled out because it just reaches talked about database and run something related to deployment together.\n",
      "order difference: 0\n",
      "Relevant sentence:  I hear it did not actually slice the whole databases databases singled out because it just reaches talked about database and run something related to deployment together.    =====    So so it just it is just able to put them together aggressive.\n",
      "order difference: 0\n",
      "Relevant sentence:  So so it just it is just able to put them together aggressive.    =====    That means if we talk only about databases on the deployment, it would have done the other way like click diplomatic conversations and then they database so that is the level of flexible.\n",
      "order difference: 0\n",
      "Relevant sentence:  So we are working on a technique where we can detect that the slide is being presented and then automatically pull out information from that using Standard computer vision techniques and then once the vision was a slight information is converted to text a lot of the same information can be used in terms of applying what is relevant and what is not and what is the topic and what is a keyword and so on so forth, right?    =====    So obviously and and I will just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that.\n",
      "order difference: 0\n",
      "Relevant sentence:  So obviously and and I will just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that.    =====    In the coming weeks and months is that in a shed setting?\n",
      "order difference: 0\n",
      "Relevant sentence:  In the coming weeks and months is that in a shed setting?    =====    Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on.\n",
      "order difference: 0\n",
      "Relevant sentence:  Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on.    =====    Let is say a bunch of people are crowded around the conference call content speakerphone or whatever, right?\n",
      "order difference: 0\n",
      "Relevant sentence:  Let is say a bunch of people are crowded around the conference call content speakerphone or whatever, right?    =====    We are continually creating a library of our signature using standard MFC sea bass techniques and creating patterns and storing them for every speaker that we know and then as we detect changes in those patterns, we we kind of apply that to speaker dilation and then if the signature actually matches someone in our database\n",
      "order difference: 0\n",
      "Relevant sentence:  We are continually creating a library of our signature using standard MFC sea bass techniques and creating patterns and storing them for every speaker that we know and then as we detect changes in those patterns, we we kind of apply that to speaker dilation and then if the signature actually matches someone in our database    =====    So I am just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we have done some amount of proof of Concepts and investigation into it and we plan to do more on this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order difference: 0\n",
      "Relevant sentence:  So I am just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we have done some amount of proof of Concepts and investigation into it and we plan to do more on this.    =====    We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right.\n",
      "order difference: 1\n",
      "Relevant sentence:  We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right.    =====    So we do not need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also\n",
      "order difference: 0\n",
      "Relevant sentence:  So we do not need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also    =====    We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there is an unknown speaker.\n",
      "order difference: 0\n",
      "Relevant sentence:  We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there is an unknown speaker.    =====    Maybe someone can manually tag it and so on using our user interface, right?\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13), (14, 14), (15, 15), (16, 16), (17, 17), (18, 18)]\n",
      "[[[\"Okay, I guess so it kind of going into the details right the other I guess very important aspect is how we pull out meeting Primitives, I guess. So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there's a project manager in the call was actually writing down the action item or something many times these Message right. So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on. So maybe you can quickly run through how we pull out action items. \"], '2019-10-31T14:17:13Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '69109483e398424f96b987d904227cf1'], [[\"Should I just like I think when we say action items, let's let me put one point before we talk about it. So actually we are talking about action items that are being in the free-flow conversation like what we are doing right now. So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services. There's if they have seen a lot of exotic references like that. So what what what we do differently is we don't we don't need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture. What are the action items that are that it that they either bought things as an action items and then and then and then gives gives away. So for this it is it's this this whole action item algorithm or the other approach is little different from what we have been discussing earlier. So this This fairly has nothing to do with the with the language model that we discussed earlier. But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we fine-tune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not. So how do we do that is we have actually collected lot of training data for this. So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this. \"], '2019-10-31T14:17:55Z', '3f01f2032f584b178fafde6b437058ae', 'e7071f03540e41928e524f6358fce509'], [[\"So again the action item as a whole is not just a model here sigh that's what I wanted to highlight here. This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I'm okay to have a lot of noise in the carrot patch. Sorry, but I don't want to miss even a single action item. That would be a likely candidate. So that's why we find you this classifier to have a highest possible. You'll recall or wherein we don't want to miss anything that has an accent. Mmm, but we are okay to have lot of that means if I capture 15 out of 15 candidate action items. I'm okay to have only four of them being the real action items, but I don't want to miss even one of the action items one of those pork perfect. So so so we have trained a language model to fine-tune such that we can be we have adopted that language model to be a binary classifier. Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent. And then and then what we do is just I'll talk I'll talk briefly about the validation of this and then we'll move on to the next steps in the pie pan. So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items. So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only 50 action items. But as a total it has actually it has identified only 70, even though the noise is list. We don't consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we didn't only candidate action items. \"], '2019-10-31T14:19:55Z', '3f01f2032f584b178fafde6b437058ae', '6052f095303e4390a3bef29c89cf8f28'], [[\"So the inference is fairly simple. What we do is we just we just pass the center. So that means as soon as we get this speech segments from specific sequence from the call, right? So we slice the segments into individual sentences. And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item. Say for example, if there is an action item detected by the candidate, but I didn't find any grammatically relevant subject in them. So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step. So this grammar rules and then the patterns that we have identified and anything that's not actually qualifying enough for from the pattern should be disregarded. That's why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect. So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action. \"], '2019-10-31T14:21:56Z', '3f01f2032f584b178fafde6b437058ae', 'e44d0a245c4d403d8b2c46bb0b9bb9c0'], [[\"Okay, cool, so I guess here's a taking a quick example, so here are three different segments, right? Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle follow-up type of action items like Doom or regression tests before we deploy let's send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right? You are very nuanced and these types of actions are actually pulled out automatically from the conversations. That is one. I guess the second is by intelligently applying our graph. We are also able to extract who it is assigned to write based on who's present in the call. And you know who's speaking and who's the recipient and so on? Yep. Yeah. \"], '2019-10-31T14:23:30Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ecf667ce7d2341bc9de3acb7140eeba7'], [['I guess once this these things are detected. They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved. '], '2019-10-31T14:24:42Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a939ecf68bc24d3895eef49731912d5c']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"What are the use cases that we always talk about is, you know a lot of times when you have a meeting, let's say you and I are having this call and then we produce a summary it will be always good to know who should you know, what people who are would actually likely to watch this, right? Yeah, and so kind of generating this idea of who are the recommended Watchers. You're a discussion right are more importantly, you know, as we see in e-commerce lot of times right you buy this product you also You know you get this common thing that saves users who bought this are also interested in these other types of products, right? So those types of things can be applied to Enterprise intelligence as well because a lot of times T teams keep discussing the same subjects again and again, right so it's very common that in a team for example in an engineering team a particular type of databases that you know is being considered for their architecture, you know, the engineer leaves the company goes away voila six months later. A new person comes and then he comes and talks about the same subject right ether can very easily extract the idea that this discussion has happened before and actually say hey now that you're discussing this subject. You may also want to follow up on this other topic right? Are you watch this other discussion that happened a few months ago and that makes teams just work a lot efficiently and save a lot of time in going back and forth, right? So that's the beauty of this type of relationships. \"], '2019-10-31T13:50:45Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2e6829cebf67481d95955e3afdf08c5b'], [[\"Yeah, so so it actually brings it to one more notion. Right? We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right? We're in we can do recommendations Martellus. That's what you just saw. It's one of the you know extraction. \"], '2019-10-31T13:52:13Z', '3f01f2032f584b178fafde6b437058ae', 'd5a60e4f0a5a4ce48d929b81dd6260d6'], [[\"Lemons search recommendation smart alerts and so on. That's right. Yeah. Okay. That's great. So let's move on and maybe just give a quick example not going to spend a whole lot of time on this but just to give a representation of here is a real world example. Let me see if I can actually pull up the graph itself. Yeah. Yeah. Actually I have it here little bit here. Let me stop the content here and show the real graph. \"], '2019-10-31T13:52:41Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '97f2b973beea4fad9394feb35dde9990'], [[\"I don't know if you're able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things. Right? So one is we're able to we took essentially one of the workspaces and map the interactions into a into a graph here and let's say we want to find out who the goo. Will experts are in a workspace in this can be very simple as a who's the person who's interested in a particular technology. Right? So those types of relationships can be gleaned very easily from the knowledge graph, right like so for example in this particular case when we run this query about who's who's a personal talked about Google these three people who come up myself Cullen and Karthik right where we talk a lot about Google. So these types of relationships get pulled out very easily from the knowledge. Graphite. Yep. That's just a quick example at a sample of what we do. \"], '2019-10-31T13:53:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2413039a385f4b5e96464f3064d6142b']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[['Whole lot of huge HR conversation within in software engineering team so it could it could so it could still give out some important moments. But even if there is a slight mention of software engineering its prices for it higher than than the rest but it gives you a very good summary of what is happening. '], '2019-10-31T14:06:48Z', '3f01f2032f584b178fafde6b437058ae', 'e23d686b4b614aba8e082a32c44d539a']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Got it yet. So moving on I guess the next very I guess very important thing one way. One of the things that I always like to say is ether is the world's best meeting somebody engine right there. So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half. How do you Pull out what's important and what's not so maybe you can just quickly run through. \"], '2019-10-31T14:02:14Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '958c5e5250b846b1b1e79045b696a018'], [[\"Yeah, sure. So I think I got a use case level. That's right. Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time. We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about. I'll come to the training part A little later, but we just passed it through that are. A box and then what comes out is? What is the score for a certain segment when you say segment? It's like a Texan which is actually fairly self-contained either either. It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that's currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right? So and then we score the in the scoring process is what the training aspect is. It's fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have fine-tuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time. So we really cannot rely only on those numbers. So what we do is when we do this the similarity task, you know fine-tuning of the language model. What we do is we have we we continuously create a list of summaries. That means we have set of like \"], '2019-10-31T14:02:48Z', '3f01f2032f584b178fafde6b437058ae', '45f9dc69f29441e8b517565893255f0c'], [[\"Up tents of or hundreds of calls and then we manually curate what are the most important moments given the converse given the meeting given that this meeting is part of a certain Channel. And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process. We generate like lot of candidate Al Gore models that will come out for that. We come up from the initial filtration of their performance and then we pass all those candidate models. Through this validation data on this we keep updating this validation data so that we can we can safely say that if it passes the validation set because it hasn't seen those validation satyr during training if it passes the validation set we can fairly say that we can deploy that into the, you know, Ever Changing dynamics of the team. So without without much Concepts so once so, that's how we validate. So this this kind of a semi-automatic autonomous approach because we just don't want to automate it we can we can definitely automate but but the whole point Of the channel Minds to ever evolve at the same time. We should also, you know, improve our improve or adapt to the validation data that we create. So it's a semi-auto autonomous approach that we adopt the pews for the validation. And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward. We just we just passed this, you know, all the segments. So this scoring box and then what what comes out is again. It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context. And then what comes out is the score. I mean we needn't worry about the what do you call the quantifiable T of the score because you know, it's all relative. So each segment will have relative score on of course passes through certain minimal threshold. That means so what if there is a \"], '2019-10-31T14:04:48Z', '3f01f2032f584b178fafde6b437058ae', '86d5c1d132554eaf8b26567de70faa9d']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"That's good thinking. Yeah, maybe we can now just dive deeper. Yeah. Sure. What I'll do is I'll ask you speak. I'll also create markers here. So you can kind of get a feel for it as we go on but wine to get started and let's dive in and talk a little bit about Channel Minds. \"], '2019-10-31T13:20:31Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'e79cf121424c4717afd9092c89923582']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"So moving on from the knowledge graph. Let's move on to keyphrase extraction, right? Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it's too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the \"], '2019-10-31T13:54:33Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '95a41af139e448c19878b2703b380e0f'], [[\"Yeah, this is this is like Channel Minds. This is also I am in we can call this as a fairly, you know, secondary generic service because we don't use keyphrase extraction stand alone. But what we do is when we say topic identification or be identified the potential important moments in the call. So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a by-product as a as a representation of those topics of the the important moments in the conversation. So so that brings us to how we do that keyphrase extraction from the from the technical standpoint. So so what we do is it's a two step process. So we're in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point. We don't have any context of what is important and what is not important. All we know is this this this diagram or the three words combination sounds as if it's an important people. So let me just put it in my queuing for the scoring in the next steps. So for that we use we use the graph right? So this is this is live. This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket. So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of \"], '2019-10-31T13:54:58Z', '3f01f2032f584b178fafde6b437058ae', 'fefe76dee147480e853c0df3db683dbf'], [[\"Whole context of the either the topic of the important movement. So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating. So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it. Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let's say in software engineering even though we talked at length about environment or environmental issues. It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it doesn't really need. Need to be captured as a as an important environmental issues as an important topic of the people. So we just we just so Channel Minds just drops it or even the associated key phrases. \"], '2019-10-31T13:56:58Z', '3f01f2032f584b178fafde6b437058ae', 'b85dddabb62f4cc6896abc7ebdde9618'], [[\"So when you have see how it comes is when you have let's say the conversation about machine learning or or any software engineering related. So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we don't want to show them. So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them. So That's that's how it works. And then coming to come into the training part of it. What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem. Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows. So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms. And then the data sources that are available. So one of these data sets that we use for our general benchmarking is this SST wherein it captures all the sentence similarity task action. So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are. So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just fine-tune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this. \"], '2019-10-31T13:58:15Z', '3f01f2032f584b178fafde6b437058ae', 'b11cd18c8a1e4b2cbd3ea53775db9f64'], [['We do is we take we take each candidate key face on the contacts associated with it. When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there. We just passed the context through this algorithm fine-tuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know. Text and then we correlate that with the context associated with the channel Minds at the end of this this whole process this multi step three step process. What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment. Come to those Down Citizen a little while. '], '2019-10-31T14:00:15Z', '3f01f2032f584b178fafde6b437058ae', 'f4773b1607784818b1f9ec84d60f497d'], [[\"So I guess it's a very good very quick kind of a real world example of this extracted from real call, right? So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right? That's right. for example pull-out top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so \"], '2019-10-31T14:01:18Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '2a6e41e2ddda495d82a94089f247211b']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"I think before before we get started with its II think I think I'll just give you a heads up on a thin configuration by it. So how we are placed as a team. Mlh. \"], '2019-10-31T13:18:46Z', '3f01f2032f584b178fafde6b437058ae', '48da3759d2eb45f49c1ba344eec381ce'], [[\"Great great portion. Maybe you know, I sorry for not doing this, but maybe you can just give a quick introduction about yourself. And also maybe give a little bit of background about Ari, I think sure. Yeah, so I'm Vanka. \"], '2019-10-31T13:18:55Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '642438db75064a729d29f91ac8463dcb'], [[\"Then and I leave The A Team we are we are a team of 5. Ml Engineers who are who primarily work on machine learning deployments and also building the state-of-the-art machine learning models. So it's a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor. I mean as a team they worked on very broader set of are use cases ranging. Not just not just in the NLP. I also also like the Imaging and then the video processing and on the text, I mean the speech-to-text and and and the whole whole spectrum of the AI ecosystem. So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the state-of-the-art models in the Deep learning or any other machine learning space coming out then so that's where you see, you know. Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe. So having said that I think I think that should be good enough with the team and then maybe it's good time to get here. \"], '2019-10-31T13:19:10Z', '3f01f2032f584b178fafde6b437058ae', 'aaaa272fedd34dc482ce4005349d1bb0']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"You're able to see this, right? Yes. Okay, excellent. Okay, so when could I thought it'll be good for us to do a little bit have a dis little bit of a discussion on just the I stack with ether. I did a separate overview of our platform. So I'm assuming that a lot of the folks who are seeing. This will be gone through that that call and got up. Bit of an understanding about what ether is over. All right, but just to reiterate if you look at ethers a I stack there are a few things that that we want to kind of highlight, right? The first is its concept of Channel or team mines where whereby we are representing the team context both the static aspects of it. In other words. Let's say there's a team that is working on software engineering or databases or Our devops in general, right? So there is a static idea that they're working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently. Is that a production issue that is being addressed right now it is that a particular type of database are talking about or you know, a particular aspect of their software engineering stack that they're talking about. So there's a dime static and dynamic aspects. So the first time Idea is idea about Channel or team Minds. We're in ether. We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide. So that's what we call as Chandler team wins. The second is \"], '2019-10-31T13:09:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0811e5112d64a2283f7245cad8a2f9c'], [[\"Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them. So one quick way of kind of talking about the the graph would be that it's a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right? So that's either graph the second. I think the the next one is this idea of you know, how once a call is over. Let's say you're in a meeting and you're and the team is having a discussion and in an hour's call you're talking about a bunch of different topics. How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information. And so how do you extract what is Meaningful and what's not so that is another aspect of how either ether zai gets applied to just the meetings their interactions, right? The next is the idea of topic detection using communities, which is a you know, when you there's a there's a meeting that's happening. Being and you're having a discussion, maybe it's a group meeting and you're talking about five different topics in the call or you're talking about, you know, you're doing a two people are talking about one particular subject. But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right? So that's the other aspect that \"], '2019-10-31T13:11:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b60bd6a19af74c8babd823c334cabe41'], [[\"Should talk about next is the keyphrase extraction, which is sometimes it's hard to blame the entire discussion. So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them. First of all, the weight is very hard to read and understand so sometimes it's important to just be able to pull out. What are the key phrases right in a conversational setting. Segments so that you can quickly in a snare at-a-glance come to know what is what is being discussed and so on and so forth. So, how do we do that? So that's a very interesting aspect of ethers a sec as well and last but not the least. We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right? So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss. So, of course, there's also a couple of other things that we are working on. On the background and we'll touch upon those as well. So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects. Sure. Okay, so, all right. So before we get started a lot of times question comes up when we talk about ether how we do our speech-to-text, right? We just to kind of lay this out is we don't \"], '2019-10-31T13:13:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b052f73988884a48894804b2d1113e77'], [[\"Build a speech to text technology ourselves because a lot of it one one reason for it is that it there's a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time. So we actually focus on we assume that that is actually a speech-to-text engine that's in the background either with our with our partners lot of times. When we go to market with our partners, they actually like to use their own speech-to-text technology for integrating. And so the way we built ether was to have a lot of flexibility in being able to associate any speech-to-text engine to with our for our purposes. So the way we do this is, you know showcases app, which is ether meet. We integrate with the close partner called Deep Graham to provide. Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well. We've integrated with AWS transcribe. We also have the ability to integrate with other models. We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality. It's also the most expensive. So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider? Let's say deepground as a first pass. And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible-- So we \"], '2019-10-31T13:15:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'cc053b7c0140422da427a2de89414448'], [[\"Can pause with Google's speeches video model. So that's the other kind of unique aspect about how we've built it inside our architecture. So the pipeline is very flexible. We have the ability to associate speech-to-text Provider by workspace by and we have the ability to do it in two passes one passes. So on and so forth, so it's very very flexible. Right? So anyway, that is a little quick note on. How we do speech to text so yeah, okay. So now we're getting to the interesting portion. So let's talk about Channel Minds right little deeper into Channel Minds. Maybe you can just give us a quick overview of what channel Minds is. I mean, I guess we've already discussed what channel minds are but more about how we build it and how we use it and so on. \"], '2019-10-31T13:17:51Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a7d5164db7a84332b5973d95477f6c2c']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"So here's a good example. I mean, I think we all had the solution as well. Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case. This is the engineering team, right? \"], '2019-10-31T14:07:57Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b411b227696341bba3ef7cc36371c806'], [[\"Okay. No, this is a new ones as well. Right thus often times, you know, people are talking like, you know, in a team of say five six people one a call teams tend to get into discussions, you know, we're going back and forth particular subject and then you move on to some other subject in some other topic and so on right where so how do we kind of use this? How do we pull these chapters out of pull these topics out and and show them? Yeah. \"], '2019-10-31T14:08:31Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '15c91e41708949e6b6661aa7213b5f70'], [[\"So the the whole intent of this app doesn't topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about. So to keep it simple. It's just a stock affection adult done done in a very flexible way. Let's say what we do is when you are as you have shown in the example at wearing one Call we are run through all the multiple channels of then we got different sub arrays. So what it does is if there are if there is a broader, you know, the broader categories of topics that are being discussed in certain calls. So so what this some topic extraction does is it will be very very, you know Broad in its topic identification also, so so let's say a certain Paul covered software engineering in which we talked about Lambda and Learning deployment and then in the same pot. We talked about Recruitment and also the product strategy what it does is most likely could put Lambda and deployment the same topic because you know, they've been discussed together. But otherwise if in another call we talked about Lambda base deployments for a whole lot of 45 minutes. What it does is it will be able to defeat evil to slice machine learning related components into one one topic and Lambda base if there is a fair segregation it will be able To slice them. So it's like a fairly flexible topic slicing algorithm that we that we have in place a topic extraction. \"], '2019-10-31T14:09:02Z', '3f01f2032f584b178fafde6b437058ae', 'bfb6232992d24ca7af89c09a807be6f6'], [['Perfect. Yeah, okay. So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graph-based for this. '], '2019-10-31T14:10:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0fd2a6dbbea446c88b98dd6cd79958e7'], [[\"That's right. So that's the second part of it sighs. So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they're moving back and forth. So what we do is we just organized the meeting into the graph that that's fairly simple because you know, you have lot of this text segments and then we we have eat them as the node. And then we have a graph a graph with with all these conversations as a notes. Then what we do is to this is where the Elegance of graph algorithms + The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there. So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed. It just would be found between them but no, it should be formed between Docker or the recruitment because even though they're talked in the same conversation or even inverse cos they are actually talked right one after the other because \"], '2019-10-31T14:11:00Z', '3f01f2032f584b178fafde6b437058ae', 'ef4868f848594956b91214db33188407'], [[\"In the first step. We don't even form a relationship actually. So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting. So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends. Actually, there was strong association between within 10 people where in most of the people are connected with most of the others. So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out. I mean, I mean relatively so sure so that's what the topic is. So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics. \"], '2019-10-31T14:12:22Z', '3f01f2032f584b178fafde6b437058ae', 'c8c884f333ad49ce8447248a4a41dfc8'], [[\"So just to just to be just to be aligned with the with the flow. What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community. But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated. So we are just giving you as a different conversation. So okay, that's all the community algorithms desk aside. And then how we trial how we trial is as I said, it's more of it. It comes from the language model fine-tuning which has nothing to do with the communities. But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model. So it's a it's a combination. A nation of community algorithm parameters and the language model performance. So there's no profit business straight for training gear. Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here. What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth. And then the validator community formation. \"], '2019-10-31T14:13:44Z', '3f01f2032f584b178fafde6b437058ae', '7e78f8c1912640d5a7874ed1673c3bdc'], [[\"That's something very unique as well. Right the fact that when a user is interacting with our tool. Yep at the manual tasks that they do very naturally helps reinforce our a models. \"], '2019-10-31T14:15:17Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'dbc27c69e0cb400792109ef93ffa4b9a']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Yeah, sure son. So I think with the headset that you gave about the channel Minds I meant that that's like a thousand feet free of what channel mine does. I mean to keep it simple. It's just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period. Out of time. So I'll just walk you through I'll give you a tip. I'll give you what goes behind the scenes for the for the channel Minds technically and then we'll come to how it works across all the a downstream applications. So Channel Minds as we as we have architecture. These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether. Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion. So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans. I mean the feature extractor for the whole process wherein we train we train the neural net. Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a pre-loaded, you know library of domain mines be call. So we stopped with such which talks about each domain when talks about certain certain. You know, what you call the horizontal. It's a wonder my mind is software engineering the other one could be markers. \"], '2019-10-31T13:20:49Z', '3f01f2032f584b178fafde6b437058ae', 'acf261aee5bf4ea6adfcb987687da4d5'], [[\"And I mean it could be sale. So that's ever-growing. That means we keep on adding the the new domains to our domain Library. So when when a user's invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel. So which means I mean, Coming to the language model aspect of it. We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you're doing earlier, right? So that's on the language model. Coming to coming to fine-tune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about. I'm going to show some examples in the next slides, but but to give you what it means, let's say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked. Let's say the if the engineering teams talks about production. \"], '2019-10-31T13:22:49Z', '3f01f2032f584b178fafde6b437058ae', 'eac06a96244c481ab1e2e4445eddd5bd'], [[\"In past two weeks or three weeks. What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data. I'll talk about the Mind generation in the next slide, but How do we fine-tune I'll just continue on that. So so along with fine tuning this language model wherein you know, software engineering language model would be fine-tuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that. Once we once we have the language model, that's fine tune. We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet. So so that's where the channel mind comes into play when we say mine. The model is the actual neural network model and the mind is is the graph data structure that organizes the information. Action that is coming, you know to The Ether AI engine if you're it. \"], '2019-10-31T13:24:49Z', '3f01f2032f584b178fafde6b437058ae', '07aa7bee0c1d4d5b8fb24bb453411b15'], [[\"I guess one way to talk about that would be there's a static component. Then there's a dynamic component. Right? Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on. Yep. \"], '2019-10-31T13:26:24Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0004d9a74fe448f5af8ab09915ca2eb6'], [[\"That makes it so this we're doing this way. What we have done is we have had to hack the data hunger of the more of the neural network language models. I because we get the data in a very small increments for the machine learning model. So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it's a static component. And then in the meantime, we don't want to lose the information that we have. Have gathered which is recency and other aspects of it. So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we're giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently. So that's kind of the engineering that we did for the channel Minds got it. Yeah, we can move to the next slide. Okay? Yeah. \"], '2019-10-31T13:26:51Z', '3f01f2032f584b178fafde6b437058ae', '6a0a928643ab4788aa51b94b2ea8952e'], [[\"Oh, yeah, I'm sorry. I I think I think we can on the validation component. What we do is actually there are there is a two-stage validation one is one is the language model that we that we have two other people which is well, which is actually fine-tune various tasks. When I say a task it is it is like asking asking the language model to predict whether whether a sentence is at whether a sentence whether two sentences are continuous. Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations. So so we have we have fairly statistical validation approaches to validate this auxiliary tasks. So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation. So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks. So that way we just we just semi-automated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are. \"], '2019-10-31T13:27:54Z', '3f01f2032f584b178fafde6b437058ae', 'e55cb15e24f34c1090a70d0c8bc8f562'], [[\"So I guess this is kind of a very it's a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated. How is that attach to the with a slack Channel and then how it how the channel Minds self-generated right? Yeah. That's right. \"], '2019-10-31T13:29:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'd2c0d63048af47c0808ed53e761c9f7b']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Got it. Excellent. Just want to call out that when we say Channel. It is just in the context of a team, right like essentially Channel equals a team. So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right? Like for example, that could be a virtual team. Let's say on either some other channel at home or some other let's say Google Hangouts for example, right if there is a concept of a Group in Google Hangout and that prisons attain the same level of attachment of mines and ending can also happen there. \"], '2019-10-31T13:35:23Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b5e0038d0a064f619167d6d0c34e6f82'], [[\"Cool. Alright, so that is actually a good segue to actually before we do that. I wanted to kind of call out Channel minds and action. All right, so there is there is here is a kind of an example. Let me actually take this down and show it in a real slack conversation. So let's give me a second here. Let me pull up Slack. \"], '2019-10-31T13:36:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '3a204f1bbd3148a09474a475c92d3ae5'], [[\"Or the real test. Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels. Right? So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right? So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics. And then when you pass it through when you have that meeting in the context of a software engineering mind, the discussion summarizes The Ether summarizes the discussion pulls out topics related to software for example things about database continuously ICD kubernetes Etc. Our infrastructure that Kafka whereas when you talk about when you run the same meeting through the marketing channel, you know, it pulls out things about, you know, digital marketing. You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right? So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that's associated with it. Right. So again, let me go back switch to my presentation here. \"], '2019-10-31T13:36:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '879767f019d74aabbba1b22bc86ff0cb'], [[\"it's fair play shows how how the channel man is able to differentiate based on the Mind attached to it during the \"], '2019-10-31T13:38:49Z', '3f01f2032f584b178fafde6b437058ae', '3e7f63d9f4b446a18a0b25758e6020ca'], [[\"All right, so it's a great segue into you know, so when we talked about Channel Minds you brought up this notion of the dynamic portion. That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that's a very unique way of representing the intelligence of the Insight that's happening in the context of teams and and the organization in a graph format and using this in a variety of different ways. So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like. So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is. Maybe you can just walk us through this a little bit. \"], '2019-10-31T13:39:03Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '49a9c7427412404abce4ff763aad210b']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Something like, you know, if I'm part of a channel that's a very direct relationship which doesn't require a lot of intelligence which is get it right out of the station. Whereas when I say, hey, you know Karthik follow up on this production issue, you know the idea that Karthik is the person who I'm assigning this action to is something that is not so intuitive and needs to be gleaned right by first applying NLP in these types of rules then later on also being getting represented in the laugh \"], '2019-10-31T13:43:50Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'c0378db3c78e4aae90c1b891b5ccafaf'], [[\"That's right. Yeah. So as you said the example that you gave write a card they can you follow the on this can come as part of the conversation in the free text, you know free language. So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get. So having said that I'll just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component. So we're in the in the computation graph as we as mentioned earlier. It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks. So say for example, if I have to give you one example of how the how the body is non-intuitive relations could be is you know, let's say let's say let's say Karthik talked about kubernetes in one of the in couple of calls \"], '2019-10-31T13:44:21Z', '3f01f2032f584b178fafde6b437058ae', '9bc06ede99df459890697edb5ca18a38'], [[\"Yeah, okay. So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik. So so so what it does is it also forms a relation between Karthik as anode which is the user and then the kubernetes as a topic and then says you know here Initially then as as as as more and more conversations around kubernetes are happening. The talked about can get interest into is a is an expert in tuber natives even say that is very cool. Yeah. So how in fact we can even take consensus just because Karthik is talking we need not say that he could be an expert. But if I orthotic that means every time Karthik talks about kubernetes if you are a watch it so which which makes in which makes him kind of we approve his Don't open it is and that we captured that inside to and then reinforce that that relationship as a Karthik is an expert in kubernetes. So that's how the evaluation of you know, relationships happened within the that's one of the example that I just gave program give you an idea of how computation graph works. So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we're going to talk about a little so so so and also other top XO from the from the from the computation graph perspective. I think I just Brave briefly highlighted. What bought the nodes could be along with the the factual notes like the users and favorite pics. So we we just organize the topics key phrases captured as the notes on that. They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting. \"], '2019-10-31T13:45:29Z', '3f01f2032f584b178fafde6b437058ae', 'f144cefb8c3240909750cb9940444be9'], [['Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation. '], '2019-10-31T13:47:29Z', '3f01f2032f584b178fafde6b437058ae', 'd664f7f953984352a85c1b8b06a309b8'], [[\"Yes, I eat a graph is more of a traditional representation of God. Yes, it's teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them. Yeah, that's like not. Okay and then I guess once you have these types of graphs. What can you do with them? \"], '2019-10-31T13:47:43Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'ca7d7bdff13246d89898f335ec0ab4ac'], [[\"So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations. In fact, we can even do better at this point. If you don't talk about anything else if direct enables us to form the you know, form the form this non-inductive relationships like talked about a certain topic or action item assigned to so now let's take forward and then use This graph that is actually being formed after all the conversations. And then what we what we do is we just put it through a graph neural networks kind or the different graph algorithms. And then what comes out is actually a lot more, you know a lot more insights that will enable us to do like very non-intuitive recommendations. So as I talked about that Karthik being expert in a in kubernetes, right so that can be formed from the from some of this. You know, I'd rather than that we use like the node embeddings what I mean by no damn wedding is when there is Karthik so we don't just we don't just see Karthik as you know a person so we also input all the information that he that actually this ether captures about about that. That means all the relationships about the topics whom he follows or whom who I mean, what are the topics that he usually discusses and then we just call that whole component and then we encode everything into into the cottage. It snowed embedded like that. All the users will have their own representation that not just captures what who they are. But but what they come as a combination represents, so once they have this as a mathematical object, like like a like a embedding what we can do is we can do lot of you know algorithms on because we are free to do all the math around it and then we can you can get for the similar users to kartik from the context of you know, the topics that that he discusses or from the context of the action items. \"], '2019-10-31T13:48:01Z', '3f01f2032f584b178fafde6b437058ae', '2c322826f6084509a38f3ea7be1705f2'], [['Just think of integrating these insights into you know, a ticket management tool like jira, right? So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this. '], '2019-10-31T13:50:01Z', '3f01f2032f584b178fafde6b437058ae', '42c18ef5d2f543f98e10b9c46d7e1d3a'], [[\"That's kind of a that's what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it. \"], '2019-10-31T13:50:23Z', '3f01f2032f584b178fafde6b437058ae', 'abceb463b6d442dd88e9607b7c09c7b9']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Got it tigers have wanted to show a quick example of how this works. Right? So here's a call that happened and where there's a bunch of discussion that that happened between a group of people and we are able to very nicely kind of pull out the fact that the shunt and Arjun talked about deployment and configuration devops related subjects and then the Russians and blanket in then moved on and talked about some database subjects like Seattle and Cloud SQL exactly exactly. Things like that and then they went back Arjun venkat and three shots now talked about databases. Right? And so there's these top. This is one says even the whole subject is about about software. I guess, you know different topics are different groups of topics and the people involved in those conversations are pulled out a very elegant way I think is very cool. \"], '2019-10-31T14:15:37Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '0586a3fbdb6e4276ae19b4f04f5e3311'], [[\"That's right. So possibly it did actually you can observe one things. I hear it didn't actually slice the whole databases databases singled out because it just reaches talked about database and run something related to deployment together. So so it just it's just able to put them together aggressive. That means if we talk only about databases on the deployment, it would have done the other way like click diplomatic conversations and then they database so that's the level of flexible. Granular Kappa can get you can go from the top level where in you have totally relevant unrelated topics discussed. So they end up as a topics or to the as we go granular. We just get what you see right now make sense. \"], '2019-10-31T14:16:29Z', '3f01f2032f584b178fafde6b437058ae', 'fb2a244ad7bf446f9b97a082430c6a27']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"So a quick heads up on this on this slide because this puts everything I can with my cousin in one single view. So so this this just shows how how the chat the domain Minds, you know shape-shifts into the channel and by learning all the information that it gets from the conversations. So let me get just started my mind Generations on the top. So we we we use open data to to you know, generate generate a fix. A library of domain Minds as as we mentioned some of the samples here some this is ever growing we keep on adding so to this list. So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is well-versed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model. It's a simple example would be a bug a bug in nature may be different from the bug in a software engineering model. I mean just a very very intuitive example on that. So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering. Nearing a not about some biology right? So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation. So this domain mind gets it domain language for who gets attached to the to the channel when the user says invites you to the channel. So from once we have this domain language model right as we were talking about the domain minder. \"], '2019-10-31T13:30:03Z', '3f01f2032f584b178fafde6b437058ae', '79d8bd4f528d42128311b753ac48139d'], [[\"That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph. So that means if someone is talking about deployment aunt and then if in a certain channel is if they always associate deployment with let's say AWS Lambda. So this relationship is learned that when there is an aid of a deployment. This is likelihood that with the talk about a double s Lambda also, it means that they seem to be talking about a similar as similar aspect for that certain Tim. So this is kind of relationship that this combination of language model undermined men captures. \"], '2019-10-31T13:32:03Z', '3f01f2032f584b178fafde6b437058ae', 'e1e4c629ba3549f09e95805e87b19902'], [[\"That's on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel. So every time every time there's a new conversation that comes in the comes in the eater. Calls there would be there would be scored or they would be compared against this domain mind till we have the transformation to the channel Minds. So so this is this is fairly simple, you know, simple. What do you call it? Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind. We're in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier. We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds. So we're in along with the let's say software engineering it'll also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team. So that's this is where you know, you have the real learning component of Egypt \"], '2019-10-31T13:33:01Z', '3f01f2032f584b178fafde6b437058ae', 'f091fdbca2c645d5876c2c90d46e73f6'], [['Come sit. So excellent. Yeah. Okay as we mentioned so domain Channel mine is fairly Dynamic. That means that that it can it can read all the information that it gives every every every minute or so, whereas somewhat relatively static is the channel language model which we update once we have enough information for a neural network to be fine, too. '], '2019-10-31T13:35:01Z', '3f01f2032f584b178fafde6b437058ae', '676708b576584e38acaa6d634427fa8c']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"So I think that that kind of concludes this discussion right thanks to incur that we've covered a lot of things. Hopefully this gives you a pretty good idea to the viewer about the different things types of things that we use in either for AI and I guess in a different discussion, I guess maybe we can go into how actually a lot of this is operationalized inside our deployments, but that's a discussion for another day. All right. Thanks. Guys, appreciate it. \"], '2019-10-31T14:27:25Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'b623465fc8024dee92d363bfd236281f']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Check just like so eat a graph serves multiple purposes one one being as we talked about it. It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I'll come but where I'll start is, you know, it's about its ability. T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction. So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data. A source would just go as is to the general feeling. \"], '2019-10-31T13:39:48Z', '3f01f2032f584b178fafde6b437058ae', '547cd6b3d9a64d828e6c3eb3417149bc'], [[\"Yeah, I guess it really we're operating in the text domain. So if it is a speech data we converted to text first if there is Vision data, let's say the slides that need to be processed. I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let's say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as \"], '2019-10-31T13:40:52Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '4e970b30bd224610abf23d1fe9121aad'], [[\"So in that help engine, it's like a it's like a pre fabricating the data such so that it can go into the graph structure. So these are two different components coming together. So we're in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature. So presentation so that we can be can you know use it for all sorts of computations. So we again use the associated domain language model of the custom custom Channel language model for for feature is Amal the text that picket and then and then we also bring in the notion of Miles here. That means these two are like in Hindi interdependent. So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior. In terms of its relevance relevance and other aspects caps in other aspects. So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have. And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim. You know, Knowledge Graph like the factual graph on The Ether graph. I'll talk about the difference just just in a minute, but but so what we are trying to say here is along with the actual factual information like who spoke what or or what are the you know who attended the meeting so these Services enable The Ether \"], '2019-10-31T13:41:27Z', '3f01f2032f584b178fafde6b437058ae', 'ba1e58eebf634454876be91308dd126d'], [[\"Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself isn't are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or non-obvious inside sort of the god Apollo. \"], '2019-10-31T13:43:27Z', '3f01f2032f584b178fafde6b437058ae', '0028af3fa1cd42fb916efc5ea85f9abe']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"That's the whole point of the channel when so so so the inference that I said, it just scores against channel channel Pine and then and then what comes out is the bunch of segments that that post that mostly covers the whole conversation at the same time sticking to what the channel is related to ensure of a deviating from that. \"], '2019-10-31T14:07:07Z', '3f01f2032f584b178fafde6b437058ae', 'ccaf53d160fa453e9e591b4920256a16']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Rot it. Okay. So that's how for example in an engineering Channel. If you're spending the five ten in the first five minutes talking about the latest IPL score Kidd game as that happen, you're able to easily filter those unimportant moments out and get right into the important moments, which is what are the rest of the team can \"], '2019-10-31T14:07:26Z', '8fff81b5b2f14aa5ad67405f3e8127f3', '85355cce55d6421999d8baa188a65d87']] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================Group Cluster=========================\n",
      "[[[\"Course most of it. Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on. So obviously and and I'll just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that. Right? So we're working on a technique where we can detect that the slide is being presented and then automatically pull out information from that using Standard computer vision techniques and then once the vision was a slight information is converted to text a lot of the same information can be used in terms of applying what is relevant and what's not and what's the topic and what's a keyword and so on so forth, right? So I'm just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we've done some amount of proof of Concepts and investigation into it and we plan to do more on this. In the coming weeks and months is that in a shed setting? For example, you and I are in a desktop call. It's very clear. Who's the speaker button shared setting. Let's say a bunch of people are crowded around the conference call content speakerphone or whatever, right? We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right. So we we kind of use at least a wave. We're approaching this. Is that as we speak? We are continually creating a library of our signature using standard MFC sea bass techniques and creating patterns and storing them for every speaker that we know and then as we detect changes in those patterns, we we kind of apply that to speaker dilation and then if the signature actually matches someone in our database \"], '2019-10-31T14:25:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'f853870e10f44514a6f048debee2a416'], [[\"We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there's an unknown speaker. Maybe someone can manually tag it and so on using our user interface, right? So we don't need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also \"], '2019-10-31T14:27:02Z', '8fff81b5b2f14aa5ad67405f3e8127f3', 'a710f5a0577544f5b83550f11a02fa2f']] \n",
      "\n",
      "\n",
      "18\n",
      "Before Merging 19\n",
      "[]\n",
      "After Merging 19\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../helper_functions/\")\n",
    "\n",
    "from get_groups import call_gs\n",
    "import json\n",
    "with open('../topic_testing/demo_walkthrough_2.txt','rb') as f:\n",
    "    request = json.load(f)\n",
    "    if isinstance(request, str):\n",
    "        request = json.loads(request)\n",
    "        \n",
    "group = call_gs(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:49:46.260332Z",
     "start_time": "2020-02-24T09:49:44.842540Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# S.E\n",
    "# ent_fv_full = pickle.load(open(\"/home/ether/hdd/ether/graph_dumps/se/se_entity_feats_v3.pkl\", \"rb\"))\n",
    "# com_map = pickle.load(open(\"mind_data/se/com_map_se_h_v3\", \"rb\")`)\n",
    "#ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/se/se_entity_feats_v3.pkl\", \"rb\"))\n",
    "#com_map = pickle.load(open(\"/home/ray__/ssd/minds/se/tests/com_map.pkl\", \"rb\"))\n",
    "#com_map_ranked = pickle.load(open(\"generate_mind/ranked_com_selected_2.pkl\",\"rb\"))\n",
    "\n",
    "# ether_se\n",
    "# ent_fv_full = pickle.load(open(\"/home/ether/hdd/ether/graph_dumps/se/se_entity_feats_v3.pkl\", \"rb\"))\n",
    "# com_map = pickle.load(open(\"mind_data/se/com_map_se_h_v3\", \"rb\")`)\n",
    "#ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/ether_se/se_ether_feats_non_updated_allether.pkl\", \"rb\"))\n",
    "#com_map = pickle.load(open(\"/home/ray__/ssd/minds/ether_se/com_map_h.pkl\", \"rb\"))\n",
    "#sent_dict = pickle.load(open(\"/home/ray__/ssd/minds/ether/ether_single_label_dict_v1.pkl\",\"rb\"))\n",
    "#com_map_ranked = pickle.load(open(\"generate_mind/ranked_com_selected_2.pkl\",\"rb\"))\n",
    "\n",
    "# marketing -- current\n",
    "# ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/marketing/marketing_entity_feats_v3.pkl\",\"rb\"))\n",
    "# sent_dict = pickle.load(open(\"/home/ray__/ssd/minds/marketing/marketing_sent_dict_v3.pkl\", \"rb\"))\n",
    "# label_dict = pickle.load(open(\"/home/ray__/ssd/minds/marketing/marketing_label_dict_v3.pkl\", \"rb\"))\n",
    "# com_map = pickle.load(open(\"/home/ray__/ssd/minds/marketing/com_map.pkl\", \"rb\"))\n",
    "# ranked_com = pickle.load(open(\"/home/ray__/ssd/minds/marketing/ranked_com.pkl\", \"rb\"))\n",
    "# noun_graph = pickle.load(open(\"/home/ray__/ssd/minds/marketing/noun_graph.pkl\", \"rb\"))\n",
    "# kp_entity_graph = pickle.load(open(\"/home/ray__/ssd/minds/marketing/deployment/kp_entity_graph.pkl\", \"rb\"))\n",
    "\n",
    "# HR -- current\n",
    "# ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/hr/hr_entity_feats_v3.pkl\",\"rb\"))\n",
    "# sent_dict = pickle.load(open(\"/home/ray__/ssd/minds/hr/hr_sent_dict_v3.pkl\",\"rb\"))\n",
    "# label_dict = pickle.load(open(\"/home/ray__/ssd/minds/hr/hr_label_dict_v3.pkl\",\"rb\"))\n",
    "# com_map  = pickle.load(open(\"/home/ray__/ssd/minds/hr/com_map.pkl\",\"rb\"))\n",
    "# noun_graph = pickle.load(open(\"/home/ray__/ssd/minds/hr/deployment/noun_graph.pkl\",\"rb\"))\n",
    "# kp_entity_graph = pickle.load(open(\"/home/ray__/ssd/minds/hr/deployment/kp_entity_graph.pkl\",\"rb\"))\n",
    "# ranked_com = pickle.load(open(\"/home/ray__/ssd/minds/hr/ranked_com.pkl\",\"rb\"))\n",
    "\n",
    "# Ether_se --current\n",
    "# ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/ether_se/se_ether_entity_feats_v3.pkl\",\"rb\"))\n",
    "# sent_dict = pickle.load(open(\"/home/ray__/ssd/minds/ether_se/ether_sent_dict_v3.pkl\", \"rb\"))\n",
    "# label_dict = pickle.load(open(\"/home/ray__/ssd/minds/ether_se/ether_single_label_dict_v4.pkl\", \"rb\"))\n",
    "# com_map = pickle.load(open(\"/home/ray__/ssd/minds/ether_se/com_map.pkl\", \"rb\"))\n",
    "# ranked_com = pickle.load(open(\"/home/ray__/ssd/minds/ether_se/ranked_com.pkl\", \"rb\"))\n",
    "# #noun_graph = pickle.load(open(\"/home/ray__/ssd/minds/ether_se/meeting_noun_graph.pkl\", \"rb\"))\n",
    "# kp_entity_graph = pickle.load(open(\"/home/ray__/ssd/minds/ether_se/se_ether_ent_kp_noun_graph_fromsd.pkl\", \"rb\"))\n",
    "\n",
    "# # S.E --current\n",
    "# ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/se/se_entity_feats_v3.pkl\",\"rb\"))\n",
    "# sent_dict = pickle.load(open(\"/home/ray__/ssd/minds/se/se_sent_dict_v3.pkl\", \"rb\"))\n",
    "# # ent_graph = nx.read_gpickle(\"/home/ray__/ssd/minds/se/se_ent_graph_wcosine_pruned_v3.gpkl\")\n",
    "# # label_dict = pickle.load(open(\"/home/ray__/ssd/minds/ether/ether_single_label_dict_v1.pkl\",\"rb\"))\n",
    "# com_map = pickle.load(open(\"/home/ray__/ssd/minds/se/com_map.pkl\", \"rb\"))\n",
    "# ranked_com = pickle.load(open(\"/home/ray__/ssd/minds/se/ranked_com.pkl\", \"rb\"))\n",
    "# noun_graph = pickle.load(open(\"/home/ray__/ssd/minds/se/se_noun_graph.pkl\", \"rb\"))\n",
    "# kp_entity_graph = pickle.load(open(\"/home/ray__/ssd/minds/se/deployment/kp_entity_graph.pkl\", \"rb\"))\n",
    "\n",
    "# ai -- current\n",
    "# ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/ai/ai_entity.pkl\",\"rb\"))\n",
    "# sent_dict = pickle.load(open(\"/home/ray__/ssd/minds/ai/ai_sent.pkl\", \"rb\"))\n",
    "# com_map = pickle.load(open(\"/home/ray__/ssd/minds/ai/com_map.pkl\",\"rb\"))\n",
    "# noun_graph = pickle.load(open(\"/home/ray__/ssd/minds/ai/noun_graph.pkl\", \"rb\"))\n",
    "# kp_entity_graph = pickle.load(open(\"/home/ray__/ssd/minds/ai/deployment/kp_entity_graph.pkl\", \"rb\"))\n",
    "# ranked_com = pickle.load(open(\"/home/ray__/ssd/minds/ai/ranked_com.pkl\",\"rb\"))\n",
    "\n",
    "\n",
    "# product -- current\n",
    "# ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/product/products_entity_feats_v3.pkl\",\"rb\"))\n",
    "# sent_dict = pickle.load(open(\"/home/ray__/ssd/minds/product/products_sent_dict_v3.pkl\",\"rb\"))\n",
    "# label_dict = pickle.load(open(\"/home/ray__/ssd/minds/product/products_label_dict_v3.pkl\",\"rb\"))\n",
    "# com_map  = pickle.load(open(\"/home/ray__/ssd/minds/product/com_map.pkl\",\"rb\"))\n",
    "# noun_graph = pickle.load(open(\"/home/ray__/ssd/minds/product/noun_graph.pkl\",\"rb\"))\n",
    "# kp_entity_graph = pickle.load(open(\"/home/ray__/ssd/minds/product/deployment/kp_entity_graph.pkl\",\"rb\"))\n",
    "# ranked_com = pickle.load(open(\"/home/ray__/ssd/minds/product/ranked_com.pkl\", \"rb\"))\n",
    "\n",
    "# sales -- current\n",
    "# ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/sales/sales_entity_feats_v3.pkl\",\"rb\"))\n",
    "# sent_dict = pickle.load(open(\"/home/ray__/ssd/minds/sales/sales_sent_dict_v3.pkl\",\"rb\"))\n",
    "# label_dict = pickle.load(open(\"/home/ray__/ssd/minds/sales/sales_label_dict_v3.pkl\",\"rb\"))\n",
    "# com_map  = pickle.load(open(\"/home/ray__/ssd/minds/sales/com_map.pkl\",\"rb\"))\n",
    "# noun_graph = pickle.load(open(\"/home/ray__/ssd/minds/sales/noun_graph.pkl\",\"rb\"))\n",
    "# kp_entity_graph = pickle.load(open(\"/home/ray__/ssd/minds/sales/deployment/kp_entity_graph.pkl\",\"rb\"))\n",
    "\n",
    "# customer_service\n",
    "ent_fv_full = pickle.load(open(\"/home/ray__/ssd/minds/customer_service/entity.pkl\",\"rb\"))\n",
    "sent_dict = pickle.load(open(\"/home/ray__/ssd/minds/customer_service/sent_dict.pkl\", \"rb\"))\n",
    "label_dict = pickle.load(open(\"/home/ray__/ssd/minds/customer_service/label_dict.pkl\", \"rb\"))\n",
    "kp_entity_graph = pickle.load(open(\"/home/ray__/ssd/minds/customer_service/kp_entity_graph.pkl\", \"rb\"))\n",
    "com_map = pickle.load(open(\"/home/ray__/ssd/minds/customer_service/com_map.pkl\", \"rb\"))\n",
    "ranked_com = pickle.load(open(\"/home/ray__/ssd/minds/customer_service/ranked_com.pkl\", \"rb\"))\n",
    "\n",
    "\n",
    "# ent_fv = {}\n",
    "\n",
    "# for ent in ent_fv_full.keys():\n",
    "#     if len(sent_dict[ent]) <= 3:\n",
    "#         continue\n",
    "#     ent_fv[ent] = ent_fv_full[ent]\n",
    "    \n",
    "common_entities = ent_fv_full.keys() & com_map.keys()\n",
    "ent_fv = {}\n",
    "for ent in common_entities:\n",
    "    #if ent in sent_dict.keys(): #and label_dict[ent]=='PER':\n",
    "    #    continue\n",
    "    #if len(sent_dict[ent])>2:\n",
    "    ent_fv[ent] = ent_fv_full[ent]\n",
    "\n",
    "#ent_fv = ent_fv_full    \n",
    "# common_entities = ent_fv_full.keys() & ent_graph.nodes()\n",
    "# ent_fv = {}\n",
    "# for ent in common_entities:\n",
    "#     if ent_graph.nodes[ent]['node_freq']<=10:\n",
    "#         print (ent)\n",
    "#         continue\n",
    "#     ent_fv[ent] = ent_fv_full[ent]\n",
    "\n",
    "# common_entities = ent_fv_full.keys() & ent_graph.nodes()\n",
    "# ent_fv = {}\n",
    "# for ent in common_entities:\n",
    "#     if ent_graph.nodes[ent]['node_freq']<=3:\n",
    "#         print (ent)\n",
    "#         continue\n",
    "#     ent_fv[ent] = ent_fv_full[ent]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:49:46.326765Z",
     "start_time": "2020-02-24T09:49:46.263967Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from filter_groups import CandidateKPExtractor\n",
    "\n",
    "kp_e = CandidateKPExtractor()\n",
    "# entity_list = [node for node in kp_entity_graph if kp_entity_graph.nodes[node]['node_type']=='entity']\n",
    "# entity_list_lower = [ele.lower() for ele in entity_list]\n",
    "uncased_nodes = [ele.lower() for ele in kp_entity_graph]\n",
    "uncased_node_dict = dict(zip(list(kp_entity_graph),uncased_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:49:47.692473Z",
     "start_time": "2020-02-24T09:49:46.329871Z"
    }
   },
   "outputs": [],
   "source": [
    "# #list out multi-word key_phrases\n",
    "# kp_nodes = [node for node in kp_entity_graph if kp_entity_graph.nodes[node]['node_type']!='entity']\n",
    "# multi_tok_kps = [ele for ele in kp_nodes if len(ele.split(' '))>1]\n",
    "# multi_tok_kps = list(set(multi_tok_kps)-set(entity_list_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:49:47.779482Z",
     "start_time": "2020-02-24T09:49:47.703669Z"
    }
   },
   "outputs": [],
   "source": [
    "# multi_kp_tokens = []\n",
    "# for kp in multi_tok_kps:\n",
    "#     multi_kp_tokens.extend(kp.split(' '))\n",
    "    \n",
    "# multi_kp_tokens = list(set(multi_kp_tokens))\n",
    "# noun_graph_tokens = list(set(multi_kp_tokens)&set(noun_graph))\n",
    "# kp_entity_graph.add_nodes_from(noun_graph_tokens,node_type='kp_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:49:47.962452Z",
     "start_time": "2020-02-24T09:49:47.781983Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# for kp in multi_tok_kps:\n",
    "#     kp_nouns = set(kp.split(' '))&set(noun_graph_tokens)\n",
    "#     for noun in kp_nouns:\n",
    "#         kp_entity_graph.add_edge(kp,noun,edge_type='token_kp_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:49:48.047641Z",
     "start_time": "2020-02-24T09:49:47.972281Z"
    }
   },
   "outputs": [],
   "source": [
    "# pickle.dump(kp_entity_graph, open(\"/home/ray__/ssd/minds/sales/deployment/kp_entity_graph.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:49:48.194132Z",
     "start_time": "2020-02-24T09:49:48.051989Z"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from scipy.spatial.distance import cosine\n",
    "# group_ent_full = {}\n",
    "# group_kp = {}\n",
    "# group_kp_map = {}\n",
    "# group_filtered_kps = {}\n",
    "\n",
    "# import text_preprocessing.preprocess as tp\n",
    "# for groupid, groupobj in group.items():\n",
    "#     seg_text = \" \".join([segobj['originalText'] for segobj in groupobj])\n",
    "#     text_kps = kp_e.get_candidate_phrases(seg_text)\n",
    "#     text_kps = list(set([ele.lower() for ele in text_kps]))\n",
    "#     tagged_sents = nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(seg_text))\n",
    "#     #print (seg_text)\n",
    "#     #print (tagged_sents[0])\n",
    "#     #print (tp.preprocess(seg_text, stop_words=False, word_tokenize=True, pos=True)[1][0])\n",
    "#     #print (tagged_sents[0] == tp.preprocess(seg_text, stop_words=False, word_tokenize=True, pos=True)[1][0])\n",
    "#     #break\n",
    "#     text_nouns = []\n",
    "#     for tagged_sent in tagged_sents:\n",
    "#         text_nouns.extend([ele[0] for ele in list(tagged_sent) if ele[1].startswith('NN')])\n",
    "#     text_nouns = [ele.lower() for ele in text_nouns]\n",
    "#     intersecting_nouns = list(set(text_nouns)&set(kp_entity_graph))\n",
    "#     intersection_ctr = 0\n",
    "#     filtered_kps = []\n",
    "#     for kp in text_kps:\n",
    "#         if len(kp.split(' '))>1:\n",
    "#             kp_nouns = list(set(kp.split(' '))&set(intersecting_nouns))\n",
    "# #             for noun in kp_nouns:\n",
    "# #                 rem_nouns = list(set(kp_nouns)-set([noun]))\n",
    "# #                 if set(rem_nouns)&set(kp_entity_graph[noun])==set(rem_nouns):\n",
    "# #                     filtered_kps.append(kp)\n",
    "# #                     continue\n",
    "#             for noun in kp_nouns:\n",
    "#                 if noun in kp_entity_graph.nodes():\n",
    "#                     filtered_kps.append(kp)\n",
    "#                     continue\n",
    "#     filtered_kps = list(set(filtered_kps))\n",
    "#     group_filtered_kps[groupid] = filtered_kps\n",
    "#     candidate_sents = [sent.lower() for sent in nltk.sent_tokenize(seg_text)]\n",
    "#     filtered_sents = []\n",
    "#     for sent in candidate_sents:\n",
    "#         if any(kp in sent for kp in filtered_kps):\n",
    "#             filtered_sents.append(sent)\n",
    "#     filtered_paragraph = ' '.join(filtered_sents)\n",
    "#     para_feats = gpt_model.get_para_feats(filtered_paragraph)\n",
    "    \n",
    "#     noun_list = [ele.split(' ') for ele in filtered_kps]\n",
    "#     noun_list = sum(noun_list, [])\n",
    "#     noun_list = list(set(noun_list)&set([uncased_node_dict[ele] for ele in uncased_node_dict]))\n",
    "#     noun_node_list = [key  for (key, value) in uncased_node_dict.items() if value in noun_list]\n",
    "#     ent_node_list = [ele for ele in noun_node_list if kp_entity_graph.nodes[ele]['node_type']=='entity']\n",
    "#     noun_node_list = list(set(noun_node_list)-set(ent_node_list))\n",
    "    \n",
    "#     group_kp[groupid] = noun_list\n",
    "#     kp_Map_list = []\n",
    "#     kp_ent_map = []\n",
    "#     for noun in noun_node_list:\n",
    "#         kp_Map_list.extend([ele for ele in list(kp_entity_graph[noun]) \n",
    "#                             if kp_entity_graph[noun][ele]['edge_type']=='token_kp_map'])\n",
    "#     group_kp_map[groupid] = kp_Map_list\n",
    "#     for kp in list(set(kp_Map_list)):\n",
    "#         kp_ent_map.extend([ele for ele in list(kp_entity_graph[kp]) if kp_entity_graph.nodes[ele]['node_type']=='entity'])\n",
    "    \n",
    "#     kp_ent_map = list(set(kp_ent_map+ent_node_list))\n",
    "#     kp_ent_map = list(set(kp_ent_map)&set(ent_fv))\n",
    "#     dist_list = []\n",
    "#     for entity in kp_ent_map:\n",
    "#         dist_list.append((entity, 1-cosine(ent_fv[entity],para_feats)))\n",
    "#     group_ent_full[groupid] = sorted(dist_list, key=lambda kv:kv[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:50:50.611207Z",
     "start_time": "2020-02-24T09:49:48.206837Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter groups with communities.\n",
    "\n",
    "import nltk\n",
    "from scipy.spatial.distance import cosine\n",
    "from community import best_partition\n",
    "import statistics\n",
    "import networkx as nx\n",
    "group_ent = {}\n",
    "group_kp = {}\n",
    "group_kp_map = {}\n",
    "group_filtered_kps = {}\n",
    "\n",
    "import text_preprocessing.preprocess as tp\n",
    "for groupid, groupobj in group.items():\n",
    "    seg_text = \" \".join([segobj['originalText'] for segobj in groupobj])\n",
    "    text_kps = kp_e.get_candidate_phrases(seg_text)\n",
    "    text_kps = list(set([ele.lower() for ele in text_kps]))\n",
    "    tagged_sents = nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(seg_text))\n",
    "    #print (seg_text)\n",
    "    #print (tagged_sents[0])\n",
    "    #print (tp.preprocess(seg_text, stop_words=False, word_tokenize=True, pos=True)[1][0])\n",
    "    #print (tagged_sents[0] == tp.preprocess(seg_text, stop_words=False, word_tokenize=True, pos=True)[1][0])\n",
    "    #break\n",
    "    text_nouns = []\n",
    "    for tagged_sent in tagged_sents:\n",
    "        text_nouns.extend([ele[0] for ele in list(tagged_sent) if ele[1].startswith('NN')])\n",
    "    text_nouns = [ele.lower() for ele in text_nouns]\n",
    "    \n",
    "    intersecting_nouns = list(set(text_nouns)&set(kp_entity_graph))\n",
    "    \n",
    "    intersection_ctr = 0\n",
    "    filtered_kps = []\n",
    "    for kp in text_kps:\n",
    "        if len(kp.split(' '))>1:\n",
    "            kp_nouns = list(set(kp.split(' '))&set(intersecting_nouns))\n",
    "#             for noun in kp_nouns:\n",
    "#                 rem_nouns = list(set(kp_nouns)-set([noun]))\n",
    "#                 if set(rem_nouns)&set(kp_entity_graph[noun])==set(rem_nouns):\n",
    "#                     filtered_kps.append(kp)\n",
    "#                     continue\n",
    "            for noun in kp_nouns:\n",
    "                if noun in kp_entity_graph.nodes():\n",
    "                    filtered_kps.append(kp)\n",
    "                    continue\n",
    "    filtered_kps = list(set(filtered_kps))\n",
    "    group_filtered_kps[groupid] = filtered_kps\n",
    "    candidate_sents = [sent.lower() for sent in nltk.sent_tokenize(seg_text)]\n",
    "    filtered_sents = []\n",
    "    for sent in candidate_sents:\n",
    "        if any(kp in sent for kp in filtered_kps):\n",
    "            filtered_sents.append(sent)\n",
    "    #filtered_paragraph = ' '.join(filtered_sents)\n",
    "    #para_feats = gpt_model.get_para_feats(filtered_paragraph)\n",
    "    \n",
    "    \n",
    "    noun_list = [ele.split(' ') for ele in filtered_kps]\n",
    "    noun_list = sum(noun_list, [])\n",
    "    noun_list = list(set(noun_list)&set([uncased_node_dict[ele] for ele in uncased_node_dict]))\n",
    "    noun_node_list = [key  for (key, value) in uncased_node_dict.items() if value in noun_list]\n",
    "    ent_node_list = [ele for ele in noun_node_list if kp_entity_graph.nodes[ele]['node_type']=='entity']\n",
    "    noun_node_list = list(set(noun_node_list)-set(ent_node_list))\n",
    "    \n",
    "    group_kp[groupid] = noun_list\n",
    "    kp_Map_list = []\n",
    "    kp_ent_map = []\n",
    "    for noun in noun_node_list:\n",
    "        kp_Map_list.extend([ele for ele in list(kp_entity_graph[noun]) \n",
    "                            if kp_entity_graph[noun][ele]['edge_type']=='token_kp_map'])\n",
    "    group_kp_map[groupid] = kp_Map_list\n",
    "    for kp in list(set(kp_Map_list)):\n",
    "        kp_ent_map.extend([ele for ele in list(kp_entity_graph[kp]) if kp_entity_graph.nodes[ele]['node_type']=='entity'])\n",
    "    \n",
    "    kp_ent_map = list(set(kp_ent_map+ent_node_list))\n",
    "    kp_ent_map = list(set(kp_ent_map)&set(ent_fv))\n",
    "    \n",
    "    sent_list = filtered_sents\n",
    "    sent_fv = [gpt_model.get_text_feats(sent) for sent in sent_list]\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(len(sent_fv)))\n",
    "    \n",
    "\n",
    "    node_list = range(len(sent_fv))\n",
    "    for index1, nodea in enumerate(range(len(sent_fv))):\n",
    "        for index2, nodeb in enumerate(range(len(sent_fv))):\n",
    "            if index2 >= index1:\n",
    "                c_score = 1 - cosine(sent_fv[nodea], sent_fv[nodeb])\n",
    "                #if c_score>= outlier_score:\n",
    "                G.add_edge(nodea, nodeb, weight = c_score)\n",
    "        closest_connection_n = sorted(dict(G[nodea]).items(), key=lambda kv:kv[1][\"weight\"], reverse=True)\n",
    "        weights_n = list(map(lambda kv: (kv[1][\"weight\"]).tolist(), closest_connection_n))\n",
    "        q3 = np.percentile(weights_n, 75)\n",
    "        iqr = np.subtract(*np.percentile(weights_n, [75, 25]))\n",
    "        #outlier_score = q3 + (1.5 * iqr)\n",
    "        outlier_score = q3 + (1 * iqr)\n",
    "        for nodeb, param in dict(G[nodea]).items():\n",
    "            if param['weight']>=q3:\n",
    "                pass\n",
    "            else:\n",
    "                G.remove_edge(nodea, nodeb)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    comm_temp = best_partition(G, resolution=1)\n",
    "    \n",
    "    prev = 0 \n",
    "    comm_map = {}\n",
    "    for ent, cls in sorted(comm_temp.items(),key=lambda kv:kv[1]):\n",
    "        if prev!=cls:\n",
    "            prev = cls\n",
    "        if cls in comm_map.keys():\n",
    "            comm_map[cls].append(ent)\n",
    "        else:\n",
    "            comm_map[cls] = [ent]\n",
    "            \n",
    "    agg_fv = {}\n",
    "    if True in [True if len(s_list)>1 else False for s_list in comm_map.values() ]:\n",
    "        threshold = 1\n",
    "    else:\n",
    "        threshold = 0\n",
    "    for comm, s_list in comm_map.items():\n",
    "        if len(s_list)>threshold:\n",
    "            temp_fv = [sent_fv[s] for s in s_list]\n",
    "            agg_fv[comm] = np.mean(temp_fv, axis=0)\n",
    "    \n",
    "    dist_list = {}\n",
    "    for pos, fv in agg_fv.items():\n",
    "        temp_list = []\n",
    "        for entity in ent_fv.keys():\n",
    "            temp_list.append((entity, 1-cosine(ent_fv[entity], fv)))\n",
    "        dist_list[pos] = sorted(temp_list, key=lambda kv:kv[1], reverse=True)[:10]\n",
    "    \n",
    "    group_ent[groupid] = [e for e_list in dist_list.values() for e in e_list]\n",
    "    #group_ent[groupid] = sorted([e for e_list in dist_list.values() for e in e_list], key=lambda kv:kv[1], reverse=True)[:10]\n",
    "#     dist_list = []\n",
    "#     for entity in kp_ent_map:\n",
    "#         dist_list.append((entity, 1-cosine(ent_fv[entity],para_feats)))\n",
    "#     group_ent[groupid] = sorted(dist_list, key=lambda kv:kv[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:50:50.665109Z",
     "start_time": "2020-02-24T09:50:50.613678Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## for sentence instead of group\n",
    "\n",
    "# import nltk\n",
    "# from scipy.spatial.distance import cosine\n",
    "# group_ent = {}\n",
    "# group_kp = {}\n",
    "# group_kp_map = {}\n",
    "# group_kp_ent = {}\n",
    "# group_filtered_kps = {}\n",
    "\n",
    "# for groupid, groupobj in group.items():\n",
    "#     seg_text = \" \".join([segobj['originalText'] for segobj in groupobj])\n",
    "#     text_kps = kp_e.get_candidate_phrases(seg_text)\n",
    "#     text_kps = list(set([ele.lower() for ele in text_kps]))\n",
    "#     tagged_sents = nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(seg_text))\n",
    "#     text_nouns = []\n",
    "#     for tagged_sent in tagged_sents:\n",
    "#         text_nouns.extend([ele[0] for ele in list(tagged_sent) if ele[1].startswith('NN')])\n",
    "#     text_nouns = [ele.lower() for ele in text_nouns]\n",
    "#     intersecting_nouns = list(set(text_nouns)&set(kp_entity_graph))\n",
    "#     intersection_ctr = 0\n",
    "#     filtered_kps = []\n",
    "#     for kp in text_kps:\n",
    "#         if len(kp.split(' '))>1:\n",
    "#             kp_nouns = list(set(kp.split(' '))&set(intersecting_nouns))\n",
    "# #             for noun in kp_nouns:\n",
    "# #                 rem_nouns = list(set(kp_nouns)-set([noun]))\n",
    "# #                 if set(rem_nouns)&set(kp_entity_graph[noun])==set(rem_nouns):\n",
    "# #                     filtered_kps.append(kp)\n",
    "# #                     continue\n",
    "#             for noun in kp_nouns:\n",
    "#                 if noun in kp_entity_graph.nodes():\n",
    "#                     filtered_kps.append(kp)\n",
    "#                     continue\n",
    "#     filtered_kps = list(set(filtered_kps))\n",
    "#     group_filtered_kps[groupid] = filtered_kps\n",
    "#     candidate_sents = [sent.lower() for sent in nltk.sent_tokenize(seg_text)]\n",
    "#     filtered_sents = []\n",
    "#     for sent in candidate_sents:\n",
    "#         if any(kp in sent for kp in filtered_kps):\n",
    "#             filtered_sents.append(sent)\n",
    "    \n",
    "#     noun_list = [ele.split(' ') for ele in filtered_kps]\n",
    "#     noun_list = sum(noun_list, [])\n",
    "#     noun_list = list(set(noun_list)&set([uncased_node_dict[ele] for ele in uncased_node_dict]))\n",
    "#     noun_node_list = [key  for (key, value) in uncased_node_dict.items() if value in noun_list]\n",
    "#     ent_node_list = [ele for ele in noun_node_list if kp_entity_graph.nodes[ele]['node_type']=='entity']\n",
    "#     noun_node_list = list(set(noun_node_list)-set(ent_node_list))\n",
    "\n",
    "#     group_kp[groupid] = noun_list\n",
    "#     kp_Map_list = []\n",
    "#     kp_ent_map = []\n",
    "#     for noun in noun_node_list:\n",
    "#         kp_Map_list.extend([ele for ele in list(kp_entity_graph[noun]) \n",
    "#                             if kp_entity_graph[noun][ele]['edge_type']=='token_kp_map'])\n",
    "#     group_kp_map[groupid] = kp_Map_list\n",
    "#     for kp in list(set(kp_Map_list)):\n",
    "#         kp_ent_map.extend([ele for ele in list(kp_entity_graph[kp]) if kp_entity_graph.nodes[ele]['node_type']=='entity'])\n",
    "\n",
    "#     kp_ent_map = list(set(kp_ent_map+ent_node_list))\n",
    "#     kp_ent_map = list(set(kp_ent_map)&set(ent_fv))\n",
    "\n",
    "#     tot_ent_list = []\n",
    "#     for sent in filtered_sents:\n",
    "#         para_feats = gpt_model.get_para_feats(sent)\n",
    "\n",
    "#         dist_list = []\n",
    "#         for entity in kp_ent_map:\n",
    "#             dist_list.append((entity, 1-cosine(ent_fv[entity],para_feats)))\n",
    "#         tot_ent_list.append(sorted(dist_list, key=lambda kv:kv[1], reverse=True)[0])\n",
    "#     group_kp_ent[groupid] = kp_ent_map\n",
    "#     group_ent[groupid] = tot_ent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:50:50.999784Z",
     "start_time": "2020-02-24T09:50:50.667526Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Groupid:  7\n",
      "\n",
      " You're able to see this, right? Yes. Okay, excellent. Okay, so when could I thought it'll be good for us to do a little bit have a dis little bit of a discussion on just the I stack with ether. I did a separate overview of our platform. So I'm assuming that a lot of the folks who are seeing. This will be gone through that that call and got up. Bit of an understanding about what ether is over. All right, but just to reiterate if you look at ethers a I stack there are a few things that that we want to kind of highlight, right? The first is its concept of Channel or team mines where whereby we are representing the team context both the static aspects of it. In other words. Let's say there's a team that is working on software engineering or databases or Our devops in general, right? So there is a static idea that they're working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently. Is that a production issue that is being addressed right now it is that a particular type of database are talking about or you know, a particular aspect of their software engineering stack that they're talking about. So there's a dime static and dynamic aspects. So the first time Idea is idea about Channel or team Minds. We're in ether. We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide. So that's what we call as Chandler team wins. The second is  Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them. So one quick way of kind of talking about the the graph would be that it's a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right? So that's either graph the second. I think the the next one is this idea of you know, how once a call is over. Let's say you're in a meeting and you're and the team is having a discussion and in an hour's call you're talking about a bunch of different topics. How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information. And so how do you extract what is Meaningful and what's not so that is another aspect of how either ether zai gets applied to just the meetings their interactions, right? The next is the idea of topic detection using communities, which is a you know, when you there's a there's a meeting that's happening. Being and you're having a discussion, maybe it's a group meeting and you're talking about five different topics in the call or you're talking about, you know, you're doing a two people are talking about one particular subject. But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right? So that's the other aspect that  Should talk about next is the keyphrase extraction, which is sometimes it's hard to blame the entire discussion. So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them. First of all, the weight is very hard to read and understand so sometimes it's important to just be able to pull out. What are the key phrases right in a conversational setting. Segments so that you can quickly in a snare at-a-glance come to know what is what is being discussed and so on and so forth. So, how do we do that? So that's a very interesting aspect of ethers a sec as well and last but not the least. We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right? So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss. So, of course, there's also a couple of other things that we are working on. On the background and we'll touch upon those as well. So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects. Sure. Okay, so, all right. So before we get started a lot of times question comes up when we talk about ether how we do our speech-to-text, right? We just to kind of lay this out is we don't  Build a speech to text technology ourselves because a lot of it one one reason for it is that it there's a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time. So we actually focus on we assume that that is actually a speech-to-text engine that's in the background either with our with our partners lot of times. When we go to market with our partners, they actually like to use their own speech-to-text technology for integrating. And so the way we built ether was to have a lot of flexibility in being able to associate any speech-to-text engine to with our for our purposes. So the way we do this is, you know showcases app, which is ether meet. We integrate with the close partner called Deep Graham to provide. Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well. We've integrated with AWS transcribe. We also have the ability to integrate with other models. We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality. It's also the most expensive. So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider? Let's say deepground as a first pass. And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible-- So we  Can pause with Google's speeches video model. So that's the other kind of unique aspect about how we've built it inside our architecture. So the pipeline is very flexible. We have the ability to associate speech-to-text Provider by workspace by and we have the ability to do it in two passes one passes. So on and so forth, so it's very very flexible. Right? So anyway, that is a little quick note on. How we do speech to text so yeah, okay. So now we're getting to the interesting portion. So let's talk about Channel Minds right little deeper into Channel Minds. Maybe you can just give us a quick overview of what channel Minds is. I mean, I guess we've already discussed what channel minds are but more about how we build it and how we use it and so on. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['UX', 'Big Data', 'Bullseye', 'Optimizely', 'X', 'SubscriptMe', 'Ireland', 'Ideation', 'CMO', 'Optiverse', 'Integrations', 'Optiverse', 'App', 'Process Street', 'EQ', 'Web', 'Marketing', 'English', 'HubSpot', 'CTA', 'Ecommerce', 'DIY', 'Ebay', 'EQ', 'Enterprise', 'EMEA', 'Web', 'GDPR', 'HubSpot', 'CX', 'Bullseye', 'Ideation', 'Persona', 'Focus', 'Marketing', 'Optimizely', 'Big Data', 'Intelligence', 'Web', 'Integrations', 'People', 'Office', 'X', 'PM', 'CSM', 'CS', 'Organization', \"I'm\", 'Marketing', 'Bullseye', 'Marketing', 'Internet', 'Millennials', 'Blog', 'CMO', 'Web', 'Context', 'App', 'Ideation', 'CX', 'SubscriptMe', 'Optiverse', 'People', 'Ireland', 'Close and Buffer', 'Ground', 'X', 'CMO', 'DRI', 'Mall', 'Web', 'Google Analytics', 'Google', 'YouTube', 'CTA', 'Google Docs', 'Google Forms', 'Integrations', 'App', 'Personas']\n",
      "\n",
      "\n",
      "Groupid:  6\n",
      "\n",
      " I think before before we get started with its II think I think I'll just give you a heads up on a thin configuration by it. So how we are placed as a team. Mlh.  Great great portion. Maybe you know, I sorry for not doing this, but maybe you can just give a quick introduction about yourself. And also maybe give a little bit of background about Ari, I think sure. Yeah, so I'm Vanka.  Then and I leave The A Team we are we are a team of 5. Ml Engineers who are who primarily work on machine learning deployments and also building the state-of-the-art machine learning models. So it's a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor. I mean as a team they worked on very broader set of are use cases ranging. Not just not just in the NLP. I also also like the Imaging and then the video processing and on the text, I mean the speech-to-text and and and the whole whole spectrum of the AI ecosystem. So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the state-of-the-art models in the Deep learning or any other machine learning space coming out then so that's where you see, you know. Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe. So having said that I think I think that should be good enough with the team and then maybe it's good time to get here. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['DRI', 'Tenet 5', 'Optiverse', 'Organization', 'Anthropologists', 'Unbounce', 'People', 'SMART', 'Bullseye', 'Advisory Board', 'Ireland', 'Boston', 'Tech', 'Marketing', 'One Size', 'Spanish', 'Europe', 'English', 'Blog', 'Ground']\n",
      "\n",
      "\n",
      "Groupid:  4\n",
      "\n",
      " That's good thinking. Yeah, maybe we can now just dive deeper. Yeah. Sure. What I'll do is I'll ask you speak. I'll also create markers here. So you can kind of get a feel for it as we go on but wine to get started and let's dive in and talk a little bit about Channel Minds. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Context', 'Customer Service Department', 'Dear Readers', 'Train', 'All-in', 'Miss', 'Ideation', 'Customer Success', 'Marketing and Sales Department', 'World Series', 'Context', 'Ideation', 'RD', 'CX', 'Blog', 'Marketing', 'Post', 'Dear Readers', 'Intelligence', 'UX']\n",
      "\n",
      "\n",
      "Groupid:  9\n",
      "\n",
      " Yeah, sure son. So I think with the headset that you gave about the channel Minds I meant that that's like a thousand feet free of what channel mine does. I mean to keep it simple. It's just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period. Out of time. So I'll just walk you through I'll give you a tip. I'll give you what goes behind the scenes for the for the channel Minds technically and then we'll come to how it works across all the a downstream applications. So Channel Minds as we as we have architecture. These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether. Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion. So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans. I mean the feature extractor for the whole process wherein we train we train the neural net. Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a pre-loaded, you know library of domain mines be call. So we stopped with such which talks about each domain when talks about certain certain. You know, what you call the horizontal. It's a wonder my mind is software engineering the other one could be markers.  And I mean it could be sale. So that's ever-growing. That means we keep on adding the the new domains to our domain Library. So when when a user's invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel. So which means I mean, Coming to the language model aspect of it. We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you're doing earlier, right? So that's on the language model. Coming to coming to fine-tune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about. I'm going to show some examples in the next slides, but but to give you what it means, let's say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked. Let's say the if the engineering teams talks about production.  In past two weeks or three weeks. What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data. I'll talk about the Mind generation in the next slide, but How do we fine-tune I'll just continue on that. So so along with fine tuning this language model wherein you know, software engineering language model would be fine-tuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that. Once we once we have the language model, that's fine tune. We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet. So so that's where the channel mind comes into play when we say mine. The model is the actual neural network model and the mind is is the graph data structure that organizes the information. Action that is coming, you know to The Ether AI engine if you're it.  I guess one way to talk about that would be there's a static component. Then there's a dynamic component. Right? Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on. Yep.  That makes it so this we're doing this way. What we have done is we have had to hack the data hunger of the more of the neural network language models. I because we get the data in a very small increments for the machine learning model. So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it's a static component. And then in the meantime, we don't want to lose the information that we have. Have gathered which is recency and other aspects of it. So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we're giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently. So that's kind of the engineering that we did for the channel Minds got it. Yeah, we can move to the next slide. Okay? Yeah.  Oh, yeah, I'm sorry. I I think I think we can on the validation component. What we do is actually there are there is a two-stage validation one is one is the language model that we that we have two other people which is well, which is actually fine-tune various tasks. When I say a task it is it is like asking asking the language model to predict whether whether a sentence is at whether a sentence whether two sentences are continuous. Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations. So so we have we have fairly statistical validation approaches to validate this auxiliary tasks. So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation. So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks. So that way we just we just semi-automated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.  So I guess this is kind of a very it's a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated. How is that attach to the with a slack Channel and then how it how the channel Minds self-generated right? Yeah. That's right. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['AI', 'Tech', 'Bot', 'App', 'AIs', 'Web', 'Internet', 'Big Data', 'Intelligence', 'Bots', 'Guide', 'Marketing', 'Bullseye', 'Optiverse', 'Ideation', 'Blog', 'Ireland', 'Internet', 'English', 'Ground', 'UX', 'Intelligence', 'Web', 'App', 'Google Analytics', 'English', 'CTA', 'Integrations', 'Names', 'Silos', 'UX', 'Optiverse', 'Excel', 'Website', 'Google Analytics', 'Web', 'Integrations', 'Optimizely', 'App', 'Process Street', 'English', 'Europe', 'Spanish', 'Ireland', 'Marketing', 'CMO', 'UX', 'United States', 'Boston', 'Tech', 'Optiverse', 'SubscriptMe', 'Fortune 500', 'Optimizely', 'Consumer Insights', 'CMO', 'UX', 'Process Street', 'Ios', 'Unbounce', 'Drawing Board', 'App', 'Enps', 'Bullseye', 'CSM', 'Department', 'Y', 'Harvard Business Reviewadmits', 'Rep', 'Shoulds', 'UX', 'CMO', 'Optiverse', 'Ideation', 'Marketing', 'Advisory Board', 'Bullseye', 'Optimizely', 'DRI', 'CX']\n",
      "\n",
      "\n",
      "Groupid:  13\n",
      "\n",
      " So a quick heads up on this on this slide because this puts everything I can with my cousin in one single view. So so this this just shows how how the chat the domain Minds, you know shape-shifts into the channel and by learning all the information that it gets from the conversations. So let me get just started my mind Generations on the top. So we we we use open data to to you know, generate generate a fix. A library of domain Minds as as we mentioned some of the samples here some this is ever growing we keep on adding so to this list. So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is well-versed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model. It's a simple example would be a bug a bug in nature may be different from the bug in a software engineering model. I mean just a very very intuitive example on that. So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering. Nearing a not about some biology right? So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation. So this domain mind gets it domain language for who gets attached to the to the channel when the user says invites you to the channel. So from once we have this domain language model right as we were talking about the domain minder.  That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph. So that means if someone is talking about deployment aunt and then if in a certain channel is if they always associate deployment with let's say AWS Lambda. So this relationship is learned that when there is an aid of a deployment. This is likelihood that with the talk about a double s Lambda also, it means that they seem to be talking about a similar as similar aspect for that certain Tim. So this is kind of relationship that this combination of language model undermined men captures.  That's on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel. So every time every time there's a new conversation that comes in the comes in the eater. Calls there would be there would be scored or they would be compared against this domain mind till we have the transformation to the channel Minds. So so this is this is fairly simple, you know, simple. What do you call it? Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind. We're in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier. We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds. So we're in along with the let's say software engineering it'll also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team. So that's this is where you know, you have the real learning component of Egypt  Come sit. So excellent. Yeah. Okay as we mentioned so domain Channel mine is fairly Dynamic. That means that that it can it can read all the information that it gives every every every minute or so, whereas somewhat relatively static is the channel language model which we update once we have enough information for a neural network to be fine, too. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Blog', 'Boston', 'Marketing', 'English', 'CMO', 'Internet', 'Us', 'Web', 'Ireland', 'Names', 'Web', 'App', 'Internet', 'CTA', 'Integrations', 'Website', 'Messenger', 'App Store', 'YouTube', 'Slackbot', 'Optiverse', 'Ireland', 'CMO', 'SubscriptMe', 'Consumer Insights', 'Big Data', 'Fortune 500', 'Marketing', 'Portals', 'Us', 'UX', 'English', 'Engineering', 'Tech', 'Intelligence', 'App', 'Marketing', 'Department', 'Drawing Board', 'Shoulds', 'Channel', 'Global Navigation', 'Ad', 'UX', 'C', 'Segment', 'Heneeds', 'Imessage', 'SERP', 'Party']\n",
      "\n",
      "\n",
      "Groupid:  10\n",
      "\n",
      " Got it. Excellent. Just want to call out that when we say Channel. It is just in the context of a team, right like essentially Channel equals a team. So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right? Like for example, that could be a virtual team. Let's say on either some other channel at home or some other let's say Google Hangouts for example, right if there is a concept of a Group in Google Hangout and that prisons attain the same level of attachment of mines and ending can also happen there.  Cool. Alright, so that is actually a good segue to actually before we do that. I wanted to kind of call out Channel minds and action. All right, so there is there is here is a kind of an example. Let me actually take this down and show it in a real slack conversation. So let's give me a second here. Let me pull up Slack.  Or the real test. Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels. Right? So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right? So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics. And then when you pass it through when you have that meeting in the context of a software engineering mind, the discussion summarizes The Ether summarizes the discussion pulls out topics related to software for example things about database continuously ICD kubernetes Etc. Our infrastructure that Kafka whereas when you talk about when you run the same meeting through the marketing channel, you know, it pulls out things about, you know, digital marketing. You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right? So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that's associated with it. Right. So again, let me go back switch to my presentation here.  it's fair play shows how how the channel man is able to differentiate based on the Mind attached to it during the  All right, so it's a great segue into you know, so when we talked about Channel Minds you brought up this notion of the dynamic portion. That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that's a very unique way of representing the intelligence of the Insight that's happening in the context of teams and and the organization in a graph format and using this in a variety of different ways. So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like. So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is. Maybe you can just walk us through this a little bit. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Big Data', 'Boston', 'X', 'UX', 'CMO', 'Ireland', 'Marketing', 'Know Everything', 'West', 'Context', 'Millennials', 'App', 'Department', 'Internet', 'Web', 'YouTube', 'Marketing', 'Blog', 'CX', 'Online', 'Marketing', 'Bullseye', 'Website', 'Blog', 'Ground', 'Advisory Board', 'X', 'Boston', 'Drawing Board', 'App', 'Marketing', 'English', 'Bullseye', 'Names', 'CMO', 'Ideation', 'Persona', 'Shoulds', 'App', 'CSM', 'UX', 'CTA', 'Persona', 'Marketing', 'App', 'Names', 'Drawing Board', 'Website', 'CMO', 'Excel']\n",
      "\n",
      "\n",
      "Groupid:  15\n",
      "\n",
      " Check just like so eat a graph serves multiple purposes one one being as we talked about it. It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I'll come but where I'll start is, you know, it's about its ability. T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction. So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data. A source would just go as is to the general feeling.  Yeah, I guess it really we're operating in the text domain. So if it is a speech data we converted to text first if there is Vision data, let's say the slides that need to be processed. I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let's say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as  So in that help engine, it's like a it's like a pre fabricating the data such so that it can go into the graph structure. So these are two different components coming together. So we're in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature. So presentation so that we can be can you know use it for all sorts of computations. So we again use the associated domain language model of the custom custom Channel language model for for feature is Amal the text that picket and then and then we also bring in the notion of Miles here. That means these two are like in Hindi interdependent. So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior. In terms of its relevance relevance and other aspects caps in other aspects. So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have. And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim. You know, Knowledge Graph like the factual graph on The Ether graph. I'll talk about the difference just just in a minute, but but so what we are trying to say here is along with the actual factual information like who spoke what or or what are the you know who attended the meeting so these Services enable The Ether  Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself isn't are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or non-obvious inside sort of the god Apollo. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Y', 'UX', 'Big Data', 'Marketing', 'RD', 'Silos', 'KPIs', 'CTAs', 'Advisory Board', 'CMO', 'Google Docs', 'UX', 'CTA', 'App', 'URL', 'Names', 'Web', 'Process Street', 'Google Analytics', 'Integrations']\n",
      "\n",
      "\n",
      "Groupid:  11\n",
      "\n",
      " Something like, you know, if I'm part of a channel that's a very direct relationship which doesn't require a lot of intelligence which is get it right out of the station. Whereas when I say, hey, you know Karthik follow up on this production issue, you know the idea that Karthik is the person who I'm assigning this action to is something that is not so intuitive and needs to be gleaned right by first applying NLP in these types of rules then later on also being getting represented in the laugh  That's right. Yeah. So as you said the example that you gave write a card they can you follow the on this can come as part of the conversation in the free text, you know free language. So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get. So having said that I'll just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component. So we're in the in the computation graph as we as mentioned earlier. It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks. So say for example, if I have to give you one example of how the how the body is non-intuitive relations could be is you know, let's say let's say let's say Karthik talked about kubernetes in one of the in couple of calls  Yeah, okay. So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik. So so so what it does is it also forms a relation between Karthik as anode which is the user and then the kubernetes as a topic and then says you know here Initially then as as as as more and more conversations around kubernetes are happening. The talked about can get interest into is a is an expert in tuber natives even say that is very cool. Yeah. So how in fact we can even take consensus just because Karthik is talking we need not say that he could be an expert. But if I orthotic that means every time Karthik talks about kubernetes if you are a watch it so which which makes in which makes him kind of we approve his Don't open it is and that we captured that inside to and then reinforce that that relationship as a Karthik is an expert in kubernetes. So that's how the evaluation of you know, relationships happened within the that's one of the example that I just gave program give you an idea of how computation graph works. So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we're going to talk about a little so so so and also other top XO from the from the from the computation graph perspective. I think I just Brave briefly highlighted. What bought the nodes could be along with the the factual notes like the users and favorite pics. So we we just organize the topics key phrases captured as the notes on that. They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting.  Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.  Yes, I eat a graph is more of a traditional representation of God. Yes, it's teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them. Yeah, that's like not. Okay and then I guess once you have these types of graphs. What can you do with them?  So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations. In fact, we can even do better at this point. If you don't talk about anything else if direct enables us to form the you know, form the form this non-inductive relationships like talked about a certain topic or action item assigned to so now let's take forward and then use This graph that is actually being formed after all the conversations. And then what we what we do is we just put it through a graph neural networks kind or the different graph algorithms. And then what comes out is actually a lot more, you know a lot more insights that will enable us to do like very non-intuitive recommendations. So as I talked about that Karthik being expert in a in kubernetes, right so that can be formed from the from some of this. You know, I'd rather than that we use like the node embeddings what I mean by no damn wedding is when there is Karthik so we don't just we don't just see Karthik as you know a person so we also input all the information that he that actually this ether captures about about that. That means all the relationships about the topics whom he follows or whom who I mean, what are the topics that he usually discusses and then we just call that whole component and then we encode everything into into the cottage. It snowed embedded like that. All the users will have their own representation that not just captures what who they are. But but what they come as a combination represents, so once they have this as a mathematical object, like like a like a embedding what we can do is we can do lot of you know algorithms on because we are free to do all the math around it and then we can you can get for the similar users to kartik from the context of you know, the topics that that he discusses or from the context of the action items.  Just think of integrating these insights into you know, a ticket management tool like jira, right? So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this.  That's kind of a that's what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['CMO', 'English', 'Marketing', 'Unbounce', 'Net Promoter', 'Forbes', 'CX', 'HBR', 'Y', 'United States', 'Big Data', 'UX', 'Optimizely', 'Process Street', 'Google Analytics', 'Qualaroo', 'Optiverse', 'CMO', 'Break', 'Integrations', 'Cloud', 'Google Analytics', 'Big Data', 'Excel', 'Customer Data Platform', 'AI', 'Technology', 'Break', 'Optimizely', 'Global Navigation', 'Names', 'UX', 'App', 'CTA', 'Excel', 'Persona', 'Web', 'Website', 'CTAs', 'Blog', 'CMO', 'Optimizely', 'TED', 'UX', 'English', 'Big Data', 'Optiverse', 'Process Street', 'Marketing', 'Five Whys']\n",
      "\n",
      "\n",
      "Groupid:  1\n",
      "\n",
      " What are the use cases that we always talk about is, you know a lot of times when you have a meeting, let's say you and I are having this call and then we produce a summary it will be always good to know who should you know, what people who are would actually likely to watch this, right? Yeah, and so kind of generating this idea of who are the recommended Watchers. You're a discussion right are more importantly, you know, as we see in e-commerce lot of times right you buy this product you also You know you get this common thing that saves users who bought this are also interested in these other types of products, right? So those types of things can be applied to Enterprise intelligence as well because a lot of times T teams keep discussing the same subjects again and again, right so it's very common that in a team for example in an engineering team a particular type of databases that you know is being considered for their architecture, you know, the engineer leaves the company goes away voila six months later. A new person comes and then he comes and talks about the same subject right ether can very easily extract the idea that this discussion has happened before and actually say hey now that you're discussing this subject. You may also want to follow up on this other topic right? Are you watch this other discussion that happened a few months ago and that makes teams just work a lot efficiently and save a lot of time in going back and forth, right? So that's the beauty of this type of relationships.  Yeah, so so it actually brings it to one more notion. Right? We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right? We're in we can do recommendations Martellus. That's what you just saw. It's one of the you know extraction.  Lemons search recommendation smart alerts and so on. That's right. Yeah. Okay. That's great. So let's move on and maybe just give a quick example not going to spend a whole lot of time on this but just to give a representation of here is a real world example. Let me see if I can actually pull up the graph itself. Yeah. Yeah. Actually I have it here little bit here. Let me stop the content here and show the real graph.  I don't know if you're able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things. Right? So one is we're able to we took essentially one of the workspaces and map the interactions into a into a graph here and let's say we want to find out who the goo. Will experts are in a workspace in this can be very simple as a who's the person who's interested in a particular technology. Right? So those types of relationships can be gleaned very easily from the knowledge graph, right like so for example in this particular case when we run this query about who's who's a personal talked about Google these three people who come up myself Cullen and Karthik right where we talk a lot about Google. So these types of relationships get pulled out very easily from the knowledge. Graphite. Yep. That's just a quick example at a sample of what we do. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['X', 'Cheap', 'Site', 'Office', 'Leaving Us', 'Marketing', 'CS', 'Organization', 'People', 'Website', 'CMO', 'Engineering', 'Ground', 'Department', 'Forbes', 'Marketing', 'Tech', 'CSM', 'Success Department', 'TED', 'Brands', 'Internet', 'Blog', 'Marketing', 'CX', 'CSMs', 'Harvard Business Review', 'Board', 'Names', 'Image', 'X', 'Names', 'CTA', 'Website', 'App', 'Boston', 'Internet-connected', 'Persona', 'App Store', 'Marketing', 'Dear Readers', 'Us', 'Blog', 'Guide', 'English', 'CMO', 'Marketing', 'Post', 'Boston', 'Internet']\n",
      "\n",
      "\n",
      "Groupid:  5\n",
      "\n",
      " So moving on from the knowledge graph. Let's move on to keyphrase extraction, right? Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it's too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the  Yeah, this is this is like Channel Minds. This is also I am in we can call this as a fairly, you know, secondary generic service because we don't use keyphrase extraction stand alone. But what we do is when we say topic identification or be identified the potential important moments in the call. So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a by-product as a as a representation of those topics of the the important moments in the conversation. So so that brings us to how we do that keyphrase extraction from the from the technical standpoint. So so what we do is it's a two step process. So we're in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point. We don't have any context of what is important and what is not important. All we know is this this this diagram or the three words combination sounds as if it's an important people. So let me just put it in my queuing for the scoring in the next steps. So for that we use we use the graph right? So this is this is live. This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket. So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of  Whole context of the either the topic of the important movement. So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating. So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it. Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let's say in software engineering even though we talked at length about environment or environmental issues. It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it doesn't really need. Need to be captured as a as an important environmental issues as an important topic of the people. So we just we just so Channel Minds just drops it or even the associated key phrases.  So when you have see how it comes is when you have let's say the conversation about machine learning or or any software engineering related. So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we don't want to show them. So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them. So That's that's how it works. And then coming to come into the training part of it. What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem. Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows. So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms. And then the data sources that are available. So one of these data sets that we use for our general benchmarking is this SST wherein it captures all the sentence similarity task action. So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are. So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just fine-tune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.  We do is we take we take each candidate key face on the contacts associated with it. When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there. We just passed the context through this algorithm fine-tuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know. Text and then we correlate that with the context associated with the channel Minds at the end of this this whole process this multi step three step process. What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment. Come to those Down Citizen a little while.  So I guess it's a very good very quick kind of a real world example of this extracted from real call, right? So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right? That's right. for example pull-out top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Website', 'Blog', 'App', 'CTA', 'Web', 'Persona', 'Bullseye', 'Marketing', 'Guide', 'Excel', 'English', 'App', 'Names', 'Qualaroo', 'Web', 'Verizon', 'Reddit', 'Human', 'Bot', 'SubscriptMe', 'Shoulds', 'Drawing Board', 'Names', 'English', 'Bullseye', 'App', 'CSM', 'Jargon', 'Website', 'Marketing', 'People', 'Gut', \"I'm\", 'X', 'Tetris', 'Bullseye', 'Optiverse', 'Jargon', 'Organization', 'SMART', 'English', 'UX', 'Excel', 'CTA', 'Names', 'C', 'Google Docs', 'Ph', 'CTAs', 'Optimizely', 'CMO', 'Marketing', 'Optiverse', 'English', 'Big Data', 'Ideation', 'Fortune 500', 'Process Street', 'UX', 'Net Promoter', 'CSM', 'Drawing Board', 'Ground', 'CSRs', 'Rep', 'Shoulds', 'Board', 'Call', 'Department', 'Walkthrough']\n",
      "\n",
      "\n",
      "Groupid:  3\n",
      "\n",
      " Got it yet. So moving on I guess the next very I guess very important thing one way. One of the things that I always like to say is ether is the world's best meeting somebody engine right there. So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half. How do you Pull out what's important and what's not so maybe you can just quickly run through.  Yeah, sure. So I think I got a use case level. That's right. Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time. We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about. I'll come to the training part A little later, but we just passed it through that are. A box and then what comes out is? What is the score for a certain segment when you say segment? It's like a Texan which is actually fairly self-contained either either. It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that's currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right? So and then we score the in the scoring process is what the training aspect is. It's fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have fine-tuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time. So we really cannot rely only on those numbers. So what we do is when we do this the similarity task, you know fine-tuning of the language model. What we do is we have we we continuously create a list of summaries. That means we have set of like  Up tents of or hundreds of calls and then we manually curate what are the most important moments given the converse given the meeting given that this meeting is part of a certain Channel. And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process. We generate like lot of candidate Al Gore models that will come out for that. We come up from the initial filtration of their performance and then we pass all those candidate models. Through this validation data on this we keep updating this validation data so that we can we can safely say that if it passes the validation set because it hasn't seen those validation satyr during training if it passes the validation set we can fairly say that we can deploy that into the, you know, Ever Changing dynamics of the team. So without without much Concepts so once so, that's how we validate. So this this kind of a semi-automatic autonomous approach because we just don't want to automate it we can we can definitely automate but but the whole point Of the channel Minds to ever evolve at the same time. We should also, you know, improve our improve or adapt to the validation data that we create. So it's a semi-auto autonomous approach that we adopt the pews for the validation. And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward. We just we just passed this, you know, all the segments. So this scoring box and then what what comes out is again. It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context. And then what comes out is the score. I mean we needn't worry about the what do you call the quantifiable T of the score because you know, it's all relative. So each segment will have relative score on of course passes through certain minimal threshold. That means so what if there is a \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['X', 'Office', 'Optiverse', 'Unbounce', 'Us', 'Focus', 'Boston', 'Shoulds', 'English', 'Tetris', 'Guide', 'EQ', 'English', 'Drawing Board', 'Blog', 'Boston', 'Ground', 'Bullseye', 'Office', 'App', 'Advisory Board', 'Optiverse', 'Bullseye', 'DRI', 'Marketing', 'Consumer Insights', 'Ideation', 'SMART', 'People', 'Process Street', 'Harvard Business Reviewadmits', 'Drawing Board', 'Optiverse', 'CMO', 'European', 'SubscriptMe', 'UX', 'Engineering', 'App', 'Marketing', 'Marketing', 'CMO', 'English', 'CSM', 'CCOs', 'Fortune 500', 'Engineering', 'CSR', 'Management', 'Forbes', 'Promoter', 'NPS', 'CSAT', 'Promoter Score', 'CES', 'Wootric', 'Net Promoter Score', 'European', 'NPS Survey', 'Promoters']\n",
      "\n",
      "\n",
      "Groupid:  2\n",
      "\n",
      " Whole lot of huge HR conversation within in software engineering team so it could it could so it could still give out some important moments. But even if there is a slight mention of software engineering its prices for it higher than than the rest but it gives you a very good summary of what is happening. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Tech', 'Big Data', 'Product', 'Slackbot', 'Process Street', 'Marketing', 'Enterprise', 'CMO', 'Blog', 'Business', 'Software', 'Tech', 'Enterprise', 'Cloud', 'Internet', 'Technology', 'Software-as-a-service', 'SaaS', 'Service Hub', 'Web']\n",
      "\n",
      "\n",
      "Groupid:  16\n",
      "\n",
      " That's the whole point of the channel when so so so the inference that I said, it just scores against channel channel Pine and then and then what comes out is the bunch of segments that that post that mostly covers the whole conversation at the same time sticking to what the channel is related to ensure of a deviating from that. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Web', 'CMO', 'App', 'Millennials', 'Netflix', 'Marketing', 'Miller s Law', 'English', 'Internet', 'Enterprise']\n",
      "\n",
      "\n",
      "Groupid:  17\n",
      "\n",
      " Rot it. Okay. So that's how for example in an engineering Channel. If you're spending the five ten in the first five minutes talking about the latest IPL score Kidd game as that happen, you're able to easily filter those unimportant moments out and get right into the important moments, which is what are the rest of the team can \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Tech', 'Engineering', 'UX', 'App', 'SaaS', 'Cloud', 'Excel', 'Epic', 'Web', 'English', 'Ground', 'CSM', 'Office', 'Bullseye', 'CSRs', 'CSR', 'KPIs', 'CSMs', 'Shoulds', 'Mentee']\n",
      "\n",
      "\n",
      "Groupid:  8\n",
      "\n",
      " So here's a good example. I mean, I think we all had the solution as well. Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case. This is the engineering team, right?  Okay. No, this is a new ones as well. Right thus often times, you know, people are talking like, you know, in a team of say five six people one a call teams tend to get into discussions, you know, we're going back and forth particular subject and then you move on to some other subject in some other topic and so on right where so how do we kind of use this? How do we pull these chapters out of pull these topics out and and show them? Yeah.  So the the whole intent of this app doesn't topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about. So to keep it simple. It's just a stock affection adult done done in a very flexible way. Let's say what we do is when you are as you have shown in the example at wearing one Call we are run through all the multiple channels of then we got different sub arrays. So what it does is if there are if there is a broader, you know, the broader categories of topics that are being discussed in certain calls. So so what this some topic extraction does is it will be very very, you know Broad in its topic identification also, so so let's say a certain Paul covered software engineering in which we talked about Lambda and Learning deployment and then in the same pot. We talked about Recruitment and also the product strategy what it does is most likely could put Lambda and deployment the same topic because you know, they've been discussed together. But otherwise if in another call we talked about Lambda base deployments for a whole lot of 45 minutes. What it does is it will be able to defeat evil to slice machine learning related components into one one topic and Lambda base if there is a fair segregation it will be able To slice them. So it's like a fairly flexible topic slicing algorithm that we that we have in place a topic extraction.  Perfect. Yeah, okay. So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graph-based for this.  That's right. So that's the second part of it sighs. So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they're moving back and forth. So what we do is we just organized the meeting into the graph that that's fairly simple because you know, you have lot of this text segments and then we we have eat them as the node. And then we have a graph a graph with with all these conversations as a notes. Then what we do is to this is where the Elegance of graph algorithms + The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there. So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed. It just would be found between them but no, it should be formed between Docker or the recruitment because even though they're talked in the same conversation or even inverse cos they are actually talked right one after the other because  In the first step. We don't even form a relationship actually. So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting. So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends. Actually, there was strong association between within 10 people where in most of the people are connected with most of the others. So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out. I mean, I mean relatively so sure so that's what the topic is. So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.  So just to just to be just to be aligned with the with the flow. What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community. But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated. So we are just giving you as a different conversation. So okay, that's all the community algorithms desk aside. And then how we trial how we trial is as I said, it's more of it. It comes from the language model fine-tuning which has nothing to do with the communities. But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model. So it's a it's a combination. A nation of community algorithm parameters and the language model performance. So there's no profit business straight for training gear. Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here. What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth. And then the validator community formation.  That's something very unique as well. Right the fact that when a user is interacting with our tool. Yep at the manual tasks that they do very naturally helps reinforce our a models. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Optimizely', 'UX', 'Focus', 'Blog', 'Persona', 'Advisory Board', 'DRI', 'Process Street', 'Bullseye', 'Excel', 'Office', 'People', 'Ground', 'X', 'Happiness', \"I'm\", 'Understand', \"I'm Sorry\", 'Eat', 'Pray', 'English', 'UX', 'SQL', 'CMO', 'Europe', 'Virality', 'Optimizely', 'Netflix', 'Product', 'Boston', 'App', 'Web', 'Excel', 'UX', 'Blog', 'Integrations', 'SLAs', 'Community', 'CTA', 'Process Street', 'UX', 'Process Street', 'Excel', 'SEO', 'URLs', 'Segment', 'Integrations', 'CTA', 'Optimizely', 'Web', 'Marketing', 'Wiki', 'Blog', 'CMO', 'Ideation', 'Focus', 'Advisory Board', 'DRI', 'Fortune 500', 'YouTube', 'YouTube', 'Twitter', 'Blog', 'Facebook', 'Internet', 'Millennials', 'Social', 'Business', 'CX', 'Online']\n",
      "\n",
      "\n",
      "Groupid:  12\n",
      "\n",
      " Got it tigers have wanted to show a quick example of how this works. Right? So here's a call that happened and where there's a bunch of discussion that that happened between a group of people and we are able to very nicely kind of pull out the fact that the shunt and Arjun talked about deployment and configuration devops related subjects and then the Russians and blanket in then moved on and talked about some database subjects like Seattle and Cloud SQL exactly exactly. Things like that and then they went back Arjun venkat and three shots now talked about databases. Right? And so there's these top. This is one says even the whole subject is about about software. I guess, you know different topics are different groups of topics and the people involved in those conversations are pulled out a very elegant way I think is very cool.  That's right. So possibly it did actually you can observe one things. I hear it didn't actually slice the whole databases databases singled out because it just reaches talked about database and run something related to deployment together. So so it just it's just able to put them together aggressive. That means if we talk only about databases on the deployment, it would have done the other way like click diplomatic conversations and then they database so that's the level of flexible. Granular Kappa can get you can go from the top level where in you have totally relevant unrelated topics discussed. So they end up as a topics or to the as we go granular. We just get what you see right now make sense. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Nike', 'Olympics', 'Uber', 'Amazon', 'English', 'CTA', 'Reddit', 'Boston', 'Scout', 'Chicago', 'Germany', 'Europe', 'Customer Success', 'CDO', 'San Francisco', 'HBR', 'CA', 'Las Vegas', 'CMO', 'US-based', 'Tech', 'Cloud', 'App', 'Technology', 'Software', 'Web', 'DIY', 'Internet', 'AI', 'Netflix', 'Happiness', 'Emerson College', 'Office', 'College', 'X', 'Boston', 'Internet-connected', 'God', 'West', 'People', 'SubscriptMe', 'Europe', 'Segment', 'United States', 'Automation', 'Strategic CSMs', 'Australia', 'Unbounce', 'CMO', 'Mention', 'Web', 'Pivotal', 'Europe', 'Engineering', 'Process Street', 'Integrations', 'Support', 'Department', 'Internet', 'Germany', 'KPIs', 'Consortium for Service Innovation', 'Online', 'SMB', 'SLAs', 'KCS', 'UX', 'Khoros', 'KCS Academy', 'Web']\n",
      "\n",
      "\n",
      "Groupid:  0\n",
      "\n",
      " Okay, I guess so it kind of going into the details right the other I guess very important aspect is how we pull out meeting Primitives, I guess. So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there's a project manager in the call was actually writing down the action item or something many times these Message right. So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on. So maybe you can quickly run through how we pull out action items.  Should I just like I think when we say action items, let's let me put one point before we talk about it. So actually we are talking about action items that are being in the free-flow conversation like what we are doing right now. So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services. There's if they have seen a lot of exotic references like that. So what what what we do differently is we don't we don't need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture. What are the action items that are that it that they either bought things as an action items and then and then and then gives gives away. So for this it is it's this this whole action item algorithm or the other approach is little different from what we have been discussing earlier. So this This fairly has nothing to do with the with the language model that we discussed earlier. But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we fine-tune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not. So how do we do that is we have actually collected lot of training data for this. So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.  So again the action item as a whole is not just a model here sigh that's what I wanted to highlight here. This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I'm okay to have a lot of noise in the carrot patch. Sorry, but I don't want to miss even a single action item. That would be a likely candidate. So that's why we find you this classifier to have a highest possible. You'll recall or wherein we don't want to miss anything that has an accent. Mmm, but we are okay to have lot of that means if I capture 15 out of 15 candidate action items. I'm okay to have only four of them being the real action items, but I don't want to miss even one of the action items one of those pork perfect. So so so we have trained a language model to fine-tune such that we can be we have adopted that language model to be a binary classifier. Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent. And then and then what we do is just I'll talk I'll talk briefly about the validation of this and then we'll move on to the next steps in the pie pan. So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items. So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only 50 action items. But as a total it has actually it has identified only 70, even though the noise is list. We don't consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we didn't only candidate action items.  So the inference is fairly simple. What we do is we just we just pass the center. So that means as soon as we get this speech segments from specific sequence from the call, right? So we slice the segments into individual sentences. And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item. Say for example, if there is an action item detected by the candidate, but I didn't find any grammatically relevant subject in them. So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step. So this grammar rules and then the patterns that we have identified and anything that's not actually qualifying enough for from the pattern should be disregarded. That's why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect. So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.  Okay, cool, so I guess here's a taking a quick example, so here are three different segments, right? Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle follow-up type of action items like Doom or regression tests before we deploy let's send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right? You are very nuanced and these types of actions are actually pulled out automatically from the conversations. That is one. I guess the second is by intelligently applying our graph. We are also able to extract who it is assigned to write based on who's present in the call. And you know who's speaking and who's the recipient and so on? Yep. Yeah.  I guess once this these things are detected. They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Ideation', 'CMO', 'Unbounce', 'Fortune 500', 'Bullseye', 'UX', 'Focus', 'Ireland', 'Context', 'Consumer Insights', 'Bullseye', 'Drawing Board', 'Jargon', 'Office', 'Shoulds', 'Engineering', 'Organization', 'Ground', 'Marketing', 'X', 'Drawing Board', 'Website', 'Names', 'Walkthrough', 'App', 'Bullseye', 'Critical Path', 'Office', 'Process Street', 'Advisory Board', 'English', 'UX', 'App', 'Process Street', 'Optimizely', 'Optiverse', 'Drawing Board', 'CTA', 'Web', 'Excel', 'Office', 'Names', 'App', 'English', 'CTA', 'Boston', 'App Store', 'X', 'ATT', 'Internet-connected', 'Shoulds', 'Office', 'Names', 'Department', 'App', 'Millennials', 'Marketing', 'Blog', 'CMO', 'Drawing Board', 'Drawing Board', 'Names', 'Jargon', 'English', 'UX', 'CTA', 'Persona', 'CTAs', 'CSAT', 'Advisory Board']\n",
      "\n",
      "\n",
      "Groupid:  18\n",
      "\n",
      " Course most of it. Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on. So obviously and and I'll just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that. Right? So we're working on a technique where we can detect that the slide is being presented and then automatically pull out information from that using Standard computer vision techniques and then once the vision was a slight information is converted to text a lot of the same information can be used in terms of applying what is relevant and what's not and what's the topic and what's a keyword and so on so forth, right? So I'm just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we've done some amount of proof of Concepts and investigation into it and we plan to do more on this. In the coming weeks and months is that in a shed setting? For example, you and I are in a desktop call. It's very clear. Who's the speaker button shared setting. Let's say a bunch of people are crowded around the conference call content speakerphone or whatever, right? We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right. So we we kind of use at least a wave. We're approaching this. Is that as we speak? We are continually creating a library of our signature using standard MFC sea bass techniques and creating patterns and storing them for every speaker that we know and then as we detect changes in those patterns, we we kind of apply that to speaker dilation and then if the signature actually matches someone in our database  We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there's an unknown speaker. Maybe someone can manually tag it and so on using our user interface, right? So we don't need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Office', 'Website', 'Drawing Board', 'X', 'App', 'Advisory Board', 'Ideas Forum', 'People', \"You're\", 'Boston', 'DRI', 'Organization', 'Bullseye', 'Marketing', 'Website', 'Advisory Board', 'Board', 'Blog', 'Focus', 'Product Management', 'Focus', 'Advisory Board', 'DRI', 'Marketing', 'Organization', 'Names', 'Bullseye', 'People', 'How-to', 'Board']\n",
      "\n",
      "\n",
      "Groupid:  14\n",
      "\n",
      " So I think that that kind of concludes this discussion right thanks to incur that we've covered a lot of things. Hopefully this gives you a pretty good idea to the viewer about the different things types of things that we use in either for AI and I guess in a different discussion, I guess maybe we can go into how actually a lot of this is operationalized inside our deployments, but that's a discussion for another day. All right. Thanks. Guys, appreciate it. \n",
      "\n",
      "\n",
      " controlled Group features to Entities: \n",
      "\n",
      " ['Advisory Board', 'Engineering', 'Dear Readers', 'EQ', 'Dos', 'DRI', 'Ideation', 'Customer Success Department', 'English', 'Jargon', 'AI', 'Bots', 'Space', 'AIs', 'Optiverse', 'Bot', 'Us', 'West', 'AI Chatbots', 'Internet']\n"
     ]
    }
   ],
   "source": [
    "for groupid, groupobj in group.items():\n",
    "    seg_text = \" \".join([segobj['originalText'] for segobj in groupobj])\n",
    "    print (\"\\n\\nGroupid: \", groupid)\n",
    "    print (\"\\n\", seg_text)\n",
    "    #print (\"\\n\\n Group features to Entities: \\n\\n\", (list(map(lambda kv:kv[0], group_ent_full[groupid]))))\n",
    "    print (\"\\n\\n controlled Group features to Entities: \\n\\n\", (list(map(lambda kv:kv[0], group_ent[groupid]))))\n",
    "    #print (\"\\n\\n Group to Entities: \\n\\n\", (list(map(lambda kv:kv[0], group_ent_p1[groupid]))))\n",
    "    #print (\"\\n\\n\", group_kp[groupid])\n",
    "    #print (\"\\n\\n\", group_filtered_kps[groupid])\n",
    "    #print (\"\\n\\n\", group_kp_ent[groupid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:50:51.057847Z",
     "start_time": "2020-02-24T09:50:51.002354Z"
    }
   },
   "outputs": [],
   "source": [
    "group_ent_score = {}\n",
    "for groupid, groupobj in group.items():\n",
    "    group_ent_score[groupid] = [com_map[ent] for ent in list(map(lambda kv:kv[0], group_ent[groupid]))]\n",
    "    group_ent_score[groupid] = [ranked_com[com] for com in group_ent_score[groupid] if com in ranked_com.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:54:47.558568Z",
     "start_time": "2020-02-24T09:54:47.494718Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "rank_index = 0\n",
    "group_rank = {}\n",
    "group_rank_detail = {}\n",
    "for groupid, group_s in group_ent_score.items():\n",
    "    rank = []\n",
    "    if len(set(group_s)) == len(group_s):\n",
    "        rank = 10**6\n",
    "        group_rank_detail[groupid] = rank\n",
    "    else:\n",
    "        count_a = Counter(group_s).most_common()\n",
    "        for i, count in count_a:\n",
    "            if count>3 :\n",
    "                rank.append(i)\n",
    "        if rank == []:\n",
    "            rank = 10**6\n",
    "        group_rank_detail[groupid] = rank\n",
    "        rank = np.mean(rank)\n",
    "        \n",
    "    group_rank[groupid] = rank\n",
    "    \n",
    "group_rel_rank = {}\n",
    "for groupid, rank in sorted(group_rank.items(), key = lambda kv: kv[1]):\n",
    "    group_rel_rank[groupid] = rank_index\n",
    "    rank_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T09:54:49.704069Z",
     "start_time": "2020-02-24T09:54:49.377704Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Groupid:  6  Group Rank:  0.0    [5, 49, 5, 2, 32, 1, 5, 26, 0, 0, 66, 6, 14, 0, 0, 0, 9, 2]\n",
      "\n",
      " I think before before we get started with its II think I think I'll just give you a heads up on a thin configuration by it. So how we are placed as a team. Mlh.  Great great portion. Maybe you know, I sorry for not doing this, but maybe you can just give a quick introduction about yourself. And also maybe give a little bit of background about Ari, I think sure. Yeah, so I'm Vanka.  Then and I leave The A Team we are we are a team of 5. Ml Engineers who are who primarily work on machine learning deployments and also building the state-of-the-art machine learning models. So it's a fairly diverse team with people from really good colleges within India and outside so and from their experience perspective there were going to very poor. I mean as a team they worked on very broader set of are use cases ranging. Not just not just in the NLP. I also also like the Imaging and then the video processing and on the text, I mean the speech-to-text and and and the whole whole spectrum of the AI ecosystem. So that gives us a fairly good configuration of the team and then we have your pretty flexible in playing around with the state-of-the-art models in the Deep learning or any other machine learning space coming out then so that's where you see, you know. Big being able to quickly adapt to the industry Trends and then and then the best practices that are within within the rest of the best machine learning organizations across the globe. So having said that I think I think that should be good enough with the team and then maybe it's good time to get here. \n",
      "\n",
      "\n",
      " [('DRI', 0.8579987287521362), ('Tenet 5', 0.8564525842666626), ('Optiverse', 0.8539626598358154), ('Organization', 0.8518118858337402), ('Anthropologists', 0.8470668792724609), ('Unbounce', 0.8421927690505981), ('People', 0.8419877886772156), ('SMART', 0.8419588804244995), ('Bullseye', 0.8376176953315735), ('Advisory Board', 0.8341171145439148), ('Ireland', 0.8824574947357178), ('Boston', 0.8812214732170105), ('Tech', 0.880003035068512), ('Marketing', 0.8792174458503723), ('One Size', 0.878521203994751), ('Spanish', 0.8766318559646606), ('Europe', 0.8745943307876587), ('English', 0.8740120530128479), ('Blog', 0.8687545657157898), ('Ground', 0.8652859330177307)]\n",
      "Entity Strength:  8\n",
      "\n",
      "\n",
      "Groupid:  13  Group Rank:  0.0    [9, 0, 6, 0, 0, 10, 13, 40, 0, 21, 40, 18, 10, 52, 36, 87, 45, 12, 160, 49, 0, 0, 2, 2, 118, 6, 13, 0, 62, 66, 18, 6, 17, 28, 27]\n",
      "\n",
      " So a quick heads up on this on this slide because this puts everything I can with my cousin in one single view. So so this this just shows how how the chat the domain Minds, you know shape-shifts into the channel and by learning all the information that it gets from the conversations. So let me get just started my mind Generations on the top. So we we we use open data to to you know, generate generate a fix. A library of domain Minds as as we mentioned some of the samples here some this is ever growing we keep on adding so to this list. So these are some of the domain Minds that we actively use and then and then what we do is for each of the domain mind betrayal specific domain language model that means when we say software engineering language model, it is well-versed with the English in general obviously, and then also it knows it knows what what the software I can be better than the rest of the language model. It's a simple example would be a bug a bug in nature may be different from the bug in a software engineering model. I mean just a very very intuitive example on that. So so that way it learns it gets the ability to you know, differentiate the conversations the even if there is a conflict of the context so it should be it the domain specific language model should be able to clearly identify that that we are talking about software engineering. Nearing a not about some biology right? So that gives us the ability for The Ether AI engine in the downstream task when we talk about these topics and important moment generation. So this domain mind gets it domain language for who gets attached to the to the channel when the user says invites you to the channel. So from once we have this domain language model right as we were talking about the domain minder.  That we generate this domain mind which is nothing but the graph representation of the of the text that is of what we think are the important topics for the or topics of the domain would be organized such that the topic hierarchy within and then and then we use the domain language model to establish various unintuitive relations between these notes and notes in the in this graph. So that means if someone is talking about deployment aunt and then if in a certain channel is if they always associate deployment with let's say AWS Lambda. So this relationship is learned that when there is an aid of a deployment. This is likelihood that with the talk about a double s Lambda also, it means that they seem to be talking about a similar as similar aspect for that certain Tim. So this is kind of relationship that this combination of language model undermined men captures.  That's on the domain minds and then in the process of selection, right when the user invoice The Ether to the to the to the channel so we get to choose as we show in the in the second the second horizontal one, very marketing software engineering HR once it shows the domain language model and the domain my gets attached to that channel. So every time every time there's a new conversation that comes in the comes in the eater. Calls there would be there would be scored or they would be compared against this domain mind till we have the transformation to the channel Minds. So so this is this is fairly simple, you know, simple. What do you call it? Attaching the channel mind is fairly simple domain decidedly and then move to the channel mind. We're in this is where the actual actual, you know, a trick comes in where in How do we how do we change the domain mind such that it retains all the nuances that it knows about the domain and also tries to incrementally learn from the in size that it has all the text that it has seen over a period of time in the in the channel That is invited to so how we do that is as we discussed earlier. We continually gain the data from the data sources that we got access to and also the ether conversations and then we we actually at a high level we Score all the topics in the domain mind against the conversations and then and then we say that the the transform domain mind to the channel Tyler May to this channel as a chat Channel Minds. So we're in along with the let's say software engineering it'll also, you know, look at the priorities of the team from the recency perspective or even what what goes as it has the most important thing for the team. So that's this is where you know, you have the real learning component of Egypt  Come sit. So excellent. Yeah. Okay as we mentioned so domain Channel mine is fairly Dynamic. That means that that it can it can read all the information that it gives every every every minute or so, whereas somewhat relatively static is the channel language model which we update once we have enough information for a neural network to be fine, too. \n",
      "\n",
      "\n",
      " [('Blog', 0.915886402130127), ('Boston', 0.9157290458679199), ('Marketing', 0.9150640368461609), ('English', 0.9131342172622681), ('CMO', 0.9119144082069397), ('Internet', 0.9115487933158875), ('Us', 0.9081630706787109), ('Web', 0.906430721282959), ('Ireland', 0.90320885181427), ('Names', 0.9031479954719543), ('Web', 0.9125445485115051), ('App', 0.9040124416351318), ('Internet', 0.9027926921844482), ('CTA', 0.8989168405532837), ('Integrations', 0.8918332457542419), ('Website', 0.8907774090766907), ('Messenger', 0.8896914124488831), ('App Store', 0.8885570168495178), ('YouTube', 0.8885510563850403), ('Slackbot', 0.8882228136062622), ('Optiverse', 0.8503949046134949), ('Ireland', 0.8376367688179016), ('CMO', 0.8375588655471802), ('SubscriptMe', 0.8373944759368896), ('Consumer Insights', 0.8321577310562134), ('Big Data', 0.8317298293113708), ('Fortune 500', 0.8304541110992432), ('Marketing', 0.8299442529678345), ('Portals', 0.8263722658157349), ('Us', 0.8239214420318604), ('UX', 0.8799082040786743), ('English', 0.8768296837806702), ('Engineering', 0.8764533400535583), ('Tech', 0.8727017641067505), ('Intelligence', 0.8711303472518921), ('App', 0.8702554702758789), ('Marketing', 0.8663461208343506), ('Department', 0.8640614748001099), ('Drawing Board', 0.8622013926506042), ('Shoulds', 0.862170398235321), ('Channel', 0.7874048352241516), ('Global Navigation', 0.7872992753982544), ('Ad', 0.786249041557312), ('UX', 0.7853240966796875), ('C', 0.7853081822395325), ('Segment', 0.7834023833274841), ('Heneeds', 0.7830104231834412), ('Imessage', 0.7829460501670837), ('SERP', 0.7817186117172241), ('Party', 0.7805309295654297)]\n",
      "Entity Strength:  23\n",
      "\n",
      "\n",
      "Groupid:  11  Group Rank:  0.0    [0, 0, 6, 32, 0, 24, 155, 0, 91, 49, 0, 114, 21, 18, 52, 114, 50, 40, 36, 88, 9, 0, 20, 0, 49, 91, 6, 80]\n",
      "\n",
      " Something like, you know, if I'm part of a channel that's a very direct relationship which doesn't require a lot of intelligence which is get it right out of the station. Whereas when I say, hey, you know Karthik follow up on this production issue, you know the idea that Karthik is the person who I'm assigning this action to is something that is not so intuitive and needs to be gleaned right by first applying NLP in these types of rules then later on also being getting represented in the laugh  That's right. Yeah. So as you said the example that you gave write a card they can you follow the on this can come as part of the conversation in the free text, you know free language. So what this what this action detection service does is it just captures that and then and then preserves it once we once we try to update the computation graph, it just goes as an inside the Karthik assigned to the action item zones action item so that gets built without which is not really a factual information that we get. So having said that I'll just Deep dive into the computation graph and then The Ether graph that on the the knowledge cups component. So we're in the in the computation graph as we as mentioned earlier. It catches attaches the non factual information that can make the that is coming out of all this NLP base Downstream tasks. So say for example, if I have to give you one example of how the how the body is non-intuitive relations could be is you know, let's say let's say let's say Karthik talked about kubernetes in one of the in couple of calls  Yeah, okay. So so what why did that what what is there a engine does is if I have to take you through the flow that the topic extraction service Maps identifies that there is a topical kubernetes and then and then we know that it is spoken by Karthik. So so so what it does is it also forms a relation between Karthik as anode which is the user and then the kubernetes as a topic and then says you know here Initially then as as as as more and more conversations around kubernetes are happening. The talked about can get interest into is a is an expert in tuber natives even say that is very cool. Yeah. So how in fact we can even take consensus just because Karthik is talking we need not say that he could be an expert. But if I orthotic that means every time Karthik talks about kubernetes if you are a watch it so which which makes in which makes him kind of we approve his Don't open it is and that we captured that inside to and then reinforce that that relationship as a Karthik is an expert in kubernetes. So that's how the evaluation of you know, relationships happened within the that's one of the example that I just gave program give you an idea of how computation graph works. So along that that just on topic so you can extend the same thing two action items which itself is an AI in AI module that we're going to talk about a little so so so and also other top XO from the from the from the computation graph perspective. I think I just Brave briefly highlighted. What bought the nodes could be along with the the factual notes like the users and favorite pics. So we we just organize the topics key phrases captured as the notes on that. They just forms the contextual relationship between these nodes and also, you know using some of the conventional techniques which is form some of the ideas whether they whether certain topics for occur within the context of a meeting.  Certain topics poker when when this group is talking about these topics, but not the other group so that kind of insights that would be captured in the computation.  Yes, I eat a graph is more of a traditional representation of God. Yes, it's teams and peoples and topics and actions in these types of things become nodes and then they just become from the relationships between them. Yeah, that's like not. Okay and then I guess once you have these types of graphs. What can you do with them?  So once we have this computation graph right along so as I said, it actually captures very non, you know non trivial aspects of the conversations of The Ether conversations. In fact, we can even do better at this point. If you don't talk about anything else if direct enables us to form the you know, form the form this non-inductive relationships like talked about a certain topic or action item assigned to so now let's take forward and then use This graph that is actually being formed after all the conversations. And then what we what we do is we just put it through a graph neural networks kind or the different graph algorithms. And then what comes out is actually a lot more, you know a lot more insights that will enable us to do like very non-intuitive recommendations. So as I talked about that Karthik being expert in a in kubernetes, right so that can be formed from the from some of this. You know, I'd rather than that we use like the node embeddings what I mean by no damn wedding is when there is Karthik so we don't just we don't just see Karthik as you know a person so we also input all the information that he that actually this ether captures about about that. That means all the relationships about the topics whom he follows or whom who I mean, what are the topics that he usually discusses and then we just call that whole component and then we encode everything into into the cottage. It snowed embedded like that. All the users will have their own representation that not just captures what who they are. But but what they come as a combination represents, so once they have this as a mathematical object, like like a like a embedding what we can do is we can do lot of you know algorithms on because we are free to do all the math around it and then we can you can get for the similar users to kartik from the context of you know, the topics that that he discusses or from the context of the action items.  Just think of integrating these insights into you know, a ticket management tool like jira, right? So when when when there is a new ticket, so so this is the graph using this unintuitive relationships can actually recommend for the set of uses that this ticket can be a said because they talk about it because they are relieved from this.  That's kind of a that's what this this computation graph in a enables us when we do all these kind of note a graph based algorithms built graph based Solutions around it. \n",
      "\n",
      "\n",
      " [('CMO', 0.8930200934410095), ('English', 0.8686546683311462), ('Marketing', 0.8675892949104309), ('Unbounce', 0.8671282529830933), ('Net Promoter', 0.8655504584312439), ('Forbes', 0.8652161359786987), ('CX', 0.8591326475143433), ('HBR', 0.8586050868034363), ('Y', 0.8577815890312195), ('United States', 0.855497419834137), ('Big Data', 0.8849444389343262), ('UX', 0.881866455078125), ('Optimizely', 0.8750540614128113), ('Process Street', 0.8713739514350891), ('Google Analytics', 0.870581865310669), ('Qualaroo', 0.8703526258468628), ('Optiverse', 0.87035071849823), ('CMO', 0.8668541312217712), ('Break', 0.8663938641548157), ('Integrations', 0.8663844466209412), ('Cloud', 0.841611385345459), ('Google Analytics', 0.8294210433959961), ('Big Data', 0.8291980624198914), ('Excel', 0.8275197148323059), ('Customer Data Platform', 0.8230602145195007), ('AI', 0.8192580342292786), ('Technology', 0.818967342376709), ('Break', 0.8183454871177673), ('Optimizely', 0.8183367252349854), ('Global Navigation', 0.8171061277389526), ('Names', 0.9444670677185059), ('UX', 0.9401024580001831), ('App', 0.9342764019966125), ('CTA', 0.9340456128120422), ('Excel', 0.9301506280899048), ('Persona', 0.9266456961631775), ('Web', 0.9265641570091248), ('Website', 0.9251614212989807), ('CTAs', 0.9247507452964783), ('Blog', 0.9228137731552124), ('CMO', 0.8405853509902954), ('Optimizely', 0.8375061750411987), ('TED', 0.8329814076423645), ('UX', 0.8322024345397949), ('English', 0.8285340666770935), ('Big Data', 0.827017068862915), ('Optiverse', 0.8255177736282349), ('Process Street', 0.8241779804229736), ('Marketing', 0.8233794569969177), ('Five Whys', 0.8170724511146545)]\n",
      "Entity Strength:  17\n",
      "\n",
      "\n",
      "Groupid:  17  Group Rank:  2.0    [66, 62, 18, 83, 114, 40, 0, 2, 2, 3, 5, 2, 2, 38, 2, 27, 2]\n",
      "\n",
      " Rot it. Okay. So that's how for example in an engineering Channel. If you're spending the five ten in the first five minutes talking about the latest IPL score Kidd game as that happen, you're able to easily filter those unimportant moments out and get right into the important moments, which is what are the rest of the team can \n",
      "\n",
      "\n",
      " [('Tech', 0.8423750996589661), ('Engineering', 0.8337199091911316), ('UX', 0.8272740840911865), ('App', 0.826350748538971), ('SaaS', 0.82493656873703), ('Cloud', 0.8243107199668884), ('Excel', 0.8222519755363464), ('Epic', 0.8201937079429626), ('Web', 0.8179003000259399), ('English', 0.816921591758728), ('Ground', 0.7932121157646179), ('CSM', 0.7854987978935242), ('Office', 0.7848998308181763), ('Bullseye', 0.782995343208313), ('CSRs', 0.7784423828125), ('CSR', 0.7726778388023376), ('KPIs', 0.7716609239578247), ('CSMs', 0.7716034650802612), ('Shoulds', 0.770799458026886), ('Mentee', 0.7693803906440735)]\n",
      "Entity Strength:  5\n",
      "\n",
      "\n",
      "Groupid:  1  Group Rank:  2.3333333333333335    [1, 1, 61, 3, 1, 6, 1, 5, 1, 36, 0, 62, 2, 17, 0, 6, 66, 2, 132, 20, 16, 10, 9, 6, 24, 2, 0, 19, 21, 95, 1, 21, 52, 36, 18, 0, 65, 50, 45, 6, 136, 13, 9, 5, 0, 0, 6, 0, 10]\n",
      "\n",
      " What are the use cases that we always talk about is, you know a lot of times when you have a meeting, let's say you and I are having this call and then we produce a summary it will be always good to know who should you know, what people who are would actually likely to watch this, right? Yeah, and so kind of generating this idea of who are the recommended Watchers. You're a discussion right are more importantly, you know, as we see in e-commerce lot of times right you buy this product you also You know you get this common thing that saves users who bought this are also interested in these other types of products, right? So those types of things can be applied to Enterprise intelligence as well because a lot of times T teams keep discussing the same subjects again and again, right so it's very common that in a team for example in an engineering team a particular type of databases that you know is being considered for their architecture, you know, the engineer leaves the company goes away voila six months later. A new person comes and then he comes and talks about the same subject right ether can very easily extract the idea that this discussion has happened before and actually say hey now that you're discussing this subject. You may also want to follow up on this other topic right? Are you watch this other discussion that happened a few months ago and that makes teams just work a lot efficiently and save a lot of time in going back and forth, right? So that's the beauty of this type of relationships.  Yeah, so so it actually brings it to one more notion. Right? We can actually capture the person of the user within the graph of depending based on the interactions, you know conversations interactions and other aspects of the person and then we have a person a match that can go into this apps and insights part on the on the extreme right? We're in we can do recommendations Martellus. That's what you just saw. It's one of the you know extraction.  Lemons search recommendation smart alerts and so on. That's right. Yeah. Okay. That's great. So let's move on and maybe just give a quick example not going to spend a whole lot of time on this but just to give a representation of here is a real world example. Let me see if I can actually pull up the graph itself. Yeah. Yeah. Actually I have it here little bit here. Let me stop the content here and show the real graph.  I don't know if you're able to see this but here is an example of a real graph right where you know, there is a there is a particular insight about the bunch of different things. Right? So one is we're able to we took essentially one of the workspaces and map the interactions into a into a graph here and let's say we want to find out who the goo. Will experts are in a workspace in this can be very simple as a who's the person who's interested in a particular technology. Right? So those types of relationships can be gleaned very easily from the knowledge graph, right like so for example in this particular case when we run this query about who's who's a personal talked about Google these three people who come up myself Cullen and Karthik right where we talk a lot about Google. So these types of relationships get pulled out very easily from the knowledge. Graphite. Yep. That's just a quick example at a sample of what we do. \n",
      "\n",
      "\n",
      " [('X', 0.8444468975067139), ('Cheap', 0.8415548801422119), ('Site', 0.8385162949562073), ('Office', 0.8345085978507996), ('Leaving Us', 0.8331208229064941), ('Marketing', 0.8330835103988647), ('CS', 0.8323124647140503), ('Organization', 0.8306354880332947), ('People', 0.8276341557502747), ('Website', 0.8261405229568481), ('CMO', 0.8609455227851868), ('Engineering', 0.8524812459945679), ('Ground', 0.8514152765274048), ('Department', 0.8508412837982178), ('Forbes', 0.8430217504501343), ('Marketing', 0.8428158164024353), ('Tech', 0.842006504535675), ('CSM', 0.8409196138381958), ('Success Department', 0.8385036587715149), ('TED', 0.8376142978668213), ('Brands', 0.9029218554496765), ('Internet', 0.8998796939849854), ('Blog', 0.8953348994255066), ('Marketing', 0.8941836357116699), ('CX', 0.8891869187355042), ('CSMs', 0.8826484680175781), ('Harvard Business Review', 0.8804475665092468), ('Board', 0.8791747689247131), ('Names', 0.8776072859764099), ('Image', 0.8771405220031738), ('X', 0.8725703358650208), ('Names', 0.869438648223877), ('CTA', 0.8628993630409241), ('Website', 0.8602645397186279), ('App', 0.8515719771385193), ('Boston', 0.849063515663147), ('Internet-connected', 0.8477383852005005), ('Persona', 0.8477321863174438), ('App Store', 0.8465914726257324), ('Marketing', 0.8455061912536621), ('Dear Readers', 0.9178162813186646), ('Us', 0.9119410514831543), ('Blog', 0.9118666052818298), ('Guide', 0.9090221524238586), ('English', 0.9056465029716492), ('CMO', 0.9030870199203491), ('Marketing', 0.9019590020179749), ('Post', 0.9003318548202515), ('Boston', 0.9002949595451355), ('Internet', 0.8998941779136658)]\n",
      "Entity Strength:  45\n",
      "\n",
      "\n",
      "Groupid:  5  Group Rank:  2.3333333333333335    [36, 9, 18, 52, 40, 50, 5, 6, 5, 114, 0, 18, 21, 40, 35, 161, 2, 27, 28, 21, 0, 5, 18, 2, 36, 6, 1, 1, 1, 5, 49, 5, 0, 114, 52, 21, 116, 88, 0, 6, 49, 0, 5, 118, 91, 2, 28, 2, 2, 41, 27, 19, 14, 17]\n",
      "\n",
      " So moving on from the knowledge graph. Let's move on to keyphrase extraction, right? Yeah, Sookie physics action again just to reiterate lot of time raw transcripts are pretty useless because it's too long and too much has discussed you want to be able to quickly glance, you know glance at at at a moment in a call and say what was discussed right in this is where key phrases come into the  Yeah, this is this is like Channel Minds. This is also I am in we can call this as a fairly, you know, secondary generic service because we don't use keyphrase extraction stand alone. But what we do is when we say topic identification or be identified the potential important moments in the call. So what we do is instead of study showing the whole lot of text that you can anybody in the transcripts what we do is we identify the most relevant keep Phrases that can summarize the whole either the topic of the most important moment and then then show those key phrases as a by-product as a as a representation of those topics of the the important moments in the conversation. So so that brings us to how we do that keyphrase extraction from the from the technical standpoint. So so what we do is it's a two step process. So we're in in one in one step what we do is we extract the For the what could be what is the what is the what is the word or a or a set of forms that can be that is likely a key face which has no context of this at this point. We don't have any context of what is important and what is not important. All we know is this this this diagram or the three words combination sounds as if it's an important people. So let me just put it in my queuing for the scoring in the next steps. So for that we use we use the graph right? So this is this is live. This is not the ether graph that we talked about but this is just another algorithm to you know, to find out what are the candidate key places within the text that Wicket. So once we pass this, you know that this text or the segment text segment through the through the algorithm what we get is a set of candidates, I would say with lot of noise around it which we need to denoise in the next steps set of candidates which which kind of  Whole context of the either the topic of the important movement. So once we have this candidate key phrases what we do is we just pass it through our scoring service, which will ran all these candidates against the channel Minds because as we as we mentioned earlier the channel main caps is what is what is most relevant to the team and it is ever updating. So so any any any Downstream task could pass through this domain Channel Minds in a different in its own person in it. Own way and then gets conditioned or scored against the channel Point like so so what we do is we score each key plays against the channel Minds to get a relevance of that key phrase to the channel when let's say in software engineering even though we talked at length about environment or environmental issues. It may not be really relevant because someone just brought up that discussion briefly before the call or after the call, but still the call is ongoing so it doesn't really need. Need to be captured as a as an important environmental issues as an important topic of the people. So we just we just so Channel Minds just drops it or even the associated key phrases.  So when you have see how it comes is when you have let's say the conversation about machine learning or or any software engineering related. So there could be there could be key phrases that are not really they could be like a general language key phrases that we always use but they get they get picked up by the graph Rank and we don't want to show them. So what we do is we just we just pass it through the channel Minds on the channel Minds just says that these are these are not sounding as if they belong to this conversation so you can you can just ignore them. So That's that's how it works. And then coming to come into the training part of it. What we do is so we actually again so we use we use the same language model that we talked about for the channel minds and then we fine tune it a little bit giving it and so actually you can see language model as a fairly thick soup flexible ecosystem. Where in you just you just tell it how to do certain things it will it will it can it can certainly take it into consideration without forgetting what it already knows. So what we do is we just give it give this domain language model of the chat Channel language Model A little boost on how to actually score the key phrases from using different learning paradigms. And then the data sources that are available. So one of these data sets that we use for our general benchmarking is this SST wherein it captures all the sentence similarity task action. So it in it you have a set of sentences to say two sets of sentences and it will tell you how similar on A scale of zero to a hundred or a hundred percent how similar they are. So what we do is we take all this language models that we train for the domain and we just keep we just do a one pass learning on those sentences by giving it an ability to differentiate how two sentences or two key phrases are different so that way we just fine-tune the language model specific to the to the giving it an ability to differentiate and then once we have this ability on the language model fine tuned on this.  We do is we take we take each candidate key face on the contacts associated with it. When I say context you could be the sentence in which it is part of or it could be, you know, a part of the sentence if the sentence is been there. We just passed the context through this algorithm fine-tuned and then at the end we get a we get a feature representation and then what we do is become politically this feature representation and and then correlate it with the channel Minds which are which is again a set of related, you know. Text and then we correlate that with the context associated with the channel Minds at the end of this this whole process this multi step three step process. What we have is the score of each keep is against the how relevant is it to the channel that it is associated with and then at the end we have a set of key phrases that are finely filtered out by ignoring all the noisy key phrases from the graph Rank and then summarizing whole context of the of the top either the topic of the segment. Come to those Down Citizen a little while.  So I guess it's a very good very quick kind of a real world example of this extracted from real call, right? So where we have a particular discussion about an HR topic and then the red I guess litems are the key phrases that we extract the right in well transcript you see the full segment and then to the left in our timeline the markers you see the keywords that are extracted for that particular segment, right? That's right. for example pull-out top employer work requires substantial investment top technical universities HR talent management, and these are all things that are representative of the discussion that happened and a lot easier to look at and understand than having to read through the entire segment, I guess so \n",
      "\n",
      "\n",
      " [('Website', 0.9279940724372864), ('Blog', 0.9210701584815979), ('App', 0.9185423254966736), ('CTA', 0.9183158278465271), ('Web', 0.9176265597343445), ('Persona', 0.9171027541160583), ('Bullseye', 0.9163141250610352), ('Marketing', 0.9137030839920044), ('Guide', 0.9114995002746582), ('Excel', 0.9113408923149109), ('English', 0.84039705991745), ('App', 0.8304123878479004), ('Names', 0.8265244960784912), ('Qualaroo', 0.8216477036476135), ('Web', 0.8202614784240723), ('Verizon', 0.8183029890060425), ('Reddit', 0.8176016211509705), ('Human', 0.8174624443054199), ('Bot', 0.8169840574264526), ('SubscriptMe', 0.8164243102073669), ('Shoulds', 0.8877013921737671), ('Drawing Board', 0.8874187469482422), ('Names', 0.887310802936554), ('English', 0.8748912215232849), ('Bullseye', 0.8739155530929565), ('App', 0.8698431253433228), ('CSM', 0.868102490901947), ('Jargon', 0.8675841093063354), ('Website', 0.8674147129058838), ('Marketing', 0.8672933578491211), ('People', 0.837371289730072), ('Gut', 0.8272235989570618), (\"I'm\", 0.823190450668335), ('X', 0.8207924365997314), ('Tetris', 0.8183797597885132), ('Bullseye', 0.8127418160438538), ('Optiverse', 0.8124776482582092), ('Jargon', 0.8114970922470093), ('Organization', 0.8056585788726807), ('SMART', 0.8037814497947693), ('English', 0.8741562962532043), ('UX', 0.8735487461090088), ('Excel', 0.8705735802650452), ('CTA', 0.8698524832725525), ('Names', 0.8679738640785217), ('C', 0.8635128736495972), ('Google Docs', 0.854725182056427), ('Ph', 0.8512507677078247), ('CTAs', 0.8508195877075195), ('Optimizely', 0.8507091403007507), ('CMO', 0.865900456905365), ('Marketing', 0.8651872277259827), ('Optiverse', 0.8632102608680725), ('English', 0.8573082685470581), ('Big Data', 0.8563127517700195), ('Ideation', 0.855911374092102), ('Fortune 500', 0.8551043272018433), ('Process Street', 0.8543336987495422), ('UX', 0.8499174118041992), ('Net Promoter', 0.8493012189865112), ('CSM', 0.9075537919998169), ('Drawing Board', 0.9061723351478577), ('Ground', 0.9039984941482544), ('CSRs', 0.9037513136863708), ('Rep', 0.8987776637077332), ('Shoulds', 0.8952693939208984), ('Board', 0.8951702117919922), ('Call', 0.8950574994087219), ('Department', 0.894299328327179), ('Walkthrough', 0.8941856026649475)]\n",
      "Entity Strength:  48\n",
      "\n",
      "\n",
      "Groupid:  3  Group Rank:  2.3333333333333335    [1, 3, 49, 32, 13, 0, 27, 0, 5, 149, 0, 28, 9, 0, 2, 5, 3, 18, 26, 49, 5, 5, 6, 2, 5, 1, 91, 28, 49, 0, 0, 2, 62, 18, 6, 6, 0, 0, 2, 118, 62, 2, 0, 0]\n",
      "\n",
      " Got it yet. So moving on I guess the next very I guess very important thing one way. One of the things that I always like to say is ether is the world's best meeting somebody engine right there. So we do a phenomenally good job of understanding not just pulling out random things based on frequency of words are freaking of topics, but on really utilizing how we apply Channel Minds to an overall discussion meeting of an hour hour and a half. How do you Pull out what's important and what's not so maybe you can just quickly run through.  Yeah, sure. So I think I got a use case level. That's right. Actually we what we do is one when as the conversation happens, so and we have this speech to text transcripts coming out of the transcript or service what we really continuously in the real time. We continue is core those conversations as if you know and then we pass it through this channel minds and then the whole process that that that we just talked about. I'll come to the training part A little later, but we just passed it through that are. A box and then what comes out is? What is the score for a certain segment when you say segment? It's like a Texan which is actually fairly self-contained either either. It just captures that you know a text that is Captain between fairly small pauses between or even when there is a speaker change and then we started the text and then we just score against the channel Minds to get up the relevant score of that segment to the conversation that's currently happening and So to the as a whole to the team and for the channel That that it is that in which that call is happen, right? So and then we score the in the scoring process is what the training aspect is. It's fairly similar to how we actually trained key phrase scoring service wherein we have a we have a sentence similarity tasks on which feed on which we have fine-tuned the associated channel channel model and the channel minds and then what we do is we we actually really one important aspect of it is the validation because because what what we get out of the model, I mean the the numbers the validation number that the model used could be fairly could be deceiving a time. So we really cannot rely only on those numbers. So what we do is when we do this the similarity task, you know fine-tuning of the language model. What we do is we have we we continuously create a list of summaries. That means we have set of like  Up tents of or hundreds of calls and then we manually curate what are the most important moments given the converse given the meeting given that this meeting is part of a certain Channel. And then what we do is the we just we just have a huge Corpus on which we have to validate so during the cleaning process. We generate like lot of candidate Al Gore models that will come out for that. We come up from the initial filtration of their performance and then we pass all those candidate models. Through this validation data on this we keep updating this validation data so that we can we can safely say that if it passes the validation set because it hasn't seen those validation satyr during training if it passes the validation set we can fairly say that we can deploy that into the, you know, Ever Changing dynamics of the team. So without without much Concepts so once so, that's how we validate. So this this kind of a semi-automatic autonomous approach because we just don't want to automate it we can we can definitely automate but but the whole point Of the channel Minds to ever evolve at the same time. We should also, you know, improve our improve or adapt to the validation data that we create. So it's a semi-auto autonomous approach that we adopt the pews for the validation. And then once we have this scoring scoring algorithm in place, the inference is pretty straightforward. We just we just passed this, you know, all the segments. So this scoring box and then what what comes out is again. It is as I said, it is conditioned when I say we are actually scoring something what it means is that it is code against the channel minds or the relevance of the of the meat clicking on the relevant context. And then what comes out is the score. I mean we needn't worry about the what do you call the quantifiable T of the score because you know, it's all relative. So each segment will have relative score on of course passes through certain minimal threshold. That means so what if there is a \n",
      "\n",
      "\n",
      " [('X', 0.8521145582199097), ('Office', 0.8507457375526428), ('Optiverse', 0.8500800132751465), ('Unbounce', 0.8397456407546997), ('Us', 0.8389908671379089), ('Focus', 0.8386772274971008), ('Boston', 0.8381655216217041), ('Shoulds', 0.8347660303115845), ('English', 0.8347060680389404), ('Tetris', 0.8335797786712646), ('Guide', 0.8973963260650635), ('EQ', 0.89228755235672), ('English', 0.8915868997573853), ('Drawing Board', 0.8862215280532837), ('Blog', 0.8839288353919983), ('Boston', 0.8814070224761963), ('Ground', 0.880659818649292), ('Bullseye', 0.8805200457572937), ('Office', 0.8784106373786926), ('App', 0.8768287301063538), ('Advisory Board', 0.9008370637893677), ('Optiverse', 0.8955349326133728), ('Bullseye', 0.8861441016197205), ('DRI', 0.884236752986908), ('Marketing', 0.8786467909812927), ('Consumer Insights', 0.8782865405082703), ('Ideation', 0.8782195448875427), ('SMART', 0.876173734664917), ('People', 0.8745229244232178), ('Process Street', 0.8744139075279236), ('Harvard Business Reviewadmits', 0.8420341610908508), ('Drawing Board', 0.8280323147773743), ('Optiverse', 0.8279260396957397), ('CMO', 0.8270974159240723), ('European', 0.8260413408279419), ('SubscriptMe', 0.8244612812995911), ('UX', 0.8231055736541748), ('Engineering', 0.8210349678993225), ('App', 0.8202386498451233), ('Marketing', 0.8181838393211365), ('Marketing', 0.8735119104385376), ('CMO', 0.8695573806762695), ('English', 0.8650693893432617), ('CSM', 0.8635470271110535), ('CCOs', 0.8624991774559021), ('Fortune 500', 0.8609618544578552), ('Engineering', 0.85862135887146), ('CSR', 0.8580591678619385), ('Management', 0.8546918034553528), ('Forbes', 0.8536732792854309), ('Promoter', 0.900749146938324), ('NPS', 0.8994738459587097), ('CSAT', 0.8849605321884155), ('Promoter Score', 0.8779964447021484), ('CES', 0.8736079335212708), ('Wootric', 0.8730118274688721), ('Net Promoter Score', 0.8632284998893738), ('European', 0.860262930393219), ('NPS Survey', 0.8598705530166626), ('Promoters', 0.8568510413169861)]\n",
      "Entity Strength:  94\n",
      "\n",
      "\n",
      "Groupid:  18  Group Rank:  5.0    [3, 36, 28, 1, 18, 26, 1, 29, 0, 5, 5, 5, 6, 36, 26, 19, 9, 38, 26, 5, 6, 5, 21, 5, 1, 19]\n",
      "\n",
      " Course most of it. Maybe we can just spend a couple of minutes really quick on a couple of minor other things that we are working on. So obviously and and I'll just talk to this right we working on a vision pipeline as well because obviously a lot of business meetings involve slide presentations and all that. Right? So we're working on a technique where we can detect that the slide is being presented and then automatically pull out information from that using Standard computer vision techniques and then once the vision was a slight information is converted to text a lot of the same information can be used in terms of applying what is relevant and what's not and what's the topic and what's a keyword and so on so forth, right? So I'm just going to skip past this and then similarly the other kind of very interesting subject that we you know, we are looking into we've done some amount of proof of Concepts and investigation into it and we plan to do more on this. In the coming weeks and months is that in a shed setting? For example, you and I are in a desktop call. It's very clear. Who's the speaker button shared setting. Let's say a bunch of people are crowded around the conference call content speakerphone or whatever, right? We want to be able to detect that there are two different speakers are three different speakers and then also be able to associate a particular speaker with a particular, you know, identify the speaker I guess right. So we we kind of use at least a wave. We're approaching this. Is that as we speak? We are continually creating a library of our signature using standard MFC sea bass techniques and creating patterns and storing them for every speaker that we know and then as we detect changes in those patterns, we we kind of apply that to speaker dilation and then if the signature actually matches someone in our database  We actually identify and tag that tag that speaker and then later on we plan to expose this in other ways as well where if there's an unknown speaker. Maybe someone can manually tag it and so on using our user interface, right? So we don't need to go into two sub detail around this, but I just want to kind of quickly call out that these are a couple of things that were also \n",
      "\n",
      "\n",
      " [('Office', 0.8894124031066895), ('Website', 0.8710196018218994), ('Drawing Board', 0.8696662783622742), ('X', 0.8685906529426575), ('App', 0.8652856349945068), ('Advisory Board', 0.8642154932022095), ('Ideas Forum', 0.8591955304145813), ('People', 0.8585387468338013), (\"You're\", 0.8574733734130859), ('Boston', 0.8563052415847778), ('DRI', 0.8663024306297302), ('Organization', 0.8616289496421814), ('Bullseye', 0.8615428805351257), ('Marketing', 0.8536105751991272), ('Website', 0.8505840301513672), ('Advisory Board', 0.848917543888092), ('Board', 0.8487134575843811), ('Blog', 0.8468117713928223), ('Focus', 0.8464668393135071), ('Product Management', 0.8436440229415894), ('Focus', 0.8164420127868652), ('Advisory Board', 0.8118034601211548), ('DRI', 0.8106339573860168), ('Marketing', 0.8035947680473328), ('Organization', 0.8009629845619202), ('Names', 0.8009599447250366), ('Bullseye', 0.7994822263717651), ('People', 0.7980661392211914), ('How-to', 0.7945858240127563), ('Board', 0.794145941734314)]\n",
      "Entity Strength:  6\n",
      "\n",
      "\n",
      "Groupid:  8  Group Rank:  6.6    [9, 50, 26, 5, 91, 5, 114, 3, 1, 2, 1, 8, 1, 7, 7, 7, 7, 0, 0, 0, 2, 0, 18, 40, 114, 9, 162, 52, 91, 91, 114, 52, 40, 6, 9, 0, 5, 26, 5, 118, 12, 12, 12, 9, 12, 10, 39, 12, 24, 43]\n",
      "\n",
      " So here's a good example. I mean, I think we all had the solution as well. Yeah where you know when you pass meeting the taxes on a variety of different subjects and once we take it through our meeting summary engine is somebody that is extracted pulls out all the relevant topics related to that theme in this case. This is the engineering team, right?  Okay. No, this is a new ones as well. Right thus often times, you know, people are talking like, you know, in a team of say five six people one a call teams tend to get into discussions, you know, we're going back and forth particular subject and then you move on to some other subject in some other topic and so on right where so how do we kind of use this? How do we pull these chapters out of pull these topics out and and show them? Yeah.  So the the whole intent of this app doesn't topic extraction is to be as you rightly said to be able to slice the whole meeting into certain, you know chunk such that each turn would represent a fairly independent context in which it is on what it is talking about. So to keep it simple. It's just a stock affection adult done done in a very flexible way. Let's say what we do is when you are as you have shown in the example at wearing one Call we are run through all the multiple channels of then we got different sub arrays. So what it does is if there are if there is a broader, you know, the broader categories of topics that are being discussed in certain calls. So so what this some topic extraction does is it will be very very, you know Broad in its topic identification also, so so let's say a certain Paul covered software engineering in which we talked about Lambda and Learning deployment and then in the same pot. We talked about Recruitment and also the product strategy what it does is most likely could put Lambda and deployment the same topic because you know, they've been discussed together. But otherwise if in another call we talked about Lambda base deployments for a whole lot of 45 minutes. What it does is it will be able to defeat evil to slice machine learning related components into one one topic and Lambda base if there is a fair segregation it will be able To slice them. So it's like a fairly flexible topic slicing algorithm that we that we have in place a topic extraction.  Perfect. Yeah, okay. So so maybe like for a say in this case when cat like for example, because because use ether graph for this as we do we use any like standardized Community detection algorithms that are graph-based for this.  That's right. So that's the second part of it sighs. So where in you know as I said the whole the whole the whole meeting is actually can be organized very well elegantly into a meeting structure the graph such as what it gives us is abuse as the abilities of being able to form the interactions between topics as if you know, they're moving back and forth. So what we do is we just organized the meeting into the graph that that's fairly simple because you know, you have lot of this text segments and then we we have eat them as the node. And then we have a graph a graph with with all these conversations as a notes. Then what we do is to this is where the Elegance of graph algorithms + The Machine learning the language model combination comes we start forming the relationships between this text segments using the language model associated with the with the channel That is there. So what we have at the end of this step is we have kind of a graph in which the relationships are formed based on the And pixelated so that means in any Docker lated sentences would be actually formed. It just would be found between them but no, it should be formed between Docker or the recruitment because even though they're talked in the same conversation or even inverse cos they are actually talked right one after the other because  In the first step. We don't even form a relationship actually. So so once we have this relationships that the graph that is where in you have certain lationship Saint and then certain relationships proud what we do is we form communities within within within the whole meeting. So that means eventually what it boils down is a community is nothing but to keep it simple if it does nothing but a identifying a very concentrated relationships that means there are set of you know, Call it as a close close group within your friends. Actually, there was strong association between within 10 people where in most of the people are connected with most of the others. So so what it means is that if you bring the same notion into the communities Community something where in you have a very strong association between the text that is that is protects notes that are part of so what so when we see such communities what it says is it talks about something that is that is highly relevant within but not so relevant when Go out. I mean, I mean relatively so sure so that's what the topic is. So once we once we form this communities, which we go with various Community algorithms like Logan and Cody composition as an end product, we have like a candidate communities that can talk with that that we can fairly confidently say that this community talks about certain topics.  So just to just to be just to be aligned with the with the flow. What happens is if you talk about Docker, you know, once in the start of the conversation and to also towards the end of the meeting what we do is we can be as we as a community formation the community forming algorithm can can safely put them into a single Community. But as a most person what we do is just to do the slicing properly, which is separate them and then highlight that these were talked about You know darker but they are actually separated. So we are just giving you as a different conversation. So okay, that's all the community algorithms desk aside. And then how we trial how we trial is as I said, it's more of it. It comes from the language model fine-tuning which has nothing to do with the communities. But we we we actually played around with this community algorithms and then we have come up with a set of parameters that works the best for the associated language model. So it's a it's a combination. A nation of community algorithm parameters and the language model performance. So there's no profit business straight for training gear. Its if it comes as a bits and pieces and then how will validate as I said, I think as we always go with the with the topics that we manually created like like we can even use the manual markers that the users created as you have created multiple topics here. What we do is if you create a Copic Marker we use that as our validation as a human validation so sub truth. And then the validator community formation.  That's something very unique as well. Right the fact that when a user is interacting with our tool. Yep at the manual tasks that they do very naturally helps reinforce our a models. \n",
      "\n",
      "\n",
      " [('Optimizely', 0.8865281343460083), ('UX', 0.8861829042434692), ('Focus', 0.8807106614112854), ('Blog', 0.8780390024185181), ('Persona', 0.8754066824913025), ('Advisory Board', 0.8749224543571472), ('DRI', 0.8742961287498474), ('Process Street', 0.8735588192939758), ('Bullseye', 0.8734809756278992), ('Excel', 0.8730385899543762), ('Office', 0.8452422618865967), ('People', 0.8442126512527466), ('Ground', 0.8419119119644165), ('X', 0.8404679298400879), ('Happiness', 0.8331174254417419), (\"I'm\", 0.822981059551239), ('Understand', 0.8221073150634766), (\"I'm Sorry\", 0.8208609223365784), ('Eat', 0.8189231157302856), ('Pray', 0.8189231157302856), ('English', 0.8324474096298218), ('UX', 0.827976644039154), ('SQL', 0.827225387096405), ('CMO', 0.8269177079200745), ('Europe', 0.8204130530357361), ('Virality', 0.8186464905738831), ('Optimizely', 0.8181986212730408), ('Netflix', 0.8138759732246399), ('Product', 0.8133794665336609), ('Boston', 0.8112995624542236), ('App', 0.9242804646492004), ('Web', 0.9183065891265869), ('Excel', 0.9160361289978027), ('UX', 0.9153321981430054), ('Blog', 0.9139968752861023), ('Integrations', 0.906089723110199), ('SLAs', 0.9048339128494263), ('Community', 0.903961181640625), ('CTA', 0.9033246636390686), ('Process Street', 0.9032422304153442), ('UX', 0.8837143778800964), ('Process Street', 0.8777768611907959), ('Excel', 0.8765685558319092), ('SEO', 0.8730705976486206), ('URLs', 0.8726377487182617), ('Segment', 0.8720718622207642), ('Integrations', 0.872055172920227), ('CTA', 0.8711768984794617), ('Optimizely', 0.8694759607315063), ('Web', 0.8691587448120117), ('Marketing', 0.8965680003166199), ('Wiki', 0.8919492363929749), ('Blog', 0.8849208950996399), ('CMO', 0.8812758326530457), ('Ideation', 0.879523754119873), ('Focus', 0.8790587186813354), ('Advisory Board', 0.8785430192947388), ('DRI', 0.87762051820755), ('Fortune 500', 0.8759632706642151), ('YouTube', 0.8735490441322327), ('YouTube', 0.8673886656761169), ('Twitter', 0.8665163516998291), ('Blog', 0.8645423054695129), ('Facebook', 0.8642048239707947), ('Internet', 0.8625221848487854), ('Millennials', 0.8595477342605591), ('Social', 0.8550724983215332), ('Business', 0.8535048961639404), ('CX', 0.8532423973083496), ('Online', 0.8520111441612244)]\n",
      "Entity Strength:  68\n",
      "\n",
      "\n",
      "Groupid:  10  Group Rank:  8.0    [0, 1, 0, 0, 6, 60, 55, 63, 39, 18, 17, 10, 40, 12, 6, 9, 24, 43, 6, 5, 36, 9, 2, 26, 1, 0, 28, 18, 6, 0, 5, 21, 0, 5, 50, 27, 18, 2, 52, 50, 6, 18, 21, 28, 36, 0, 114]\n",
      "\n",
      " Got it. Excellent. Just want to call out that when we say Channel. It is just in the context of a team, right like essentially Channel equals a team. So for whatever reason let a ether is, you know taken out of the slack context the team could actually be something else right? Like for example, that could be a virtual team. Let's say on either some other channel at home or some other let's say Google Hangouts for example, right if there is a concept of a Group in Google Hangout and that prisons attain the same level of attachment of mines and ending can also happen there.  Cool. Alright, so that is actually a good segue to actually before we do that. I wanted to kind of call out Channel minds and action. All right, so there is there is here is a kind of an example. Let me actually take this down and show it in a real slack conversation. So let's give me a second here. Let me pull up Slack.  Or the real test. Yeah, so this is actually example where for example there are three channels here software engineering marketing and HR right in and what we did essentially was take the same discussion or meeting through three different channels. Right? So basically at have attached three different mines to the same conversation and see what type of summaries are produced, right? So for example, in this case, We to use a standardized data data set I guess where which talks about a bunch of different topics about HR related topics marketing related topics and software related topics. And then when you pass it through when you have that meeting in the context of a software engineering mind, the discussion summarizes The Ether summarizes the discussion pulls out topics related to software for example things about database continuously ICD kubernetes Etc. Our infrastructure that Kafka whereas when you talk about when you run the same meeting through the marketing channel, you know, it pulls out things about, you know, digital marketing. You know, what platforms how do you do outbound reaching so on and so forth, right and similarly when you do it on top of HR, it talks about HR related topics, which could be about employment about investment in a chart budgets a gas is a little thing of the talks about Out HR leaders and productivity employee benefits and so on and so forth, right? So this is a great example of how you know the same exact same meeting can produce three different summaries based on the channel mind that has been associated with it or the context that's associated with it. Right. So again, let me go back switch to my presentation here.  it's fair play shows how how the channel man is able to differentiate based on the Mind attached to it during the  All right, so it's a great segue into you know, so when we talked about Channel Minds you brought up this notion of the dynamic portion. That is the chat that happens within the context is all captured in a graph and we talked about ether graph earlier as well as something that's a very unique way of representing the intelligence of the Insight that's happening in the context of teams and and the organization in a graph format and using this in a variety of different ways. So I guess you know We put this kind of block diagram together to kind of outline what the pipeline looks like. So half of this kind of leads into how the graph is actually formed and then the other half talks about how it is. Maybe you can just walk us through this a little bit. \n",
      "\n",
      "\n",
      " [('Big Data', 0.8031137585639954), ('Boston', 0.8012310266494751), ('X', 0.8010876774787903), ('UX', 0.8007030487060547), ('CMO', 0.8003175854682922), ('Ireland', 0.7979102730751038), ('Marketing', 0.7963574528694153), ('Know Everything', 0.7947643399238586), ('West', 0.7932979464530945), ('Context', 0.7921647429466248), ('Millennials', 0.8879448771476746), ('App', 0.882733941078186), ('Department', 0.8821914196014404), ('Internet', 0.8820953369140625), ('Web', 0.8790464997291565), ('YouTube', 0.8767250180244446), ('Marketing', 0.8766237497329712), ('Blog', 0.872149646282196), ('CX', 0.8705443143844604), ('Online', 0.8705270886421204), ('Marketing', 0.8964856863021851), ('Bullseye', 0.8964300155639648), ('Website', 0.8905770778656006), ('Blog', 0.8894803524017334), ('Ground', 0.8893267512321472), ('Advisory Board', 0.8892119526863098), ('X', 0.8886367082595825), ('Boston', 0.885514497756958), ('Drawing Board', 0.8843850493431091), ('App', 0.8784587383270264), ('Marketing', 0.8672614097595215), ('English', 0.864218533039093), ('Bullseye', 0.8590870499610901), ('Names', 0.8570284247398376), ('CMO', 0.8544408679008484), ('Ideation', 0.8541040420532227), ('Persona', 0.8519999384880066), ('Shoulds', 0.8516972064971924), ('App', 0.8510884046554565), ('CSM', 0.8509861826896667), ('UX', 0.8919443488121033), ('CTA', 0.8805519938468933), ('Persona', 0.8780274391174316), ('Marketing', 0.8745267987251282), ('App', 0.8716139197349548), ('Names', 0.8710638284683228), ('Drawing Board', 0.8669472336769104), ('Website', 0.866020143032074), ('CMO', 0.8635892271995544), ('Excel', 0.8635499477386475)]\n",
      "Entity Strength:  40\n",
      "\n",
      "\n",
      "Groupid:  7  Group Rank:  9.0    [5, 1, 2, 0, 5, 0, 49, 49, 18, 91, 149, 40, 6, 0, 52, 123, 124, 149, 2, 40, 42, 24, 5, 5, 50, 6, 40, 1, 3, 1, 2, 2, 1, 5, 1, 6, 5, 6, 10, 39, 9, 0, 40, 63, 18, 5, 24, 2, 49, 1, 0, 30, 2, 1, 0, 5, 11, 40, 42, 12, 52, 116, 18]\n",
      "\n",
      " You're able to see this, right? Yes. Okay, excellent. Okay, so when could I thought it'll be good for us to do a little bit have a dis little bit of a discussion on just the I stack with ether. I did a separate overview of our platform. So I'm assuming that a lot of the folks who are seeing. This will be gone through that that call and got up. Bit of an understanding about what ether is over. All right, but just to reiterate if you look at ethers a I stack there are a few things that that we want to kind of highlight, right? The first is its concept of Channel or team mines where whereby we are representing the team context both the static aspects of it. In other words. Let's say there's a team that is working on software engineering or databases or Our devops in general, right? So there is a static idea that they're working on these types of car idea of domains or subjects for example, and then there is a dynamic issue aspects of it, which is what conversations are they having recently. Is that a production issue that is being addressed right now it is that a particular type of database are talking about or you know, a particular aspect of their software engineering stack that they're talking about. So there's a dime static and dynamic aspects. So the first time Idea is idea about Channel or team Minds. We're in ether. We try to clean the idea or the context of what the team is all about and is able to represent that as a model and use that model to extract important information provide context to the interactions and the analytics that we provide. So that's what we call as Chandler team wins. The second is  Alveta graph where all you know, every Enterprise has a lot of interactions that happen and in general there is this idea that in ether we try to capture all these interactions and and and take a lot of these unstructured interactions and per system is structured format so that we can gain insights and understanding from them. So one quick way of kind of talking about the the graph would be that it's a graph of who said what when and in what context and then we use it both in both computationally and then also for insights, right? So that's either graph the second. I think the the next one is this idea of you know, how once a call is over. Let's say you're in a meeting and you're and the team is having a discussion and in an hour's call you're talking about a bunch of different topics. How do you kind of I understand and and extract what is important in this column not and you know it all flooded with so much information. And so how do you extract what is Meaningful and what's not so that is another aspect of how either ether zai gets applied to just the meetings their interactions, right? The next is the idea of topic detection using communities, which is a you know, when you there's a there's a meeting that's happening. Being and you're having a discussion, maybe it's a group meeting and you're talking about five different topics in the call or you're talking about, you know, you're doing a two people are talking about one particular subject. But then in that subject are touching on five or six different things how ether automatically extracts these chapters are these topics and makes them available either on the time line around the summaries, right? So that's the other aspect that  Should talk about next is the keyphrase extraction, which is sometimes it's hard to blame the entire discussion. So a lot of products in the market today just do a blind transcription of the conversations and sometimes these transcript tration, you know, nobody reads them. First of all, the weight is very hard to read and understand so sometimes it's important to just be able to pull out. What are the key phrases right in a conversational setting. Segments so that you can quickly in a snare at-a-glance come to know what is what is being discussed and so on and so forth. So, how do we do that? So that's a very interesting aspect of ethers a sec as well and last but not the least. We also automatically extract key meeting Primitives right action items and decisions who conversations and be able to you know offer them as such Stood markers in addition to we do this manually anyway, right? So in any tell me call you can kind of click on the plus sign and create a lot of these manually as a call is going on, but we also have a way by which we are automatically detecting these and how we present them and you know how we use them is another aspect of ethers a a stack that I talk will discuss. So, of course, there's also a couple of other things that we are working on. On the background and we'll touch upon those as well. So my intent in this call is is to kind of have this discussion with you where we can maybe dig deep dive a little bit on each of these aspects. Sure. Okay, so, all right. So before we get started a lot of times question comes up when we talk about ether how we do our speech-to-text, right? We just to kind of lay this out is we don't  Build a speech to text technology ourselves because a lot of it one one reason for it is that it there's a lot of vendors in the market place that do this well, and we also believe that this is going to be like a table Stakes thing that will be driven down costs will go down over a period of time. So we actually focus on we assume that that is actually a speech-to-text engine that's in the background either with our with our partners lot of times. When we go to market with our partners, they actually like to use their own speech-to-text technology for integrating. And so the way we built ether was to have a lot of flexibility in being able to associate any speech-to-text engine to with our for our purposes. So the way we do this is, you know showcases app, which is ether meet. We integrate with the close partner called Deep Graham to provide. Custom models, which are caused optimized and continually trained and we use that and then we of course use a couple of other providers as well. We've integrated with AWS transcribe. We also have the ability to integrate with other models. We use Google Cloud speech with their video model for somebody processing because it provides the best kind of quality. It's also the most expensive. So in inside ethers engine, we have this ability where we do a first pass shall we say with the with the with the with a different provider? Let's say deepground as a first pass. And then once we determine that these are the key segments in the call that really needs to be, you know presented to the user and we want to be able to you know, use the best quality possible-- So we  Can pause with Google's speeches video model. So that's the other kind of unique aspect about how we've built it inside our architecture. So the pipeline is very flexible. We have the ability to associate speech-to-text Provider by workspace by and we have the ability to do it in two passes one passes. So on and so forth, so it's very very flexible. Right? So anyway, that is a little quick note on. How we do speech to text so yeah, okay. So now we're getting to the interesting portion. So let's talk about Channel Minds right little deeper into Channel Minds. Maybe you can just give us a quick overview of what channel Minds is. I mean, I guess we've already discussed what channel minds are but more about how we build it and how we use it and so on. \n",
      "\n",
      "\n",
      " [('UX', 0.8291013240814209), ('Big Data', 0.8237020373344421), ('Bullseye', 0.8221886157989502), ('Optimizely', 0.8211629986763), ('X', 0.8183799386024475), ('SubscriptMe', 0.8151213526725769), ('Ireland', 0.813481867313385), ('Ideation', 0.8125318288803101), ('CMO', 0.8111626505851746), ('Optiverse', 0.8072134852409363), ('Integrations', 0.9299280643463135), ('Optiverse', 0.9273160099983215), ('App', 0.9243090748786926), ('Process Street', 0.9222777485847473), ('EQ', 0.9160574674606323), ('Web', 0.915080189704895), ('Marketing', 0.9120669960975647), ('English', 0.9115464687347412), ('HubSpot', 0.9101243615150452), ('CTA', 0.9092522859573364), ('Ecommerce', 0.8459134697914124), ('DIY', 0.8451635241508484), ('Ebay', 0.8362982273101807), ('EQ', 0.8313150405883789), ('Enterprise', 0.8312608003616333), ('EMEA', 0.829647958278656), ('Web', 0.8248825073242188), ('GDPR', 0.8241505026817322), ('HubSpot', 0.8235468864440918), ('CX', 0.8232442736625671), ('Bullseye', 0.8431841135025024), ('Ideation', 0.8416927456855774), ('Persona', 0.8338701128959656), ('Focus', 0.8337638974189758), ('Marketing', 0.8311174511909485), ('Optimizely', 0.8303059339523315), ('Big Data', 0.8287159204483032), ('Intelligence', 0.8281126022338867), ('Web', 0.8268564939498901), ('Integrations', 0.8254216909408569), ('People', 0.8734489679336548), ('Office', 0.8557013869285583), ('X', 0.852082371711731), ('PM', 0.8502210378646851), ('CSM', 0.8470554351806641), ('CS', 0.846581220626831), ('Organization', 0.8442817330360413), (\"I'm\", 0.84013432264328), ('Marketing', 0.8383634090423584), ('Bullseye', 0.8377681374549866), ('Marketing', 0.9217402935028076), ('Internet', 0.9183439016342163), ('Millennials', 0.9162915349006653), ('Blog', 0.9130864143371582), ('CMO', 0.909116804599762), ('Web', 0.9084144234657288), ('Context', 0.9074700474739075), ('App', 0.9074299335479736), ('Ideation', 0.9058310985565186), ('CX', 0.9045268297195435), ('SubscriptMe', 0.8708462119102478), ('Optiverse', 0.8692731261253357), ('People', 0.868412435054779), ('Ireland', 0.8590529561042786), ('Close and Buffer', 0.850755512714386), ('Ground', 0.8491731286048889), ('X', 0.8474748134613037), ('CMO', 0.8472242951393127), ('DRI', 0.8470139503479004), ('Mall', 0.8468886613845825), ('Web', 0.8983266949653625), ('Google Analytics', 0.8965771198272705), ('Google', 0.891055703163147), ('YouTube', 0.8905109167098999), ('CTA', 0.889487624168396), ('Google Docs', 0.884786069393158), ('Google Forms', 0.8804128766059875), ('Integrations', 0.8801637887954712), ('App', 0.8794205188751221), ('Personas', 0.8773500323295593)]\n",
      "Entity Strength:  80\n",
      "\n",
      "\n",
      "Groupid:  0  Group Rank:  12.5    [5, 0, 32, 118, 5, 0, 63, 2, 5, 28, 3, 27, 62, 5, 2, 6, 1, 28, 36, 21, 18, 5, 3, 91, 26, 0, 18, 91, 49, 28, 52, 40, 114, 3, 21, 18, 0, 52, 0, 45, 1, 65, 27, 3, 21, 17, 18, 39, 6, 9, 0, 28, 28, 21, 0, 52, 50, 88, 26]\n",
      "\n",
      " Okay, I guess so it kind of going into the details right the other I guess very important aspect is how we pull out meeting Primitives, I guess. So for example one very important thing that happens when teams discuss in projects and so on so forth is action items right A lot of times these things just get created and unless there's a project manager in the call was actually writing down the action item or something many times these Message right. So one of the things that we try to do with either is to try to pull out these meeting mating Primitives right action items decisions and so on. So maybe you can quickly run through how we pull out action items.  Should I just like I think when we say action items, let's let me put one point before we talk about it. So actually we are talking about action items that are being in the free-flow conversation like what we are doing right now. So which means that we need not explicitly mention some way upward for the action item to be captured which most of this, you know, transcription services or sorry Services. There's if they have seen a lot of exotic references like that. So what what what we do differently is we don't we don't need need ether use it explicitly mention any anything to for either to be able to record the action item so you can you just talk as usual in the conversation so it can it can it can certainly capture. What are the action items that are that it that they either bought things as an action items and then and then and then gives gives away. So for this it is it's this this whole action item algorithm or the other approach is little different from what we have been discussing earlier. So this This fairly has nothing to do with the with the language model that we discussed earlier. But what we do is we use we use a generic language model that means a language model that has actually fairly good understanding of that language in general English language in general then what we did is we fine-tune that language model to to set up action item to build an action item classifier, which will take as an Put the sentence and then outputs whether the sentence contains an actual likelihood actually likely action candidate or not. So how do we do that is we have actually collected lot of training data for this. So this is kind of a exercise that we did for us to be able to train this model and then we create a lot of free flow conversation sentences where in there are action items and then obviously the counter examples where there are action items then we built a binary classifier for this.  So again the action item as a whole is not just a model here sigh that's what I wanted to highlight here. This is again a funneling process wherein in the first step, we actually captured the likelihood of an action item under the prime motor of this step is not to miss any candidate action items at an expense of I'm okay to have a lot of noise in the carrot patch. Sorry, but I don't want to miss even a single action item. That would be a likely candidate. So that's why we find you this classifier to have a highest possible. You'll recall or wherein we don't want to miss anything that has an accent. Mmm, but we are okay to have lot of that means if I capture 15 out of 15 candidate action items. I'm okay to have only four of them being the real action items, but I don't want to miss even one of the action items one of those pork perfect. So so so we have trained a language model to fine-tune such that we can be we have adopted that language model to be a binary classifier. Aaron it just says it just gives us a you know, spectrum of likelihood of being an action item from zero to a hundred percent. And then and then what we do is just I'll talk I'll talk briefly about the validation of this and then we'll move on to the next steps in the pie pan. So how we evaluate this binary classifier is again the same thing we manually tag it and then we just look at we just look at the coverage in terms of the if I if we give you like a thousand sentences out of which hundred are action items. So we validate this model for the coverage that means the model that covers almost all the hundred action items at an expense of you know, having a hundred born on action items would be preferred more than a model that actually captured only 50 action items. But as a total it has actually it has identified only 70, even though the noise is list. We don't consider that because as we as I said in the further funneling process, we will be able to funnel it further so that we didn't only candidate action items.  So the inference is fairly simple. What we do is we just we just pass the center. So that means as soon as we get this speech segments from specific sequence from the call, right? So we slice the segments into individual sentences. And then we just pass each of the segment sentence through this action item detection, which will give you will give us a score likely its core of being an action item for each of the sentence and then if it hits the threshold any any sentence that has individual would be passed through the You know a post processing wherein we have we have learned a lot of grammar rules and then and then the pattern mining algorithms which which actually gives the this action item detection ability to find out the pattern that can form as a grammar pattern that can be called as an action item. Say for example, if there is an action item detected by the candidate, but I didn't find any grammatically relevant subject in them. So we would prefer to drop that instead of trying to Label it as an action item in the post processing which just passed this candidates that we have identified in the previous step. So this grammar rules and then the patterns that we have identified and anything that's not actually qualifying enough for from the pattern should be disregarded. That's why we are okay to have lot of noise because the noise will get filtered out in this step and then eventually will end up having only, you know, very small and we are very we are very aggressive in this aspect. So it will filter out Lord of all the noise and then be the end up having fairly good set of concentrated set of action.  Okay, cool, so I guess here's a taking a quick example, so here are three different segments, right? Yeah where we pull out our additional segments is run through real calls where we are not only able to pull out, you know subtle follow-up type of action items like Doom or regression tests before we deploy let's send migration of these are not like typical traditional action items where someone says amen I can go, you know take an action to do this or something very specific right? You are very nuanced and these types of actions are actually pulled out automatically from the conversations. That is one. I guess the second is by intelligently applying our graph. We are also able to extract who it is assigned to write based on who's present in the call. And you know who's speaking and who's the recipient and so on? Yep. Yeah.  I guess once this these things are detected. They can always be, you know made into permanent, you know actions are moved to a different action item tracking problem solved. \n",
      "\n",
      "\n",
      " [('Ideation', 0.765069842338562), ('CMO', 0.7483407258987427), ('Unbounce', 0.7449039220809937), ('Fortune 500', 0.7433973550796509), ('Bullseye', 0.7433745861053467), ('UX', 0.740432620048523), ('Focus', 0.7396297454833984), ('Ireland', 0.7393150925636292), ('Context', 0.7367204427719116), ('Consumer Insights', 0.7360078692436218), ('Bullseye', 0.8805509805679321), ('Drawing Board', 0.877170979976654), ('Jargon', 0.8739297389984131), ('Office', 0.8711191415786743), ('Shoulds', 0.8703793883323669), ('Engineering', 0.869957685470581), ('Organization', 0.869903028011322), ('Ground', 0.8688973188400269), ('Marketing', 0.8683835864067078), ('X', 0.8663198351860046), ('Drawing Board', 0.8748369216918945), ('Website', 0.8716297745704651), ('Names', 0.8604047298431396), ('Walkthrough', 0.8591823577880859), ('App', 0.8584676384925842), ('Bullseye', 0.857875645160675), ('Critical Path', 0.8577914834022522), ('Office', 0.8543069362640381), ('Process Street', 0.8541402816772461), ('Advisory Board', 0.8533865213394165), ('English', 0.8874150514602661), ('UX', 0.8845890760421753), ('App', 0.8834583759307861), ('Process Street', 0.879460334777832), ('Optimizely', 0.8787890672683716), ('Optiverse', 0.8784651756286621), ('Drawing Board', 0.878211498260498), ('CTA', 0.8749266862869263), ('Web', 0.8723000884056091), ('Excel', 0.8721087574958801), ('Office', 0.8970903158187866), ('Names', 0.8776116967201233), ('App', 0.8697522282600403), ('English', 0.8661995530128479), ('CTA', 0.8654735088348389), ('Boston', 0.8644669651985168), ('App Store', 0.8628479242324829), ('X', 0.8587638139724731), ('ATT', 0.8586220145225525), ('Internet-connected', 0.8581982851028442), ('Shoulds', 0.9136378765106201), ('Office', 0.9120502471923828), ('Names', 0.9105311036109924), ('Department', 0.9098330736160278), ('App', 0.9093198776245117), ('Millennials', 0.9084745049476624), ('Marketing', 0.9081728458404541), ('Blog', 0.9081685543060303), ('CMO', 0.9044349789619446), ('Drawing Board', 0.903395414352417), ('Drawing Board', 0.8762008547782898), ('Names', 0.8649501204490662), ('Jargon', 0.8645336031913757), ('English', 0.8636378645896912), ('UX', 0.8630536794662476), ('CTA', 0.8604984879493713), ('Persona', 0.8587393164634705), ('CTAs', 0.8578182458877563), ('CSAT', 0.8569740056991577), ('Advisory Board', 0.856082022190094)]\n",
      "Entity Strength:  34\n",
      "\n",
      "\n",
      "Groupid:  12  Group Rank:  13.0    [25, 0, 52, 35, 0, 4, 0, 0, 0, 2, 2, 0, 0, 55, 66, 18, 40, 124, 10, 8, 59, 3, 1, 1, 0, 65, 1, 55, 1, 2, 0, 0, 70, 70, 0, 32, 0, 40, 0, 62, 91, 17, 10, 0, 38, 38, 43, 158, 162, 38, 38, 40]\n",
      "\n",
      " Got it tigers have wanted to show a quick example of how this works. Right? So here's a call that happened and where there's a bunch of discussion that that happened between a group of people and we are able to very nicely kind of pull out the fact that the shunt and Arjun talked about deployment and configuration devops related subjects and then the Russians and blanket in then moved on and talked about some database subjects like Seattle and Cloud SQL exactly exactly. Things like that and then they went back Arjun venkat and three shots now talked about databases. Right? And so there's these top. This is one says even the whole subject is about about software. I guess, you know different topics are different groups of topics and the people involved in those conversations are pulled out a very elegant way I think is very cool.  That's right. So possibly it did actually you can observe one things. I hear it didn't actually slice the whole databases databases singled out because it just reaches talked about database and run something related to deployment together. So so it just it's just able to put them together aggressive. That means if we talk only about databases on the deployment, it would have done the other way like click diplomatic conversations and then they database so that's the level of flexible. Granular Kappa can get you can go from the top level where in you have totally relevant unrelated topics discussed. So they end up as a topics or to the as we go granular. We just get what you see right now make sense. \n",
      "\n",
      "\n",
      " [('Nike', 0.7994637489318848), ('Olympics', 0.7923092246055603), ('Uber', 0.791509747505188), ('Amazon', 0.7899616360664368), ('English', 0.7860202789306641), ('CTA', 0.7792900204658508), ('Reddit', 0.7786486744880676), ('Boston', 0.7785419225692749), ('Scout', 0.7769589424133301), ('Chicago', 0.7768175005912781), ('Germany', 0.7368026971817017), ('Europe', 0.7358860373497009), ('Customer Success', 0.7336157560348511), ('CDO', 0.7276662588119507), ('San Francisco', 0.7270495295524597), ('HBR', 0.7267357707023621), ('CA', 0.7245065569877625), ('Las Vegas', 0.7221003770828247), ('CMO', 0.7187958359718323), ('US-based', 0.7184132933616638), ('Tech', 0.8345057964324951), ('Cloud', 0.8339487314224243), ('App', 0.8265824913978577), ('Technology', 0.8222839832305908), ('Software', 0.8216351866722107), ('Web', 0.8207979202270508), ('DIY', 0.8191925883293152), ('Internet', 0.8191421627998352), ('AI', 0.8183603286743164), ('Netflix', 0.8172134757041931), ('Happiness', 0.8003770709037781), ('Emerson College', 0.7993713021278381), ('Office', 0.7900288105010986), ('College', 0.7823485136032104), ('X', 0.7799007892608643), ('Boston', 0.7757052183151245), ('Internet-connected', 0.7756810188293457), ('God', 0.7750101685523987), ('West', 0.7689472436904907), ('People', 0.7683176398277283), ('SubscriptMe', 0.7599054574966431), ('Europe', 0.7561550736427307), ('Segment', 0.7516394853591919), ('United States', 0.74983811378479), ('Automation', 0.7472074627876282), ('Strategic CSMs', 0.7472074627876282), ('Australia', 0.7439712285995483), ('Unbounce', 0.7434771060943604), ('CMO', 0.7432565689086914), ('Mention', 0.7416374683380127), ('Web', 0.8138808012008667), ('Pivotal', 0.8110108971595764), ('Europe', 0.8100658059120178), ('Engineering', 0.8094393014907837), ('Process Street', 0.8086919188499451), ('Integrations', 0.8020338416099548), ('Support', 0.7983574867248535), ('Department', 0.7974530458450317), ('Internet', 0.7959104776382446), ('Germany', 0.7948274612426758), ('KPIs', 0.8656764030456543), ('Consortium for Service Innovation', 0.8535484075546265), ('Online', 0.8505268692970276), ('SMB', 0.8480179905891418), ('SLAs', 0.847277820110321), ('KCS', 0.8468254208564758), ('UX', 0.8466910123825073), ('Khoros', 0.8460966944694519), ('KCS Academy', 0.845500111579895), ('Web', 0.8447374701499939)]\n",
      "Entity Strength:  72\n",
      "\n",
      "\n",
      "Groupid:  9  Group Rank:  14.8    [66, 18, 40, 10, 5, 6, 5, 49, 5, 9, 0, 10, 0, 2, 40, 18, 0, 52, 21, 147, 49, 114, 36, 40, 18, 91, 0, 0, 0, 0, 6, 0, 0, 0, 66, 49, 2, 118, 2, 0, 91, 32, 28, 18, 5, 2, 17, 155, 41, 27, 0, 49, 5, 6, 26, 5, 5, 24]\n",
      "\n",
      " Yeah, sure son. So I think with the headset that you gave about the channel Minds I meant that that's like a thousand feet free of what channel mine does. I mean to keep it simple. It's just captures the Ever Changing dynamics of the team fixing to the static part as he is like if a team talks about software engineering so it know the The Ether AI knows that it talks about software engineering and at the same time, it just gets it up, you know get adapted to what what is happening within the team over a period. Out of time. So I'll just walk you through I'll give you a tip. I'll give you what goes behind the scenes for the for the channel Minds technically and then we'll come to how it works across all the a downstream applications. So Channel Minds as we as we have architecture. These is a combination of a language model plus plus a representation of the the whole text that we glean out of The Ether. Ether calls or any other data sources that we get access to and though that takes being represented as a graph or a bar or in certain cases a different data structure that will give us access in a in a priority of the hierarchical fashion. So coming to coming to the language model aspect of it which is which is like the which is like the base that acts as a trans. I mean the feature extractor for the whole process wherein we train we train the neural net. Work language model on on the on the source of data that we choose to so having now that we are coming to the data source what we how we started with this channel Minds is to we have a pre-loaded, you know library of domain mines be call. So we stopped with such which talks about each domain when talks about certain certain. You know, what you call the horizontal. It's a wonder my mind is software engineering the other one could be markers.  And I mean it could be sale. So that's ever-growing. That means we keep on adding the the new domains to our domain Library. So when when a user's invites ether to the channel, we give the option to choose one of these domain Minds so that so that as soon as the user chooses determine what we do is we attach the associated language model to that channel. So which means I mean, Coming to the language model aspect of it. We use the neural neural network based language models like birth GPT which are which have recently proven to be the state of the art and have beaten most of the benchmarks in the nice language processing tasks and even and also that and also they have worked really well for us or in last one year wherein we have seen significant gains compared to what you're doing earlier, right? So that's on the language model. Coming to coming to fine-tune that means how do we adapt that language model to the channel in which it is chosen is when when we choose when the user chooses a certain domain mind what it does is it gives a baseline, you know information to The Ether about the channel on what it is talking about. I'm going to show some examples in the next slides, but but to give you what it means, let's say if the user chooses software engineering and then it Gives an idea of what this team would be working on and talking about so that the just handles the cold start problem effectively and then as the conversations built up in the channel and as the number of you know ether calls that happen in the channel what what it does is it gives the software engineering intact and it just updates its it just updates the priorities based on what is being talked. Let's say the if the engineering teams talks about production.  In past two weeks or three weeks. What it does is ETA automatically understands that any discussion related relating to production deployment should be prioritized and the mind for that comes and that decision capabilities for the AI engine comes from this channel Minds because it continuously sees what what is happening in the in the channel and then organelles the data coming to organizing the data. I'll talk about the Mind generation in the next slide, but How do we fine-tune I'll just continue on that. So so along with fine tuning this language model wherein you know, software engineering language model would be fine-tuned for the to adapt to the changes in the team that team conversations and parities and then that gives that gives The Ether ability to you know, flexibly understand what what is being talked about along with that. Once we once we have the language model, that's fine tune. We also adjust Oddities of the channel of based on the data structure that I just briefly mentioned which is the graph so that the the graph would be re readjusted with the priorities on the topics that are being discussed will be given a lot more importance than the than the than the others that are not mentioned yet. So so that's where the channel mind comes into play when we say mine. The model is the actual neural network model and the mind is is the graph data structure that organizes the information. Action that is coming, you know to The Ether AI engine if you're it.  I guess one way to talk about that would be there's a static component. Then there's a dynamic component. Right? Like the static component is the model which is pre of trained and you know publicly available data and then there is the dynamic component which is the constant interactions and new updates that is happening between the teams and all of this gets mapped into a graph and brings it gives it the element of what is recency and so on. Yep.  That makes it so this we're doing this way. What we have done is we have had to hack the data hunger of the more of the neural network language models. I because we get the data in a very small increments for the machine learning model. So but we have their own to to keep the to accumulate the data as much as possible and then after the language model which is which is what you said, it's a static component. And then in the meantime, we don't want to lose the information that we have. Have gathered which is recency and other aspects of it. So we have introduced this channel men that takes care of this the more recent aspects under the changing dynamics that we're giving a giving the AI engine an additional boost of recency without actually changing the static component very frequently. So that's kind of the engineering that we did for the channel Minds got it. Yeah, we can move to the next slide. Okay? Yeah.  Oh, yeah, I'm sorry. I I think I think we can on the validation component. What we do is actually there are there is a two-stage validation one is one is the language model that we that we have two other people which is well, which is actually fine-tune various tasks. When I say a task it is it is like asking asking the language model to predict whether whether a sentence is at whether a sentence whether two sentences are continuous. Or not that gives the ability for the language wanted to you know, learn to understand the language and also the nuances of the conversations. So so we have we have fairly statistical validation approaches to validate this auxiliary tasks. So we follow them but whereas for the downstream tasks we had to formulate our own ways of validation, which we are going to talk a little bit later and then coming to validating the mind which is not which is the graph representation. So what we do for validating the graphics, Action of the mind is we have a pre annotated human annotated, you know topics of the graph communities that are formed of line and then we compare them with the the new channel Minds that get generated every time there is a new data and then and then we keep updating this Benchmark get also so that it keeps up with the with updates on the in the as an offline tasks. So that way we just we just semi-automated this validation process so that the human invention so good so that the ml engineer not really look into all the mines that are getting generated except with some exceptions where they see a lot difference in the validation numbers that they are.  So I guess this is kind of a very it's a bit of an eye chart, but I guess it breaks down the whole Channel mind life cycle into our domain mind gets generated. How is that attach to the with a slack Channel and then how it how the channel Minds self-generated right? Yeah. That's right. \n",
      "\n",
      "\n",
      " [('AI', 0.8957430720329285), ('Tech', 0.884926438331604), ('Bot', 0.8828574419021606), ('App', 0.8798366189002991), ('AIs', 0.8795092701911926), ('Web', 0.8778156042098999), ('Internet', 0.8776935935020447), ('Big Data', 0.8765066862106323), ('Intelligence', 0.8744208216667175), ('Bots', 0.8738565444946289), ('Guide', 0.8751075267791748), ('Marketing', 0.8748559951782227), ('Bullseye', 0.8741480708122253), ('Optiverse', 0.8740790486335754), ('Ideation', 0.8733741641044617), ('Blog', 0.8720807433128357), ('Ireland', 0.8693550825119019), ('Internet', 0.8692362308502197), ('English', 0.8691471219062805), ('Ground', 0.8685117363929749), ('UX', 0.9173087477684021), ('Intelligence', 0.9089534282684326), ('Web', 0.9010381102561951), ('App', 0.8982516527175903), ('Google Analytics', 0.8933254480361938), ('English', 0.8920284509658813), ('CTA', 0.8911533355712891), ('Integrations', 0.8887187242507935), ('Names', 0.8872830867767334), ('Silos', 0.8858633637428284), ('UX', 0.9010086059570312), ('Optiverse', 0.8948288559913635), ('Excel', 0.8942286968231201), ('Website', 0.8935214877128601), ('Google Analytics', 0.8929012417793274), ('Web', 0.8922476768493652), ('Integrations', 0.892128586769104), ('Optimizely', 0.89084792137146), ('App', 0.8896918296813965), ('Process Street', 0.8890053033828735), ('English', 0.8860250115394592), ('Europe', 0.8717013597488403), ('Spanish', 0.8696184754371643), ('Ireland', 0.8648335337638855), ('Marketing', 0.8647093772888184), ('CMO', 0.8634768128395081), ('UX', 0.8605292439460754), ('United States', 0.8595753312110901), ('Boston', 0.8593772649765015), ('Tech', 0.858089029788971), ('Optiverse', 0.8364450931549072), ('SubscriptMe', 0.8193013668060303), ('Fortune 500', 0.8168341517448425), ('Optimizely', 0.8161985278129578), ('Consumer Insights', 0.8119272589683533), ('CMO', 0.8103551864624023), ('UX', 0.8063986897468567), ('Process Street', 0.8061273097991943), ('Ios', 0.8032858371734619), ('Unbounce', 0.8026610016822815), ('Drawing Board', 0.8760517239570618), ('App', 0.8675190210342407), ('Enps', 0.8638049364089966), ('Bullseye', 0.8623266220092773), ('CSM', 0.8612891435623169), ('Department', 0.859304666519165), ('Y', 0.8581214547157288), ('Harvard Business Reviewadmits', 0.8570106625556946), ('Rep', 0.8563065528869629), ('Shoulds', 0.8549137115478516), ('UX', 0.9000819325447083), ('CMO', 0.8964895009994507), ('Optiverse', 0.8945325613021851), ('Ideation', 0.8924315571784973), ('Marketing', 0.8915629386901855), ('Advisory Board', 0.891308069229126), ('Bullseye', 0.8879643082618713), ('Optimizely', 0.8873081207275391), ('DRI', 0.8871737718582153), ('CX', 0.8808483481407166)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Strength:  81\n",
      "\n",
      "\n",
      "Groupid:  4  Group Rank:  1000000.0    [63, 2, 136, 57, 5, 2, 63, 5, 24, 9, 6, 136]\n",
      "\n",
      " That's good thinking. Yeah, maybe we can now just dive deeper. Yeah. Sure. What I'll do is I'll ask you speak. I'll also create markers here. So you can kind of get a feel for it as we go on but wine to get started and let's dive in and talk a little bit about Channel Minds. \n",
      "\n",
      "\n",
      " [('Context', 0.7631879448890686), ('Customer Service Department', 0.7435215711593628), ('Dear Readers', 0.7423357367515564), ('Train', 0.7378783822059631), ('All-in', 0.7376763820648193), ('Miss', 0.7365875840187073), ('Ideation', 0.7353467345237732), ('Customer Success', 0.7296316027641296), ('Marketing and Sales Department', 0.7284175753593445), ('World Series', 0.7282301187515259), ('Context', 0.8193531036376953), ('Ideation', 0.8177052736282349), ('RD', 0.8110833168029785), ('CX', 0.809455931186676), ('Blog', 0.8041525483131409), ('Marketing', 0.803684413433075), ('Post', 0.8010188341140747), ('Dear Readers', 0.8009410500526428), ('Intelligence', 0.7985624074935913), ('UX', 0.795724630355835)]\n",
      "Entity Strength:  1\n",
      "\n",
      "\n",
      "Groupid:  15  Group Rank:  1000000    [155, 6, 147, 38, 88, 26, 0, 116, 52, 18, 21, 40, 91]\n",
      "\n",
      " Check just like so eat a graph serves multiple purposes one one being as we talked about it. It just enables the the whole whole concept of Channel Minds with the with properly, you know, organizing the data that is available as a factual information and also and also being able to as a whole ether graph is actually having two components that that that that I'll come but where I'll start is, you know, it's about its ability. T to be able to glean the data from multiple data sources that reminds same like like how we if we get if we on the left we can see that there are there multiple sources from where we can actually get the data from so one on the interaction. So one thing that that we that we have intermediate is this pixelization of the actual conversations that happens in any of this audio audio video providers and then everything else would just go as is every other data. A source would just go as is to the general feeling.  Yeah, I guess it really we're operating in the text domain. So if it is a speech data we converted to text first if there is Vision data, let's say the slides that need to be processed. I guess we can extract textual information from slides and make them available in the text domain but things like messaging or let's say interactions between people and tools such as jira Google Docs or whatever which are already available in text can be used as  So in that help engine, it's like a it's like a pre fabricating the data such so that it can go into the graph structure. So these are two different components coming together. So we're in in the NIT engine what if primarily do if I have to do one, you know, if I have to put it in one sentence, we actually feature is it that means that we use all this language models that we use and then under the and all the graph based neural network architectures and then we make the text it to into a feature. So presentation so that we can be can you know use it for all sorts of computations. So we again use the associated domain language model of the custom custom Channel language model for for feature is Amal the text that picket and then and then we also bring in the notion of Miles here. That means these two are like in Hindi interdependent. So the mines enables the graphs at the same time ether graphs in Britain enables The Ether Minds to get to get you know, you know in Superior. In terms of its relevance relevance and other aspects caps in other aspects. So we also use them how we use them is you know to when we have a mind attached we use that mind and the associated model to feature is the text that we get out of the sources that we have. And also these these these NLP components would in turn enable us to do this, you know down sin tasks like keep Extraction team generation topic extraction on the insights from those Services would actually be fed into the up swim. You know, Knowledge Graph like the factual graph on The Ether graph. I'll talk about the difference just just in a minute, but but so what we are trying to say here is along with the actual factual information like who spoke what or or what are the you know who attended the meeting so these Services enable The Ether  Crew captured non intuitive insights like you know who spoke about certain topic or who I mean on whom is the action air protection because each of these Services itself isn't are a model or an AI Pipeline on its own that will enable The Ether graph to capture very counter intuitive insights of or non-obvious inside sort of the god Apollo. \n",
      "\n",
      "\n",
      " [('Y', 0.8711736798286438), ('UX', 0.8707343935966492), ('Big Data', 0.8695164322853088), ('Marketing', 0.8681412935256958), ('RD', 0.8677297234535217), ('Silos', 0.8674389719963074), ('KPIs', 0.8642018437385559), ('CTAs', 0.8641079068183899), ('Advisory Board', 0.8618856072425842), ('CMO', 0.8612263202667236), ('Google Docs', 0.8785038590431213), ('UX', 0.8675914406776428), ('CTA', 0.8614992499351501), ('App', 0.8553648591041565), ('URL', 0.8527927398681641), ('Names', 0.8520305752754211), ('Web', 0.8498403429985046), ('Process Street', 0.8495172262191772), ('Google Analytics', 0.8485347032546997), ('Integrations', 0.8483002781867981)]\n",
      "Entity Strength:  0\n",
      "\n",
      "\n",
      "Groupid:  2  Group Rank:  1000000.0    [66, 2, 160, 91, 6, 0, 9, 66, 10, 83, 90, 40]\n",
      "\n",
      " Whole lot of huge HR conversation within in software engineering team so it could it could so it could still give out some important moments. But even if there is a slight mention of software engineering its prices for it higher than than the rest but it gives you a very good summary of what is happening. \n",
      "\n",
      "\n",
      " [('Tech', 0.7818225622177124), ('Big Data', 0.7792581915855408), ('Product', 0.7703279852867126), ('Slackbot', 0.7681232690811157), ('Process Street', 0.7672199010848999), ('Marketing', 0.7663552165031433), ('Enterprise', 0.7661934494972229), ('CMO', 0.7642073631286621), ('Blog', 0.7629368305206299), ('Business', 0.7625303268432617), ('Software', 0.856117308139801), ('Tech', 0.8474297523498535), ('Enterprise', 0.8447601795196533), ('Cloud', 0.8398479223251343), ('Internet', 0.8386359810829163), ('Technology', 0.8371122479438782), ('Software-as-a-service', 0.8348283171653748), ('SaaS', 0.8323598504066467), ('Service Hub', 0.8284659385681152), ('Web', 0.8260042667388916)]\n",
      "Entity Strength:  0\n",
      "\n",
      "\n",
      "Groupid:  16  Group Rank:  1000000.0    [40, 0, 18, 39, 6, 0, 10]\n",
      "\n",
      " That's the whole point of the channel when so so so the inference that I said, it just scores against channel channel Pine and then and then what comes out is the bunch of segments that that post that mostly covers the whole conversation at the same time sticking to what the channel is related to ensure of a deviating from that. \n",
      "\n",
      "\n",
      " [('Web', 0.8013731241226196), ('CMO', 0.795066237449646), ('App', 0.7938687205314636), ('Millennials', 0.7902507781982422), ('Netflix', 0.7896831631660461), ('Marketing', 0.7862280607223511), ('Miller s Law', 0.785722017288208), ('English', 0.7857065796852112), ('Internet', 0.7842481732368469), ('Enterprise', 0.7841796278953552)]\n",
      "Entity Strength:  0\n",
      "\n",
      "\n",
      "Groupid:  14  Group Rank:  1000000.0    [26, 62, 136, 149, 2, 5, 5, 0, 49, 13, 55, 10]\n",
      "\n",
      " So I think that that kind of concludes this discussion right thanks to incur that we've covered a lot of things. Hopefully this gives you a pretty good idea to the viewer about the different things types of things that we use in either for AI and I guess in a different discussion, I guess maybe we can go into how actually a lot of this is operationalized inside our deployments, but that's a discussion for another day. All right. Thanks. Guys, appreciate it. \n",
      "\n",
      "\n",
      " [('Advisory Board', 0.7897066473960876), ('Engineering', 0.7842303514480591), ('Dear Readers', 0.7830218076705933), ('EQ', 0.7769239544868469), ('Dos', 0.7762166261672974), ('DRI', 0.7752262353897095), ('Ideation', 0.7749552726745605), ('Customer Success Department', 0.7742832899093628), ('English', 0.7701422572135925), ('Jargon', 0.7656992673873901), ('AI', 0.8348387479782104), ('Bots', 0.8206455707550049), ('Space', 0.8047945499420166), ('AIs', 0.8019129633903503), ('Optiverse', 0.7978114485740662), ('Bot', 0.7968381643295288), ('Us', 0.7942375540733337), ('West', 0.7927476763725281), ('AI Chatbots', 0.7920059561729431), ('Internet', 0.7916587591171265)]\n",
      "Entity Strength:  4\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for groupid, rank in group_rel_rank.items():\n",
    "    seg_text = \" \".join([segobj['originalText'] for segobj in group[groupid]])\n",
    "    print (\"\\n\\nGroupid: \", groupid, \" Group Rank: \", group_rank[groupid], \"  \", group_ent_score[groupid])\n",
    "    #print (\"\\n\\nGroup rank: \", index)\n",
    "    index+=1\n",
    "    print (\"\\n\", seg_text)\n",
    "    print (\"\\n\\n\", group_ent[groupid])\n",
    "    \n",
    "    repeated_com = {}\n",
    "    for ent in list(map(lambda kv: kv[0], group_ent[groupid])):\n",
    "        if com_map[ent] not in repeated_com.keys():\n",
    "            repeated_com[com_map[ent]] = [ent]\n",
    "        else:\n",
    "            repeated_com[com_map[ent]].append(ent)\n",
    "    \n",
    "    subgraph_ent = []\n",
    "    for com, ent in repeated_com.items():\n",
    "        if len(ent)>1:\n",
    "            subgraph_ent.extend(ent)\n",
    "\n",
    "    strength = kp_entity_graph.subgraph(subgraph_ent).number_of_edges()\n",
    "    print (\"Entity Strength: \", strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:52:21.424676Z",
     "start_time": "2020-02-11T06:52:21.363698Z"
    }
   },
   "outputs": [],
   "source": [
    "group_ent_temp = {}\n",
    "for groupid, ent_list in group_ent.items():\n",
    "    group_ent_temp[groupid] = list(map(lambda kv: kv[0], ent_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:52:21.562330Z",
     "start_time": "2020-02-11T06:52:21.428225Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupid:  5 \n",
      "\n",
      "\n",
      "[('Console', 1), ('Appsettings', 1), ('Connect', 1), ('Hello World', 1), ('Server', 1), ('Apps', 1), ('Json', 1), ('Browser', 1), ('Ide', 1), ('Root', 1)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:  0 \n",
      "\n",
      "\n",
      "[('Hello World', 1), ('Post', 1), ('Youtube', 1), ('Console', 1), ('Docs', 1), ('Btw', 1), ('Apps', 1), ('Browser', 1), ('Internet', 1), ('Three', 1)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:  3 \n",
      "\n",
      "\n",
      "[('Fyi', 1), ('Console', 1), ('Body', 1), ('Hello World', 1), ('Title', 1), ('User', 1), ('Main', 1), ('Btw', 1), ('Connect', 1), ('Person', 1)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:  1 \n",
      "\n",
      "\n",
      "[('Hello World', 1), ('Main', 1), ('Json', 1), ('Console', 1), ('Start', 1), ('Live-server', 1), ('Repaint', 1), ('Fyi', 1), ('Copy', 1), ('Simple', 1)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:  2 \n",
      "\n",
      "\n",
      "[('Main', 1), ('Iso', 1), ('Connect', 1), ('Pdf', 1), ('Url', 1), ('Json', 1), ('Path', 1), ('Device', 1), ('Uid', 1), ('Sqlcmd', 1)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groupid:  4 \n",
      "\n",
      "\n",
      "[('Assembly', 1), ('Start', 1), ('Main', 1), ('Json_encode', 1), ('Hello World', 1), ('Debugger', 1), ('Names', 1), ('Goto', 1), ('Code', 1), ('Txt', 1)]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for groupid, ent_list in group_ent_temp.items():\n",
    "    print (\"Groupid: \", groupid,\"\\n\\n\")\n",
    "    print (Counter(ent_list).most_common())\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T08:07:39.762499Z",
     "start_time": "2020-02-03T08:07:39.673949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bonzai', 6)\n",
      "('Web', 6)\n",
      "('Ether', 5)\n",
      "('Love', 4)\n",
      "('Code', 3)\n",
      "('Janus', 3)\n",
      "('Gypsy', 3)\n",
      "('Cto', 3)\n",
      "('Ui', 3)\n",
      "('Design', 3)\n",
      "('Easy', 2)\n",
      "('Elseif', 2)\n",
      "('Dom', 2)\n",
      "('Json', 2)\n",
      "('App', 2)\n",
      "('Apps', 2)\n",
      "('Sdk', 2)\n",
      "('Link', 2)\n",
      "('Javascript', 2)\n",
      "('Tech', 2)\n",
      "('Xyz', 2)\n",
      "('People', 2)\n",
      "('Apple', 2)\n",
      "('User Experience', 2)\n",
      "('Mvp', 2)\n",
      "('Relational Database', 1)\n",
      "('Relational', 1)\n",
      "('Data', 1)\n",
      "('Databases', 1)\n",
      "('Rdbms', 1)\n",
      "('Dbms', 1)\n",
      "('Database', 1)\n",
      "('Spreadsheet', 1)\n",
      "('Sql', 1)\n",
      "('Table', 1)\n",
      "('Day', 1)\n",
      "('Org', 1)\n",
      "('Internet', 1)\n",
      "('Dev', 1)\n",
      "('Good', 1)\n",
      "('Jane', 1)\n",
      "('Architect', 1)\n",
      "('Sense', 1)\n",
      "('Shereen', 1)\n",
      "('Mark Zuckerberg', 1)\n",
      "('Path', 1)\n",
      "('Hexarch', 1)\n",
      "('Main', 1)\n",
      "('Post', 1)\n",
      "('Gotcha', 1)\n",
      "('Room', 1)\n",
      "('Iphone', 1)\n",
      "('Ide', 1)\n",
      "('Php', 1)\n",
      "('Ruby', 1)\n",
      "('Osx', 1)\n",
      "('Apache', 1)\n",
      "('Unix', 1)\n",
      "('Rails', 1)\n",
      "('Css', 1)\n",
      "('Html', 1)\n",
      "('Ios', 1)\n",
      "('Net Core', 1)\n",
      "('__url__ Core', 1)\n",
      "('Asp', 1)\n",
      "('Visual Studio', 1)\n",
      "('Dotnet', 1)\n",
      "('Npm', 1)\n",
      "('Angular App', 1)\n",
      "('Bill Gates', 1)\n",
      "('Hipster', 1)\n",
      "('Work', 1)\n",
      "('City', 1)\n",
      "('England', 1)\n",
      "('Office', 1)\n",
      "('Computer', 1)\n",
      "('Guys', 1)\n",
      "('Ias', 1)\n",
      "('Socrates', 1)\n",
      "('Wall Street', 1)\n",
      "('Forbes', 1)\n",
      "('Bazaar', 1)\n",
      "('Cio', 1)\n",
      "('Skype', 1)\n",
      "('Visual', 1)\n",
      "('Devs', 1)\n",
      "('Youtube', 1)\n",
      "('Asos', 1)\n",
      "('Business', 1)\n",
      "('Linkedin', 1)\n",
      "('Ontology', 1)\n",
      "('Facebook', 1)\n",
      "('Groupon', 1)\n",
      "('__url__', 1)\n",
      "('Google', 1)\n",
      "('Basic', 1)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_ent_temp = []\n",
    "for groupid, ent_list in group_ent.items():\n",
    "    group_ent_temp.extend(list(map(lambda kv: kv[0], ent_list)))\n",
    "    \n",
    "\n",
    "\n",
    "print (*(Counter(group_ent_temp).most_common()), sep=\"\\n\")\n",
    "print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
