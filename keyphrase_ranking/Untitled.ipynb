{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.4653810629999997\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)\n",
    "end = timer()\n",
    "print(\"Time taken: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.3152105150000004\n",
      "Message: knowledge graph\n",
      "Embedding size: 512\n",
      "Embedding: [0.007142363116145134, 0.012228635139763355, -0.003253899747505784, ...]\n",
      "Cosine similarity: 1.0000000208608009\n",
      "\n",
      "Message: Entities and relations need to be defined well to build good graph representations.\n",
      "Embedding size: 512\n",
      "Embedding: [0.04317519813776016, -0.03976033255457878, -0.03193526342511177, ...]\n",
      "Cosine similarity: 0.43334049617738213\n",
      "\n",
      "Message: General knowledge is a subject that I learnt in school and I think it is cool.\n",
      "Embedding size: 512\n",
      "Embedding: [-0.03692379966378212, 0.037080686539411545, 0.0314854234457016, ...]\n",
      "Cosine similarity: 0.45122039014654813\n",
      "\n",
      "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the embedding will be.\n",
      "Embedding size: 512\n",
      "Embedding: [0.018790947273373604, 0.045365139842033386, -0.02001088857650757, ...]\n",
      "Cosine similarity: 0.21234554389034144\n",
      "\n",
      "Message: ontology\n",
      "Embedding size: 512\n",
      "Embedding: [-0.015751849859952927, 0.01084953360259533, -0.03132838010787964, ...]\n",
      "Cosine similarity: 0.531373372133073\n",
      "\n",
      "Message: searchengine\n",
      "Embedding size: 512\n",
      "Embedding: [0.05311790108680725, 0.05548816919326782, -0.05840738117694855, ...]\n",
      "Cosine similarity: 0.2671173995803453\n",
      "\n",
      "Message: donald trump\n",
      "Embedding size: 512\n",
      "Embedding: [0.016245892271399498, 0.03911377489566803, -0.0373338907957077, ...]\n",
      "Cosine similarity: 0.08428626687705831\n",
      "\n",
      "Message: test staging today\n",
      "Embedding size: 512\n",
      "Embedding: [-0.06633664667606354, -0.06972751766443253, -0.012996504083275795, ...]\n",
      "Cosine similarity: 0.294382901752253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute a representation for each message, showing various lengths supported.\n",
    "word = \"knowledge graph\"\n",
    "word2 = \"ontology\"\n",
    "word3 = \"searchengine\"\n",
    "word4 = \"donald trump\"\n",
    "word5 = \"test staging today\"\n",
    "sentence = \"Entities and relations need to be defined well to build good graph representations.\"\n",
    "sentence2 = \"General knowledge is a subject that I learnt in school and I think it is cool.\"\n",
    "paragraph = (\n",
    "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
    "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
    "    \"the more 'diluted' the embedding will be.\")\n",
    "messages = [word, sentence, sentence2, paragraph, word2, word3, word4, word5]\n",
    "\n",
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    start = timer()\n",
    "    message_embeddings = session.run(embed(messages))\n",
    "    end = timer()\n",
    "    print(\"Time taken: {}\".format(end-start))\n",
    "    for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "        print(\"Message: {}\".format(messages[i]))\n",
    "        print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "        message_embedding_snippet = \", \".join(\n",
    "            (str(x) for x in message_embedding[:3]))\n",
    "        print(\"Embedding: [{}, ...]\".format(message_embedding_snippet))\n",
    "        dist = cosine(np.array(message_embeddings[0]), message_embedding)\n",
    "        print(\"Cosine similarity: {}\\n\".format(1-dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on word graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_value(item_list, order='desc'):\n",
    "    \"\"\"\n",
    "    A utility function to sort lists by their value.\n",
    "    Args:\n",
    "        item_list:\n",
    "        order:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if order == 'desc':\n",
    "        sorted_list = sorted(item_list, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "    else:\n",
    "        sorted_list = sorted(item_list, key=lambda x: (x[1], x[0]), reverse=False)\n",
    "\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 10:29:34.621936 4661413312 util.py:15] [E050] Can't find model 'vendor/en_core_web_sm/en_core_web_sm-2.1.0'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shashank/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from graphrank import GraphRank, GraphUtils, TextPreprocess\n",
    "import networkx as nx\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = GraphRank()\n",
    "tp = TextPreprocess()\n",
    "utils = GraphUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_data = \"data/01DB8DEW0YFYK0ZBP2Q3XR2YT1_5f89df0e-3631-4c64-a7ff-3bf0264c830f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_graph = nx.read_gpickle(meeting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_list = []\n",
    "for node, attr in meeting_graph.nodes(data=True):\n",
    "    if attr.get(\"label\") == \"segmentId\":\n",
    "        segment_list.append(attr.get(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_graph.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was born in involved like many other engineers. I grew reading section how traffic was actually very involved with this house and crackers and little that I know that this works a major invoice on my life did you time section to do you remember the moment when the while basically saving the world asks careful for something computer make itself and the machine just does it and is sales how why the real want know like this example for the okay Google and ask the application service mostly requirement and get the job done just like that today I want to talk about technology based on other which one is a small step in that direction when happens we have an opportunity to like your users and bring more engagement to Europe. However, we can't do it need help as Google. We have been working on important organizing the also information to make a university. The access to help with that we build the knowledge that knowledge information about ent*ties and their relationships one of the interesting applications of the knowledge all being with you will language which is the concept of Google as far as the stream, but user do its on core the difference is quite clear to accord the back is find machine graph we like to refer types of functionality and then the markers takes stop strikes having grasp sales team with the machine the knowledge can also help satisfy because everything.\n",
      "\n",
      "[('find machine graph', 0.06600383267927318), ('grasp sales team', 0.05356489799337653), ('help satisfy', 0.04434305843760894), ('application service', 0.03932661121454191), ('interesting applications', 0.03870414184964266), ('Google', 0.036136741860335386), ('knowledge', 0.03503725037892761), ('major invoice', 0.03480821568870557), ('small step', 0.034303212624620334), ('refer types', 0.03182491577797579), ('traffic', 0.020202957496745447), ('involved', 0.018601937060670273), ('house', 0.01824823599052938), ('crackers', 0.017582046101687968), ('life', 0.01724157378939437), ('direction', 0.017134700457374984), ('technology', 0.017115551648152413), ('talk', 0.016995264278150932), ('time', 0.01698585824671425), ('opportunity', 0.016955110769755644), ('remember', 0.016851563590972334), ('users', 0.01682894572792605), ('today', 0.016813746664735826), ('functionality', 0.016446871829588084), ('job', 0.01640364630497507), ('moment', 0.016372963211821422), ('bring', 0.016328456458767723), ('markers', 0.016197109106847817), ('difference', 0.015947750749155654), ('clear', 0.015922960490463645), ('strikes', 0.015796877116380954), ('careful', 0.01578019402191053), ('requirement', 0.015768849943334322), ('engagement', 0.015735635086670467), ('accord', 0.015526963870243802), ('core', 0.015399944400363385), ('computer', 0.014494077751154737), ('Europe', 0.014375084420662983), ('stream', 0.014294219520653798), ('relationships', 0.01429044688225762), ('real', 0.013769881158034732), ('entties', 0.013617069540693418), ('example', 0.013592031172299542), ('university', 0.013462240897699049), ('access', 0.01342855295699177), ('concept', 0.01333810521055077), ('language', 0.013209409772316652), ('build', 0.012711384745467628), ('engineers', 0.010986780351351144)]\n",
      "\n",
      "How this works is to actually build together with you let me introduce you to my body shop this is shop we both music some and and southeast pieces. It's three time one day has to open in a reference score. We would QA an awesome selection of all piece and we can do and saying like part confident now on that correct our music action online. We would web streaming today. Most recommendations are provided my we want to make it these computers to discover and understand we have to right new okay i dont we like our apps be ready.\n",
      "\n",
      "[('music action online', 0.04137998964527672), ('southeast pieces', 0.029552325790666165), ('reference score', 0.02368923762228881), ('awesome selection', 0.022344767990479065), ('body shop', 0.021181744048694794), ('today', 0.020088639390191836), ('time', 0.019912855278022737), ('computers', 0.01909148721479957), ('apps', 0.013711778038358054), ('build', 0.013361074205646875), ('understand', 0.0123660043426158), ('QA', 0.011743476488935107), ('open', 0.011575241528037964), ('discover', 0.011191932339284897), ('web', 0.010634491828671714), ('confident', 0.010439897489371002), ('correct', 0.01040501599543384), ('introduce', 0.010130481857117547), ('recommendations', 0.01007177604366936), ('ready', 0.0076209899386061415)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# word_graph.clear()\n",
    "for i, text in enumerate(segment_list):\n",
    "    original_tokens, pos_tuple, filtered_pos_tuple = tp.preprocess_text(text, filter_by_pos=True, stop_words=False)\n",
    "    word_graph = gr.build_word_graph(input_pos_text=pos_tuple, window=2)\n",
    "    sub_keyphrases = gr.get_keyphrases(graph_obj=word_graph, input_pos_text=pos_tuple)\n",
    "    print(text)\n",
    "    print()\n",
    "    print(sub_keyphrases)\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(session, word):\n",
    "    message_embeddings = session.run(embed(word))\n",
    "    dist = cosine(np.array(message_embeddings[0]), np.array(message_embeddings[1]))\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_weight (session, word1 , word2):\n",
    "    word_list = [word1, word2]\n",
    "    cosine_dist = get_embedding(session, word_list)\n",
    "    try:\n",
    "        return 1-cosine_dist\n",
    "    except KeyError:\n",
    "        print(\"word not found: {}--{}\".format(word1, word2))\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words seen: 3/95; Time taken: 89.08197683700018\n",
      "Words seen: 4/95; Time taken: 75.70530546700138\n",
      "Words seen: 5/95; Time taken: 70.00495481100006\n",
      "Words seen: 6/95; Time taken: 72.36020541899961\n",
      "Words seen: 7/95; Time taken: 92.88816919900091\n",
      "Words seen: 8/95; Time taken: 116.05373594199955\n",
      "Words seen: 9/95; Time taken: 83.40755576900119\n",
      "Words seen: 10/95; Time taken: 77.31226481000158\n",
      "Words seen: 11/95; Time taken: 85.55513823600086\n",
      "Words seen: 12/95; Time taken: 89.35679126300056\n",
      "Words seen: 13/95; Time taken: 130.77185328700034\n",
      "Words seen: 14/95; Time taken: 117.28541655799927\n",
      "Words seen: 15/95; Time taken: 93.31047031299931\n",
      "Words seen: 16/95; Time taken: 102.00001781300125\n",
      "Words seen: 17/95; Time taken: 108.2346325210001\n",
      "Words seen: 18/95; Time taken: 97.67615771700002\n",
      "Words seen: 19/95; Time taken: 83.201917331\n",
      "Words seen: 20/95; Time taken: 93.41768364200107\n",
      "Words seen: 21/95; Time taken: 93.98788159200012\n",
      "Words seen: 22/95; Time taken: 92.58741949199975\n",
      "Words seen: 23/95; Time taken: 106.77963006299979\n",
      "Words seen: 24/95; Time taken: 106.66364253500069\n",
      "Words seen: 25/95; Time taken: 106.3728490350004\n",
      "Words seen: 26/95; Time taken: 113.75581046000116\n",
      "Words seen: 27/95; Time taken: 103.54900950499905\n",
      "Words seen: 28/95; Time taken: 100.10446931600018\n",
      "Words seen: 29/95; Time taken: 129.71095399099977\n",
      "Words seen: 30/95; Time taken: 141.22326836799948\n",
      "Words seen: 31/95; Time taken: 109.86142006599948\n",
      "Words seen: 32/95; Time taken: 106.16467760100022\n",
      "Words seen: 33/95; Time taken: 113.12057394200019\n",
      "Words seen: 34/95; Time taken: 108.46271738999894\n",
      "Words seen: 35/95; Time taken: 112.61941502599984\n",
      "Words seen: 36/95; Time taken: 112.07686508799998\n",
      "Words seen: 37/95; Time taken: 119.97859433200028\n",
      "Words seen: 38/95; Time taken: 122.9529248939998\n",
      "Words seen: 39/95; Time taken: 120.13497604999975\n",
      "Words seen: 40/95; Time taken: 247.10007216699887\n",
      "Words seen: 41/95; Time taken: 150.3756780520016\n",
      "Words seen: 42/95; Time taken: 122.21401255899946\n",
      "Words seen: 43/95; Time taken: 127.200761995\n",
      "Words seen: 44/95; Time taken: 129.36093309200078\n",
      "Words seen: 45/95; Time taken: 133.98571507400084\n",
      "Words seen: 46/95; Time taken: 132.13318004699977\n",
      "Words seen: 47/95; Time taken: 130.70052200099963\n",
      "Words seen: 48/95; Time taken: 135.07097466699997\n",
      "Words seen: 49/95; Time taken: 141.64864927899907\n",
      "Words seen: 50/95; Time taken: 138.0836811679983\n",
      "Words seen: 51/95; Time taken: 142.60457442799998\n",
      "Words seen: 52/95; Time taken: 227.6990062650002\n",
      "Words seen: 53/95; Time taken: 171.98307332200056\n",
      "Words seen: 54/95; Time taken: 186.96158336199915\n",
      "Words seen: 55/95; Time taken: 159.5041656400008\n",
      "Words seen: 56/95; Time taken: 158.31729052500123\n",
      "Words seen: 57/95; Time taken: 158.13734049900086\n",
      "Words seen: 58/95; Time taken: 169.2278941759996\n",
      "Words seen: 59/95; Time taken: 169.05312073500136\n",
      "Words seen: 60/95; Time taken: 168.8593203170003\n",
      "Words seen: 61/95; Time taken: 168.61116040399975\n",
      "Words seen: 62/95; Time taken: 192.55138971899942\n",
      "Words seen: 63/95; Time taken: 216.17288339000152\n",
      "Words seen: 64/95; Time taken: 151.74236278700118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0801 15:08:48.154980 4661413312 session.py:1622] Session failed to close after 30 seconds. Continuing after this point may leave your program in an undefined state.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-bff31fa0e31c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"edge_emb_wt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0memb_edge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_edge_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0memb_edge_weight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mout_vocab_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-d02b853f6b72>\u001b[0m in \u001b[0;36mget_edge_weight\u001b[0;34m(session, word1, word2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_edge_weight\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcosine_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcosine_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-06d9109b6deb>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(session, word)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmessage_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sentence_encoder/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sentence_encoder/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sentence_encoder/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sentence_encoder/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sentence_encoder/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sentence_encoder/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "in_vocab_count = 0\n",
    "out_vocab_count = 0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "\n",
    "    for i, (node1, node2, attr) in enumerate(word_graph.edges.data()):\n",
    "        start = timer()\n",
    "        if attr.get(\"edge_emb_wt\") is None:\n",
    "            emb_edge_weight = get_edge_weight(session, node1.lower(), node2.lower())\n",
    "            if emb_edge_weight == 0:\n",
    "                out_vocab_count += 1\n",
    "            else:\n",
    "                in_vocab_count += 1\n",
    "            word_graph.add_edge(node1, node2, edge_emb_wt=emb_edge_weight)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        end = timer()\n",
    "        print(\"Words seen: {}/{}; Time taken: {}\".format(i, len(word_graph.edges.data()), end-start))\n",
    "\n",
    "print(\"###########################\")\n",
    "print(\"Total in_vocab_words = {}\".format(in_vocab_count))\n",
    "print(\"Total out_of_vocab_words = {}\".format(out_vocab_count))\n",
    "print(\"Percentage of out_of_vocab = {}\".format((out_vocab_count/in_vocab_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeDataView([('engineer', 'traffic', {'weight': 1.0, 'edge_emb_wt': 0.40124842524528503}), ('traffic', 'involved', {'weight': 1.0, 'edge_emb_wt': 0.49344101548194885}), ('involved', 'house', {'weight': 1.0, 'edge_emb_wt': 0.3551652133464813}), ('house', 'cracker', {'weight': 1.0, 'edge_emb_wt': 0.36292627453804016}), ('cracker', 'major', {'weight': 1.0, 'edge_emb_wt': 0.3910221457481384}), ('major', 'invoice', {'weight': 1.0, 'edge_emb_wt': 0.296808660030365}), ('invoice', 'life', {'weight': 1.0, 'edge_emb_wt': 0.20629160106182098}), ('life', 'time', {'weight': 1.0, 'edge_emb_wt': 0.7616047263145447}), ('time', 'remember', {'weight': 1.0, 'edge_emb_wt': 0.6120784878730774}), ('time', 'piece', {'weight': 1.0, 'edge_emb_wt': 0.6457200050354004}), ('time', 'day', {'weight': 1.0, 'edge_emb_wt': 0.7213506102561951}), ('remember', 'moment', {'weight': 1.0, 'edge_emb_wt': 0.6937558054924011}), ('moment', 'careful', {'weight': 1.0, 'edge_emb_wt': 0.6300485730171204}), ('careful', 'computer', {'weight': 1.0, 'edge_emb_wt': 0.3228817284107208}), ('computer', 'machine', {'weight': 1.0, 'edge_emb_wt': 0.534201443195343}), ('computer', 'recommendation', {'weight': 1.0, 'edge_emb_wt': 0.22471214830875397}), ('computer', 'discover', {'weight': 1.0, 'edge_emb_wt': 0.3478313088417053}), ('machine', 'sale', {'weight': 1.0, 'edge_emb_wt': 0.5049940943717957}), ('machine', 'find', {'weight': 1.0, 'edge_emb_wt': 0.46509307622909546}), ('machine', 'graph', {'weight': 1.0, 'edge_emb_wt': 0.36085161566734314}), ('machine', 'team', {'weight': 1.0, 'edge_emb_wt': 0.5283851027488708}), ('machine', 'knowledge', {'weight': 1.0, 'edge_emb_wt': 0.5044450163841248}), ('sale', 'real', {'weight': 1.0, 'edge_emb_wt': 0.46741199493408203}), ('sale', 'grasp', {'weight': 1.0, 'edge_emb_wt': 0.5201505422592163}), ('sale', 'team', {'weight': 1.0, 'edge_emb_wt': 0.4310635030269623}), ('real', 'example', {'weight': 1.0, 'edge_emb_wt': 0.33674681186676025}), ('example', 'Google', {'weight': 1.0, 'edge_emb_wt': 0.30882528424263}), ('Google', 'application', {'weight': 1.0, 'edge_emb_wt': 0.2530096173286438}), ('Google', 'help', {'weight': 1.0, 'edge_emb_wt': 0.36838167905807495}), ('Google', 'university', {'weight': 1.0, 'edge_emb_wt': 0.2370445728302002}), ('Google', 'concept', {'weight': 1.0, 'edge_emb_wt': 0.2076081484556198}), ('Google', 'stream', {'weight': 1.0, 'edge_emb_wt': 0.3151191473007202}), ('application', 'service', {'weight': 1.0, 'edge_emb_wt': 0.5970404744148254}), ('application', 'interesting', {'weight': 1.0, 'edge_emb_wt': 0.2825956642627716}), ('application', 'knowledge', {'weight': 1.0, 'edge_emb_wt': 0.3731509745121002}), ('service', 'requirement', {'weight': 1.0, 'edge_emb_wt': 0.5925727486610413}), ('requirement', 'job', {'weight': 1.0, 'edge_emb_wt': 0.49635642766952515}), ('job', 'today', {'weight': 1.0, 'edge_emb_wt': 0.42041128873825073}), ('today', 'talk', {'weight': 1.0, 'edge_emb_wt': 0.2350994050502777}), ('today', 'web', {'weight': 1.0, 'edge_emb_wt': 0.37044650316238403}), ('today', 'recommendation', {'weight': 1.0, 'edge_emb_wt': 0.2595774233341217}), ('talk', 'technology', {'weight': 1.0, 'edge_emb_wt': 0.3599839210510254}), ('technology', 'small', {'weight': 1.0, 'edge_emb_wt': 0.4153781235218048}), ('small', 'step', {'weight': 1.0, 'edge_emb_wt': 0.4049410820007324}), ('step', 'direction', {'weight': 1.0, 'edge_emb_wt': 0.7072793245315552}), ('direction', 'opportunity', {'weight': 1.0, 'edge_emb_wt': 0.6512970328330994}), ('opportunity', 'user', {'weight': 1.0, 'edge_emb_wt': 0.30145353078842163}), ('user', 'bring', {'weight': 1.0, 'edge_emb_wt': 0.27091169357299805}), ('bring', 'engagement', {'weight': 1.0, 'edge_emb_wt': 0.3329695761203766}), ('engagement', 'Europe', {'weight': 1.0, 'edge_emb_wt': 0.2903504967689514}), ('Europe', 'help', {'weight': 1.0, 'edge_emb_wt': 0.25212597846984863}), ('help', 'access', {'weight': 1.0, 'edge_emb_wt': 0.23837760090827942}), ('help', 'build', {'weight': 1.0, 'edge_emb_wt': 0.24504174292087555}), ('help', 'knowledge', {'weight': 1.0, 'edge_emb_wt': 0.3241264820098877}), ('help', 'satisfy', {'weight': 1.0, 'edge_emb_wt': 0.5151340365409851}), ('university', 'access', {'weight': 1.0, 'edge_emb_wt': 0.4597405791282654}), ('build', 'knowledge', {'weight': 1.0, 'edge_emb_wt': 0.3377724587917328}), ('build', 'introduce', {'weight': 1.0, 'edge_emb_wt': 0.2707758843898773}), ('knowledge', 'entties', {'weight': 1.0, 'edge_emb_wt': 0.39228111505508423}), ('knowledge', 'language', {'weight': 1.0, 'edge_emb_wt': 0.5013172030448914}), ('entties', 'relationship', {'weight': 1.0, 'edge_emb_wt': 0.25772666931152344}), ('relationship', 'interesting', {'weight': 1.0, 'edge_emb_wt': 0.2511501908302307}), ('language', 'concept', {'weight': 1.0, 'edge_emb_wt': 0.30937978625297546}), ('stream', 'core', {'weight': 1.0, 'edge_emb_wt': 0.18045857548713684}), ('core', 'difference', {'weight': 1.0, 'edge_emb_wt': 0.3645024001598358}), ('difference', 'clear', {'weight': 1.0}), ('clear', 'accord', {'weight': 1.0}), ('accord', 'find', {'weight': 1.0}), ('graph', 'refer', {'weight': 1.0}), ('refer', 'type', {'weight': 1.0}), ('type', 'functionality', {'weight': 1.0}), ('functionality', 'marker', {'weight': 1.0}), ('marker', 'strike', {'weight': 1.0}), ('strike', 'grasp', {'weight': 1.0}), ('introduce', 'body', {'weight': 1.0}), ('body', 'shop', {'weight': 1.0}), ('shop', 'music', {'weight': 1.0}), ('music', 'southeast', {'weight': 1.0}), ('music', 'correct', {'weight': 1.0}), ('music', 'action', {'weight': 1.0}), ('southeast', 'piece', {'weight': 1.0}), ('piece', 'selection', {'weight': 1.0}), ('piece', 'confident', {'weight': 1.0}), ('day', 'open', {'weight': 1.0}), ('open', 'reference', {'weight': 1.0}), ('reference', 'score', {'weight': 1.0}), ('score', 'QA', {'weight': 1.0}), ('QA', 'awesome', {'weight': 1.0}), ('awesome', 'selection', {'weight': 1.0}), ('confident', 'correct', {'weight': 1.0}), ('action', 'online', {'weight': 1.0}), ('online', 'web', {'weight': 1.0}), ('discover', 'understand', {'weight': 1.0}), ('understand', 'apps', {'weight': 1.0}), ('apps', 'ready', {'weight': 1.0})])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_graph.edges.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_pagerank = nx.pagerank(word_graph, weight=\"edge_emb_wt\")\n",
    "unbiased_pagerank = nx.pagerank(word_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_biased_rank = sort_by_value(biased_pagerank.items())\n",
    "sorted_unbiased_rank = sort_by_value(unbiased_pagerank.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tup in enumerate(sorted_biased_rank):\n",
    "    word = tup[0]\n",
    "    biased_rank = i\n",
    "    biased_pagerank_score = tup[1]\n",
    "    word_graph.add_node(word, wt_val=biased_pagerank_score, wt_rank=biased_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tup in enumerate(sorted_unbiased_rank):\n",
    "    word = tup[0]\n",
    "    unbiased_rank = i\n",
    "    unbiased_pagerank_score = tup[1]\n",
    "    word_graph.add_node(word, val=unbiased_pagerank_score, rank=unbiased_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_wise_ranking(word_graph, segment_list):\n",
    "    for i, sub_text in enumerate(segment_list):\n",
    "        original_tokens, pos_tuple, filtered_pos_tuple = tp.preprocess_text(sub_text, filter_by_pos=True, stop_words=False)\n",
    "        sub_keyphrases = gr.get_keyphrases(graph_obj=word_graph, input_pos_text=pos_tuple, post_process=True)\n",
    "        wt_sub_keyphrase = gr.get_keyphrases(word_graph, input_pos_text=pos_tuple, post_process=True, weight=\"edge_emb_wt\")\n",
    "\n",
    "        keyphrase_rank_list = []\n",
    "        for i, phrase_tup in enumerate(wt_sub_keyphrase):\n",
    "            wt_rank = i\n",
    "            wt_word = phrase_tup[0]\n",
    "            for j, un_phrase_tup in enumerate(sub_keyphrases):\n",
    "                word = un_phrase_tup[0]\n",
    "                if word == wt_word:\n",
    "                    orig_rank = j\n",
    "                    tup = (word, orig_rank, wt_rank, sub_text)\n",
    "                    keyphrase_rank_list.append(tup)\n",
    "        \n",
    "        # print(sub_text)\n",
    "        yield keyphrase_rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "kr = get_segment_wise_ranking(word_graph, segment_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word \t\t ===> Index | Original rank | Weighted rank | Difference\n",
      "========New Segment=========\n",
      "I was born in involved like many other engineers. I grew reading section how traffic was actually very involved with this house and crackers and little that I know that this works a major invoice on my life did you time section to do you remember the moment when the while basically saving the world asks careful for something computer make itself and the machine just does it and is sales how why the real want know like this example for the okay Google and ask the application service mostly requirement and get the job done just like that today I want to talk about technology based on other which one is a small step in that direction when happens we have an opportunity to like your users and bring more engagement to Europe. However, we can't do it need help as Google. We have been working on important organizing the also information to make a university. The access to help with that we build the knowledge that knowledge information about ent*ties and their relationships one of the interesting applications of the knowledge all being with you will language which is the concept of Google as far as the stream, but user do its on core the difference is quite clear to accord the back is find machine graph we like to refer types of functionality and then the markers takes stop strikes having grasp sales team with the machine the knowledge can also help satisfy because everything.\n",
      "find machine graph\n",
      "0 | 0 | 0 | 0\n",
      "\n",
      "grasp sales team\n",
      "1 | 1 | 1 | 0\n",
      "\n",
      "application service\n",
      "2 | 3 | 2 | 1\n",
      "\n",
      "help satisfy\n",
      "3 | 2 | 3 | -1\n",
      "\n",
      "refer types\n",
      "4 | 9 | 4 | 5\n",
      "\n",
      "small step\n",
      "5 | 7 | 5 | 2\n",
      "\n",
      "knowledge\n",
      "6 | 6 | 6 | 0\n",
      "\n",
      "interesting applications\n",
      "7 | 4 | 7 | -3\n",
      "\n",
      "Google\n",
      "8 | 5 | 8 | -3\n",
      "\n",
      "time\n",
      "9 | 11 | 9 | 2\n",
      "\n",
      "major invoice\n",
      "10 | 8 | 10 | -2\n",
      "\n",
      "direction\n",
      "11 | 18 | 11 | 7\n",
      "\n",
      "clear\n",
      "12 | 26 | 12 | 14\n",
      "\n",
      "accord\n",
      "13 | 30 | 13 | 17\n",
      "\n",
      "traffic\n",
      "14 | 13 | 14 | -1\n",
      "\n",
      "involved\n",
      "15 | 15 | 15 | 0\n",
      "\n",
      "today\n",
      "16 | 10 | 16 | -6\n",
      "\n",
      "strikes\n",
      "17 | 27 | 17 | 10\n",
      "\n",
      "markers\n",
      "18 | 24 | 18 | 6\n",
      "\n",
      "functionality\n",
      "19 | 21 | 19 | 2\n",
      "\n",
      "computer\n",
      "20 | 12 | 20 | -8\n",
      "\n",
      "opportunity\n",
      "21 | 19 | 21 | -2\n",
      "\n",
      "difference\n",
      "22 | 25 | 22 | 3\n",
      "\n",
      "crackers\n",
      "23 | 17 | 23 | -6\n",
      "\n",
      "requirement\n",
      "24 | 34 | 24 | 10\n",
      "\n",
      "moment\n",
      "25 | 33 | 25 | 8\n",
      "\n",
      "house\n",
      "26 | 16 | 26 | -10\n",
      "\n",
      "technology\n",
      "27 | 23 | 27 | -4\n",
      "\n",
      "remember\n",
      "28 | 35 | 28 | 7\n",
      "\n",
      "engagement\n",
      "29 | 28 | 29 | -1\n",
      "\n",
      "job\n",
      "30 | 36 | 30 | 6\n",
      "\n",
      "bring\n",
      "31 | 22 | 31 | -9\n",
      "\n",
      "language\n",
      "32 | 47 | 32 | 15\n",
      "\n",
      "access\n",
      "33 | 45 | 33 | 12\n",
      "\n",
      "university\n",
      "34 | 44 | 34 | 10\n",
      "\n",
      "users\n",
      "35 | 20 | 35 | -15\n",
      "\n",
      "careful\n",
      "36 | 37 | 36 | 1\n",
      "\n",
      "life\n",
      "37 | 29 | 37 | -8\n",
      "\n",
      "build\n",
      "38 | 14 | 38 | -24\n",
      "\n",
      "real\n",
      "39 | 41 | 39 | 2\n",
      "\n",
      "entties\n",
      "40 | 43 | 40 | 3\n",
      "\n",
      "Europe\n",
      "41 | 38 | 41 | -3\n",
      "\n",
      "talk\n",
      "42 | 32 | 42 | -10\n",
      "\n",
      "example\n",
      "43 | 42 | 43 | -1\n",
      "\n",
      "relationships\n",
      "44 | 40 | 44 | -4\n",
      "\n",
      "engineers\n",
      "45 | 48 | 45 | 3\n",
      "\n",
      "concept\n",
      "46 | 46 | 46 | 0\n",
      "\n",
      "stream\n",
      "47 | 39 | 47 | -8\n",
      "\n",
      "core\n",
      "48 | 31 | 48 | -17\n",
      "\n",
      "========New Segment=========\n",
      "How this works is to actually build together with you let me introduce you to my body shop this is shop we both music some and and southeast pieces. It's three time one day has to open in a reference score. We would QA an awesome selection of all piece and we can do and saying like part confident now on that correct our music action online. We would web streaming today. Most recommendations are provided my we want to make it these computers to discover and understand we have to right new okay i dont we like our apps be ready.\n",
      "music action online\n",
      "0 | 0 | 0 | 0\n",
      "\n",
      "southeast pieces\n",
      "1 | 1 | 1 | 0\n",
      "\n",
      "body shop\n",
      "2 | 4 | 2 | 2\n",
      "\n",
      "reference score\n",
      "3 | 2 | 3 | -1\n",
      "\n",
      "awesome selection\n",
      "4 | 3 | 4 | -1\n",
      "\n",
      "time\n",
      "5 | 6 | 5 | 1\n",
      "\n",
      "apps\n",
      "6 | 8 | 6 | 2\n",
      "\n",
      "understand\n",
      "7 | 10 | 7 | 3\n",
      "\n",
      "today\n",
      "8 | 5 | 8 | -3\n",
      "\n",
      "open\n",
      "9 | 12 | 9 | 3\n",
      "\n",
      "computers\n",
      "10 | 7 | 10 | -3\n",
      "\n",
      "QA\n",
      "11 | 11 | 11 | 0\n",
      "\n",
      "web\n",
      "12 | 14 | 12 | 2\n",
      "\n",
      "correct\n",
      "13 | 16 | 13 | 3\n",
      "\n",
      "confident\n",
      "14 | 15 | 14 | 1\n",
      "\n",
      "discover\n",
      "15 | 13 | 15 | -2\n",
      "\n",
      "introduce\n",
      "16 | 17 | 16 | 1\n",
      "\n",
      "build\n",
      "17 | 9 | 17 | -8\n",
      "\n",
      "ready\n",
      "18 | 19 | 18 | 1\n",
      "\n",
      "recommendations\n",
      "19 | 18 | 19 | -1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Word \\t\\t ===> Index | Original rank | Weighted rank | Difference\")\n",
    "for seg in list(kr):\n",
    "    print(\"========New Segment=========\")\n",
    "    print(seg[0][-1])\n",
    "    for i, (word, orig_rank, wt_rank, text) in enumerate(seg):\n",
    "        diff = orig_rank - wt_rank\n",
    "        print(\"{}\".format(word))\n",
    "        print(\"{} | {} | {} | {}\".format(i, orig_rank, wt_rank, diff))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in word_graph.edges.data():\n",
    "    print(i[0], i[1], i[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
