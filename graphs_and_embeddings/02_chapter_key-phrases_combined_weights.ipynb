{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import iso8601\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "\n",
    "import itertools, nltk, string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import networkx as nx\n",
    "#stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "import numpy as np\n",
    "from nltk.util import ngrams\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./long_stopwords.txt') as f:\n",
    "    stop_words = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def formatTime(tz_time):    \n",
    "    isoTime = iso8601.parse_date(tz_time)\n",
    "    ts = isoTime.timestamp()\n",
    "    ts = datetime.utcfromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "    return ts\n",
    "\n",
    "def getValjsonDF(df):\n",
    "    df.columns = list(pd.Series(df.columns).apply(lambda x: x.strip()))\n",
    "    df = df.drop(df.index[0])\n",
    "    df = df['value']\n",
    "    json_list = list()\n",
    "    for i in df:\n",
    "        if type(i)==str:\n",
    "            json_list.append(json.loads(i))\n",
    "    df = pd.DataFrame(json_list)\n",
    "    return df\n",
    "\n",
    "def replaceHyphen(col_series):\n",
    "    return col_series.apply(lambda x: x.replace('-','').strip())\n",
    "\n",
    "def stripColNames(df):\n",
    "    return list(pd.Series(df.columns).apply(lambda x: x.strip()))\n",
    "\n",
    "def getregexChunks(text,grammar):\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    tagged_sents = nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(text))\n",
    "    all_chunks = list(itertools.chain.from_iterable(nltk.chunk.tree2conlltags(chunker.parse(tagged_sent))\n",
    "                                                        for tagged_sent in tagged_sents))\n",
    "    return all_chunks\n",
    "\n",
    "def getCandidatePhrases(text,grammar = [r\"\"\"base: {(<JJ.*>*<NN.*>+<IN>)?<JJ>*<NN.*>+}\"\"\",\n",
    "                                        r\"\"\"nounverb:{<NN.+>+<.+>{0,2}<VBG>{1}}\"\"\",\n",
    "                                        r\"\"\"verbnoun:{<VBG>{1}<.+>{0,2}<NN.+>+}\"\"\",\n",
    "                                       r\"\"\" nounnoun:{<NN.+>+<.+>{0,2}<NN.+>+}\"\"\"]):\n",
    "#def getCandidatePhrases(text,grammar=[r'keyphrase: {(<JJ>* <NN.*>+ <IN>)? <JJ>* <NN.*>+}']):\n",
    "    punct = set(string.punctuation)\n",
    "    all_chunks = []\n",
    "    for pattern in grammar:\n",
    "        all_chunks+=getregexChunks(text,pattern)\n",
    "        \n",
    "    candidates = [' '.join(word for word, pos, \n",
    "                           chunk in group).lower() \n",
    "                  for key, group in itertools.groupby(all_chunks, \n",
    "                  lambda_unpack(lambda word, pos, chunk: chunk != 'O')) if key]\n",
    "    out = [cand for cand in candidates if cand not in stop_words and not all(char in punct for char in cand)]\n",
    "    \n",
    "    return out\n",
    "\n",
    "def deDoupCandidateList(candidate_keyphrase_list):\n",
    "    '''applies stopword filters, merge sub-phrases into parent, merge overlapping phrases'''\n",
    "    pass\n",
    "\n",
    "def lambda_unpack(f):\n",
    "    return lambda args: f(*args)\n",
    "\n",
    "\n",
    "def getBigramSentence(sent,embedding_dict):\n",
    "    if len(sent.split(' '))>1:\n",
    "        sent = sent.split(' ')\n",
    "        sent_merged = ' '.join(sent)\n",
    "        t_bigrams = list(ngrams(sent,2))\n",
    "        t_bigrams_token = list(pd.Series(t_bigrams).apply(lambda x: x[0]+'_'+x[1]))\n",
    "        lookup_tokens = list(set(embedding_dict.keys()).intersection(set(t_bigrams_token)))\n",
    "        for bigram_token in lookup_tokens:\n",
    "            repl_str = bigram_token.split('_')[0]+' '+bigram_token.split('_')[1]\n",
    "            sent_merged = sent_merged.replace(repl_str,bigram_token)\n",
    "        split_ = sent_merged.lower().split(' ')\n",
    "    else:\n",
    "        split_ = [sent.lower()]\n",
    "    return split_\n",
    "\n",
    "def getEmbedVector(chat, feature_dict, p_list):\n",
    "    p_ctr = len(p_list)\n",
    "    chat = getBigramSentence(chat.lower(),feature_dict)\n",
    "    #chat = chat.lower().split(' ')\n",
    "    vec_list = []\n",
    "    feature_vector = []\n",
    "    extp_feature_vector = []\n",
    "    word_ctr = 0\n",
    "    \n",
    "    for ele in chat:\n",
    "        if ele not in stop_words:\n",
    "            if ele in feature_dict.keys():\n",
    "                word_ctr += 1\n",
    "                f_vector = feature_dict[ele]\n",
    "                vec_list.append(np.array(f_vector))\n",
    "    if len(vec_list)>0:\n",
    "        for p in p_list:\n",
    "            t_features = getPMeanFeatures(vec_list, p)\n",
    "            feature_vector += list(t_features)\n",
    "        extp_feature_vector.append(np.array(feature_vector))\n",
    "        return extp_feature_vector[0]\n",
    "    else:\n",
    "        return [0]*300*p_ctr\n",
    "\n",
    "def getPMeanFeatures(embed_list, p):\n",
    "    if p == 1:\n",
    "        return np.mean(np.array(embed_list), axis=0)\n",
    "    else:\n",
    "        p_pow_list = []\n",
    "        for embed in embed_list:\n",
    "            embed = embed ** p\n",
    "            p_pow_list.append(embed)\n",
    "        p_mat = np.array(p_pow_list)\n",
    "        p_mat = np.mean(p_mat, axis=0)\n",
    "        p_mat_ = np.array([ownpow(item, 1 / p) for item in p_mat])\n",
    "        return p_mat_\n",
    "\n",
    "def getEmbeddingWeight(chat, weight_dict):\n",
    "    chat_weight_list = []\n",
    "    for ele in chat.split( ):\n",
    "        if ele not in stop_words and ele in weight_dict.keys():\n",
    "            chat_weight_list.append(weight_dict[ele])\n",
    "    return sum(chat_weight_list)\n",
    "\n",
    "def ownpow(a, b):\n",
    "    if a > 0:\n",
    "        return a ** b\n",
    "    if a <= 0:\n",
    "        temp = abs(a) ** b\n",
    "        return -1 * temp\n",
    "    \n",
    "def getNormWeights(node_weights,fn):\n",
    "    #degree centrality\n",
    "    if fn == 'degree_centrality':\n",
    "        node_degrees = dict(nx.degree(kpGraph))\n",
    "        for k, v in node_weights.items():\n",
    "#             if node_degrees[k]<2:\n",
    "#                 norm_factor = 10\n",
    "#             else:\n",
    "            norm_factor = node_degrees[k]\n",
    "            node_weights[k] = v/norm_factor\n",
    "    \n",
    "    #closeness centrality\n",
    "    if fn=='closeness':\n",
    "        node_closeness = nx.current_flow_closeness_centrality(kpGraph)\n",
    "        for k, v in node_weights.items():\n",
    "            node_weights[k] = v/node_closeness[k]\n",
    "    \n",
    "    #betweenness\n",
    "    if fn=='betweenness':\n",
    "        node_betweenness = nx.current_flow_betweenness_centrality(kpGraph)\n",
    "        for k, v in node_weights.items():\n",
    "            node_weights[k] = v * node_betweenness[k]\n",
    "    #degree_bet\n",
    "    if fn == 'degree_bet':\n",
    "        node_degrees = dict(nx.degree(kpGraph))\n",
    "        node_betweenness = nx.current_flow_betweenness_centrality(kpGraph)\n",
    "        for k, v in node_weights.items():\n",
    "            node_norm = node_degrees[k] + node_betweenness[k]\n",
    "            node_weights[k] = v/node_norm\n",
    "    #node_weights = sorted(node_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "    return node_weights\n",
    "\n",
    "def getDirEdge(curr_node,nxt_node,personalization_dict):\n",
    "    curr_node_score = personalization_dict[curr_node]\n",
    "    nxt_node_score = personalization_dict[nxt_node]\n",
    "    if curr_node_score>nxt_node_score:\n",
    "        order_ = nxt_node,curr_node\n",
    "    else:\n",
    "        order_ = curr_node,nxt_node\n",
    "    return order_\n",
    "\n",
    "def getDFFromDict(dict_,col_names):\n",
    "    dict_df = pd.DataFrame.from_dict(dict_,orient='index').reset_index()\n",
    "    dict_df.columns = col_names\n",
    "    return dict_df\n",
    "\n",
    "def getMeanOutNodeScore(node_, kpGraph):\n",
    "    if node_ in kpGraph.nodes():\n",
    "        out_edges = [out_edge for out_edge in [edge[1] for edge in kpGraph.out_edges(node_)]]\n",
    "    if len(out_edges)>0:\n",
    "        return np.mean([kpGraph[node_][x]['weight'] for x in out_edges])\n",
    "    else:\n",
    "        return 0.0 #small non-zero value\n",
    "\n",
    "def getMeanInNodeScore(node_, kpGraph):\n",
    "    if node_ in kpGraph.nodes():\n",
    "        in_edges = [in_edge for in_edge in [edge[0] for edge in kpGraph.in_edges(node_)]]\n",
    "    if len(in_edges)>0:\n",
    "        return np.mean([kpGraph[x][node_]['weight'] for x in in_edges])\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def stripStops(phrase):\n",
    "    split_tokens = phrase.split()\n",
    "    if split_tokens[0] in stop_words:\n",
    "        split_tokens = split_tokens[1:]\n",
    "    if split_tokens[-1] in stop_words:\n",
    "        split_tokens = split_tokens[:-1]\n",
    "        \n",
    "    return ' '.join(split_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load \n",
    "embedding_dict_path = 'data/ether_engg_embedding_dict.pkl'\n",
    "embedding_dict = pickle.load(open(embedding_dict_path,'rb'))\n",
    "\n",
    "weight_dict_path = 'data/ether_engg_weight_dict.pkl'\n",
    "weight_dict = pickle.load(open(weight_dict_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/venkat/Downloads/test_csvs/7c5a224f4fb54cdb83724612dd1088e8.csv')\n",
    "df_test = getValjsonDF(df_test)\n",
    "df_test['createdAt'] = df_test['createdAt'].apply(lambda x: datetime.datetime.strptime(x[:-4],'%Y-%m-%dT%H:%M:%S.%f'))\n",
    "df_test = df_test[df_test['transcriber']=='deepgram']\n",
    "df_test = df_test.sort_values(by='createdAt').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#sort and get chapter subsets\n",
    "#split dataframe into chapters\n",
    "time_stamp_list = list(df_test['createdAt'])\n",
    "chapter_df_list = []\n",
    "\n",
    "for idx in range(len(time_stamp_list)):\n",
    "    if idx==0:\n",
    "        chp_start_time = time_stamp_list[idx]\n",
    "    print(idx)\n",
    "    chp_end_time = chp_start_time+datetime.timedelta(seconds=300)\n",
    "    chaper_subset = df_test[df_test['createdAt'].between(chp_start_time,chp_end_time,inclusive=True)]\n",
    "    chp_start_time = chp_end_time+datetime.timedelta(seconds=1)\n",
    "    \n",
    "    chapter_df_list.append(chaper_subset)\n",
    "    break_ctr = max(chaper_subset.index)\n",
    "    if break_ctr>=len(df_test)-1:\n",
    "        break\n",
    "        \n",
    "assert sum([ele.shape[0] for ele in chapter_df_list])==len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for txt,time in zip(chapter_df_list[1]['originalText'],chapter_df_list[1]['createdAt']):\n",
    "#     print(txt)\n",
    "#     print(time)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "['back yeah okay', 'yeah yeah yeah', 'same thing', 'few things', 'okay yeah']\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "#do burst mode - aggregate all transcripts in each chapter and calculate key-phrase scores\n",
    "#no pre-processing, just get the transcript level key-phrases\n",
    "#curr_chapter = pd.concat([chapter_df_list[-2],chapter_df_list[-3]])\n",
    "curr_chapter = chapter_df_list[4]\n",
    "\n",
    "start = time.time()\n",
    "candidate_keys = []\n",
    "sent_list = []\n",
    "tra_sent_list = []\n",
    "for transcript in list(curr_chapter['originalText']):\n",
    "    transcript_sents = nltk.sent_tokenize(transcript)\n",
    "    for sent_ in transcript_sents:\n",
    "        if len(sent_.split(' '))>5:\n",
    "            tra_sent_list.append(sent_.strip())\n",
    "            sent_list.append(sent_.strip())\n",
    "    filtr_transcript = ' '.join(tra_sent_list)\n",
    "    candidate_keys+=list(set(getCandidatePhrases(filtr_transcript)))\n",
    "# #filter stop_word only key-phrases    \n",
    "# print(len(candidate_keys))\n",
    "candidate_keys = list(set(candidate_keys)-set(stop_words))\n",
    "drop_list = []\n",
    "for candidate in candidate_keys:\n",
    "    candidate_split = list(set(candidate.split(' ')))\n",
    "    if len(set(stop_words).intersection(candidate_split))==len(candidate_split):\n",
    "        drop_list.append(candidate)\n",
    "print(len(candidate_keys))\n",
    "candidate_keys = list(set(candidate_keys)-set(drop_list))\n",
    "print(drop_list)\n",
    "print(len(candidate_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basic slack install flow', 'next week', 'necessary permissions for installs', 'simple kind of login', 'installation process', 'back end', 'permissions for installs', 'authenticates', 'other kind of corner cases', 'back-end perspective', 'front end', 'other pages in place right', 'good shape']\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"From a back-end perspective if we are ready to integrate. With the front end say sometime next week, \\\n",
    "                then we'll be okay. So basically, you know the basic slack install flow right have a very simple kind of login. \\\n",
    "                I mean installation process takes you to slack and authenticates and gives you the necessary permissions for installs, \\\n",
    "                comes back right and then from the back end all the information we need is ready so that we can go and put the other \\\n",
    "                pages in place right like all the other kind of corner cases. So if we do that then I think we'll be in good shape.\"\"\"\n",
    "\n",
    "tra_sent_list = []\n",
    "candidate_keys = []\n",
    "sent_list = []\n",
    "\n",
    "transcript_sents = nltk.sent_tokenize(sample_text)\n",
    "for sent_ in transcript_sents:\n",
    "    if len(sent_.split(' '))>5:\n",
    "        tra_sent_list.append(sent_.strip())\n",
    "        sent_list.append(stripSpaces(sent_))\n",
    "\n",
    "filtr_transcript = ' '.join(tra_sent_list)\n",
    "candidate_keys=list(set(getCandidatePhrases(filtr_transcript)))\n",
    "\n",
    "print(candidate_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_list = [1,3,5]\n",
    "\n",
    "sent_feat_list = []\n",
    "sent_dist_list = []\n",
    "candidate_embedding_list = []\n",
    "\n",
    "for sent in sent_list:\n",
    "    sent_feats = getEmbedVector(sent,embedding_dict,p_list)\n",
    "    sent_feat_list.append(sent_feats)\n",
    "    \n",
    "# for candidate in candidate_keys:\n",
    "#     candidate_embedding_list.append(getEmbedVector(candidate,embedding_dict,p_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic slack install flow 0.9315945826157038\n",
      "next week 0.0001\n",
      "necessary permissions for installs 0.5388867436736838\n",
      "simple kind of login 0.5306938992884916\n",
      "installation process 0.5730167863360691\n",
      "back end 0.0001\n",
      "permissions for installs 0.5388867436736838\n",
      "authenticates 0.0001\n",
      "other kind of corner cases 0.630023013490366\n",
      "back-end perspective 0.8440460874184231\n",
      "front end 0.0001\n",
      "other pages in place right 0.574491033986358\n",
      "good shape 0.8156128974994202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkat/Documents/virtualenvironments/localtest/lib/python3.7/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "#iterate key-phrases through each sentence and use them as initial score - if there are duplicates, take max\n",
    "score_list = []\n",
    "for candidate in candidate_keys:\n",
    "    \n",
    "    candidate_feats = getEmbedVector(candidate,embedding_dict,p_list)\n",
    "    candidate_embedding_list.append(candidate_feats)\n",
    "    curr_scores = []\n",
    "    \n",
    "    for sent_,sent_feats in zip(sent_list,sent_feat_list):\n",
    "        if candidate.lower() in sent_.lower():\n",
    "            curr_dist = 1-spatial.distance.cosine(candidate_feats,sent_feats)\n",
    "            if curr_dist!=curr_dist:\n",
    "                curr_dist=0.0001\n",
    "            print(candidate,curr_dist)\n",
    "            curr_scores.append(curr_dist)\n",
    "    score_list.append(np.mean(np.array(curr_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key_feat_dict = dict(zip(candidate_keys,candidate_embedding_list))\n",
    "personalization_dict = dict(zip(candidate_keys,score_list))\n",
    "#personalization_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Minimum distance threshold:  0.44960753667639886\n",
      "Total edges formed:  78\n",
      "Total edges after pruning:  7\n",
      "Removing following dangling nodes:  ['next week', 'simple kind of login', 'back end', 'authenticates', 'front end']\n"
     ]
    }
   ],
   "source": [
    "## build graph with candidates and use p-means cosine similarity as an edge connection\n",
    "#kpGraph.clear()\n",
    "kpGraph = nx.DiGraph()\n",
    "#kpGraph = nx.Graph()\n",
    "kpGraph.add_nodes_from(candidate_keys)\n",
    "print(len(kpGraph.nodes()))\n",
    "edge_weight_list = []\n",
    "\n",
    "for i in range(len(candidate_keys)):\n",
    "    curr_node = candidate_keys[i]\n",
    "    if curr_node in kpGraph.nodes():\n",
    "        for j in range(i+1,len(candidate_keys)):\n",
    "            nxt_node = candidate_keys[j]\n",
    "            if nxt_node in kpGraph.nodes():\n",
    "                edge_weight = 1-spatial.distance.cosine(key_feat_dict[curr_node],key_feat_dict[nxt_node])\n",
    "                if edge_weight!=edge_weight:\n",
    "                    edge_weight = 0.0\n",
    "                edge_weight_list.append(edge_weight)\n",
    "                #add inward edge to the most influential node\n",
    "                #node2 has to be most influential\n",
    "                node1,node2 = getDirEdge(curr_node,nxt_node,personalization_dict)\n",
    "                if node1!=node2:\n",
    "                    kpGraph.add_edge(node1,node2,weight=edge_weight)\n",
    "                \n",
    "# #get min_edge_weight\n",
    "edge_retain_perc = 0.1\n",
    "edge_weight_list.sort(reverse=True)\n",
    "edge_weight_list = edge_weight_list[0:int(len(edge_weight_list)*edge_retain_perc)]\n",
    "min_edge_dist = min(edge_weight_list)\n",
    "print('Minimum distance threshold: ', min_edge_dist)\n",
    "\n",
    "drop_list = []\n",
    "edge_list = kpGraph.edges\n",
    "print('Total edges formed: ', len(edge_list))\n",
    "\n",
    "for edge in edge_list:\n",
    "    if kpGraph[edge[0]][edge[1]]['weight']<min_edge_dist:\n",
    "        drop_list.append(edge)\n",
    "        \n",
    "kpGraph.remove_edges_from(drop_list)\n",
    "print('Total edges after pruning: ', len(kpGraph.edges))\n",
    "#remove nodes with no edges\n",
    "print('Removing following dangling nodes: ', list(nx.isolates(kpGraph)))\n",
    "kpGraph.remove_nodes_from(list(nx.isolates(kpGraph)))\n",
    "nstart = {k:v for k, v in personalization_dict.items() if k in kpGraph.nodes()}\n",
    "node_weights = nx.pagerank(kpGraph, alpha=0.85, max_iter=100,tol=0.0001, \n",
    "                            personalization=nstart, nstart=None)\n",
    "# end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basic slack install flow': 0.14071493615745184,\n",
       " 'necessary permissions for installs': 0.0633215368811905,\n",
       " 'installation process': 0.06733196538137921,\n",
       " 'permissions for installs': 0.11712725225964377,\n",
       " 'other kind of corner cases': 0.12963310843563536,\n",
       " 'back-end perspective': 0.31852794110029037,\n",
       " 'other pages in place right': 0.06750519589420159,\n",
       " 'good shape': 0.09583806389020712}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_scores_page_rank = getDFFromDict(node_weights,['key-phrase','pr_score']).sort_values(by='pr_score',ascending=False)\n",
    "node_scores_cosine = getDFFromDict(nstart,['key-phrase','cs_score']).sort_values(by='cs_score',ascending=False)\n",
    "node_scores_page_rank['pr_score'] = node_scores_page_rank['pr_score'].apply(lambda x: x/max(node_scores_page_rank['pr_score']))\n",
    "node_scores_cosine['cs_score'] = node_scores_cosine['cs_score'].apply(lambda x: x/max(node_scores_cosine['cs_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key-phrase</th>\n",
       "      <th>pr_score</th>\n",
       "      <th>cs_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back-end perspective</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>basic slack install flow</td>\n",
       "      <td>0.441766</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other kind of corner cases</td>\n",
       "      <td>0.406976</td>\n",
       "      <td>0.676285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permissions for installs</td>\n",
       "      <td>0.367714</td>\n",
       "      <td>0.578456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good shape</td>\n",
       "      <td>0.300878</td>\n",
       "      <td>0.875502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>other pages in place right</td>\n",
       "      <td>0.211929</td>\n",
       "      <td>0.616675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>installation process</td>\n",
       "      <td>0.211385</td>\n",
       "      <td>0.615092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>necessary permissions for installs</td>\n",
       "      <td>0.198794</td>\n",
       "      <td>0.578456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           key-phrase  pr_score  cs_score\n",
       "0                back-end perspective  1.000000  0.906023\n",
       "1            basic slack install flow  0.441766  1.000000\n",
       "2          other kind of corner cases  0.406976  0.676285\n",
       "3            permissions for installs  0.367714  0.578456\n",
       "4                          good shape  0.300878  0.875502\n",
       "5          other pages in place right  0.211929  0.616675\n",
       "6                installation process  0.211385  0.615092\n",
       "7  necessary permissions for installs  0.198794  0.578456"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_scores = pd.merge(node_scores_page_rank,node_scores_cosine,on='key-phrase')\n",
    "df_final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_final_scores['phrase_bias'] = df_final_scores['key-phrase'].apply(lambda x: getEmbeddingWeight(x, weight_dict))\n",
    "df_final_scores['phrase_bias'] = df_final_scores['phrase_bias'].apply(lambda x: x/max(df_final_scores['phrase_bias']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_scores['in_edges'] = df_final_scores['key-phrase'].apply(lambda x: len(kpGraph.in_edges(x))+1)\n",
    "df_final_scores['in_edges'] = df_final_scores['in_edges'].apply(lambda x: x/max(df_final_scores['in_edges']))\n",
    "df_final_scores['out_edges'] = df_final_scores['key-phrase'].apply(lambda x: len(kpGraph.out_edges(x))+1)\n",
    "df_final_scores['out_edges'] = df_final_scores['out_edges'].apply(lambda x: x/max(df_final_scores['out_edges']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_scores['mind_context'] = df_final_scores['cs_score']+df_final_scores['phrase_bias']\n",
    "df_final_scores['graph_context'] = df_final_scores['pr_score']+df_final_scores['in_edges']+df_final_scores['out_edges']\n",
    "df_final_scores = df_final_scores.sort_values(by='graph_context', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_scores['weighted_in_edge_score'] = df_final_scores['key-phrase'].apply(lambda x: getMeanInNodeScore(x,kpGraph))\n",
    "df_final_scores['weighted_out_edge_score'] = df_final_scores['key-phrase'].apply(lambda x: getMeanOutNodeScore(x,kpGraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_scores['weighted_in_edge_score'] = df_final_scores['weighted_in_edge_score']*df_final_scores['in_edges']\n",
    "df_final_scores['weighted_out_edge_score'] = df_final_scores['weighted_out_edge_score']*df_final_scores['out_edges']\n",
    "df_final_scores['degree_score'] = df_final_scores['weighted_out_edge_score']/df_final_scores['weighted_in_edge_score']\n",
    "#df_final_scores['degree_score'] = df_final_scores['degree_score'].apply(lambda x: x/max(df_final_scores['degree_score']))\n",
    "#del df_final_scores['weighted_in_edge_score']\n",
    "#del df_final_scores['weighted_out_edge_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_scores['mind_context'] = df_final_scores['mind_context'].apply(lambda x: x/max(df_final_scores['mind_context']))\n",
    "df_final_scores['graph_context'] = df_final_scores['graph_context'].apply(lambda x: x/max(df_final_scores['graph_context']))\n",
    "\n",
    "df_final_scores['final_score'] = df_final_scores['mind_context']+df_final_scores['graph_context']\n",
    "df_final_scores = df_final_scores.sort_values(by='final_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_final_scores['key-phrase'] = df_final_scores['key-phrase'].apply(lambda x: stripStops(x))\n",
    "df_final_scores['key_len'] = df_final_scores['key-phrase'].apply(lambda x: len(x.split(' ')))\n",
    "df_final_scores = df_final_scores[df_final_scores['key_len']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key-phrase</th>\n",
       "      <th>pr_score</th>\n",
       "      <th>cs_score</th>\n",
       "      <th>phrase_bias</th>\n",
       "      <th>in_edges</th>\n",
       "      <th>out_edges</th>\n",
       "      <th>mind_context</th>\n",
       "      <th>graph_context</th>\n",
       "      <th>weighted_in_edge_score</th>\n",
       "      <th>weighted_out_edge_score</th>\n",
       "      <th>degree_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>key_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>language model</td>\n",
       "      <td>0.816070</td>\n",
       "      <td>0.685153</td>\n",
       "      <td>0.692144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.761392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.530315</td>\n",
       "      <td>0.536167</td>\n",
       "      <td>1.011035</td>\n",
       "      <td>1.761392</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time than other other food join</td>\n",
       "      <td>0.862379</td>\n",
       "      <td>0.808920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614742</td>\n",
       "      <td>0.337508</td>\n",
       "      <td>0.085775</td>\n",
       "      <td>0.254143</td>\n",
       "      <td>1.614742</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>start time</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.782176</td>\n",
       "      <td>0.786196</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.527253</td>\n",
       "      <td>0.338039</td>\n",
       "      <td>0.141018</td>\n",
       "      <td>0.417165</td>\n",
       "      <td>1.394274</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worst time</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853014</td>\n",
       "      <td>0.524370</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.761440</td>\n",
       "      <td>0.539888</td>\n",
       "      <td>0.237240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.301328</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reason calls</td>\n",
       "      <td>0.186568</td>\n",
       "      <td>0.679806</td>\n",
       "      <td>0.573345</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.692761</td>\n",
       "      <td>0.377169</td>\n",
       "      <td>0.150590</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>1.599962</td>\n",
       "      <td>1.069930</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pin people</td>\n",
       "      <td>0.302600</td>\n",
       "      <td>0.740161</td>\n",
       "      <td>0.566307</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.722236</td>\n",
       "      <td>0.341246</td>\n",
       "      <td>0.198351</td>\n",
       "      <td>0.110104</td>\n",
       "      <td>0.555097</td>\n",
       "      <td>1.063482</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>team score</td>\n",
       "      <td>0.101226</td>\n",
       "      <td>0.597441</td>\n",
       "      <td>0.756027</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.748219</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>0.065390</td>\n",
       "      <td>0.243043</td>\n",
       "      <td>3.716819</td>\n",
       "      <td>1.026793</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meeting graph</td>\n",
       "      <td>0.230415</td>\n",
       "      <td>0.923799</td>\n",
       "      <td>0.620552</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.853742</td>\n",
       "      <td>0.157342</td>\n",
       "      <td>0.082593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.011083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coming by by tuesday</td>\n",
       "      <td>0.255992</td>\n",
       "      <td>0.703013</td>\n",
       "      <td>0.483123</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.655714</td>\n",
       "      <td>0.297379</td>\n",
       "      <td>0.178602</td>\n",
       "      <td>0.111554</td>\n",
       "      <td>0.624597</td>\n",
       "      <td>0.953093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>engineering mind</td>\n",
       "      <td>0.087329</td>\n",
       "      <td>0.593257</td>\n",
       "      <td>0.608983</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.267212</td>\n",
       "      <td>0.031796</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>8.279304</td>\n",
       "      <td>0.931829</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trust person</td>\n",
       "      <td>0.291547</td>\n",
       "      <td>0.775372</td>\n",
       "      <td>0.419445</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.660513</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.125215</td>\n",
       "      <td>0.071351</td>\n",
       "      <td>0.569828</td>\n",
       "      <td>0.922314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kind of kind</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>0.611214</td>\n",
       "      <td>0.500733</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.614702</td>\n",
       "      <td>0.300454</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.279062</td>\n",
       "      <td>4.338988</td>\n",
       "      <td>0.915156</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flexibility usability standpoint point</td>\n",
       "      <td>0.218798</td>\n",
       "      <td>0.779055</td>\n",
       "      <td>0.404887</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.654502</td>\n",
       "      <td>0.222309</td>\n",
       "      <td>0.101456</td>\n",
       "      <td>0.078463</td>\n",
       "      <td>0.773375</td>\n",
       "      <td>0.876811</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>platform afternoon</td>\n",
       "      <td>0.442175</td>\n",
       "      <td>0.795563</td>\n",
       "      <td>0.273430</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.590956</td>\n",
       "      <td>0.246197</td>\n",
       "      <td>0.086392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>large scripts</td>\n",
       "      <td>0.230152</td>\n",
       "      <td>0.713728</td>\n",
       "      <td>0.487349</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.663974</td>\n",
       "      <td>0.170906</td>\n",
       "      <td>0.086738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>layer format</td>\n",
       "      <td>0.252441</td>\n",
       "      <td>0.718824</td>\n",
       "      <td>0.365929</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.599669</td>\n",
       "      <td>0.186052</td>\n",
       "      <td>0.082476</td>\n",
       "      <td>0.048998</td>\n",
       "      <td>0.594085</td>\n",
       "      <td>0.785721</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>parallel experiments</td>\n",
       "      <td>0.151889</td>\n",
       "      <td>0.701936</td>\n",
       "      <td>0.404017</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.611389</td>\n",
       "      <td>0.136687</td>\n",
       "      <td>0.056557</td>\n",
       "      <td>0.082581</td>\n",
       "      <td>1.460133</td>\n",
       "      <td>0.748076</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>country compute</td>\n",
       "      <td>0.082468</td>\n",
       "      <td>0.593020</td>\n",
       "      <td>0.325809</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.507943</td>\n",
       "      <td>0.140154</td>\n",
       "      <td>0.033533</td>\n",
       "      <td>0.103485</td>\n",
       "      <td>3.086074</td>\n",
       "      <td>0.648097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>api cards</td>\n",
       "      <td>0.094334</td>\n",
       "      <td>0.678383</td>\n",
       "      <td>0.250928</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.513738</td>\n",
       "      <td>0.109822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071488</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.623560</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>reading from the responses</td>\n",
       "      <td>0.116002</td>\n",
       "      <td>0.550020</td>\n",
       "      <td>0.193575</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.411071</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>0.130796</td>\n",
       "      <td>2.154828</td>\n",
       "      <td>0.584022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>all libraries</td>\n",
       "      <td>0.070468</td>\n",
       "      <td>0.506758</td>\n",
       "      <td>0.126610</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.350136</td>\n",
       "      <td>0.080459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.430595</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                key-phrase  pr_score  cs_score  phrase_bias  \\\n",
       "0                           language model  0.816070  0.685153     0.692144   \n",
       "1          time than other other food join  0.862379  0.808920     1.000000   \n",
       "2                               start time  0.595640  0.782176     0.786196   \n",
       "3                               worst time  1.000000  0.853014     0.524370   \n",
       "4                             reason calls  0.186568  0.679806     0.573345   \n",
       "5                               pin people  0.302600  0.740161     0.566307   \n",
       "6                               team score  0.101226  0.597441     0.756027   \n",
       "7                            meeting graph  0.230415  0.923799     0.620552   \n",
       "8                     coming by by tuesday  0.255992  0.703013     0.483123   \n",
       "9                         engineering mind  0.087329  0.593257     0.608983   \n",
       "10                            trust person  0.291547  0.775372     0.419445   \n",
       "12                            kind of kind  0.104018  0.611214     0.500733   \n",
       "14  flexibility usability standpoint point  0.218798  0.779055     0.404887   \n",
       "15                      platform afternoon  0.442175  0.795563     0.273430   \n",
       "16                           large scripts  0.230152  0.713728     0.487349   \n",
       "17                            layer format  0.252441  0.718824     0.365929   \n",
       "18                    parallel experiments  0.151889  0.701936     0.404017   \n",
       "19                         country compute  0.082468  0.593020     0.325809   \n",
       "20                               api cards  0.094334  0.678383     0.250928   \n",
       "21              reading from the responses  0.116002  0.550020     0.193575   \n",
       "22                           all libraries  0.070468  0.506758     0.126610   \n",
       "\n",
       "    in_edges  out_edges  mind_context  graph_context  weighted_in_edge_score  \\\n",
       "0   1.000000   1.000000      0.761392       1.000000                0.530315   \n",
       "1   0.692308   0.176471      1.000000       0.614742                0.337508   \n",
       "2   0.653846   0.235294      0.867021       0.527253                0.338039   \n",
       "3   0.461538   0.058824      0.761440       0.539888                0.237240   \n",
       "4   0.346154   0.529412      0.692761       0.377169                0.150590   \n",
       "5   0.423077   0.235294      0.722236       0.341246                0.198351   \n",
       "6   0.153846   0.529412      0.748219       0.278574                0.065390   \n",
       "7   0.153846   0.058824      0.853742       0.157342                0.082593   \n",
       "8   0.346154   0.235294      0.655714       0.297379                0.178602   \n",
       "9   0.076923   0.588235      0.664617       0.267212                0.031796   \n",
       "10  0.269231   0.176471      0.660513       0.261800                0.125215   \n",
       "12  0.153846   0.588235      0.614702       0.300454                0.064315   \n",
       "14  0.230769   0.176471      0.654502       0.222309                0.101456   \n",
       "15  0.192308   0.058824      0.590956       0.246197                0.086392   \n",
       "16  0.192308   0.058824      0.663974       0.170906                0.086738   \n",
       "17  0.153846   0.117647      0.599669       0.186052                0.082476   \n",
       "18  0.115385   0.117647      0.611389       0.136687                0.056557   \n",
       "19  0.076923   0.235294      0.507943       0.140154                0.033533   \n",
       "20  0.038462   0.176471      0.513738       0.109822                0.000000   \n",
       "21  0.076923   0.294118      0.411071       0.172951                0.060699   \n",
       "22  0.038462   0.117647      0.350136       0.080459                0.000000   \n",
       "\n",
       "    weighted_out_edge_score  degree_score  final_score  key_len  \n",
       "0                  0.536167      1.011035     1.761392        2  \n",
       "1                  0.085775      0.254143     1.614742        6  \n",
       "2                  0.141018      0.417165     1.394274        2  \n",
       "3                  0.000000      0.000000     1.301328        2  \n",
       "4                  0.240938      1.599962     1.069930        2  \n",
       "5                  0.110104      0.555097     1.063482        2  \n",
       "6                  0.243043      3.716819     1.026793        2  \n",
       "7                  0.000000      0.000000     1.011083        2  \n",
       "8                  0.111554      0.624597     0.953093        4  \n",
       "9                  0.263247      8.279304     0.931829        2  \n",
       "10                 0.071351      0.569828     0.922314        2  \n",
       "12                 0.279062      4.338988     0.915156        3  \n",
       "14                 0.078463      0.773375     0.876811        4  \n",
       "15                 0.000000      0.000000     0.837153        2  \n",
       "16                 0.000000      0.000000     0.834880        2  \n",
       "17                 0.048998      0.594085     0.785721        2  \n",
       "18                 0.082581      1.460133     0.748076        2  \n",
       "19                 0.103485      3.086074     0.648097        2  \n",
       "20                 0.071488           inf     0.623560        2  \n",
       "21                 0.130796      2.154828     0.584022        4  \n",
       "22                 0.117647           inf     0.430595        2  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In_Edges: \n",
      "['language model', 'next week', 'meeting']\n",
      "\n",
      "Out_Edges: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "key_ = 'meeting graph'\n",
    "print('In_Edges: ')\n",
    "print([edge[0] for edge in kpGraph.in_edges(key_)])\n",
    "print()\n",
    "print('Out_Edges: ')\n",
    "print([edge[1] for edge in kpGraph.out_edges(key_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In_Edges: \n",
      "['next week']\n",
      "\n",
      "Out_Edges: \n",
      "['meeting graph', 'language model']\n"
     ]
    }
   ],
   "source": [
    "key_ = 'meeting'\n",
    "print('In_Edges: ')\n",
    "print([edge[0] for edge in kpGraph.in_edges(key_)])\n",
    "print()\n",
    "print('Out_Edges: ')\n",
    "print([edge[1] for edge in kpGraph.out_edges(key_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'worst' in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.22568348e-01,  2.61646181e-01,  6.21008649e-02, -3.35652456e-02,\n",
       "       -2.39757970e-01, -2.60026008e-01,  2.00880215e-01, -2.24116191e-01,\n",
       "        1.96480572e-01,  1.42902702e-01, -7.98235014e-02,  3.33956070e-02,\n",
       "       -8.38135481e-02, -1.55800253e-01, -4.61133663e-03,  1.68200582e-01,\n",
       "        7.82136917e-02,  1.12497188e-01, -1.99435670e-02, -1.02097012e-01,\n",
       "        7.36215487e-02,  4.76110799e-05, -1.88313648e-02, -9.14450362e-02,\n",
       "        5.40803969e-02, -9.01148543e-02, -2.23167002e-01,  1.04137652e-01,\n",
       "       -9.31515768e-02, -8.61513019e-02, -2.00394899e-01,  1.83853149e-01,\n",
       "       -6.23841733e-02, -8.15735292e-03, -9.13078059e-03,  3.98679152e-02,\n",
       "        1.33876175e-01, -2.50617534e-01,  7.85041749e-02,  2.54105300e-01,\n",
       "        6.47041947e-02, -1.63657025e-01,  3.69483292e-01,  7.16926232e-02,\n",
       "        7.93766603e-02, -1.72588438e-01, -6.03112429e-02, -7.49131888e-02,\n",
       "       -1.10869236e-01,  1.83374316e-01, -1.94696188e-01,  1.66751906e-01,\n",
       "        1.01264343e-01, -4.16857928e-01, -9.84342992e-02, -3.82937603e-02,\n",
       "       -6.61987588e-02, -1.09959424e-01,  7.15568066e-02, -2.40259826e-01,\n",
       "       -1.17873572e-01, -1.86184824e-01, -1.90124124e-01, -2.81372637e-01,\n",
       "       -2.65101314e-01, -1.61379203e-01, -2.89766580e-01,  2.45186985e-01,\n",
       "       -1.05446115e-01,  7.82037377e-02,  1.57427132e-01,  9.30932257e-03,\n",
       "        3.23503554e-01, -4.98378873e-02, -2.21655905e-01, -3.14611197e-01,\n",
       "        1.56114519e-01, -1.92770168e-01,  4.88537438e-02,  1.26172319e-01,\n",
       "        6.55976385e-02, -1.96105510e-01,  2.59938776e-01, -1.44441441e-01,\n",
       "       -2.80844215e-02, -2.02483401e-01,  1.13756679e-01,  1.56170979e-01,\n",
       "       -1.78545132e-01,  2.24287376e-01,  2.04496369e-01, -1.15291839e-02,\n",
       "       -3.53064500e-02, -5.39672673e-01, -6.72010183e-02, -1.46699503e-01,\n",
       "       -5.17193861e-02, -1.29482970e-01,  7.67972022e-02, -1.12313703e-01,\n",
       "       -6.46939874e-02, -4.19183224e-02, -3.30348760e-02,  4.09802468e-03,\n",
       "       -1.83613479e-01, -3.17887694e-01, -1.12217166e-01, -1.63222060e-01,\n",
       "       -1.09402105e-01, -8.35811198e-02, -6.80908784e-02,  1.59961879e-01,\n",
       "       -2.90125422e-02, -1.08893529e-01,  9.33377594e-02, -3.77846509e-02,\n",
       "        2.36979332e-02, -3.37699093e-02,  1.06125675e-01,  1.61862105e-01,\n",
       "       -3.50756049e-01, -1.39752984e-01,  4.04710025e-02,  3.75040054e-01,\n",
       "       -1.56351775e-02, -1.28963590e-01, -1.86409801e-01, -2.40712598e-01,\n",
       "       -1.28264666e-01,  6.05382510e-02, -1.92539379e-01, -3.14171195e-01,\n",
       "        9.81597006e-02,  1.94776319e-02,  3.40712331e-02, -2.12740630e-01,\n",
       "        1.56306237e-01, -3.78041826e-02,  4.00536098e-02,  7.84597620e-02,\n",
       "        1.21604651e-01,  7.54168481e-02,  1.52697802e-01, -1.82036027e-01,\n",
       "       -5.79366535e-02,  1.97991282e-01, -2.12634295e-01, -3.43492664e-02,\n",
       "       -2.41697341e-01,  4.01571095e-02,  3.03005636e-01,  1.99493155e-01,\n",
       "       -5.33238091e-02, -1.56704430e-02, -7.25392029e-02, -2.03016877e-01,\n",
       "       -1.71935767e-01, -5.54826017e-03, -5.24673164e-02,  6.85433969e-02,\n",
       "       -2.39989042e-01,  1.21465266e-01, -1.72163740e-01, -9.89107862e-02,\n",
       "       -8.00368413e-02,  3.17531303e-02, -7.22671077e-02,  3.30182584e-03,\n",
       "       -1.14413209e-01, -5.49730957e-02, -1.99748337e-01, -1.53340518e-01,\n",
       "       -1.00968458e-01, -2.15682432e-01, -9.47837979e-02,  4.04577926e-02,\n",
       "        2.01346472e-01, -1.28298953e-01,  8.45210552e-02,  2.63366610e-01,\n",
       "       -8.54030699e-02, -7.65927434e-02,  1.72360525e-01, -2.17611566e-01,\n",
       "       -4.68103848e-02, -2.05565035e-01,  7.26561174e-02,  1.94138616e-01,\n",
       "        2.31992587e-01,  9.88165438e-02,  3.60270627e-02,  7.84758180e-02,\n",
       "       -1.58828143e-02, -3.46062146e-02, -3.12684685e-01, -6.86341375e-02,\n",
       "       -1.63560674e-01,  1.32016018e-01, -5.17334752e-02, -3.78422022e-01,\n",
       "        1.19956890e-02,  3.42184335e-01, -1.75198726e-02, -6.40842095e-02,\n",
       "        3.13857496e-02, -1.29998669e-01, -1.13449126e-01, -9.40729231e-02,\n",
       "        1.59062982e-01, -9.76440981e-02,  6.64829016e-02,  1.78228796e-01,\n",
       "       -3.26257169e-01,  9.49084684e-02, -3.18583965e-01, -4.06399034e-02,\n",
       "        2.75063187e-01,  1.05345748e-01, -9.65401605e-02, -1.18498363e-01,\n",
       "        2.16297749e-02, -4.36411798e-02,  8.57567322e-03, -5.51207289e-02,\n",
       "        2.44758278e-02, -1.17023617e-01,  1.62425950e-01, -3.44137214e-02,\n",
       "        7.66721144e-02,  3.64765525e-02,  2.17918590e-01, -1.43687174e-01,\n",
       "       -7.94310942e-02,  2.17897668e-01,  2.43040472e-01, -4.67053168e-02,\n",
       "       -5.39303897e-03, -1.05163209e-01,  3.98296535e-01,  8.53132084e-02,\n",
       "        2.75212452e-02,  6.41819136e-03,  5.33879399e-02, -7.01996163e-02,\n",
       "       -3.40231508e-02, -1.26032114e-01, -2.06188578e-03,  1.58284139e-02,\n",
       "       -1.36557445e-01, -2.80347139e-01, -2.63083607e-01,  2.14196309e-01,\n",
       "       -3.87942828e-02,  3.44326859e-03, -7.63465688e-02, -1.08870827e-01,\n",
       "        1.27589524e-01,  3.18572037e-02, -1.55237526e-01, -1.29651383e-01,\n",
       "       -8.81590769e-02, -8.24004933e-02,  1.29514500e-01,  2.41366588e-02,\n",
       "        2.30703130e-01,  4.27263565e-02,  7.20714778e-02, -6.40572980e-02,\n",
       "       -3.50374460e-01, -6.39024675e-02,  1.94005102e-01,  7.71809593e-02,\n",
       "        2.17615619e-01,  2.25982457e-01,  5.19783050e-03, -8.97770077e-02,\n",
       "       -1.45962209e-01, -3.13513517e-01, -3.65356058e-02,  1.11157335e-01,\n",
       "        1.70654044e-01, -2.92947263e-01, -9.03208926e-02,  1.47648171e-01,\n",
       "       -1.02858260e-01,  4.44665886e-02, -1.79569349e-01, -1.85606033e-01,\n",
       "       -1.27729759e-01, -4.15278785e-02, -2.69802779e-01,  1.51716381e-01,\n",
       "       -2.51268983e-01, -6.06857091e-02, -1.95391357e-01, -6.96262941e-02,\n",
       "        4.55284007e-02,  8.13481510e-02,  1.84924696e-02, -5.10312729e-02,\n",
       "       -2.22568348e-01,  2.61646178e-01,  6.21008646e-02, -3.35652457e-02,\n",
       "       -2.39757968e-01, -2.60026007e-01,  2.00880213e-01, -2.24116190e-01,\n",
       "        1.96480574e-01,  1.42902700e-01, -7.98235023e-02,  3.33956073e-02,\n",
       "       -8.38135486e-02, -1.55800254e-01, -4.61133667e-03,  1.68200582e-01,\n",
       "        7.82136911e-02,  1.12497187e-01, -1.99435667e-02, -1.02097013e-01,\n",
       "        7.36215488e-02,  4.76110803e-05, -1.88313650e-02, -9.14450366e-02,\n",
       "        5.40803970e-02, -9.01148539e-02, -2.23167004e-01,  1.04137651e-01,\n",
       "       -9.31515768e-02, -8.61513027e-02, -2.00394895e-01,  1.83853149e-01,\n",
       "       -6.23841736e-02, -8.15735302e-03, -9.13078057e-03,  3.98679149e-02,\n",
       "        1.33876174e-01, -2.50617537e-01,  7.85041750e-02,  2.54105297e-01,\n",
       "        6.47041936e-02, -1.63657025e-01,  3.69483288e-01,  7.16926229e-02,\n",
       "        7.93766598e-02, -1.72588436e-01, -6.03112435e-02, -7.49131889e-02,\n",
       "       -1.10869236e-01,  1.83374316e-01, -1.94696190e-01,  1.66751907e-01,\n",
       "        1.01264343e-01, -4.16857924e-01, -9.84342998e-02, -3.82937604e-02,\n",
       "       -6.61987595e-02, -1.09959423e-01,  7.15568058e-02, -2.40259826e-01,\n",
       "       -1.17873571e-01, -1.86184823e-01, -1.90124124e-01, -2.81372637e-01,\n",
       "       -2.65101315e-01, -1.61379204e-01, -2.89766582e-01,  2.45186983e-01,\n",
       "       -1.05446115e-01,  7.82037370e-02,  1.57427131e-01,  9.30932260e-03,\n",
       "        3.23503558e-01, -4.98378874e-02, -2.21655907e-01, -3.14611197e-01,\n",
       "        1.56114518e-01, -1.92770168e-01,  4.88537443e-02,  1.26172317e-01,\n",
       "        6.55976386e-02, -1.96105512e-01,  2.59938778e-01, -1.44441440e-01,\n",
       "       -2.80844213e-02, -2.02483401e-01,  1.13756680e-01,  1.56170980e-01,\n",
       "       -1.78545132e-01,  2.24287374e-01,  2.04496370e-01, -1.15291839e-02,\n",
       "       -3.53064498e-02, -5.39672665e-01, -6.72010182e-02, -1.46699503e-01,\n",
       "       -5.17193862e-02, -1.29482967e-01,  7.67972016e-02, -1.12313702e-01,\n",
       "       -6.46939871e-02, -4.19183220e-02, -3.30348760e-02,  4.09802474e-03,\n",
       "       -1.83613480e-01, -3.17887689e-01, -1.12217166e-01, -1.63222060e-01,\n",
       "       -1.09402105e-01, -8.35811195e-02, -6.80908778e-02,  1.59961877e-01,\n",
       "       -2.90125425e-02, -1.08893529e-01,  9.33377590e-02, -3.77846513e-02,\n",
       "        2.36979331e-02, -3.37699091e-02,  1.06125676e-01,  1.61862105e-01,\n",
       "       -3.50756052e-01, -1.39752985e-01,  4.04710028e-02,  3.75040050e-01,\n",
       "       -1.56351777e-02, -1.28963589e-01, -1.86409800e-01, -2.40712597e-01,\n",
       "       -1.28264664e-01,  6.05382507e-02, -1.92539377e-01, -3.14171192e-01,\n",
       "        9.81597007e-02,  1.94776320e-02,  3.40712326e-02, -2.12740629e-01,\n",
       "        1.56306237e-01, -3.78041823e-02,  4.00536095e-02,  7.84597623e-02,\n",
       "        1.21604650e-01,  7.54168488e-02,  1.52697801e-01, -1.82036028e-01,\n",
       "       -5.79366540e-02,  1.97991282e-01, -2.12634299e-01, -3.43492667e-02,\n",
       "       -2.41697344e-01,  4.01571097e-02,  3.03005639e-01,  1.99493151e-01,\n",
       "       -5.33238090e-02, -1.56704429e-02, -7.25392035e-02, -2.03016874e-01,\n",
       "       -1.71935767e-01, -5.54826023e-03, -5.24673164e-02,  6.85433963e-02,\n",
       "       -2.39989043e-01,  1.21465266e-01, -1.72163738e-01, -9.89107861e-02,\n",
       "       -8.00368418e-02,  3.17531298e-02, -7.22671074e-02,  3.30182589e-03,\n",
       "       -1.14413210e-01, -5.49730960e-02, -1.99748338e-01, -1.53340519e-01,\n",
       "       -1.00968458e-01, -2.15682434e-01, -9.47837985e-02,  4.04577932e-02,\n",
       "        2.01346473e-01, -1.28298955e-01,  8.45210558e-02,  2.63366613e-01,\n",
       "       -8.54030709e-02, -7.65927435e-02,  1.72360526e-01, -2.17611568e-01,\n",
       "       -4.68103845e-02, -2.05565035e-01,  7.26561175e-02,  1.94138617e-01,\n",
       "        2.31992585e-01,  9.88165448e-02,  3.60270627e-02,  7.84758177e-02,\n",
       "       -1.58828142e-02, -3.46062142e-02, -3.12684687e-01, -6.86341377e-02,\n",
       "       -1.63560673e-01,  1.32016018e-01, -5.17334761e-02, -3.78422021e-01,\n",
       "        1.19956889e-02,  3.42184340e-01, -1.75198728e-02, -6.40842087e-02,\n",
       "        3.13857501e-02, -1.29998668e-01, -1.13449126e-01, -9.40729237e-02,\n",
       "        1.59062982e-01, -9.76440984e-02,  6.64829020e-02,  1.78228798e-01,\n",
       "       -3.26257163e-01,  9.49084686e-02, -3.18583965e-01, -4.06399032e-02,\n",
       "        2.75063184e-01,  1.05345748e-01, -9.65401597e-02, -1.18498364e-01,\n",
       "        2.16297751e-02, -4.36411802e-02,  8.57567327e-03, -5.51207283e-02,\n",
       "        2.44758278e-02, -1.17023618e-01,  1.62425949e-01, -3.44137217e-02,\n",
       "        7.66721143e-02,  3.64765525e-02,  2.17918588e-01, -1.43687175e-01,\n",
       "       -7.94310949e-02,  2.17897667e-01,  2.43040472e-01, -4.67053168e-02,\n",
       "       -5.39303896e-03, -1.05163210e-01,  3.98296529e-01,  8.53132084e-02,\n",
       "        2.75212455e-02,  6.41819128e-03,  5.33879406e-02, -7.01996165e-02,\n",
       "       -3.40231504e-02, -1.26032112e-01, -2.06188581e-03,  1.58284141e-02,\n",
       "       -1.36557444e-01, -2.80347142e-01, -2.63083608e-01,  2.14196308e-01,\n",
       "       -3.87942830e-02,  3.44326859e-03, -7.63465689e-02, -1.08870826e-01,\n",
       "        1.27589525e-01,  3.18572040e-02, -1.55237524e-01, -1.29651381e-01,\n",
       "       -8.81590773e-02, -8.24004934e-02,  1.29514502e-01,  2.41366589e-02,\n",
       "        2.30703131e-01,  4.27263565e-02,  7.20714785e-02, -6.40572984e-02,\n",
       "       -3.50374458e-01, -6.39024686e-02,  1.94005103e-01,  7.71809592e-02,\n",
       "        2.17615619e-01,  2.25982458e-01,  5.19783044e-03, -8.97770069e-02,\n",
       "       -1.45962207e-01, -3.13513517e-01, -3.65356061e-02,  1.11157335e-01,\n",
       "        1.70654046e-01, -2.92947264e-01, -9.03208923e-02,  1.47648169e-01,\n",
       "       -1.02858259e-01,  4.44665891e-02, -1.79569347e-01, -1.85606031e-01,\n",
       "       -1.27729759e-01, -4.15278784e-02, -2.69802782e-01,  1.51716382e-01,\n",
       "       -2.51268978e-01, -6.06857088e-02, -1.95391358e-01, -6.96262946e-02,\n",
       "        4.55284005e-02,  8.13481500e-02,  1.84924696e-02, -5.10312735e-02,\n",
       "       -2.22568347e-01,  2.61646181e-01,  6.21008652e-02, -3.35652456e-02,\n",
       "       -2.39757970e-01, -2.60026009e-01,  2.00880215e-01, -2.24116192e-01,\n",
       "        1.96480573e-01,  1.42902701e-01, -7.98235015e-02,  3.33956071e-02,\n",
       "       -8.38135475e-02, -1.55800253e-01, -4.61133663e-03,  1.68200582e-01,\n",
       "        7.82136912e-02,  1.12497188e-01, -1.99435671e-02, -1.02097012e-01,\n",
       "        7.36215493e-02,  4.76110798e-05, -1.88313648e-02, -9.14450364e-02,\n",
       "        5.40803967e-02, -9.01148545e-02, -2.23167001e-01,  1.04137652e-01,\n",
       "       -9.31515771e-02, -8.61513026e-02, -2.00394900e-01,  1.83853148e-01,\n",
       "       -6.23841732e-02, -8.15735297e-03, -9.13078059e-03,  3.98679151e-02,\n",
       "        1.33876175e-01, -2.50617533e-01,  7.85041750e-02,  2.54105300e-01,\n",
       "        6.47041948e-02, -1.63657025e-01,  3.69483293e-01,  7.16926232e-02,\n",
       "        7.93766605e-02, -1.72588438e-01, -6.03112431e-02, -7.49131884e-02,\n",
       "       -1.10869236e-01,  1.83374316e-01, -1.94696187e-01,  1.66751905e-01,\n",
       "        1.01264343e-01, -4.16857925e-01, -9.84342991e-02, -3.82937602e-02,\n",
       "       -6.61987593e-02, -1.09959422e-01,  7.15568062e-02, -2.40259826e-01,\n",
       "       -1.17873571e-01, -1.86184823e-01, -1.90124125e-01, -2.81372637e-01,\n",
       "       -2.65101312e-01, -1.61379204e-01, -2.89766581e-01,  2.45186985e-01,\n",
       "       -1.05446115e-01,  7.82037376e-02,  1.57427132e-01,  9.30932254e-03,\n",
       "        3.23503556e-01, -4.98378877e-02, -2.21655906e-01, -3.14611198e-01,\n",
       "        1.56114519e-01, -1.92770166e-01,  4.88537441e-02,  1.26172319e-01,\n",
       "        6.55976382e-02, -1.96105510e-01,  2.59938778e-01, -1.44441440e-01,\n",
       "       -2.80844214e-02, -2.02483402e-01,  1.13756679e-01,  1.56170980e-01,\n",
       "       -1.78545133e-01,  2.24287375e-01,  2.04496368e-01, -1.15291839e-02,\n",
       "       -3.53064499e-02, -5.39672673e-01, -6.72010184e-02, -1.46699502e-01,\n",
       "       -5.17193863e-02, -1.29482968e-01,  7.67972025e-02, -1.12313704e-01,\n",
       "       -6.46939878e-02, -4.19183225e-02, -3.30348758e-02,  4.09802469e-03,\n",
       "       -1.83613478e-01, -3.17887694e-01, -1.12217167e-01, -1.63222060e-01,\n",
       "       -1.09402105e-01, -8.35811199e-02, -6.80908781e-02,  1.59961879e-01,\n",
       "       -2.90125421e-02, -1.08893529e-01,  9.33377599e-02, -3.77846507e-02,\n",
       "        2.36979334e-02, -3.37699094e-02,  1.06125675e-01,  1.61862105e-01,\n",
       "       -3.50756048e-01, -1.39752984e-01,  4.04710025e-02,  3.75040055e-01,\n",
       "       -1.56351776e-02, -1.28963590e-01, -1.86409800e-01, -2.40712597e-01,\n",
       "       -1.28264666e-01,  6.05382511e-02, -1.92539378e-01, -3.14171195e-01,\n",
       "        9.81597003e-02,  1.94776318e-02,  3.40712329e-02, -2.12740631e-01,\n",
       "        1.56306236e-01, -3.78041828e-02,  4.00536099e-02,  7.84597616e-02,\n",
       "        1.21604651e-01,  7.54168480e-02,  1.52697802e-01, -1.82036026e-01,\n",
       "       -5.79366532e-02,  1.97991280e-01, -2.12634297e-01, -3.43492663e-02,\n",
       "       -2.41697342e-01,  4.01571094e-02,  3.03005636e-01,  1.99493154e-01,\n",
       "       -5.33238092e-02, -1.56704431e-02, -7.25392031e-02, -2.03016879e-01,\n",
       "       -1.71935768e-01, -5.54826019e-03, -5.24673163e-02,  6.85433964e-02,\n",
       "       -2.39989041e-01,  1.21465266e-01, -1.72163739e-01, -9.89107866e-02,\n",
       "       -8.00368412e-02,  3.17531299e-02, -7.22671079e-02,  3.30182586e-03,\n",
       "       -1.14413209e-01, -5.49730953e-02, -1.99748339e-01, -1.53340518e-01,\n",
       "       -1.00968457e-01, -2.15682431e-01, -9.47837976e-02,  4.04577928e-02,\n",
       "        2.01346473e-01, -1.28298954e-01,  8.45210550e-02,  2.63366612e-01,\n",
       "       -8.54030695e-02, -7.65927430e-02,  1.72360524e-01, -2.17611566e-01,\n",
       "       -4.68103849e-02, -2.05565035e-01,  7.26561176e-02,  1.94138618e-01,\n",
       "        2.31992588e-01,  9.88165446e-02,  3.60270628e-02,  7.84758183e-02,\n",
       "       -1.58828142e-02, -3.46062145e-02, -3.12684684e-01, -6.86341370e-02,\n",
       "       -1.63560674e-01,  1.32016018e-01, -5.17334754e-02, -3.78422024e-01,\n",
       "        1.19956891e-02,  3.42184335e-01, -1.75198726e-02, -6.40842090e-02,\n",
       "        3.13857497e-02, -1.29998669e-01, -1.13449126e-01, -9.40729235e-02,\n",
       "        1.59062981e-01, -9.76440990e-02,  6.64829014e-02,  1.78228796e-01,\n",
       "       -3.26257170e-01,  9.49084677e-02, -3.18583967e-01, -4.06399032e-02,\n",
       "        2.75063186e-01,  1.05345749e-01, -9.65401609e-02, -1.18498362e-01,\n",
       "        2.16297751e-02, -4.36411801e-02,  8.57567320e-03, -5.51207285e-02,\n",
       "        2.44758277e-02, -1.17023616e-01,  1.62425951e-01, -3.44137212e-02,\n",
       "        7.66721147e-02,  3.64765527e-02,  2.17918588e-01, -1.43687173e-01,\n",
       "       -7.94310937e-02,  2.17897667e-01,  2.43040471e-01, -4.67053165e-02,\n",
       "       -5.39303898e-03, -1.05163209e-01,  3.98296532e-01,  8.53132079e-02,\n",
       "        2.75212454e-02,  6.41819132e-03,  5.33879402e-02, -7.01996161e-02,\n",
       "       -3.40231510e-02, -1.26032113e-01, -2.06188578e-03,  1.58284137e-02,\n",
       "       -1.36557446e-01, -2.80347138e-01, -2.63083607e-01,  2.14196309e-01,\n",
       "       -3.87942825e-02,  3.44326858e-03, -7.63465682e-02, -1.08870826e-01,\n",
       "        1.27589523e-01,  3.18572036e-02, -1.55237525e-01, -1.29651382e-01,\n",
       "       -8.81590764e-02, -8.24004931e-02,  1.29514501e-01,  2.41366587e-02,\n",
       "        2.30703129e-01,  4.27263564e-02,  7.20714772e-02, -6.40572977e-02,\n",
       "       -3.50374459e-01, -6.39024679e-02,  1.94005102e-01,  7.71809587e-02,\n",
       "        2.17615620e-01,  2.25982457e-01,  5.19783049e-03, -8.97770073e-02,\n",
       "       -1.45962208e-01, -3.13513517e-01, -3.65356061e-02,  1.11157335e-01,\n",
       "        1.70654045e-01, -2.92947260e-01, -9.03208931e-02,  1.47648170e-01,\n",
       "       -1.02858260e-01,  4.44665890e-02, -1.79569348e-01, -1.85606032e-01,\n",
       "       -1.27729760e-01, -4.15278788e-02, -2.69802780e-01,  1.51716382e-01,\n",
       "       -2.51268981e-01, -6.06857094e-02, -1.95391356e-01, -6.96262941e-02,\n",
       "        4.55284006e-02,  8.13481505e-02,  1.84924696e-02, -5.10312730e-02])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1 = getEmbedVector('other pages in place right',embedding_dict,p_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From a back-end perspective if we are ready to integrate.',\n",
       " \"With the front end say sometime next week,                 then we'll be okay.\",\n",
       " 'So basically, you know the basic slack install flow right have a very simple kind of login.',\n",
       " 'I mean installation process takes you to slack and authenticates and gives you the necessary permissions for installs,                 comes back right and then from the back end all the information we need is ready so that we can go and put the other                 pages in place right like all the other kind of corner cases.',\n",
       " \"So if we do that then I think we'll be in good shape.\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripSpaces(text):\n",
    "    return re.sub(' +', ' ',text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I mean installation process takes you to slack and authenticates and gives you the necessary permissions for installs, comes back right and then from the back end all the information we need is ready so that we can go and put the other pages in place right like all the other kind of corner cases.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stripSpaces(sent_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "pickle_dumps = pickle.dumps(obj=kpGraph, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '7FC12B08E704D495',\n",
       "  'HostId': 'S6FMYBkwWZW3QtU+VXuQhlfaMCUc6ayT96O6Uf8Ot8P9DlYckrQEgU9XPkbOlpJbO9/VuvM/uyo=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'S6FMYBkwWZW3QtU+VXuQhlfaMCUc6ayT96O6Uf8Ot8P9DlYckrQEgU9XPkbOlpJbO9/VuvM/uyo=',\n",
       "   'x-amz-request-id': '7FC12B08E704D495',\n",
       "   'date': 'Wed, 03 Jul 2019 06:22:32 GMT',\n",
       "   'etag': '\"ba4cf2df3f315881705259f9d9629a85\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"ba4cf2df3f315881705259f9d9629a85\"'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = 'meetinggraphs'\n",
    "key = 'samplegraph'\n",
    "s3.Object(bucket,key).put(Body=pickle_dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('basic slack install flow', 'necessary permissions for installs', 'installation process', 'permissions for installs', 'other kind of corner cases', 'back-end perspective', 'other pages in place right', 'good shape'))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpGraph.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "del kpGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #download from s3\n",
    "# file_obj = self.s3_client.download_file(file_name='s3://meetinggraphs/samplegraph')\n",
    "# file_obj_bytestring = file_obj[\"Body\"].read()\n",
    "# kpGraph = pickle.loads(file_obj_bytestring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `kpGraph` not found.\n"
     ]
    }
   ],
   "source": [
    "kpGraph.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localtest",
   "language": "python",
   "name": "localtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
